<!DOCTYPE NETSCAPE-Bookmark-file-1>
	<HTML>
	<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=UTF-8">
	<Title>Bookmarks</Title>
	<H1>Bookmarks</H1>
	<DT><H3 FOLDED>Favourites</H3>
	<DL><p>
		<DT><A HREF="https://www.google.com/?client=safari&channel=mac_bm">Google</A>
		<DT><A HREF="https://www.wikipedia.org/">Wikipedia</A>
		<DT><A HREF="https://www.apple.com/es">Apple</A>
		<DT><A HREF="https://www.bing.com/">Bing</A>
		<DT><A HREF="https://www.google.com/?client=safari&channel=ipad_bm">Google</A>
		<DT><A HREF="https://es.yahoo.com/">Yahoo</A>
	</DL><p>
	<DT><H3 FOLDED>Bookmarks Menu</H3>
	<DL><p>
	</DL><p>
	<DT><H3 FOLDED>Tab Group Favourites</H3>
	<DL><p>
	</DL><p>
	<DT><H3 FOLDED id="com.apple.ReadingList">Reading List</H3>
	<DL><p>
		<DT><A HREF="https://github.com/huggingface/text-generation-inference/tree/main/benchmark">text-generation-inference/benchmark at main ¬∑ huggingface/text-generation-inference</A>
		<DT><A HREF="https://github.com/meta-pytorch/tritonbench">meta-pytorch/tritonbench: Tritonbench is a collection of PyTorch custom operators with example inputs to measure their performance.</A>
		<DT><A HREF="https://github.com/S-LoRA/S-LoRA">S-LoRA: Serving Thousands of Concurrent LoRA Adapters [paper]</A>
		<DT><A HREF="https://github.com/triton-lang/triton/issues/4868">Reproducibility</A>
		<DT><A HREF="https://github.com/Jokeren/triton-samples/blob/main/Triton_Tools_Tutorial.ipynb">File not found</A>
		<DT><A HREF="https://github.com/pytorch/pytorch/blob/20af56d4359c3f5fed2e8f94e111a8502f2ebeb3/test/test_flop_counter.py#L736">pytorch/test/test_flop_counter.py at 20af56d4359c3f5fed2e8f94e111a8502f2ebeb3 ¬∑ pytorch/pytorch</A>
		<DT><A HREF="https://github.com/pytorch/ao/blob/6b529961bd0b41953d26cdde5851f460839d5cf6/torchao/profiler/device_spec.py#L111">ao/torchao/profiler/device_spec.py at 6b529961bd0b41953d26cdde5851f460839d5cf6 ¬∑ pytorch/ao</A>
		<DT><A HREF="https://github.com/microsoft/microxcaling?tab=readme-ov-file#Spec-Configuration">MX Pytorch Emulation Library</A>
		<DT><A HREF="https://astralord.github.io/posts/transformer-inference-optimization-toolset/">Transformers Inference Optimization Toolset</A>
		<DT><A HREF="https://colab.research.google.com/drive/1XQwio7DsqB5LP2D574f_uIb8G7KhirNa?usp=sharing#scrollTo=P5sS86KpdaTI">Google Colab</A>
		<DT><A HREF="https://github.com/meta-pytorch/workshops/blob/master/ASPLOS_2024/inductor.pdf">workshops/ASPLOS_2024/inductor.pdf at master ¬∑ meta-pytorch/workshops</A>
		<DT><A HREF="https://github.com/ai-compiler-study/flash-attention/blob/main/extra/benchmark_flash_attention_v3.py#L116">flash-attention/extra/benchmark_flash_attention_v3.py at main ¬∑ ai-compiler-study/flash-attention</A>
		<DT><A HREF="https://github.com/facebookresearch/xformers/tree/4a9dd7ec079e0c935db10daa2a1a89fd19cfa231">facebookresearch/xformers at 4a9dd7ec079e0c935db10daa2a1a89fd19cfa231</A>
		<DT><A HREF="https://gist.github.com/cloneofsimo/af610ff8aa11a3f57956e7d7f578409c">FlashAttention comparison</A>
		<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/kernels/triton/inference/gptq/a100_qlinear.py">Breadcrumbs</A>
		<DT><A HREF="https://carpedm30.notion.site/FLUX-Triton-Implementation-7f021f6de14f4fe8a5331bc6e778168a">Notion</A>
		<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/blob/master/pipeline-gemm/README.md">CUTLASS Hopper GEMMs with pipelined kernel design</A>
		<DT><A HREF="https://github.com/search?q=repo%3ANVIDIA%2FTensorRT-Model-Optimizer%20FLUX&type=code">Code search results</A>
		<DT><A HREF="https://fkong.tech/posts/">Posts ¬∑ fkong' tech blog</A>
		<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173/4">https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173/4</A>
		<DT><A HREF="https://docs.pytorch.org/docs/stable/torch.compiler_inductor_profiling.html#benchmark-individual-triton-kernel">TorchInductor GPU Profiling</A>
		<DT><A HREF="https://github.com/sgl-project/sglang/blob/a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0/python/sglang/srt/layers/prefill_attention.py#L147">sglang/python/sglang/srt/layers/prefill_attention.py at a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0 ¬∑ sgl-project/sglang</A>
		<DT><A HREF="https://docs.google.com/document/u/2/d/1ZcxkW1FRNVm9AvDuTthRHvM09XnbkXOQzOE0yqSVMQI/edit">torch_custom_operators - Google Docs</A>
		<DT><A HREF="https://www.youtube.com/watch?v=d0gS5TXarXc&t=80s">Signals. I spent 2 years to understand this part. - YouTube</A>
		<DT><A HREF="https://user-images.githubusercontent.com/3841370/253379177-38ba1531-ea0d-4851-b31a-a6d4ddc944b0.png">253379177-38ba1531-ea0d-4851-b31a-a6d4ddc944b0.png 7.178√ó4.390 pixels</A>
		<DT><A HREF="https://colab.research.google.com/github/corolla-johnson/mkultra/blob/master/tuning_finetune.ipynb#scrollTo=cE2jNS5UMXKh">tuning_finetune_alice.ipynb - Colab</A>
		<DT><A HREF="https://www.amazon.es/dp/1452182787/?tag=halcyonreal0b-21">The Art of Pixar: Revised and Expanded Edition (Disney) Hardcover ‚Äì 30 Nov. 2020</A>
		<DT><A HREF="https://www.ebay.com/itm/153542159104?chn=ps&_trkparms=ispr%3D1&amdata=enc%3A1sq8JBcRtT6KcLZ-t4nHwlA91&norover=1&mkevt=1&mkrid=711-117182-37290-0&mkcid=2&itemid=153542159104&targetid=1262843335169&device=c&mktype=&googleloc=1005421&poi=&campaignid=15275224983&mkgroupid=131097072938&rlsatarget=pla-1262843335169&abcId=9300697&merchantid=137762152&gclid=CjwKCAiAiKuOBhBQEiwAId_sK4Vo04TQeVRAMajvPpCiWSkXUUfG3ndA9DARYgVeIuHrVnJj3IawnRoCimQQAvD_BwE">Studio Ghibli Layout Design Exhibition Hayao Miyazaki Art Book | eBay</A>
		<DT><A HREF="https://www.google.com/search?q=Studio+Ghibli+Layout+Design+Exhibition+Art+Book+Hayao+Miyazaki+From&sxsrf=AOaemvLdkPamZzJFeOFzCcVI5u7vYqv05w:1640740904393&source=lnms&sa=X&ved=2ahUKEwjryJiW7If1AhWOHhQKHXJPCDwQ_AUoA3oECAEQBQ&biw=2240&bih=1180&dpr=2">Studio Ghibli Layout Design Exhibition Art Book Hayao Miyazaki From - Google Search</A>
		<DT><A HREF="https://www.amazon.com/Art-Pixar-Complete-Scripts-Animation/dp/0811879631">Amazon.com</A>
		<DT><A HREF="https://www.google.com/search?q=pixar+layouts+and+background+art+book+by&source=lmns&bih=1180&biw=2240&client=safari&hl=en&sa=X&ved=2ahUKEwj09tjS6of1AhUN2-AKHb9hAj4Q_AUoAnoECAEQAg">pixar layouts and background art book by - Google Search</A>
		<DT><A HREF="https://www.tatteredcover.com/book/9781423138662">404 Not Found</A>
		<DT><A HREF="https://www.tatteredcover.com/contact-us-1">404 Not Found</A>
		<DT><A HREF="https://www.tatteredcover.com/search/site/Walt%20Disney%20Animation%20Studios%20The%20Archive%20Series%20Layout%20%26%20Background">Search</A>
		<DT><A HREF="https://www.google.com/search?q=They+Drew+as+They+Pleased+Volume+6:+The+Hidden+Art+of+Disney%27s+New+Golden+Age+(Disney+x+Chronicle+Books)&client=safari&rls=en&sxsrf=AOaemvJRzA-THgHGQjRiX72En-FKx8brUw:1640740384480&source=lnms&sa=X&ved=2ahUKEwid_aOe6of1AhWB0eAKHcyWBVcQ_AUoA3oECAEQBQ&biw=2240&bih=1180&dpr=2">They Drew as They Pleased Volume 6: The Hidden Art of Disney's New Golden Age (Disney x Chronicle Books) - Google Search</A>
		<DT><A HREF="https://www.amazon.com/They-Drew-Pleased-Hidden-Disneys/dp/1797200933/ref=pd_sbs_3/145-2891899-2697556?pd_rd_w=JgRmc&pf_rd_p=3676f086-9496-4fd7-8490-77cf7f43f846&pf_rd_r=Q0FP94JPPJA1B04P7AYN&pd_rd_r=b5b842be-d34d-482b-8b35-c39120b1a464&pd_rd_wg=vvyJu&pd_rd_i=1797200933&psc=1">Amazon.com</A>
		<DT><A HREF="https://www.creativecavepublishers.com/books/layout-background-walt-disney-animation-archives/">Creative Cave Publishers | 404 error - page not found</A>
		<DT><A HREF="https://www.amazon.com/gp/product/1423134206?ref_=dbs_m_mng_rwt_calw_thcv_1&storeType=ebooks">Walt Disney Animation Studios The Archive Series #3: Design: Walt Disney Animation Research Libr: 9781423134206: Amazon.com: Books</A>
		<DT><A HREF="https://www.amazon.com/Layout-Background-Disney-Animation-Archives/dp/142313866X">Walt Disney Animation Studios The Archive Series #4: Layout &amp; Background: Walt Disney Animation Research Libr: 9781423138662: Amazon.com: Books</A>
		<DT><A HREF="https://www.google.com/search?q=Walt+Disney+Animation+Studios+The+Archive:+Layout+%26+Background+pdf&client=safari&rls=en&sxsrf=AOaemvLEx_g8hNo7U9hbzLTYYHeOjWStnw:1640739669128&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiMm5bJ54f1AhXRA2MBHSiVAMsQ_AUoAXoECBUQAw&biw=2240&bih=1180&dpr=2#imgrc=oPV_tLZoS1wjdM&imgdii=aUZ42t3Hxy4KdM">Walt Disney Animation Studios The Archive: Layout &amp; Background pdf - Google Search</A>
		<DT><A HREF="https://www.amazon.com/Paper-Dreams-Artists-Disney-Storyboards/dp/0786863072">Amazon.com: Paper Dreams: The Art And Artists Of Disney Storyboards: 9780786863075: Canemaker, John: Books</A>
		<DT><A HREF="https://www.karts.ac.kr/en/main.do">Korea National University of Arts</A>
		<DT><A HREF="https://www.mmca.go.kr/eng/publication/publicationMain.do">Íµ≠Î¶ΩÌòÑÎåÄÎØ∏Ïà†Í¥Ä</A>
		<DT><A HREF="https://www.mmcashop.co.kr/goods/goods_view.php?goodsNo=1000001313">Íµ≠Î¶ΩÌòÑÎåÄÎØ∏Ïà†Í¥Ä Ïò®ÎùºÏù∏Ïàç ÎØ∏Ïà†Í∞ÄÍ≤å</A>
		<DT><A HREF="https://www.google.com/search?q=south+korean+illustration+university+books&client=safari&rls=en&sxsrf=AOaemvIK65RkA4i92os9bBTTqD-dsb9aGA%3A1640738171253&ei=e63LYYzyDqi5gweJu7TwCg&ved=0ahUKEwjMm_f-4Yf1AhWo3OAKHYkdDa4Q4dUDCA0&uact=5&oq=south+korean+illustration+university+books&gs_lcp=Cgdnd3Mtd2l6EAM6BAgAEEc6BQgAEM0COgQIIRAKSgQIQRgASgQIRhgAUJEHWMQQYMUSaAFwAngAgAFriAGbBZIBAzUuMpgBAKABAcgBBMABAQ&sclient=gws-wiz">south korean illustration university books - Google Search</A>
		<DT><A HREF="https://www.e-flux.com/announcements/421733/book-release-korean-art-1900-2020">Book release: Korean Art 1900-2020 - Announcements - e-flux</A>
		<DT><A HREF="https://www.phaidon.com/en-eu/store/art/korean-art-from-1953-collision-innovation-and-interaction-9780714878331">404 Not Found ‚Äì Phaidon</A>
		<DT><A HREF="https://github.com/gii-is-DP1/dp1-2020-g3-09/blob/master/docker-compose.yml">Page not found ¬∑ GitHub</A>
		<DT><A HREF="https://www.reddit.com/r/OpenAI/comments/u831xb/dalle_2_waitlist_length/">DALL-E 2 waitlist length : r/OpenAI</A>
		<DT><A HREF="https://medium.com/@DMeechan/fixing-the-installation-failed-virtualbox-error-on-mac-high-sierra-7c421362b5b5">Fixing ‚ÄòThe Installation Failed‚Äô VirtualBox Error on Mac High Sierra</A>
		<DT><A HREF="https://stackoverflow.com/questions/40523307/brew-install-docker-does-not-include-docker-engine/43365425#43365425">Brew install docker does not include docker engine?</A>
		<DT><A HREF="https://medium.com/crowdbotics/a-complete-one-by-one-guide-to-install-docker-on-your-mac-os-using-homebrew-e818eb4cfc3">A complete one-by-one guide to install Docker on your Mac OS using Homebrew</A>
		<DT><A HREF="https://formulae.brew.sh/formula/docker-compose#default">docker-compose ‚Äî Homebrew Formulae</A>
		<DT><A HREF="https://ragunathrajasekaran.medium.com/getting-started-with-spring-data-jpa-hibernate-orm-repository-part-4-95a6ef2af513">Spring Data JPA, Hibernate, ORM &amp; Repository (Part 4)</A>
		<DT><A HREF="https://docs.google.com/document/d/1x3TRnRXz8PCHAWAgb7pzNfgAfBuKPxsyvBVZKXKeBFc/edit#heading=h.7ye3de504xy7">Experimentation Prompts: Infographics - Google Docs</A>
		<DT><A HREF="https://docs.google.com/spreadsheets/d/1Og2u4LExfCgTckBDKte54tdBuI2JPdK3YN6v2L6scn8/edit#gid=2074678152">openai-humaneval - Google Sheets</A>
		<DT><A HREF="https://docs.google.com/spreadsheets/d/1zuQQnOzC_zrd4MBPQg4W0A7Ab5k0jEnPRSwy8AxiC4c/edit#gid=0">Function header - Google Sheets</A>
		<DT><A HREF="https://drive.google.com/drive/folders/1l6yNtgD-Xx0Awb0D5VZ-nuMG1ea-WwAr">Folder - Google Drive</A>
		<DT><A HREF="https://huggingface.co/settings/tokens">Hugging Face ‚Äì The AI community building the future.</A>
		<DT><A HREF="https://huggingface.co/datasets/bigcode/the-stack">bigcode/the-stack ¬∑ Datasets at Hugging Face</A>
		<DT><A HREF="https://huggingface.co/docs/datasets/repository_structure">Structure your repository</A>
		<DT><A HREF="https://huggingface.co/datasets/diversoailab/standard_humaneval/tree/main/data">diversoailab/standard_humaneval at main</A>
		<DT><A HREF="http://localhost:8888/notebooks/notebook/dataset.ipynb#2.1-Debugging-Tests">dataset - Jupyter Notebook</A>
		<DT><A HREF="http://localhost:8888/tree/notebook">notebook/</A>
		<DT><A HREF="https://mail.google.com/mail/u/1/#inbox?compose=new">Inbox - antonio.jfdominguez@gmail.com - Gmail</A>
		<DT><A HREF="https://docs.google.com/document/d/1x3TRnRXz8PCHAWAgb7pzNfgAfBuKPxsyvBVZKXKeBFc/edit#">Experimentation Prompts: Infographics - Google Docs</A>
	</DL><p>
	<DT><H3 FOLDED>30-01-2026</H3>
	<DL><p>
		<DT><H3 FOLDED>Computational Research</H3>
		<DL><p>
			<DT><H3 FOLDED>Artificial Intelligence</H3>
			<DL><p>
				<DT><H3 FOLDED>stocks</H3>
				<DL><p>
					<DT><H3 FOLDED>stocks-datacenters</H3>
					<DL><p>
						<DT><H3 FOLDED>dc-generators</H3>
						<DL><p>
							<DT><H3 FOLDED>PSIX</H3>
							<DL><p>
								<DT><A HREF="https://x.com/zephyr_z9/status/1985379651775352904">(1) Zephyr en X: "This reminds me that Weichai's subsidiary PSIX is nearly up 5000% in the last 1.5 years They make backup generators for AI DCs and will see huge revenue growth in the coming years I own the stock https://t.co/JUx1AyzI2w" / X</A>
							</DL><p>
							<DT><A HREF="https://en.weichai.com/">Weichai Group</A>
						</DL><p>
						<DT><H3 FOLDED>dc-energy</H3>
						<DL><p>
							<DT><H3 FOLDED>gas turbines</H3>
							<DL><p>
								<DT><H3 FOLDED>Doosan Enerbility Co Ltd</H3>
								<DL><p>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/2008327656840831189">(1) SemiAnalysis en X: "BREAKING: @elonmusk 's xAI has bought an 5 additional 380MW of natural gas turbines from South Korea's Doosan Enerbility. The first two units are scheduled for delivery by the end of 2026. This will power an additional 600,000+ GB200 NVL72 equivalent size cluster (or 350,000 + https://t.co/XLlzaEKaTN" / X</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://www.google.com/search?q=nuscale+stocks&num=10&client=safari&sca_esv=3f39f8a4d7ea2161&rls=en&ei=xjkJafuCJ9qVxc8Pq_f2sQs&ved=0ahUKEwj7_dyukNeQAxXaSvEDHau7PbYQ4dUDCBM&uact=5&oq=nuscale+stocks&gs_lp=Egxnd3Mtd2l6LXNlcnAiDm51c2NhbGUgc3RvY2tzMgYQABgHGB4yBhAAGAcYHjIGEAAYBxgeMgYQABgHGB4yBhAAGAcYHjIGEAAYBxgeMggQABgHGAgYHjIIEAAYBxgIGB4yCBAAGAcYCBgeMggQABgFGAcYHkjLDFCRBljVC3ACeAGQAQCYAZsBoAHQBKoBAzQuMrgBA8gBAPgBAZgCBqACnwPCAgoQABiwAxjWBBhHmAMAiAYBkAYIkgcDNC4yoAeOKLIHAzIuMrgHkAPCBwMyLTbIByA&sclient=gws-wiz-serp">nuscale stocks - Google Search</A>
						</DL><p>
						<DT><H3 FOLDED>dc-construction</H3>
						<DL><p>
							<DT><A HREF="https://epoch.ai/data/data-centers/satellite-explorer">OpenAI Stargate Abilene - Frontier Data Centers Satellite Explorer | Epoch AI</A>
						</DL><p>
						<DT><H3 FOLDED>dc-storage</H3>
						<DL><p>
							<DT><H3 FOLDED>SNDK</H3>
							<DL><p>
								<DT><A HREF="https://x.com/wallstengine/status/1986029780534530301?s=12">(1) Wall St Engine en X: "BofA Raises $SNDK PT to $230 from $125 - Buy Analyst comments: "We are raising our estimates and PO on Sandisk to $230 as 1) higher than previously expected demand from data centers starting to meaningfully impact pricing, 2) expected medium-term undersupply of HDDs is driving" / X</A>
							</DL><p>
							<DT><A HREF="https://www.google.com/search?q=seagate+techonlogies+stock&num=10&client=safari&sca_esv=674219a392467a04&rls=en&ei=ENULabOPNryIkdUPpYDsuAI&ved=0ahUKEwiz14PfjNyQAxU8RKQEHSUAGycQ4dUDCBE&uact=5&oq=seagate+techonlogies+stock&gs_lp=Egxnd3Mtd2l6LXNlcnAiGnNlYWdhdGUgdGVjaG9ubG9naWVzIHN0b2NrMgcQABiABBgNMgcQABiABBgNMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHkjoDFCCA1i1C3ABeAGQAQCYAWWgAaAEqgEDNC4yuAEDyAEA-AEBmAIHoALOBMICChAAGLADGNYEGEeYAwDiAwUSATEgQIgGAZAGCJIHAzUuMqAHszayBwM0LjK4B8gEwgcFMC4yLjXIBxs&sclient=gws-wiz-serp">seagate techonlogies stock - Google Search</A>
							<DT><A HREF="https://x.com/zephyr_z9/status/1929606952100987153">(1) Zephyr en X: "Compute &amp;amp; storage demand would go parabolic once proper long video generation comes online (15min-1hr) Lots of good memory (SSD &amp;amp; HDD) stocks can be picked up rn https://t.co/LRO2Vl6wDV" / X</A>
						</DL><p>
						<DT><H3 FOLDED>dc-space</H3>
						<DL><p>
							<DT><A HREF="https://x.com/seti_park/status/2015114363531866448">(1) SETI Park en X: "Haters Said Musk Doesn't Understand Physics. SpaceX's Heat Dissipating Chassis Patent Says Otherwise" / X</A>
						</DL><p>
					</DL><p>
					<DT><H3 FOLDED>semiconductors</H3>
					<DL><p>
						<DT><H3 FOLDED>semiconductors-supply-chain</H3>
						<DL><p>
							<DT><H3 FOLDED>Tamura</H3>
							<DL><p>
								<DT><A HREF="https://www.tamuracorp.com/global/">TAMURA CORPORATION</A>
							</DL><p>
							<DT><A HREF="https://x.com/zephyr_z9/status/1987906174726054241">(1) Zephyr en X: "Study the supply chain anon" / X</A>
							<DT><A HREF="https://x.com/hhuang/status/1987187020037562675">Google optical module supply chain struct</A>
							<DT><A HREF="https://x.com/techfund1/status/2008584961914454422">(1) Tech Fund en X: "TPU supply chain (Fubon Research) https://t.co/x4HajXbA84" / X</A>
						</DL><p>
						<DT><H3 FOLDED>semiconductors-memory</H3>
						<DL><p>
							<DT><H3 FOLDED>SK Hynix</H3>
							<DL><p>
								<DT><A HREF="https://x.com/Jukanlosreve/status/1984569063436402967">(1) Jukan en X: "Am I seeing this right??? Is Nomura actually saying that in 2027, SK hynix will have a higher operating profit than TSMC??? What the hell‚Äîdoes that even make sense? https://t.co/xHzUmuXGtB" / X</A>
							</DL><p>
							<DT><A HREF="https://x.com/aleabitoreddit/status/2014368177682292774">Memory Supercycle Supply Chain TLDR:</A>
							<DT><A HREF="https://x.com/zephyr_z9/status/1929606952100987153">Zephyr: Compute &amp; storage demand would go parabolic once proper long video generation comes online (15min-1hr) Lots of good memory (SSD &amp; HDD) stocks can be picked up rn</A>
						</DL><p>
						<DT><H3 FOLDED>semiconductors-cabling</H3>
						<DL><p>
							<DT><H3 FOLDED>CRDO</H3>
							<DL><p>
								<DT><A HREF="https://x.com/zephyr_z9/status/1981648974722593038">(1) Zephyr en X: "Time to play find the supplier Which company is supplying which cable Reply below https://t.co/xkuSAeLik9" / X</A>
								<DT><A HREF="https://x.com/aleabitoreddit/status/2008854319806787681?s=12">(1) Serenity en X: "I've added $CRDO on the 25.7% drop, taking advantage of CES misinformation. 1. Large drop initially was because investors spotted orange and blue cables in $AMZN DCs (implying $CRDO customer loss). All that happened was Amazon requested a color change for internal logistics. - https://t.co/9OANMG4hf1" / X</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>semiconductors-optics</H3>
						<DL><p>
							<DT><H3 FOLDED>LITE</H3>
							<DL><p>
								<DT><A HREF="https://www.google.com/search?q=%24LITE+stock&num=10&client=safari&sca_esv=0cb097f5cf89beeb&rls=en&ei=iJ0LaeKPBa-ZkdUPydfioAk&ved=0ahUKEwji8_bj19uQAxWvTKQEHcmrGJQQ4dUDCBE&uact=5&oq=%24LITE+stock&gs_lp=Egxnd3Mtd2l6LXNlcnAiCyRMSVRFIHN0b2NrMgUQABiABDIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yBhAAGBYYHkjHC1CgA1iPCHABeAGQAQGYAZ8DoAG_DaoBCTAuMi4yLjAuMrgBA8gBAPgBAZgCBaACnAjCAgoQABiwAxjWBBhHmAMAiAYBkAYIkgcJMS4xLjIuMC4xoAfxJ7IHCTAuMS4yLjAuMbgHmAjCBwUwLjEuNMgHEA&sclient=gws-wiz-serp">$LITE stock - Google Search</A>
								<DT><A HREF="https://x.com/ResearchQf/status/1985819030117093790">(1) QF Research en X: "$LITE guided to a big Dec Q. Sales $650M vs $562M cons. EPS $1.40 vs $1.17. OM 21% vs 18%. As always, management comments are critical. But based on what I expect (which could be wrong), this guide is before the more interesting product drivers really kick in C26 and beyond. https://t.co/JwxWawvm8G" / X</A>
							</DL><p>
							<DT><H3 FOLDED>Innolight</H3>
							<DL><p>
								<DT><A HREF="https://x.com/zephyr_z9/status/1987865354497139152">(1) Zephyr en X: "LFG!!! I can now buy my favorite optic module stock https://t.co/yhxZeh1TEm" / X</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>semiconductors-interconnects</H3>
						<DL><p>
							<DT><H3 FOLDED>fabrinet (FN)</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ResearchQf/status/1985731583400108282">(1) QF Research en X: "1) $FN is the first major interconnect supplier to report. Beat &amp;amp; guided to a big CQ4. $1.075B vs $0.98B cons and on the bright side of the ledger even today. The 3 segments discussed prior posts all contributed to upside. Datacom, DCI and HPC. Largely 1.6T for $NVDA BW Ultra, https://t.co/6phSHmJKck" / X</A>
								<DT><A HREF="https://www.google.com/search?client=safari&rls=en&q=fabrinet+stock&ie=UTF-8&oe=UTF-8">fabrinet stock - Google Search</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>TSMC</H3>
						<DL><p>
							<DT><A HREF="https://x.com/vikramskr/status/2015480051144523825">(1) Vikram Sekar en X: "TSMC Goes All-In, Intel Folds" / X</A>
						</DL><p>
						<DT><H3 FOLDED>InnoScience</H3>
						<DL><p>
							<DT><A HREF="https://finance.yahoo.com/quote/2577.HK/">InnoScience (Suzhou) Technology Holding Co., Ltd. (2577.HK) Stock Price, News, Quote &amp; History - Yahoo Finance</A>
						</DL><p>
						<DT><H3 FOLDED>AsteraLabs</H3>
						<DL><p>
							<DT><A HREF="https://finance.yahoo.com/quote/ALAB/">Astera Labs, Inc. (ALAB) Stock Price, News, Quote &amp; History - Yahoo Finance</A>
						</DL><p>
						<DT><H3 FOLDED>VeriSilicon Microelectronics</H3>
						<DL><p>
							<DT><A HREF="https://finance.yahoo.com/quote/688521.SS/">VeriSilicon Microelectronics (Shanghai) Co., Ltd. (688521.SS) Stock Price, News, Quote &amp; History - Yahoo Finance</A>
						</DL><p>
						<DT><A HREF="https://irrationalanalysis.substack.com/p/a-background-proof-guide-on-communication">A Background-Proof Guide on Communication Systems (investment analysis)</A>
						<DT><A HREF="https://wukong123.substack.com/p/will-nvidias-earnings-fall-short">Will NVIDIA's Earnings Fall Short of Expectations Next Week?</A>
						<DT><A HREF="https://x.com/rwang07/status/1930025345488494731">(1) Ray Wang en X: "üßµ‚ÄØ@MooreMorrisSemi and I just published a 4,000‚Äëword technical deep dive on HBM. A MUST READ‚ÄîI can confidently say. We break down: 1) Bonding technologies behind HBM 2) Why and how‚ÄØ SK‚ÄØ Hynix has taken the lead. 3) China‚Äôs evolved HBM capabilities. /1 Link: https://t.co/Me3btncu0x" / X</A>
						<DT><A HREF="https://x.com/zephyr_z9/status/1974904761225990420">(1) Zephyr en X: "Good report on Corning (They don't cover the tech part so I will do it here) - Corning‚Äôs Vapor Axial Deposition produces the world‚Äôs lowest-attenuation silica glass (~0.15 dB/km), reducing signal loss over long interconnects - ClearCurve (Bend Insensitive Fiber) allows 10 mm https://t.co/qppE6umpXv" / X</A>
					</DL><p>
					<DT><H3 FOLDED>quantitative-research</H3>
					<DL><p>
						<DT><H3 FOLDED>Jane Street</H3>
						<DL><p>
							<DT><A HREF="https://www.janestreet.com/join-jane-street/position/7449077002/">Machine Learning Performance Engineer :: Jane Street</A>
						</DL><p>
						<DT><A HREF="https://www.gresearch.com/">A Leading Quantitative Research and Technology Business</A>
						<DT><A HREF="https://www.fancyquantnation.com/contact">Contact ‚Äî Fancy Quant NATION</A>
						<DT><A HREF="https://www.youtube.com/watch?v=qAiaBIpv60g">My Quant Career Performance in 2024 - YouTube</A>
						<DT><A HREF="https://www.princeton.edu/~markus/research/papers/hedgefunds_bubble.pdf">Hedge Funds and the Technology Bubble</A>
						<DT><A HREF="https://x.com/weHRTyou/status/1973136123196063873">(1) Hudson River Trading en X: "We invited @dwarkesh_sp to tackle a foundational question in quant trading: What does it take to build a predictive signal from market data? We loved showing him what makes work at HRT so fun ‚Äî and why, in Marc‚Äôs words, ‚Äúit occupies a lot of very smart people for years.‚Äù https://t.co/syh56yaNdu" / X</A>
						<DT><A HREF="https://x.com/zephyr_z9/status/1980261759085683120/photo/1">(1) Zephyr en X: "Quant firm doing quant things https://t.co/yHGthywhHU" / X</A>
						<DT><A HREF="https://nof1.ai/blog/TechPost1">AI trading in real markets</A>
						<DT><A HREF="https://www.linkedin.com/company/beprop-io/">BeProp.io: Overview | LinkedIn</A>
						<DT><A HREF="https://x.com/OHatTartine/status/2003910041649532983">SSI is doing quant trading</A>
						<DT><A HREF="https://x.com/willccbb/status/2006998005149585604">quant research as eval</A>
						<DT><A HREF="https://x.com/jiqizhixin/status/2010965134123155477">(2) Êú∫Âô®‰πãÂøÉ JIQIZHIXIN en X: "If you are curious about what Liang Wenfeng wrote, this is the English version translated from Chinese by @deepseek_ai's AI. Building Models to Understand the Market Liang Wenfeng Founder of High-Flyer Quant James Simons is a titan in the field of quantitative investing. For https://t.co/qw7xzHQDHu" / X</A>
						<DT><A HREF="https://www.high-flyer.cn/en/fund/">High-Flyer | Quant</A>
						<DT><A HREF="https://github.com/LLMQuant/quant-wiki">LLMQuant/quant-wiki: We are committed to the open-sourcing quantitative knowledge, aiming to bridge the information gap between the domestic and international quantitative finance industries. Êàë‰ª¨Ëá¥Âäõ‰∫éÈáèÂåñÁü•ËØÜÁöÑÂºÄÊ∫ê‰∏éÊ±âÂåñÔºåÊâìÁ†¥ÂõΩÂÜÖÂ§ñÈáèÂåñÈáëËûçË°å‰∏ö‰ø°ÊÅØÂ∑Æ„ÄÇ</A>
					</DL><p>
					<DT><H3 FOLDED>stocks-policy</H3>
					<DL><p>
						<DT><A HREF="https://x.com/level941/status/1984342155544903833">941 en X: "Burry‚Äôs tweet is pure contempt. The system is rigged</A>
					</DL><p>
					<DT><H3 FOLDED>NVDA</H3>
					<DL><p>
						<DT><H3 FOLDED>NVDA-rack-scale</H3>
						<DL><p>
							<DT><H3 FOLDED>CRDO</H3>
							<DL><p>
								<DT><A HREF="https://x.com/theaustinlyons/status/1980742522340061691">(1) Austin Lyons en X: "$CRDO example setup for $NVDA Rubin NVL144. Lots of opportunity with these high-density racks. üßµ https://t.co/etyubFZI0z" / X</A>
							</DL><p>
							<DT><A HREF="https://x.com/TheValueist/status/1983565740939567326">kyber</A>
						</DL><p>
						<DT><H3 FOLDED>NVDA-data-center-scale</H3>
						<DL><p>
							<DT><A HREF="https://mingchikuo.craft.me/hXWKf4bRg9AFZW">NVIDIA AI Server Power Roadmap: Kyber‚Äôs Next-Generation Strategy from GPU/Rack-Level to Data-Center Scale</A>
							<DT><A HREF="https://x.com/mingchikuo/status/1983430554570924172">(1) ÈÉ≠ÊòéÈå§ (Ming-Chi Kuo) en X: "NVIDIA AI Server Power Roadmap: Kyber‚Äôs Next-Generation Strategy from GPU/Rack-Level to Data-Center Scale Full story https://t.co/4SIW7blFca https://t.co/mEHWaulpmm" / X</A>
						</DL><p>
						<DT><A HREF="https://x.com/MartinShkreli/status/1984273211693953436">new forecast: NVDA to $100T</A>
					</DL><p>
					<DT><H3 FOLDED>TSLA</H3>
					<DL><p>
						<DT><H3 FOLDED>tsla-optimus</H3>
						<DL><p>
							<DT><A HREF="https://x.com/tslaming/status/2006983709963219240">Chinese Tesla Optimous core suppliers list</A>
							<DT><A HREF="https://en.hnlens.com/">Lens Technology Co., Ltd.</A>
							<DT><A HREF="https://www.zjshc.com/en">Zhejiang Sanhua Intelligent Controls Co., Ltd.</A>
							<DT><A HREF="https://www.tuopu.com/en/home/">Ningbo Tuopu Group Co., Ltd.</A>
							<DT><A HREF="http://en.ewpt.com/">Shenzhen Everwin Precision Technology Co., Ltd.</A>
							<DT><A HREF="https://www.wolong-electric.com/">Wolong Electric Drive Group Co., Ltd.</A>
							<DT><A HREF="https://www.xccbearing.com/">Zhejiang Wuzhou Xinchun Group Co., Ltd.</A>
							<DT><A HREF="https://www.henglihydraulics.com/en/index.html">Jiangsu Hengli Hydraulic Co., Ltd.</A>
						</DL><p>
					</DL><p>
					<DT><H3 FOLDED>INTC</H3>
					<DL><p>
						<DT><A HREF="https://x.com/zephyr_z9/status/2009391090374463865">Biggest Intel bull in the world ‚Äî Donald J. Trump</A>
					</DL><p>
					<DT><H3 FOLDED>global affairs</H3>
					<DL><p>
						<DT><A HREF="https://cdn.openai.com/pdf/21b88bb5-10a3-4566-919d-f9a6b9c3e632/openai-ostp-rfi-oct-27-2025.pdf">OpenAI document submitted one week ago where they advocate for including datacenter spend within the ‚ÄúAmerican manufacturing‚Äù umbrella</A>
					</DL><p>
					<DT><H3 FOLDED>Six Tigers</H3>
					<DL><p>
						<DT><H3 FOLDED>Z.ai  Atlas fka ZhiPu (2513 HK)</H3>
						<DL><p>
						</DL><p>
						<DT><H3 FOLDED>MiniMax (0100 HK)</H3>
						<DL><p>
						</DL><p>
						<DT><A HREF="https://x.com/SemiAnalysis_/status/2007512494575890640">(1) SemiAnalysis en X: "Rolling into the new year, 2 of the Six Tigers quietly filed their IPO prospectuses and will start trading in early January if all goes well. We finally get a glimpse into audited financials of foundation model labs. TLDR: Building Machine God Ain't Cheap. (1/5)üßµ https://t.co/gNtjdUcg3B" / X</A>
					</DL><p>
					<DT><H3 FOLDED>stocks-foreign</H3>
					<DL><p>
						<DT><A HREF="https://x.com/aleabitoreddit/status/2015549311732658520">(1) Serenity en X: "TLDR of my top foreign stocks: 1. Nitto Boseki - T-Glass (Japan) 2. Unimicron - Substrates/Glass Core (Taiwan) 3. Samsung/SK Hynix - HBM (Korea) 4. Kioxia - NAND w/ $SNDK (Japan) 5. Nanya Technologies - Memory (Taiwan) US supply chains like $INTC (foundry), $MU https://t.co/Cx0jaufNNd" / X</A>
					</DL><p>
					<DT><H3 FOLDED>stocks-signals</H3>
					<DL><p>
						<DT><A HREF="https://x.com/aleabitoreddit/status/2015096496019112151">(1) Serenity en X: "Jan 25th Ratings. Post EU Tariffs and $INTC ER. Strong Buy: $SNAP $META Samsung Electronics SK Hynix $MU Unimicron $TSM $CRCL $AXTI $LPTH $COPX $LIT $AEHR $FORM $AMKR $AVGO $MRVL Buy: $COIN $SMCI $GOOGL $FIG $AMZN $IBIT $RDDT $TTD $HIMS $HOOD $COHR $AMBA $IREN $POET $AAOI https://t.co/vqGrBiT2Fg" / X</A>
						<DT><A HREF="https://x.com/aleabitoreddit/status/2014808195014001018?s=12">(1) Serenity en X: "$INTC crashes 17% and finishes the day back at $45. Short dated options are down 95%+ with leaps down 40%+. Intel is the perfect example of ‚ÄúStocks don‚Äôt move in a straight line up‚Äù (unless it‚Äôs $SNDK). And it‚Äôs still up 26% in 1M. If the fundamental thesis hasn‚Äôt changed https://t.co/azeOoWnsLR" / X</A>
						<DT><A HREF="https://x.com/aleabitoreddit/status/2014731960418238574?s=12">(1) Serenity en X: "I've hold positions in the $MU that markets sleep on: Unimicron. This one is an incredible long at $16B as they're foundational for: - $MU and Samsung memory substrates - $NVDA Rubin/Blackwell - TSMC for CoWoS process - Apple (iPhones and M-series) - Google TPUs - https://t.co/3353HerLe4" / X</A>
					</DL><p>
					<DT><A HREF="https://godelterminal.com/">Godel Terminal: We don't use the mouse in finance</A>
					<DT><A HREF="https://www.google.com/search?q=Quantum+Computing+Inc+stock&client=safari&sca_esv=eccea50fd53f25b3&rls=en&sxsrf=ADLYWIJEgUFo3u4xOkLEDjip6lZdEs2wKA%3A1731622090576&ei=ynQ2Z8nqIsXVkdUPpp_C4Q0&ved=0ahUKEwjJ99_86tyJAxXFaqQEHaaPMNwQ4dUDCA8&uact=5&oq=Quantum+Computing+Inc+stock&gs_lp=Egxnd3Mtd2l6LXNlcnAiG1F1YW50dW0gQ29tcHV0aW5nIEluYyBzdG9jazIKEAAYgAQYRhj6ATIFEAAYgAQyBRAAGIAEMgUQABiABDIFEAAYgAQyBRAAGIAEMgYQABgWGB4yBhAAGBYYHjIGEAAYFhgeMgYQABgWGB4yFhAAGIAEGEYY-gEYlwUYjAUY3QTYAQFIlBpQyANY7hhwBXgBkAEAmAHHAaAB9guqAQMwLjm4AQPIAQD4AQGYAg6gAucMwgIKEAAYsAMY1gQYR8ICDRAAGIAEGLADGEMYigXCAhkQLhiABBiwAxjRAxhDGMcBGMgDGIoF2AEBwgILEAAYgAQYhgMYigXCAggQABiABBiiBMICBRAhGKABwgIMEAAYgAQYDRhGGPoBwgIHEAAYgAQYDcICGBAAGIAEGA0YRhj6ARiXBRiMBRjdBNgBAZgDAIgGAZAGFLoGBggBEAEYCJIHBTUuNy4yoAefSA&sclient=gws-wiz-serp">Quantum Computing Inc stock - Google Search</A>
					<DT><A HREF="https://www.youtube.com/watch?v=Tqnj4lT6xv8">(1) Martin Shkreli Finance Lesson Part 1 (Full Lecture) - YouTube</A>
					<DT><A HREF="https://www.sec.gov/ix?doc=/Archives/edgar/data/0001045810/000104581024000124/nvda-20240428.htm">XBRL Viewer</A>
					<DT><A HREF="https://www.sec.gov/edgar/browse/?CIK=1045810&owner=exclude">EDGAR Entity Landing Page</A>
					<DT><A HREF="https://www.youtube.com/watch?v=HCd2UWZbn-E">(1) Martin Shkreli reacts to James Simons - Numberphile - YouTube</A>
					<DT><A HREF="https://irrationalanalysis.substack.com/p/a-background-proof-guide-on-communication">A Background-Proof Guide on Communication Systems</A>
					<DT><A HREF="https://www.bloomberg.com/news/articles/2025-04-24/alphabet-s-profit-gets-8-billion-boost-from-spacex-investment">Alphabet‚Äôs Profit Gets $8 Billion Boost From SpaceX Investment (GOOG) - Bloomberg</A>
					<DT><A HREF="http://openinsider.com/insider-sales">Latest Insider Sales - - OpenInsider</A>
					<DT><A HREF="https://github.com/LLMQuant/quant-wiki">LLMQuant/quant-wiki: We are committed to the open-sourcing quantitative knowledge, aiming to bridge the information gap between the domestic and international quantitative finance industries. Êàë‰ª¨Ëá¥Âäõ‰∫éÈáèÂåñÁü•ËØÜÁöÑÂºÄÊ∫ê‰∏éÊ±âÂåñÔºåÊâìÁ†¥ÂõΩÂÜÖÂ§ñÈáèÂåñÈáëËûçË°å‰∏ö‰ø°ÊÅØÂ∑Æ„ÄÇ</A>
					<DT><A HREF="https://openai.com/careers/research-engineer-frontier-evals/">Research Engineer, Frontier Evals | OpenAI</A>
					<DT><A HREF="https://www.youtube.com/watch?v=UNIEOecdOXk">Graphene Perovskite just revolutionised the Solar PV industry! - YouTube</A>
					<DT><A HREF="https://x.com/zephyr_z9">(1) Zephyr (@zephyr_z9) / X</A>
				</DL><p>
				<DT><H3 FOLDED>Companies</H3>
				<DL><p>
					<DT><H3 FOLDED>gpu cloud</H3>
					<DL><p>
						<DT><A HREF="https://mp.weixin.qq.com/s/ufqw-L0g56YftMkgJtzVdQ">Discuss the operational risks and liquidity management of GPU cloud. Zarbot</A>
					</DL><p>
					<DT><H3 FOLDED>Deep tech</H3>
					<DL><p>
						<DT><H3 FOLDED>fundig-rounds</H3>
						<DL><p>
							<DT><A HREF="https://hackmd.io/@0RrvBhdwQya4V6lCDWvmew/BJScF5y2n?utm_source=preview-mode&utm_medium=rec">Investment Memo - CoreWeave - HackMD</A>
							<DT><A HREF="https://artificialanalysis.ai/speech-to-text">Speech to Text (ASR) Providers Leaderboard &amp; Comparison | Artificial Analysis</A>
							<DT><A HREF="https://www.replicated.com/blog/series-c-announcement">Replicated $50M Series C To Advance Multi-Prem Software Adoption</A>
							<DT><A HREF="https://fireworks.ai/blog/why-gpus-on-demand">GPUs on-demand: Not serverless, not reserved, but some third thing</A>
							<DT><A HREF="https://www.mercatopartners.com/editorials/why-we-invested-in-lambda">Why Mercato Led Lambda‚Äôs $44M Series B</A>
							<DT><A HREF="https://artificialanalysis.ai/models/deepseek-v2">DeepSeek-V2 - Quality, Performance &amp; Price Analysis | Artificial Analysis</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ptGDaGUXInw">Mark Russinovich | Generative AI in the Cloud: Inside Microsoft AI Innovation - YouTube</A>
							<DT><A HREF="https://gwern.net/complement">Laws of Tech: Commoditize Your Complement ¬∑ Gwern.net</A>
							<DT><A HREF="https://drive.google.com/file/d/1gquqRqiT-2Be85p_5w0izGQGgHvVzncQ/view">mistral.ai strategic memo.pdf - Google Drive</A>
							<DT><A HREF="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/">Building Meta‚Äôs GenAI Infrastructure - Engineering at Meta</A>
							<DT><A HREF="https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness">Training great LLMs entirely from ground up in the wilderness as a startup ‚Äî Yi Tay</A>
						</DL><p>
						<DT><A HREF="https://gwern.net/complement">Laws of Tech: Commoditize Your Complement ¬∑ Gwern.net</A>
						<DT><A HREF="https://www.flagshippioneering.com/stories/explainer-artificial-intelligence-and-medicine">Artificial Intelligence and Medicine | Flagship Pioneering</A>
					</DL><p>
					<DT><H3 FOLDED>Meta</H3>
					<DL><p>
						<DT><H3 FOLDED>Zeyuan Allen-Zhu (physics of language models)</H3>
						<DL><p>
							<DT><A HREF="https://x.com/ZeyuanAllenZhu">(1) Zeyuan Allen-Zhu, Sc.D. (@ZeyuanAllenZhu) / X</A>
						</DL><p>
						<DT><H3 FOLDED>MSL</H3>
						<DL><p>
							<DT><A HREF="https://x.com/TrapitBansal">Trapit Bansal Co-Creator of OpenAI o1</A>
							<DT><A HREF="https://x.com/shuchaobi">Shuchao Bi:  RL/post-training/agents, multimodal RL</A>
							<DT><A HREF="https://www.linkedin.com/in/huiwen-chang-999962156/">(3) Huiwen Chang multimodal</A>
							<DT><A HREF="https://www.linji.me/">Ji Lin: multimodal, reasoning, and synthetic data</A>
							<DT><A HREF="https://www.linkedin.com/in/joelpob/">(3) Joel Pobar | LinkedIn inference</A>
							<DT><A HREF="https://www.linkedin.com/in/jackrae/">(3) Jack Rae | LinkedIn</A>
							<DT><A HREF="https://x.com/ren_hongyu">(1) Hongyu Ren (@ren_hongyu) / X</A>
							<DT><A HREF="https://x.com/jhyuxm">Jiahui Yu: Perception @OpenAI; previously co-led Gemini Multimodal @GoogleDeepMind</A>
							<DT><A HREF="https://scholar.google.com/citations?user=bMoauM4AAAAJ&hl=en">‚Ä™Shengjia Zhao‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							<DT><A HREF="https://github.com/ajtulloch">ajtulloch (Andrew Tulloch)</A>
							<DT><A HREF="https://www.meta.com/superintelligence/">Personal Superintelligence</A>
							<DT><A HREF="https://yang-song.net/">Yang Song</A>
							<DT><A HREF="https://github.com/bwasti">bwasti (Bram Wasti)</A>
							<DT><A HREF="https://tullo.ch/about/">About ‚ÄîAndrew Tulloch</A>
						</DL><p>
					</DL><p>
					<DT><H3 FOLDED>alibaba</H3>
					<DL><p>
						<DT><A HREF="https://www.youtube.com/watch?v=X0PaVrpFD14">Alibaba Cloud Founder Expects Big AI Shakeup After OpenAI Hype - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>xAI</H3>
					<DL><p>
						<DT><H3 FOLDED>xai-people</H3>
						<DL><p>
							<DT><A HREF="https://people.eecs.berkeley.edu/~hendrycks/">Dan Hendrycks</A>
							<DT><A HREF="https://twitter.com/ibab_ml">(1) Igor Babuschkin (@ibab_ml) / X</A>
							<DT><A HREF="https://twitter.com/thegregyang">(1) Greg Yang (@TheGregYang) / X</A>
							<DT><A HREF="https://twitter.com/Guodzh/status/1489371872777191437/photo/1">(1) Guodong Zhang (@Guodzh) / X</A>
							<DT><A HREF="https://thegregyang.com/">Greg Yang |¬†Professional page</A>
							<DT><A HREF="https://github.com/kykosic">kykosic (Kyle Kosic)</A>
						</DL><p>
						<DT><A HREF="https://x.ai/">xAI: Understand the Universe</A>
						<DT><A HREF="https://x.com/ibab/status/1827047684714463603">(1) ibab en X: "Grok 2 mini is now 2x faster than it was yesterday. In the last three days @lm_zheng and @MalekiSaeed rewrote our inference stack from scratch using SGLang (https://t.co/M1M8BlXosH). This has also allowed us to serve the big Grok 2 model, which requires multi-host inference, at a https://t.co/G9iXTV8o0z" / X</A>
					</DL><p>
					<DT><H3 FOLDED>Reka</H3>
					<DL><p>
						<DT><A HREF="https://www.yitay.net/">Yi Tay</A>
					</DL><p>
					<DT><H3 FOLDED>NVIDIA</H3>
					<DL><p>
						<DT><A HREF="https://www.nvidia.com/en-us/data-center/dgx-cloud/">DGX Cloud | AI Supercomputer in the Cloud | NVIDIA</A>
						<DT><A HREF="https://www.hpcwire.com/2023/03/21/nvidias-ai-factory-services-start-at-37000/">DGX Cloud Is Here: Nvidia's AI Factory Services Start at $37,000</A>
					</DL><p>
					<DT><H3 FOLDED>Imbue</H3>
					<DL><p>
						<DT><A HREF="https://imbue.com/">imbue (General Intelligence):  AI system that can reason (agents)</A>
					</DL><p>
					<DT><H3 FOLDED>EU</H3>
					<DL><p>
						<DT><H3 FOLDED>EuroHPC</H3>
						<DL><p>
							<DT><H3 FOLDED>LUMI</H3>
							<DL><p>
								<DT><A HREF="https://www.lumi-supercomputer.eu/">Front Page - LUMI</A>
							</DL><p>
							<DT><H3 FOLDED>Jupiter</H3>
							<DL><p>
								<DT><A HREF="https://www.fz-juelich.de/en/ias/jsc/jupiter">JUPITER - Exascale for Europe</A>
								<DT><A HREF="https://www.datacenterdynamics.com/en/news/europes-first-exascale-supercomputer-will-feature-24000-nvidia-gh200-superchips/">Europe's first exascale supercomputer will feature 24,000 Nvidia GH200 Superchips - DCD</A>
							</DL><p>
							<DT><H3 FOLDED>AI Act</H3>
							<DL><p>
								<DT><A HREF="https://twitter.com/BertuzLuca/status/1722997599932678450">AI Act (November 2023)</A>
							</DL><p>
							<DT><A HREF="https://euro-stack.eu/">EuroStack</A>
						</DL><p>
						<DT><H3 FOLDED>Germany</H3>
						<DL><p>
							<DT><A HREF="https://aleph-alpha.com/">ALEPH ALPHA - AI for Enterprises and Governments</A>
							<DT><A HREF="https://www.cnbc.com/2023/11/06/aleph-alpha-raises-500-million-to-build-a-european-rival-to-openai.html">Aleph Alpha raises $500 million to build a European rival to OpenAI</A>
						</DL><p>
						<DT><H3 FOLDED>France</H3>
						<DL><p>
							<DT><H3 FOLDED>Mistral AI</H3>
							<DL><p>
								<DT><A HREF="https://mistral.ai/">Mistral AI | Open source models</A>
							</DL><p>
							<DT><H3 FOLDED>Kyutai</H3>
							<DL><p>
								<DT><A HREF="https://twitter.com/kyutai_labs">(1) kyutai (@kyutai_labs) / X</A>
								<DT><A HREF="https://twitter.com/kyutai_labs/status/1725483922652283211">Founding Research Team</A>
								<DT><A HREF="http://kyutai.org/">kyutai: open science AI lab</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://cip.org/whitepaper">Whitepaper ‚Äî The Collective Intelligence Project</A>
						<DT><A HREF="https://twitter.com/scienceisstrat1/status/1693355056634958128">economic consequences of tech stagnation for Europe‚Äôs prosperity</A>
						<DT><A HREF="https://proposal.eu-inc.org/14d076fd79c581199761dd7e8b020774?v=14d076fd79c58146b048000caeed686a">A Blueprint for implementing the EU Inc</A>
					</DL><p>
					<DT><H3 FOLDED>YC</H3>
					<DL><p>
						<DT><A HREF="https://www.ycombinator.com/library/4r-yc-and-hard-tech-startups">YC and Hard Tech Startups : YC Startup Library | Y Combinator</A>
					</DL><p>
					<DT><H3 FOLDED>Financial</H3>
					<DL><p>
						<DT><A HREF="https://www.jpmorgan.com/technology/artificial-intelligence">artificial-intelligence</A>
						<DT><A HREF="https://x.com/techstartups/status/1872614059725488400">techstartups en X: "‚Ä¢General Catalyst: This renowned Silicon Valley venture capital firm raised $8 billion, marking the largest sum by a U.S. venture capital group in over two years. The firm intends to allocate $4.5 billion to its core VC funds, $1.5 billion to initiating new start-ups, and $2" / X</A>
						<DT><A HREF="https://x.com/karlmehta/status/1947284189461782807">Claude Financial</A>
					</DL><p>
					<DT><H3 FOLDED>Microsoft</H3>
					<DL><p>
						<DT><A HREF="https://thegenerality.com/agi/index.html">Advancing AI for humanity | Foundation of AI</A>
						<DT><A HREF="https://github.com/microsoft/unilm">microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities</A>
					</DL><p>
					<DT><H3 FOLDED>token-economy</H3>
					<DL><p>
						<DT><H3 FOLDED>pareto-frontier-cost-efficient</H3>
						<DL><p>
							<DT><A HREF="https://x.com/swyx/status/1908215411214344669">Google's Gemini 2.5 pareto frontier model capabilities &amp; pricing/efficiency</A>
						</DL><p>
						<DT><H3 FOLDED>military-strategy</H3>
						<DL><p>
							<DT><A HREF="http://www.china.org.cn/english/china_key_words/2022-07/13/content_78321654.html">"Encircling the Cities from the Countryside"</A>
						</DL><p>
						<DT><A HREF="https://x.com/simonw/status/1841942172310110343">Gemini Flash-8B cost 0.00097</A>
						<DT><A HREF="https://www.ovhcloud.com/en/public-cloud/prices/">Price list: A comparison of our Public Cloud offers | OVHcloud Worldwide</A>
						<DT><A HREF="https://x.com/rwang07/status/1905207610606760014">Barclays on AI compute and Agentic AI</A>
						<DT><A HREF="https://www.youtube.com/watch?v=Z-XYhq0190E">Neural Software | Future of AI - YouTube</A>
						<DT><A HREF="https://www.tensoreconomics.com/p/moe-inference-economics-from-first">MoE Inference Economics from First Principles</A>
					</DL><p>
					<DT><H3 FOLDED>flop-economy</H3>
					<DL><p>
						<DT><H3 FOLDED>neoclouds</H3>
						<DL><p>
							<DT><A HREF="https://x.com/PytorchToAtoms/status/1860915799122211022">(1) Pytorch To Atoms en X: "When GPU neocloud tell you that you need to "self-manage" and install yourself CUDA and IB drivers, slurm and their DC techs are eating Cheetos while plugging in transceivers https://t.co/yD9jN8Uwk6" / X</A>
							<DT><A HREF="https://www.latent.space/p/enterprise">The Most Dangerous Thing An AI Startup Can Do Is Build For Other AI Startups</A>
							<DT><A HREF="https://semianalysis.com/2025/03/26/the-gpu-cloud-clustermax-rating-system-how-to-rent-gpus/">The GPU Cloud ClusterMAX‚Ñ¢ Rating System | How to Rent GPUs ‚Äì SemiAnalysis</A>
							<DT><A HREF="https://x.com/semianalysis_/status/1929584608888156491?s=12">On-demand prices have stabilized in 2Q 2025 due to NVIDIA shipment and deployment delays for the GB200 and GB300 as well as general Neocloud procurement caution.</A>
						</DL><p>
						<DT><H3 FOLDED>cost-model</H3>
						<DL><p>
							<DT><H3 FOLDED>cost-model-inference</H3>
							<DL><p>
								<DT><A HREF="https://docs.google.com/spreadsheets/d/1WJNEAcCnCdscawEaGIOZkQvH_KyDEgRyjK99Rg82VW8/edit?gid=0#gid=0">Wavespeed-DataCrunch cost model - Google Sheets</A>
							</DL><p>
							<DT><A HREF="https://docs.google.com/spreadsheets/d/1WJNEAcCnCdscawEaGIOZkQvH_KyDEgRyjK99Rg82VW8/edit?gid=0#gid=0">Wavespeed-DataCrunch cost model - Google Sheets</A>
						</DL><p>
						<DT><H3 FOLDED>gpu-market</H3>
						<DL><p>
							<DT><A HREF="https://www.theinformation.com/articles/oracle-assures-investors-ai-cloud-margins-struggles-profit-older-nvidia-chips?utm_source=ti_app">Oracle Assures Investors on AI Cloud Margins as It Struggles to Profit From Older Nvidia Chips ‚Äî The Information</A>
						</DL><p>
						<DT><A HREF="https://cloud.hypertec.com/pricing/">Cost-Effective Cloud Pricing Tailored to Your Workloads | Hypertec Cloud</A>
						<DT><A HREF="https://www.together.ai/blog/nvidia-gb200-together-gpu-cluster-36k">Together AI to Co-Build Turbocharged NVIDIA GB200 Cluster with 36K Blackwell GPUs in Partnership with Hypertec Cloud</A>
						<DT><A HREF="https://www.together.ai/blog/introducing-the-together-enterprise-platform">Introducing The Together Enterprise Platform: Run GenAI securely in any environment, with 2x faster inference and continuous model optimization</A>
						<DT><A HREF="https://www.together.ai/blog/nvidia-h200-and-h100-gpu-cluster-performance-together-kernel-collection">Supercharging NVIDIA H200 and H100 GPU Cluster Performance With Together Kernel Collection</A>
						<DT><A HREF="https://x.com/satyanadella/status/1883753899255046301">Jevons paradox</A>
					</DL><p>
					<DT><H3 FOLDED>DC-research</H3>
					<DL><p>
						<DT><H3 FOLDED>dc-research-approach</H3>
						<DL><p>
							<DT><A HREF="https://x.com/eatonphil/status/1919404092624982157">Google's Hybrid Approach to Research</A>
							<DT><A HREF="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/38149.pdf">Google‚Äôs Hybrid Approach to Research</A>
							<DT><A HREF="https://docs.google.com/document/d/1BzbjwGsCMO-X2A0pgAZTTAT022jgwxM20SDpB4gP52I/edit?tab=t.0">Industrial AI Research Collaboration Early Statement - Google Docs</A>
						</DL><p>
						<DT><H3 FOLDED>sk-research-hub</H3>
						<DL><p>
							<DT><A HREF="https://cvlab.kaist.ac.kr/home">CVLAB</A>
							<DT><A HREF="https://sihyun.me/">Sihyun Yu</A>
							<DT><A HREF="https://mingukkang.github.io/">Minguk Kang</A>
							<DT><A HREF="https://yangspace.co.kr/">Sejong Yang</A>
							<DT><A HREF="https://seominjoon.github.io/">Minjoon Seo</A>
						</DL><p>
						<DT><H3 FOLDED>1X</H3>
						<DL><p>
							<DT><A HREF="https://www.1x.tech/discover/1x-world-model-sampling-challenge">1X World Model: Sampling Challenge Update</A>
							<DT><A HREF="https://github.com/thu-ml/RoboticsDiffusionTransformer">thu-ml/RoboticsDiffusionTransformer: RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation</A>
							<DT><A HREF="https://github.com/1x-technologies/1xgpt?tab=readme-ov-file">1x-technologies/1xgpt: world modeling challenge for humanoid robots</A>
							<DT><A HREF="https://github.com/1x-technologies/dc-collab">1x-technologies/dc-collab: shared research repo for DC and 1X</A>
						</DL><p>
						<DT><H3 FOLDED>replicate</H3>
						<DL><p>
						</DL><p>
						<DT><A HREF="https://carpedm30.notion.site/DataCrunch-Project-12d60168829780d5ab7cfad7ce6d083e">[DataCrunch] Project</A>
						<DT><A HREF="https://gwern.net/complement">Laws of Tech: Commoditize Your Complement ¬∑ Gwern.net</A>
						<DT><A HREF="https://github.com/genmoai/models/tree/main">genmoai/models: The best OSS video generation models</A>
						<DT><A HREF="https://crusoe.ai/cloud/">Crusoe Cloud</A>
					</DL><p>
					<DT><H3 FOLDED>AI labs</H3>
					<DL><p>
						<DT><H3 FOLDED>Georgia Tech</H3>
						<DL><p>
							<DT><A HREF="https://www.gatech.edu/">Georgia Institute of Technology</A>
						</DL><p>
						<DT><H3 FOLDED>SHI Labs</H3>
						<DL><p>
							<DT><H3 FOLDED>shi-labs-efficient-GenAI-inference</H3>
							<DL><p>
								<DT><A HREF="https://github.com/SHI-Labs/NATTEN">SHI-Labs/NATTEN: Neighborhood Attention Extension. Bringing attention to a neighborhood near you!</A>
							</DL><p>
							<DT><A HREF="https://shi-labs.com/">SHI Labs</A>
							<DT><A HREF="https://github.com/alihassanijr">alihassanijr (Ali Hassani)</A>
							<DT><A HREF="https://github.com/SHI-Labs/NATTEN">SHI-Labs/NATTEN: Neighborhood Attention Extension. Bringing attention to a neighborhood near you!</A>
							<DT><A HREF="https://github.com/SHI-Labs">SHI Labs github</A>
						</DL><p>
						<DT><H3 FOLDED>KAUST</H3>
						<DL><p>
							<DT><A HREF="https://www.kaust.edu.sa/en/">King Abdullah University of Science and Technology | KAUST</A>
							<DT><A HREF="https://www.kaust.edu.sa/en/research/generative-ai">Generative AI</A>
							<DT><A HREF="https://www.kaust.edu.sa/en/research/generative-ai/gen-ai-factory">GenAI Factory: ML sys</A>
						</DL><p>
						<DT><H3 FOLDED>NVlabs</H3>
						<DL><p>
							<DT><H3 FOLDED>nvlabs-applied-research</H3>
							<DL><p>
								<DT><A HREF="https://research.nvidia.com/labs/adlr/">NVIDIA Applied Deep Learning Research - NVIDIA ADLR</A>
								<DT><A HREF="https://research.nvidia.com/labs/adlr/projects/">Projects - NVIDIA ADLR</A>
								<DT><A HREF="https://research.nvidia.com/labs/adlr/projects/bigvgan/">BigVGAN: A Universal Neural Vocoder with Large-Scale Training - NVIDIA ADLR</A>
								<DT><A HREF="https://blog.shi-labs.com/distributed-gemm-88be6a481e2b">Distributed GEMM: CUTLASS-native Tensor Parallelism | SHI Labs</A>
							</DL><p>
							<DT><H3 FOLDED>nvlabs-robotics</H3>
							<DL><p>
								<DT><A HREF="https://research.nvidia.com/labs/srl/">NVIDIA Seattle Robotics Lab</A>
							</DL><p>
							<DT><H3 FOLDED>nvlabs-genai</H3>
							<DL><p>
								<DT><A HREF="https://research.nvidia.com/labs/genair/">Fundamental Generative AI Research</A>
							</DL><p>
							<DT><A HREF="https://github.com/NVlabs">NVIDIA Research Projects</A>
							<DT><A HREF="https://www.nvidia.com/en-us/research/">Research at NVIDIA | Advancing the Latest Technology | NVIDIA</A>
						</DL><p>
						<DT><A HREF="https://blog.shi-labs.com/distributed-gemm-88be6a481e2b">Distributed GEMM: CUTLASS-native Tensor Parallelism | SHI Labs</A>
					</DL><p>
					<DT><H3 FOLDED>china</H3>
					<DL><p>
						<DT><H3 FOLDED>Offshore Holding</H3>
						<DL><p>
							<DT><A HREF="https://chatgpt.com/c/6812bb42-d7d4-800c-987f-e1a552318a37">Chinese Tech Legal Structures</A>
							<DT><A HREF="https://www.sec.gov/Archives/edgar/data/1577552/000119312514184994/d709111df1.htm#:~:text=Due%20to%20PRC%20legal%20restrictions,ICP%20licenses%20and%20operate%20the">Alibaba Group Holding Limited Form F-1 Registration Statement</A>
						</DL><p>
						<DT><A HREF="https://x.com/johannes_hage/status/1939759423897092143">china open-source</A>
					</DL><p>
					<DT><H3 FOLDED>ai-jobs</H3>
					<DL><p>
						<DT><H3 FOLDED>ai-jobs-hiring</H3>
						<DL><p>
							<DT><H3 FOLDED>hiring-popular</H3>
							<DL><p>
								<DT><A HREF="https://www.indeed.com/q-Math-Software-Engineer-jobs.html">Math Software Engineer Jobs, Employment | Indeed.com</A>
								<DT><A HREF="https://www.simplyhired.com/search?q=mathematical+software+developer&job=RsU31mOh80Jmmo7WTgmur_p1hgEjCAW3Ni0kvM1M5qdfpIHKCj7tvw">SimplyHired</A>
								<DT><A HREF="https://www.glassdoor.com/Job/remote-mathematics-jobs-SRCH_IL.0,6_IS11047_KO7,18.htm">Glassdoor</A>
								<DT><A HREF="https://engineering.atspotify.com/">Spotify Engineering</A>
								<DT><A HREF="https://www.workatastartup.com/application/preview">Y Combinator's Work at a Startup</A>
								<DT><A HREF="https://jobs.lever.co/cohere/fab6d469-b35c-4c72-be88-30fe3effe570/apply">Cohere - Machine Learning Intern (Fall 2022)</A>
							</DL><p>
							<DT><H3 FOLDED>how we hire</H3>
							<DL><p>
								<DT><A HREF="https://careers.google.com/how-we-hire/#step-your-resume">How we hire - Google Careers</A>
								<DT><A HREF="https://www.google.com/about/careers/applications/jobs/results/">Search Jobs ‚Äî Google Careers</A>
								<DT><A HREF="https://scholar.google.com/citations?hl=en&user=aON3WZYAAAAJ&view_op=list_works&gmla=AOV7GLM2TckIKC7Mc7ZA3FSqKOLUKYf7X8mE915uFnfQ_2qb17xgxLafbFNftpTSWd_anXcnGVCsYkOw1KOcHcUL">‚Ä™Antonio J. Dominguez‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
								<DT><A HREF="https://wellfound.com/jobs/2708656-principal-software-engineer-c-cuda-raptor">Principal Software Engineer C++ / CUDA (Raptor) at SpaceX ‚Ä¢ Hawthorne | Wellfound (formerly AngelList Talent)</A>
							</DL><p>
							<DT><A HREF="https://boards.greenhouse.io/spacex/jobs/4867945002?gh_jid=4867945002">Job Application for Summer 2021 Associate Engineer - SpaceX</A>
							<DT><A HREF="https://jobs.raytheonmissilesanddefense.com/search-jobs?orgIds=30457&ac=22805&ascf=%5B%7B%22key%22:%22job_type%22,%22value%22:%22College%20Jobs%22%7D%5D">Search our Job Opportunities at Raytheon Technologies</A>
							<DT><A HREF="https://www.works-hub.com/login">WorksHub</A>
							<DT><A HREF="https://www.isomorphiclabs.com/blog">Isomorphic Labs | Blog</A>
							<DT><A HREF="https://www.talentbyblind.com/profile">Talent By Blind | Get More Offers</A>
							<DT><A HREF="https://www.lifeatspotify.com/students">Students | Life at Spotify</A>
							<DT><A HREF="https://adobe.wd5.myworkdayjobs.com/en-US/external_university/userHome">Adobe careers</A>
							<DT><A HREF="https://hnhiring.com/">All Jobs From Hacker News 'Who is Hiring?' Posts | HNHIRING</A>
							<DT><A HREF="https://www.spinics.net/lists/pgsql-jobs/index.html#01055">Postgresql Jobs</A>
							<DT><A HREF="https://www.wecanbeheroes.io/startup/iomed-0">IOMED jobs: Your career at one of Europe's coolest startups</A>
							<DT><A HREF="https://wasmer.io/">Wasmer - The Universal WebAssembly Runtime</A>
							<DT><A HREF="https://angel.co/jobs">Startup Jobs | AngelList Talent</A>
							<DT><A HREF="https://ai-jobs.net/">Jobs in AI/ML and Big Data | ai-jobs.net</A>
							<DT><A HREF="https://x.company/">X, the moonshot factory</A>
							<DT><A HREF="https://read.cv/open-roles">Open Roles</A>
							<DT><A HREF="https://himalayas.app/onboarding/talent">Job Seeker Sign Up | Himalayas</A>
							<DT><A HREF="https://apply.workable.com/huggingface/?lng=en">Hugging Face - Current Openings</A>
							<DT><A HREF="https://wellfound.com/jobs">Find Startup Jobs Near You and Remote Jobs | Wellfound (formerly AngelList Talent)</A>
							<DT><A HREF="https://startup.jobs/?q=ai">Startup Jobs ‚Äì Developer, designer, marketing, sales jobs, and more</A>
						</DL><p>
						<DT><H3 FOLDED>ai-jobs-research</H3>
						<DL><p>
							<DT><H3 FOLDED>jobs-efficient-ai</H3>
							<DL><p>
								<DT><A HREF="https://openai.com/careers/gpu-kernels-engineer/">GPU Kernels Engineer | OpenAI | OpenAI</A>
								<DT><A HREF="https://jobs.lever.co/cohere/9ce64f5b-73f7-4a66-900b-c9dee2c5fba6">Cohere - Member of Technical Staff, Model Efficiency</A>
								<DT><A HREF="https://openai.com/careers/research-engineer-post-training-model-optimization/">Research Engineer, Post-training Model Optimization | OpenAI | OpenAI</A>
								<DT><A HREF="https://openai.com/careers/software-engineer-triton-compiler/">Software Engineer, Triton Compiler | OpenAI | OpenAI</A>
								<DT><A HREF="https://x.com/nadavrot/status/1796312670779650460">(1) Nadav Rotem en X: "We are looking for GPU compiler engineers, CUDA experts, PTX aficionados, MLIR experts, Triton lovers, IEEE 754 ninjas, and people that don't need to heat their house in winter because their GPU is hot enough. We require a U.S. work permit. Please send me resumes in PDF format." / X</A>
								<DT><A HREF="https://featuresandlabels.notion.site/We-are-hiring-fal-ai-37eece7cf700403fbb63b61b757684c4">üöÄ We are hiring @ fal.ai!</A>
							</DL><p>
							<DT><H3 FOLDED>jobs-pre-training</H3>
							<DL><p>
								<DT><A HREF="https://boards.greenhouse.io/anthropic/jobs/4020189008">Job Application for Engineering Manager, Pretraining Data Platform at Anthropic</A>
							</DL><p>
							<DT><H3 FOLDED>jobs-research-interships</H3>
							<DL><p>
								<DT><A HREF="https://jobs.lever.co/cohere/0bb9479c-36a5-4a2f-ad47-6e5ca2fb37ec">Cohere - Research Internship</A>
							</DL><p>
							<DT><H3 FOLDED>jobs-inference</H3>
							<DL><p>
								<DT><H3 FOLDED>jobs-edge-inference</H3>
								<DL><p>
									<DT><A HREF="https://www.linkedin.com/jobs/view/3982459914/?refId=282fb2a3-462d-40f0-8ecc-df6f91e43130&trackingId=JZ69HVkmSEKA9xvzDIgh%2Bw%3D%3D&trk=flagship3_job_home_savedjobs">(1) ML Engineer L4, Consumer Inference | Netflix | LinkedIn</A>
								</DL><p>
								<DT><A HREF="https://openai.com/careers/distributed-systemsml-engineer/">Distributed Systems/ML Engineer | OpenAI | OpenAI</A>
								<DT><A HREF="https://openai.com/careers/platform-ml-engineering-manager-inference/">Platform ML Engineering Manager, Inference | OpenAI | OpenAI</A>
								<DT><A HREF="https://openai.com/careers/research-engineer-post-training-model-optimization/">Research Engineer, Post-training Model Optimization | OpenAI | OpenAI</A>
								<DT><A HREF="https://openai.com/careers/engineering-manager-ai-inference-systems/">Engineering Manager, AI Inference Systems | OpenAI | OpenAI</A>
								<DT><A HREF="https://openai.com/careers/software-engineer-model-inference-2/">Software Engineer, Model Inference | OpenAI | OpenAI</A>
								<DT><A HREF="https://www.linkedin.com/jobs/view/3982463651/?refId=282fb2a3-462d-40f0-8ecc-df6f91e43130&trackingId=h9VprUs6Qq25r308hAChSg%3D%3D&trk=flagship3_job_home_savedjobs">(1) Research Scientist (L6) - Machine Learning and Inference Research | Netflix | LinkedIn</A>
								<DT><A HREF="https://www.linkedin.com/jobs/view/3970207835/?refId=282fb2a3-462d-40f0-8ecc-df6f91e43130&trackingId=Hv%2BsaKKaTfWiNWRe9EjApQ%3D%3D&trk=flagship3_job_home_savedjobs">(1) Machine Learning Engineer | Replicate | LinkedIn</A>
								<DT><A HREF="https://www.linkedin.com/jobs/view/3959597204/?refId=282fb2a3-462d-40f0-8ecc-df6f91e43130&trackingId=5TkyftfTTNuKwtlBc3v5HQ%3D%3D&trk=flagship3_job_home_savedjobs">(1) Machine Learning Engineer - Inference | Together AI | LinkedIn</A>
								<DT><A HREF="https://boards.greenhouse.io/anthropic/jobs/4020356008">Job Application for Software Engineer, Inference at Anthropic</A>
							</DL><p>
							<DT><H3 FOLDED>jobs-gpu-platform</H3>
							<DL><p>
								<DT><A HREF="https://openai.com/careers/engineering-manager-gpu-platform/">Engineering Manager, GPU Platform | OpenAI | OpenAI</A>
							</DL><p>
							<DT><A HREF="https://www.anthropic.com/jobs">Jobs \ Anthropic</A>
							<DT><A HREF="https://openai.com/careers/search/?c=ai-scientist%2Calignment%2Cfrontiers%2Chuman-data%2Cplatform%2Cpost-training%2Cpre-training%2Cpreparedness%2Csafety-systems%2Csora%2Cresearch">OpenAI</A>
						</DL><p>
						<DT><H3 FOLDED>forward deployed engineer</H3>
						<DL><p>
							<DT><A HREF="https://openai.com/careers/forward-deployed-engineer-sf-san-francisco/">Forward Deployed Engineer - SF | OpenAI</A>
							<DT><A HREF="https://www.ft.com/content/91002071-7874-4cb7-9245-08ca0571c408">The new hot job in AI: forward-deployed engineers</A>
						</DL><p>
						<DT><H3 FOLDED>jobs-kernels</H3>
						<DL><p>
							<DT><H3 FOLDED>jobs-tpu</H3>
							<DL><p>
								<DT><A HREF="https://job-boards.greenhouse.io/anthropic/jobs/4720576008">Job Application for TPU Kernel Engineer at Anthropic</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://engineering.atspotify.com/">Spotify Engineering</A>
						<DT><A HREF="https://www.workatastartup.com/application/preview">Y Combinator's Work at a Startup</A>
						<DT><A HREF="https://jobs.lever.co/cohere/fab6d469-b35c-4c72-be88-30fe3effe570/apply">Cohere - Machine Learning Intern (Fall 2022)</A>
						<DT><A HREF="https://www.levels.fyi/internships/Cohere-ai/Software-Engineer-Intern/">Cohere.ai Software Engineer Intern Salaries | $64.00 / hr | Levels.fyi</A>
						<DT><A HREF="https://www.metacareers.com/v2/jobs/2587807648062439/">Software Engineer, Systems ML - Frameworks / Compilers / Kernels | Meta Careers</A>
						<DT><A HREF="https://www.youtube.com/watch?v=3xD_aUGKk_4">May 2024: The tech layoffs have oversaturated the USA tech job market. - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=blp7dRsSgBM">Open Data Engineering Q&amp;A - YouTube</A>
						<DT><A HREF="https://featuresandlabels.notion.site/We-are-hiring-fal-ai-37eece7cf700403fbb63b61b757684c4">üöÄ We are hiring @ fal.ai!</A>
						<DT><A HREF="https://www.janestreet.com/join-jane-street/position/7449077002/">Machine Learning Performance Engineer :: Jane Street</A>
						<DT><A HREF="https://landing.club/stamplist">StampList: Visa Sponsors | Landing Club</A>
						<DT><A HREF="https://job-boards.greenhouse.io/xai/jobs/4378344007">Job Application for Member of Technical Staff, Pre-training Data Infrastructure at xAI</A>
						<DT><A HREF="https://job-boards.greenhouse.io/togetherai/jobs/4385540007">Job Application for Machine Learning Engineer - Inference at Together AI</A>
						<DT><A HREF="https://apply.careers.microsoft.com/careers/job/1970393556654063">Workloads and Benchmarking Team Lead | Microsoft Careers</A>
					</DL><p>
					<DT><A HREF="https://github.com/run-ai">run:ai</A>
					<DT><A HREF="https://www.youtube.com/watch?v=j3MPhl7HcGw">The Race to Build in Antarctica - YouTube</A>
					<DT><A HREF="https://olaolusoga.com/spacex-5-step-design-manufacturing-process/">SpaceX's 5 Step Process - Ola Olusoga</A>
					<DT><A HREF="https://gwern.net/complement#:~:text=Joel%20Spolsky%20in%202002%20identified,layers%20by%20dominating%20one%20layer">Laws of Tech: Commoditize Your Complement ¬∑ Gwern.net</A>
					<DT><A HREF="https://x.com/elonmusk/status/1977281341264740625">macrohard</A>
					<DT><A HREF="https://andrewtrask.substack.com/p/gpu-demand-is-1mx-distorted-by-efficiency">GPU demand is (~1Mx) distorted by efficiency problems which are being solved</A>
					<DT><A HREF="https://x.com/jack/status/1982168068609486974">New episode: "How Elon Works"</A>
					<DT><A HREF="https://x.com/lucagrecoita/status/2004924492045254939">The most common error of a smart engineer is to optimize something that should not exist</A>
				</DL><p>
				<DT><H3 FOLDED>Papers</H3>
				<DL><p>
					<DT><H3 FOLDED>learning-notes</H3>
					<DL><p>
						<DT><A HREF="https://github.com/lcy-seso/LearningNotes">lcy-seso/LearningNotes: Ying's notes</A>
					</DL><p>
					<DT><H3 FOLDED>Information Theory &amp; Communication</H3>
					<DL><p>
						<DT><H3 FOLDED>representation theory</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=IwYiETZEGY0&list=LL&index=11&t=25s">What does AI have to do with Plato's Allegory of the Cave? - YouTube</A>
							<DT><A HREF="https://arxiv.org/abs/2405.07987">[2405.07987] The Platonic Representation Hypothesis</A>
							<DT><A HREF="https://www.youtube.com/watch?v=1_xH2mUFpZw&t=802s">The Platonic Representation Hypothesis - YouTube</A>
						</DL><p>
						<DT><A HREF="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf">(SHANNON) A Mathematical Theory of Communication</A>
						<DT><A HREF="https://twitter.com/realGeorgeHotz/status/1738013824987656635">(1) George Hotz üåë en X: ".@__tinygrad__ is really an entropics research group. Distilling neural networks down to their purest essence. The compression of the compressor. Someday net size will be measured in gates instead of FLOPS or weights." / X</A>
						<DT><A HREF="https://twitter.com/realGeorgeHotz/status/1690831164431585280">Thermodynamics is to Energy as &gt;???&gt;is to Intelligence</A>
						<DT><A HREF="https://www.youtube.com/watch?v=Z_sQg-Alg7E">Estimating the Information Flow in Deep Neural Networks - YouTube</A>
						<DT><A HREF="https://irhum.github.io/blog/spherical-harmonics/">irhum.github.io - Visual Notes on Spherical Harmonics</A>
						<DT><A HREF="https://x.com/din0s_/status/1801271625309937771">(1) dinos en X: Awesome Information Retrieval</A>
						<DT><A HREF="https://arxiv.org/pdf/1703.00810">Opening the balck box of Deep Neural Networks</A>
						<DT><A HREF="https://github.com/ravidziv/IDNNs">ravidziv/IDNNs: explore DNNs via Infomration</A>
						<DT><A HREF="https://www.youtube.com/@szymonozog7862/videos">Simon Oz - YouTube</A>
						<DT><A HREF="https://lilianweng.github.io/posts/2017-09-28-information-bottleneck/">Anatomize Deep Learning with Information Theory | Lil'Log</A>
						<DT><A HREF="https://x.com/tanishqkumar07/status/1856045600355352753">(1) Tanishq Kumar @ NeurIPS 2024 en X: "[1/7] New paper alert! Heard about the BitNet hype or that Llama-3 is harder to quantize? Our new work studies both! We formulate scaling laws for precision, across both pre and post-training https://t.co/8FC4g2fSRb. TLDR; - Models become harder to post-train quantize as they https://t.co/m212U9eJd7" / X</A>
						<DT><A HREF="https://www.youtube.com/watch?v=5UELGpaN4YE">Images, Sound, and the Hidden Geometry of Information - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=v68zYyaEmEA">Solving Wordle using information theory - YouTube</A>
						<DT><A HREF="https://colah.github.io/posts/2015-09-Visual-Information/">Visual Information Theory -- colah's blog</A>
						<DT><A HREF="https://www.youtube.com/watch?v=T_R5MIQQfXA">Are Language Models Just Weights? New AI Research Explained - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>Signal processing</H3>
					<DL><p>
						<DT><H3 FOLDED>convolution</H3>
						<DL><p>
							<DT><A HREF="https://jlebar.com/2023/9/11/convolutions.html">ML Convolutions Explained Differently</A>
						</DL><p>
						<DT><A HREF="https://www.jezzamon.com/fourier/index.html">An Interactive Introduction to Fourier Transforms</A>
						<DT><A HREF="https://www.youtube.com/watch?v=2EZap2EoMR0">Recitation 1 - Why Vibrations and Waves Matter - YouTube</A>
						<DT><A HREF="https://twitter.com/taiyasaki/status/1782856728973045843">Band-limited Neural Fields for Levels of Detail Reconstruction</A>
						<DT><A HREF="https://irhum.github.io/blog/spherical-harmonics/">irhum.github.io - Visual Notes on Spherical Harmonics</A>
						<DT><A HREF="https://x.com/Ethan_smith_20/status/1767570870598279181">Ethan en X: "Created a new method of generative model (although kinda crappy lol) that works by autoregressive sequencing fourier coefficients. Inspired by the coarse to fine generation by Diffusion models. Full write up here: https://t.co/voD78qVwIB and tldr in thread üßµ (flowers102) https://t.co/VyhR0WA4vs" / X</A>
						<DT><A HREF="https://www.youtube.com/watch?v=Cx5Z-OslNWE&list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k">Course Introduction of 18.065 by Professor Strang - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=6xaaeop7gJ8&list=PLADC1A1B7FA7FF7B6">Lecture 2, Signals and Systems: Part 1 | MIT RES.6.007 Signals and Systems, Spring 2011 - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=h4NGp4lnZBc">Chain reaction: Shooting a single neutron into a chunk of ¬≤¬≥‚ÅµU - YouTube</A>
						<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/">Stable and Scalable FP8 Deep Learning Training on Blackwell S72778 | GTC 2025 | NVIDIA On-Demand</A>
						<DT><A HREF="https://github.com/commaai/controls_challenge">commaai/controls_challenge: Can you design a controller to steer a simulated car?</A>
					</DL><p>
					<DT><H3 FOLDED>Computational Complexity</H3>
					<DL><p>
						<DT><A HREF="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem">Kolmogorov‚ÄìArnold representation theorem</A>
						<DT><A HREF="https://hadrien-montanelli.github.io/2019-06-25.html">Deep networks and the Kolmogorov‚ÄìArnold theorem</A>
						<DT><A HREF="https://math.stackexchange.com/questions/2518664/are-there-any-simple-examples-of-kolmogorov-arnold-representation">Are there any simple examples of Kolmogorov-Arnold representation?</A>
					</DL><p>
					<DT><H3 FOLDED>Numerical linear algebra</H3>
					<DL><p>
						<DT><H3 FOLDED>Random Matrix Theory</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=oPQ4mNcqY7k&t=9s">Terence Tao's central limit theorem, Double Factorials (!!) and the Moment Method #SoME3 - YouTube</A>
							<DT><A HREF="https://ericauld.github.io/2023/05/20/clt.html">Eric Auld | Math, Economics, and Computing</A>
							<DT><A HREF="https://rmt-fall2019.s3.amazonaws.com/rmt-fall2019.pdf">https://rmt-fall2019.s3.amazonaws.com/rmt-fall2019.pdf</A>
							<DT><A HREF="https://kexue.fm/archives/11335">Fast (but non-rigorous) estimation of the spectral norm of random matrices</A>
						</DL><p>
						<DT><H3 FOLDED>Rand NLA</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2302.11474">[2302.11474] Randomized Numerical Linear Algebra : A Perspective on the Field With an Eye to Software</A>
							<DT><A HREF="https://www.youtube.com/watch?v=6htbyY3rH1w&t=1699s">Is the Future of Linear Algebra.. Random? - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=fJ2EyvR85ro">Randomized Singular Value Decomposition (SVD) - YouTube</A>
						</DL><p>
						<DT><A HREF="https://archive.org/details/gantmacher-the-theory-of-matrices-vol-1-1959/page/12/mode/2up">The Theory Of Matrices Vol 1 : F. R. Gantmacher : Free Download, Borrow, and Streaming : Internet Archive</A>
						<DT><A HREF="https://www.maths.ed.ac.uk/~v1ranick/papers/gantmacher1.pdf">https://www.maths.ed.ac.uk/~v1ranick/papers/gantmacher1.pdf</A>
						<DT><A HREF="https://www.youtube.com/watch?v=Cx5Z-OslNWE&list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k">Course Introduction of 18.065 by Professor Strang - YouTube</A>
						<DT><A HREF="https://x.com/yaroslavvb/status/1822036160115617975">Where do eigenvalues come from?</A>
					</DL><p>
					<DT><H3 FOLDED>Statistics</H3>
					<DL><p>
						<DT><H3 FOLDED>probability theory</H3>
						<DL><p>
							<DT><A HREF="https://terrytao.wordpress.com/2015/09/29/275a-notes-0-foundations-of-probability-theory/">275A, Notes 0: Foundations of probability theory | What's new</A>
							<DT><A HREF="https://services.math.duke.edu/~rtd/PTE/PTE5_011119.pdf">Probability: Theory and Examples (Rick Durrett)</A>
						</DL><p>
						<DT><H3 FOLDED>optimal transport</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=C12o-60fmgE">IFML SEMINAR: 2/2/24 - Gromov-Wasserstein Alignment: Statistical and Computational Advancements... - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=EauDdCzxphE&t=3s">Optimal Transport and Information Geometry for Machine Learning and Data Science - YouTube</A>
							<DT><A HREF="https://x.com/gabrielpeyre/status/1863564944207175888">(1) Gabriel Peyr√© en X: "Optimal transport computes an interpolation between two distributions using an optimal coupling. Flow matching, on the other hand, uses a simpler ‚Äúindependent‚Äù coupling, which is the product of the marginals. https://t.co/ILrKMPwLJh" / X</A>
						</DL><p>
						<DT><H3 FOLDED>statistics-physics-informed-learning</H3>
						<DL><p>
							<DT><A HREF="https://mitmath.github.io/18337/lecture15/diffeq_machine_learning">Mixing Differential Equations and Neural Networks for Physics-Informed Learning</A>
						</DL><p>
						<DT><H3 FOLDED>statistics-bayes</H3>
						<DL><p>
							<DT><A HREF="https://ermongroup.github.io/cs228-notes/representation/directed/">Probabilistic Graphical Models: Cascades and Nets</A>
						</DL><p>
						<DT><A HREF="https://matjaz.substack.com/p/why-are-there-complete-problems-really?s=r">Why are there complete problems, really?</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/permutation">permutation</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/probability+distribution">probability distribution</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/supervised+learning">supervised learning</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/probability+density">probability density</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Banach+space">Banach space</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Wasserstein+metric">Wasserstein metric</A>
						<DT><A HREF="https://simons.berkeley.edu/workshops/deep-learning-theory-workshop">Deep Learning Theory Workshop and Summer School | Simons Institute for the Theory of Computing</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Domain_adaptation#Domain_shift">Domain adaptation - (Distribution Shift)</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Log_probability">Log probability</A>
						<DT><A HREF="https://starai.cs.ucla.edu/papers/ZhangIJCAI23.pdf">On the Paradox of Learning to Reason from Data</A>
						<DT><A HREF="https://twitter.com/sirbayes/status/1765905163020325296">(1) Kevin Patrick Murphy en X: "@fchollet claimed that "learning to reason" (robustly across problem instances) is hard because of the nature of the MLE objective. This paper proves that claim. The reason is "statistical features inherently exist in data distributions, but can hinder model generalization..." / X</A>
						<DT><A HREF="https://www.youtube.com/watch?v=xkS9GyujiqQ">03 ‚Äì NaiÃàve Bayes parameters estimation and Laplace smoothing - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>Deep Learning</H3>
					<DL><p>
						<DT><H3 FOLDED>automatic differentiation</H3>
						<DL><p>
							<DT><H3 FOLDED>Autodiff-Puzzles</H3>
							<DL><p>
								<DT><A HREF="https://github.com/srush/Autodiff-Puzzles/blob/main/autodiff_puzzlers.ipynb">Autodiff-Puzzles/autodiff_puzzlers.ipynb at main ¬∑ srush/Autodiff-Puzzles</A>
								<DT><A HREF="https://x.com/cosminnegruseri/status/2014909891107029486">pytorch puzzle (might be an old Openai interview question)</A>
							</DL><p>
							<DT><A HREF="https://x.com/karpathy/status/1803963383018066272">These 94 lines of code are everything that is needed to train a neural network. Everything else is just efficiency.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=_ds0-daMESY">Automatic Differentiation - A Revisionist History and the State of the Art - AD meets SDG and PLT - YouTube</A>
							<DT><A HREF="https://kexue.fm/archives/9902">ËÆ©ÁÇº‰∏πÊõ¥ÁßëÂ≠¶‰∏Ä‰∫õÔºà‰∏ÄÔºâÔºöSGDÁöÑÂπ≥ÂùáÊçüÂ§±Êî∂Êïõ - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
							<DT><A HREF="https://www.cs.toronto.edu/~hinton/absps/naturebp.pdf">https://www.cs.toronto.edu/~hinton/absps/naturebp.pdf</A>
							<DT><A HREF="https://arogozhnikov.github.io/2023/12/28/fastest-autograd.html">Fastest Autograd in the West</A>
							<DT><A HREF="https://www.youtube.com/watch?v=S7VG-0Tw6a4">Building an autograd engine with only Triton GPU kernels - live 2025.1.28 - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>optimization</H3>
						<DL><p>
							<DT><H3 FOLDED>convex optimization</H3>
							<DL><p>
								<DT><A HREF="https://kexue.fm/archives/11494">Revisiting Convergence Results in Convex Optimization (Part IV)</A>
								<DT><A HREF="https://kexue.fm/archives/11469">Revisiting Convergence Results in Convex Optimization (Part II)</A>
								<DT><A HREF="https://kexue.fm/archives/11480">Revisiting Convergence Results in Convex Optimization (Part III): Last Iterate Convergence of SGD</A>
								<DT><A HREF="https://web.stanford.edu/~boyd/cvxbook/">Convex Optimization</A>
								<DT><A HREF="https://en.wikipedia.org/wiki/Convex_optimization">Convex optimization - Wikipedia</A>
								<DT><A HREF="https://x.com/konstmish/status/1939637019333779935">I believe successful neural network training represents cases of "near convexity":</A>
								<DT><A HREF="https://tullo.ch/static/cambridge/ConvexOptimization-LectureNotes.pdf">https://tullo.ch/static/cambridge/ConvexOptimization-LectureNotes.pdf</A>
								<DT><A HREF="https://x.com/aaron_defazio">Aaron Defazio (@aaron_defazio) / X</A>
								<DT><A HREF="https://www.linkedin.com/posts/semianalysis_what-does-it-take-to-be-on-policy-during-activity-7410016546762358784-wcSc/?utm_medium=ios_app&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8&utm_source=social_share_send&utm_campaign=share_via">What does it take to be on-policy during RL training?</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=NE88eqLngkg">Optimization for Deep Learning (Momentum, RMSprop, AdaGrad, Adam)</A>
							<DT><A HREF="https://www.youtube.com/watch?v=6CaUxbFX8Oc&list=PLiCLbsFQNFAxOmVeqPhI5er1LGf2-L9I4">Lecture 1 Part 1: Approximate Dynamic Programming Lectures</A>
							<DT><A HREF="https://www.youtube.com/watch?v=mHO2ocZxqQM">IFML Seminar: 3/8/2024 - An Lyapunov Analysis of the Lion Optimizer - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=GM6XPEQbkS4">Provably Faster Gradient Descent via Long Steps</A>
							<DT><A HREF="https://www.youtube.com/watch?v=AKMuA_TVz3A">An observation on Generalization</A>
							<DT><A HREF="https://web.stanford.edu/~boyd/cvxbook/">Convex Optimization ‚Äì Boyd and Vandenberghe</A>
							<DT><A HREF="https://www.youtube.com/watch?v=78vq6kgsTa8">Tom Goldstein: "What do neural loss surfaces look like?" - YouTube</A>
							<DT><A HREF="https://machine-learning-etc.ghost.io/">Generating functions approach to gradient descent analysis</A>
							<DT><A HREF="https://nn.labml.ai/optimizers/index.html">Optimizers implementations</A>
						</DL><p>
						<DT><H3 FOLDED>neural networks</H3>
						<DL><p>
							<DT><H3 FOLDED>neural-networks-theory</H3>
							<DL><p>
								<DT><A HREF="https://hagan.okstate.edu/NNDesign.pdf">Neural Network Design (2nd Edition)</A>
							</DL><p>
							<DT><H3 FOLDED>nn-equivariant-invariant</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?app=desktop&v=kTvow5-eCCQ&list=PL8FnQMH2k7jzPrxqdYufoiYVHim8PyZWd&index=5">Group Equivariant Deep Learning</A>
								<DT><A HREF="https://twitter.com/JustinMSolomon/status/1538780379062075392">I know nothing about "equivariant" NNs</A>
							</DL><p>
							<DT><H3 FOLDED>Learning Dynamics</H3>
							<DL><p>
								<DT><H3 FOLDED>gradient</H3>
								<DL><p>
									<DT><H3 FOLDED>Vanishing Gradients</H3>
									<DL><p>
										<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits: Transformers Residual Stream</A>
										<DT><A HREF="https://www.youtube.com/watch?v=P6sfmUTpUmc">Building makemore Part 3: Activations &amp; Gradients, BatchNorm - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=ncTHBi8a9uA">The Fundamental Problem with Neural Networks - Vanishing Gradients - YouTube</A>
										<DT><A HREF="https://kexue.fm/archives/7888">Let‚Äôs also talk about the vanishing/exploding gradient problem of RNN</A>
										<DT><A HREF="https://x.com/cloneofsimo/status/1948850696725692493">Gradients vanish if activations are not unit-scaled. But thats not issue if you are using residual connection!</A>
									</DL><p>
									<DT><H3 FOLDED>gradient-end-of-training</H3>
									<DL><p>
										<DT><A HREF="https://x.com/aaron_defazio/status/1930705779935613184">Why do gradients increase near the end of training?</A>
										<DT><A HREF="https://arxiv.org/abs/2506.02285">[2506.02285] Why Gradients Rapidly Increase Near the End of Training</A>
									</DL><p>
									<DT><H3 FOLDED>gradient-residual-stream</H3>
									<DL><p>
										<DT><A HREF="https://x.com/cloneofsimo/status/1948850696725692493">"residual network makes your gradient happy" + intuition on depth muP</A>
									</DL><p>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1800585478539981094">What the gradient seems to really like: a thread</A>
									<DT><A HREF="https://arxiv.org/abs/2403.02241">[2403.02241] Neural Redshift: Random Networks are not Random Functions</A>
									<DT><A HREF="https://arxiv.org/abs/2004.01461">[2004.01461] Gradient Centralization: A New Optimization Technique for Deep Neural Networks</A>
									<DT><A HREF="https://arxiv.org/abs/2506.02285">[2506.02285] Why Gradients Rapidly Increase Near the End of Training</A>
									<DT><A HREF="https://centralflows.github.io/part1/">How does gradient descent work?</A>
									<DT><A HREF="https://x.com/TimDarcet/status/2000874141172555822">post-norm is pre-norm + normalizing the residual (apart from first and last layer)</A>
								</DL><p>
								<DT><H3 FOLDED>loss-spikes</H3>
								<DL><p>
									<DT><A HREF="https://wandb.ai/marin-community/marin/reports/Marin-32B-Work-In-Progress--VmlldzoxMzM1Mzk1NQ">Marin 32B Spike Fixing | marin ‚Äì Weights &amp; Biases</A>
								</DL><p>
								<DT><A HREF="https://transformer-circuits.pub/2022/toy_model/index.html#learning">Toy Models of Superposition</A>
								<DT><A HREF="https://www.fast.ai/posts/2023-09-04-learning-jumps/">fast.ai ‚Äì Can LLMs learn from a single example?</A>
								<DT><A HREF="https://arxiv.org/abs/1712.09913">[1712.09913] Visualizing the Loss Landscape of Neural Nets</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1806547801779863697">language model layer permutation</A>
								<DT><A HREF="https://kexue.fm/archives/9902">Making Alchemy More Scientific (I): SGD Average Loss Convergence</A>
								<DT><A HREF="https://www.lesswrong.com/posts/2JJtxitp6nqu6ffak/basic-facts-about-language-models-during-training-1">Basic facts about language models during training ‚Äî LessWrong</A>
								<DT><A HREF="https://x.com/kellerjordan0/status/1866333331857780873">Keller Jordan en X: "Here's an interpretability method for neural net trainings that is strong but expensive: Run the training a few thousand times, and then for pairs of inputs, measure the correlation between their final predicted outputs across runs of training. This yields a highly... 1/8üßµ https://t.co/4X2Lny0AIP" / X</A>
								<DT><A HREF="https://x.com/aaron_defazio/status/1868406236494074195/photo/1">Training recovers from loss spikes because spikes occur in only a few latent dimensions.</A>
								<DT><A HREF="https://www.jeremyjordan.me/neural-networks-training/">Neural networks: training with backpropagation.</A>
								<DT><A HREF="https://x.com/konstmish/status/1939637019333779935">I believe successful neural network training represents cases of "near convexity":</A>
								<DT><A HREF="https://x.com/QuanquanGu/status/1943725270378189135">tokens per parameter (TPP)</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1948924589280821557">Simo Ryu en X: "Ive just learned so much from this playground today. For example, here is what happens if you do gradient descent on relu MLP, even with muP setup. This shows how model is optimizing on last layers for most part, once it gets it, early layers gets updated(meaningful signal https://t.co/dmesHysK07" / X</A>
								<DT><A HREF="https://x.com/Jianlin_S/status/1962360280010375296">Rethinking the Relationship Between Learning Rate and Batch Size (Part I)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=YGLNyHd2w10">Graph Theory in State-Space - YouTube</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1970555604126069074">Simo Ryu en X: "Maybe PLRF explains this analytically as well? Idk im too stupid to see @ABAtanasov" / X</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1970575735795728395">On Gradient Destructive Interference in Power-Law Random Feature Models</A>
							</DL><p>
							<DT><H3 FOLDED>backpropagation</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=VMj-3S1tku0&t=4186s">The spelled-out intro to neural networks and backpropagation: building micrograd - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=P6sfmUTpUmc">Building makemore Part 3: Activations &amp; Gradients, BatchNorm - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=q8SA3rM6ckI">Building makemore Part 4: Becoming a Backprop Ninja - YouTube</A>
								<DT><A HREF="https://www.cs.toronto.edu/~hinton/absps/naturebp.pdf">https://www.cs.toronto.edu/~hinton/absps/naturebp.pdf</A>
							</DL><p>
							<DT><H3 FOLDED>MLP</H3>
							<DL><p>
								<DT><H3 FOLDED>KAN</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=-PFIkkwWdnM">Kolmogorov-Arnold Networks: MLP vs KAN, Math, B-Splines, Universal Approximation Theorem - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>mlp-scaling</H3>
								<DL><p>
									<DT><A HREF="https://github.com/gregorbachmann/scaling_mlps">gregorbachmann/scaling_mlps</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=TCH_1BHY58I">Building makemore Part 2: MLP - YouTube</A>
								<DT><A HREF="https://x.com/thomasahle/status/1798408687981297844">Using ùöùùöòùöõùöåùöë.ùöåùöòùöñùöôùöíùöïùöé makes KANs as fast as MLPs!</A>
								<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</A>
								<DT><A HREF="https://www.youtube.com/watch?v=OmudSvOQhCg">Why do we need activation functions? - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>SGD</H3>
							<DL><p>
								<DT><H3 FOLDED>dual Gradient Descent</H3>
								<DL><p>
									<DT><A HREF="https://kexue.fm/archives/11388">ÊµÅÂΩ¢‰∏äÁöÑÊúÄÈÄü‰∏ãÈôçÔºö5. ÂØπÂÅ∂Ê¢ØÂ∫¶‰∏ãÈôç - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
								</DL><p>
								<DT><A HREF="https://kexue.fm/archives/9902">Making Alchemy More Scientific (I): SGD Average Loss Convergence</A>
								<DT><A HREF="https://www.jeremyjordan.me/gradient-descent/">Gradient descent.</A>
								<DT><A HREF="https://centralflows.github.io/part1/">How does gradient descent work?</A>
								<DT><A HREF="https://x.com/deepcohen/status/1973191790602887544">(1) Jeremy Cohen en X: "Even with full-batch gradients, DL optimizers defy classical optimization theory, as they operate at the *edge of stability.* With @alex_damian_, we introduce "central flows": a theoretical tool to analyze these dynamics that makes accurate quantitative predictions on real NNs. https://t.co/pvvfwoQcOy" / X</A>
							</DL><p>
							<DT><H3 FOLDED>proxy model</H3>
							<DL><p>
								<DT><A HREF="https://kexue.fm/archives/8444">Can we losslessly upscale a Transformer model? (Part 1)</A>
							</DL><p>
							<DT><H3 FOLDED>circuits</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=9EN_HoEk3KY&t=2s">Ilya Sutskever: OpenAI Meta-Learning and Self-Play | Why Do Neural Networks Work?</A>
								<DT><A HREF="https://distill.pub/2020/circuits/zoom-in/">Zoom In: An Introduction to Circuits</A>
								<DT><A HREF="https://distill.pub/2020/circuits/">Thread: Circuits</A>
								<DT><A HREF="https://distill.pub/2020/circuits/visualizing-weights/">Visualizing Weights</A>
								<DT><A HREF="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens">interpreting GPT: the logit lens ‚Äî LessWrong</A>
							</DL><p>
							<DT><H3 FOLDED>latent-space</H3>
							<DL><p>
								<DT><H3 FOLDED>latent-space-visualization</H3>
								<DL><p>
									<DT><A HREF="https://www.arxiv.org/abs/2506.08725">[2506.08725] Stop Misusing t-SNE and UMAP for Visual Analytics</A>
								</DL><p>
								<DT><A HREF="https://sander.ai/2025/04/15/latents.html">Generative modelling in latent space ‚Äì Sander Dieleman</A>
							</DL><p>
							<DT><H3 FOLDED>Feature learning</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=DuBQCBWcq4M&t=340s">Greg Yang ‚Äî Feature Learning in Infinite-Width Neural Networks - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2011.14522">[2011.14522] Feature Learning in Infinite-Width Neural Networks</A>
								<DT><A HREF="https://arxiv.org/abs/2310.17813">[2310.17813] A Spectral Condition for Feature Learning</A>
							</DL><p>
							<DT><H3 FOLDED>weights</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=T_R5MIQQfXA">Are Language Models Just Weights? New AI Research Explained - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2601.00457">[2601.00457] Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=9EN_HoEk3KY&t=2s">Ilya Sutskever: OpenAI Meta-Learning and Self-Play | Why Do Neural Networks Work?</A>
							<DT><A HREF="https://www.youtube.com/watch?v=BjyZcSiVg5A">Deep Learning Theory Session. Ilya SutskeverIlya Sutskever - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=M74WKIh0ciI&list=LL&index=24">Three weight matrices in a neural network growing connections as two parallel networks are merged. - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=g0gREwiDbis">Dr. Geoffrey Hinton: A brief study of neural networks</A>
							<DT><A HREF="https://www.youtube.com/watch?v=nL7zpkfKbPs">Human MNIST Challenge: Can you recognize the Fourier transform of handwritten digits? - YouTube</A>
							<DT><A HREF="https://github.com/cloneofsimo/insightful-nn-papers">cloneofsimo/insightful-nn-papers: These papers will provide unique insightful concepts that will broaden your perspective on neural networks and deep learning</A>
							<DT><A HREF="https://ncatlab.org/nlab/show/neural+network">neural network in nLab</A>
							<DT><A HREF="https://hagan.okstate.edu/NNDesign.pdf">Neural Network Design</A>
							<DT><A HREF="https://www.youtube.com/watch?v=L3-WFKCW-tY&t=2624s">33. Neural Nets and the Learning Function - YouTube</A>
							<DT><A HREF="https://blog.janestreet.com/visualizing-piecewise-linear-neural-networks/">Jane Street Tech Blog - Visualizing piecewise linear neural networks</A>
							<DT><A HREF="https://arxiv.org/abs/1312.6098">[1312.6098] On the number of response regions of deep feed forward networks with piece-wise linear activations</A>
							<DT><A HREF="https://www.youtube.com/watch?v=AKMuA_TVz3A&t=2612s">An Observation on Generalization - YouTube</A>
							<DT><A HREF="https://lilianweng.github.io/posts/2017-09-28-information-bottleneck/">Anatomize Deep Learning with Information Theory | Lil'Log</A>
							<DT><A HREF="https://arxiv.org/abs/2310.19956">[2310.19956] The Impact of Depth on Compositional Generalization in Transformer Language Models</A>
							<DT><A HREF="https://x.com/i/bookmarks?post_id=1863100717868654951">Analyzing the global convergence of Newton is hard. Attraction basins are fractals whose boundaries are points which do not converge.</A>
							<DT><A HREF="https://arxiv.org/abs/2411.07191">[2411.07191] The Super Weight in Large Language Models</A>
							<DT><A HREF="https://www.youtube.com/watch?v=YpFaPKOeNME">NEURAL NETWORKS ARE REALLY WEIRD... - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=-uyXE7dY5H0&t=1075s">NIPS: Oral Session 4 - Ilya Sutskever - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=w3ues-NayAs">NVIDIA NTECH 2018 - Ilya Sutskever Keynote Talk - YouTube</A>
							<DT><A HREF="https://sakana.ai/ctm/">Introducing Continuous Thought Machines</A>
							<DT><A HREF="https://www.youtube.com/watch?v=0vglBR2-Ubk&list=PLLalUvky4CLK3oT1DKNPagd_lTXooYVlR&index=10">Katrina Lawrence - ML Math Refresher - YouTube</A>
							<DT><A HREF="https://x.com/tetsuoai/status/1982056085554073690">Tetsuo en X: "Andrej Karpathy summarizes how neural networks function, including the process of using a loss function in training and applying backpropagation for optimizing the network parameters through gradient descent. https://t.co/2ez08Jec3X" / X</A>
						</DL><p>
						<DT><H3 FOLDED>deep-learning-people</H3>
						<DL><p>
							<DT><H3 FOLDED>Michael Bronstein</H3>
							<DL><p>
								<DT><A HREF="https://towardsdatascience.com/predictions-and-hopes-for-geometric-graph-ml-in-2022-aa3b8b79f5cc">What does 2022 hold for Geometric &amp; Graph ML?</A>
								<DT><A HREF="https://arxiv.org/abs/2104.13478">Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges</A>
								<DT><A HREF="https://medium.com/stanford-cs224w/tackling-the-traveling-salesman-problem-with-graph-neural-networks-b86ef4300c6e">Tackling the Traveling Salesman Problem with Graph Neural Networks | by Michael Atkin | Stanford CS224W GraphML Tutorials | May, 2023 | Medium</A>
							</DL><p>
							<DT><A HREF="https://twitter.com/agikoala/status/1641838208823468032/photo/1">(1) jason en X: "Three starter pokemon in deep learning</A>
							<DT><A HREF="https://scholar.google.com/citations?user=x04W_mMAAAAJ">‚Ä™Ilya Sutskever‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							<DT><A HREF="https://scholar.google.com/citations?user=NkzyCvUAAAAJ&hl=en">‚Ä™Oriol Vinyals‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							<DT><A HREF="https://scholar.google.com/citations?user=vfT6-XIAAAAJ&hl=en">‚Ä™Quoc V. Le‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							<DT><A HREF="https://scholar.google.co.uk/citations?user=DaFHynwAAAAJ&hl=en">‚Ä™Alex Graves‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							<DT><A HREF="https://www.yitay.net/">Yi Tay</A>
							<DT><A HREF="https://www.jasonwei.net/thoughts">Thoughts ‚Äî Jason Wei</A>
							<DT><A HREF="https://hwchung27.github.io/">Hyung Won Chung</A>
							<DT><A HREF="https://twitter.com/ilyasut/status/1790517455628198322">(1) Ilya Sutskever en X: "After almost a decade, I have made the decision to leave OpenAI. ¬†The company‚Äôs trajectory has been nothing short of miraculous, and I‚Äôm confident that OpenAI will build AGI that is both safe and beneficial under the leadership of @sama, @gdb, @miramurati and now, under the" / X</A>
							<DT><A HREF="https://twitter.com/merettm">akub Pachocki (OpenAI dota bot)</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Ckz8XA2hW84&list=LL&index=14&t=1s">Ilya Sutskever (OpenAI) and Jensen Huang (NVIDIA CEO) : AI Today and Vision of the Future (3/2023) - YouTube</A>
							<DT><A HREF="https://www.linkedin.com/in/alecradford/">Alec Radford</A>
							<DT><A HREF="https://www.linkedin.com/in/markchen90/">Mark Chen: Head of Fronteirs Research at OpenAI</A>
							<DT><A HREF="https://x.com/peterthedecent">(1) Peter (@peterthedecent) / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=AJV4WLSc4pw">Ilya Sutskever |Neuroscience has brought many very important great ideas to AI|The first year of AGI - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>deep-learning-lectures</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=bZF4N8HR1cc">09 ‚Äì AE, DAE, and VAE with PyTorch; generative adversarial networks (GAN) and code - YouTube</A>
							<DT><A HREF="https://mlcollective.org/dlct/">ML Collective</A>
							<DT><A HREF="https://informationisbeautiful.net/">Information is Beautiful</A>
							<DT><A HREF="https://www.youtube.com/watch?v=v7arCzjQk38">Robust Gradient Descent: Agnostically Estimating an Unknown Affine Transformation... - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=MRNrbLRxNyg">Toward a Grand Unified Theory of Accelerations in Optimization and Machine Learning - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=M74WKIh0ciI&list=LL&index=24">Three weight matrices in a neural network growing connections as two parallel networks are merged. - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=EI6k2g9CUHo">Baharan Mirzasoleiman - How Structure Helps in Machine Learning - YouTube</A>
							<DT><A HREF="https://nn.labml.ai/unet/index.html">U-Net</A>
							<DT><A HREF="https://github.com/Atcold/NYU-DLSP21">Atcold/NYU-DLSP21: NYU Deep Learning Spring 2021</A>
							<DT><A HREF="https://atcold.github.io/NYU-DLSP21/">DEEP LEARNING ¬∑ Deep Learning</A>
							<DT><A HREF="https://uvadlc.github.io/">UvA Deep Learning Course (Amsterdam)</A>
							<DT><A HREF="https://mathematical-tours.github.io/maths-ia-course/">The Mathematics of IA - Mathematical Tours of Data Sciences</A>
							<DT><A HREF="https://cs229.stanford.edu/lectures-spring2022/main_notes.pdf">CS229 Lecture Notes</A>
							<DT><A HREF="https://www.youtube.com/watch?v=UOvPeC8WOt8">The Neural Network, A Visual Introduction - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ys-G9uEW3O0">02 ‚Äì Discrete probability recap, NaiÃàve Bayes classification - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=BjyZcSiVg5A">Deep Learning Theory Session. Ilya SutskeverIlya Sutskever - YouTube</A>
							<DT><A HREF="https://github.com/EurekaLabsAI">EurekaLabsAI</A>
						</DL><p>
						<DT><H3 FOLDED>deep-learning-books</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=kuvFoXzTK3E">Prof. Chris Bishop's NEW Deep Learning Textbook (Microsoft)</A>
							<DT><A HREF="https://www.cis.upenn.edu/~jean/math-deep.pdf">Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning</A>
						</DL><p>
						<DT><H3 FOLDED>deep-learning-tuning</H3>
						<DL><p>
							<DT><A HREF="https://damek.github.io/STAT-4830/section/11/notes.html">A Playbook for Tuning Deep Learning Models | STAT 4830: Numerical Optimization for Data Science and Machine Learning</A>
							<DT><A HREF="https://github.com/google-research/tuning_playbook">google-research/tuning_playbook: A playbook for systematically maximizing the performance of deep learning models.</A>
						</DL><p>
						<DT><H3 FOLDED>Machine Learning</H3>
						<DL><p>
							<DT><H3 FOLDED>Physics-Informed Learning</H3>
							<DL><p>
								<DT><A HREF="https://mitmath.github.io/18337/lecture15/diffeq_machine_learning">Mixing Differential Equations and Neural Networks</A>
								<DT><A HREF="https://www.youtube.com/channel/UCDtsHjkOEMHYPGgpKX8VOPg/videos">Parallel Computing and Scientific Machine Learning (MIT 2021 Spring)</A>
								<DT><A HREF="https://twitter.com/martinmbauer/status/1529705943386275842">Protons are not fundamental particles, but dynamical systems made of quarks and gluons.</A>
								<DT><A HREF="https://twitter.com/thuereyGroup/status/1529177918479511552">How much does training with a differentiable physics simulator really improve things?</A>
								<DT><A HREF="https://www.youtube.com/watch?v=5P19hROy9vk">Why Quantum Mechanics Uses the Physics of SPRINGS - Quantum Harmonic Oscillators EXPLAINED - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=GCz6afDVy5Y">AI/ML+Physics: Recap and Summary [Physics Informed Machine Learning] - YouTube</A>
								<DT><A HREF="https://x.com/oharub/status/1863616236497633596">(1) Ruben Ohana en X: "Generating cat videos is nice, but what if you could tackle real scientific problems with the same methods? üß™üåå Introducing The Well: 16 datasets (15TB) for Machine Learning, from astrophysics to fluid dynamics and biology. üêô: https://t.co/PMAHK7i2lG üìú: https://t.co/6XLJA5lJnI https://t.co/1uqb0XUV4s" / X</A>
							</DL><p>
							<DT><H3 FOLDED>ml-cs</H3>
							<DL><p>
								<DT><A HREF="http://cs229.stanford.edu/syllabus.html">CS229: Machine Learning</A>
								<DT><A HREF="http://cs229.stanford.edu/#info">CS229: Machine Learning</A>
								<DT><A HREF="https://www.youtube.com/@machinelearningatberkeley8868">Machine Learning at Berkeley - YouTube</A>
							</DL><p>
							<DT><A HREF="https://www.simonwenkel.com/index.html">SimonWenkel.com</A>
							<DT><A HREF="https://developers.google.com/machine-learning/glossary/">Machine Learning Glossary ¬†|¬† Google Developers</A>
							<DT><A HREF="https://github.com/ageron/handson-ml2">handson-ml2: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.</A>
							<DT><A HREF="https://www.eleuther.ai/beginners.pdf">A Beginner‚Äôs Guide to Machine Learning</A>
							<DT><A HREF="https://github.com/ageron/handson-ml2">Fundamentals of Machine Learning and Deep Learning in Python (Sklearn, Keras, TensorFlow v2)</A>
							<DT><A HREF="https://snap-research.github.io/BitsFusion/">Snap.Inc: BitsFusion</A>
						</DL><p>
						<DT><H3 FOLDED>Constractive Learning</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2002.05709">A Simple Framework for Contrastive Learning of Visual Representations</A>
							<DT><A HREF="https://arxiv.org/abs/1911.05722">Momentum Contrast for Unsupervised Visual Representation Learning</A>
							<DT><A HREF="https://crfm.stanford.edu/2022/04/14/contrastive-learning.html">Understanding Deep Learning with Unlabeled Data: Contrastive Learning</A>
						</DL><p>
						<DT><H3 FOLDED>Unsupervised learing</H3>
						<DL><p>
							<DT><H3 FOLDED>Self-Supervised Learning</H3>
							<DL><p>
								<DT><H3 FOLDED>DINO</H3>
								<DL><p>
									<DT><H3 FOLDED>DINOv3</H3>
									<DL><p>
										<DT><A HREF="https://x.com/chrisoffner3d/status/1957731313747661132">How I read DINOv3</A>
										<DT><A HREF="https://www.youtube.com/watch?v=oGTasd3cliM">How AI Taught Itself to See [DINOv3] - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>DINOv2</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=mfXNi092n6o&list=PLLalUvky4CLK3oT1DKNPagd_lTXooYVlR&index=1">TimotheÃÅe Darcet - Scaling Self Supervised Learning for Vision An Introduction to DINOv2 - YouTube</A>
										<DT><A HREF="https://dinov2.metademolab.com/">DINOv2 by Meta AI</A>
										<DT><A HREF="https://github.com/facebookresearch/dinov2">facebookresearch/dinov2: PyTorch code and models for the DINOv2 self-supervised learning method.</A>
										<DT><A HREF="https://x.com/gabriberton/status/1974966188393513282">(1) Gabriele Berton en X: "Someone got started on this and it looks like DINOv2 outperforms DINOv3 üî• Link to the post + report in the comments If someone else wants to join the effort, do contact Emmanuel - hopefully a team effort will succeed in finding a better backbone for VPR https://t.co/DlOYrPECBl" / X</A>
									</DL><p>
									<DT><A HREF="https://github.com/facebookresearch/dino">facebookresearch/dino: PyTorch code for Vision Transformers training with the Self-Supervised learning method DINO</A>
									<DT><A HREF="https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/dino.py">vit-pytorch/vit_pytorch/dino.py at main ¬∑ lucidrains/vit-pytorch</A>
									<DT><A HREF="https://x.com/Almorgand/status/1872598770179035191">DINO-X: A unified vision model for open-world object detection and understanding</A>
									<DT><A HREF="https://x.com/TongPetersb/status/1907477153202971022">Peter Tong en X: "Vision models have been smaller than language models; what if we scale them up? Introducing Web-SSL: A family of billion-scale SSL vision models (up to 7B parameters) trained on billions of images without language supervision, using VQA to evaluate the learned representation. https://t.co/TF0llXGGWf" / X</A>
									<DT><A HREF="https://na-vae.github.io/dino_perceptual/">uv pip install dino-perceptual</A>
								</DL><p>
								<DT><H3 FOLDED>JEPA</H3>
								<DL><p>
									<DT><H3 FOLDED>I-JEPA</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/docs/transformers/en/model_doc/ijepa">I-JEPA</A>
									</DL><p>
									<DT><H3 FOLDED>V-JEPA</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2404.08471">[2404.08471] Revisiting Feature Prediction for Learning Visual Representations from Video</A>
										<DT><A HREF="https://ksagar.bearblog.dev/vjepa/">how we accidentally solved robotics by watching 1 million hours of YouTube | atharva's blog</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=jSdHmImyUjk&ab_channel=YannicKilcher">JEPA - A Path Towards Autonomous Machine Intelligence (Paper Explained) - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs/2307.12698">[2307.12698] MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features</A>
									<DT><A HREF="https://github.com/facebookresearch/jepa">facebookresearch/jepa: PyTorch code and models for V-JEPA self-supervised learning from video.</A>
									<DT><A HREF="https://openreview.net/forum?id=BZ5a1r-kVsf">A Path Towards Autonomous Machine Intelligence | OpenReview</A>
									<DT><A HREF="https://x.com/ylecun/status/2007907701989232684?s=12">(1) Yann LeCun en X: "@_arohan_ I think you missed the main ideas. - The basic premise of JEPA is that training by reconstructio/prediction in input space is evil (or counterproductive). The details are almost always unpredictable. Hence prediction must take place in representation space, where unpredictable" / X</A>
								</DL><p>
								<DT><H3 FOLDED>DoRA</H3>
								<DL><p>
									<DT><A HREF="https://shashankvkt.github.io/dora">Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video</A>
								</DL><p>
								<DT><A HREF="https://openreview.net/pdf?id=Yen1lGns2o">IS IMAGENET WORTH 1 VIDEO? LEARNING STRONG IMAGE ENCODERS FROM 1 LONG UNLABELLED VIDEO</A>
								<DT><A HREF="https://arxiv.org/abs/2103.00020">CLIP: Learning Transferable Visual Models From Natural Language Supervision</A>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1744716166290096161">(Yann LeCun) Adaptive linear classifiers</A>
								<DT><A HREF="https://github.com/imbue-ai/self_supervised">imbue-ai/self_supervised: A Pytorch-Lightning implementation of self-supervised algorithms</A>
								<DT><A HREF="https://github.com/microsoft/unilm">microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities</A>
								<DT><A HREF="https://kexue.fm/archives/9359">Using the heat equation to guide self-supervised learning</A>
								<DT><A HREF="https://x.com/nrehiew_/status/1864677276731777136">(1) wh en X: "1 of the top papers from ICLR 2024 (honourable mention) tldr: introduce a new self-supervised learning method for vision. Training on a single video matches models trained on imagenet https://t.co/kF84CoBPy2" / X</A>
								<DT><A HREF="https://x.com/TongPetersb/status/1907477153202971022">Peter Tong en X: "Vision models have been smaller than language models; what if we scale them up? Introducing Web-SSL: A family of billion-scale SSL vision models (up to 7B parameters) trained on billions of images without language supervision, using VQA to evaluate the learned representation. https://t.co/TF0llXGGWf" / X</A>
								<DT><A HREF="https://www.simonsfoundation.org/event/self-supervised-learning-the-final-frontier-of-ai/">Self Supervised Learning: The Final Frontier of AI</A>
								<DT><A HREF="https://www.youtube.com/watch?v=mfXNi092n6o&list=PLLalUvky4CLK3oT1DKNPagd_lTXooYVlR&index=1">TimotheÃÅe Darcet - Scaling Self Supervised Learning for Vision An Introduction to DINOv2 - YouTube</A>
								<DT><A HREF="https://x.com/SchmidhuberAI/status/1991605057989521758">(1) J√ºrgen Schmidhuber en X: "25 years later, @ylecun's 2015 slide rehashed the 1990 paper on a recurrent neural "world model" that predicts all sensory inputs including pixels and multi-dimensional reward signals &amp;amp; pain signals: J. Schmidhuber. Making the world differentiable: On using fully recurrent https://t.co/2J903TtUe5" / X</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=AKMuA_TVz3A">An Observation on Generalization: "I have not seen an exposition of unsupervised learning that I found satisfying"</A>
						</DL><p>
						<DT><H3 FOLDED>blueprint</H3>
						<DL><p>
							<DT><H3 FOLDED>Tensor Programs</H3>
							<DL><p>
								<DT><A HREF="https://thegregyang.com/">Greg Yang |¬†Professional page</A>
								<DT><A HREF="https://arxiv.org/abs/2310.02244">[2310.02244] Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks</A>
								<DT><A HREF="https://www.youtube.com/watch?v=1aXOXHA7Jcw&t=7148s">Greg Yang | Large N Limits: Random Matrices &amp; Neural Networks | The Cartesian Cafe w/ Timothy Nguyen - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>blueprint-geometric-deep-learninng</H3>
							<DL><p>
								<DT><H3 FOLDED>geometric-deep-learninng-papers</H3>
								<DL><p>
									<DT><A HREF="https://geometricdeeplearning.com/">Geometric Deep Learning - Grids, Groups, Graphs, Geodesics, and Gauges</A>
									<DT><A HREF="https://www.youtube.com/watch?v=e5233FYNfNQ">Math Reading Group - Geometric Deep Learning I (06/08/23) - YouTube</A>
									<DT><A HREF="https://geometricdeeplearning.com/lectures/">GDL Course</A>
									<DT><A HREF="https://arxiv.org/abs/2408.00949">[2408.00949] Equivariant neural networks and piecewise linear representation theory</A>
									<DT><A HREF="https://thegradient.pub/towards-geometric-deep-learning/">Towards Geometric Deep Learning</A>
								</DL><p>
								<DT><H3 FOLDED>geometric-deep-learninng-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=PtA0lg_e5nA&list=PLn2-dEmQeTfQ8YVuHBOvAhUlnIPYxkeu3">youtube</A>
									<DT><A HREF="https://medium.com/towards-data-science/geometric-deep-learning-da09e7c17aa3">Introduction to Geometric Deep Learning | by Ahmed A. A. Elhag</A>
								</DL><p>
								<DT><H3 FOLDED>geometric-deep-learninng-software</H3>
								<DL><p>
									<DT><A HREF="https://blog.paperspace.com/geometric-deep-learning-framework-comparison/">Geometric Deep Learning Library Comparison | Paperspace Blog</A>
									<DT><A HREF="https://medium.com/towards-data-science/graph-neural-networks-a-learning-journey-since-2008-from-python-to-jax-graph-attention-networks-692e4d6d7637">Graph Neural Networks: A learning journey since 2008 ‚Äî From Python to JAX: Graph Attention Networks | by Stefano Bosisio | Mar, 2022 | Towards Data Science</A>
									<DT><A HREF="https://twitter.com/phillip_lippe/status/1536340878960173057">"Are you interested in learning JAX with Flax? We have translated our popular Deep Learning tutorials on CNNs, GNNs, (Vision) Transformers, and more from PyTorch to JAX+Flax, with considerable speedups for smaller models!</A>
									<DT><A HREF="https://github.com/phlippe/uvadlc_notebooks">phlippe/uvadlc_notebooks: Repository of Jupyter notebook tutorials for teaching the Deep Learning Course at the University of Amsterdam (MSc AI), Fall 2021/Spring 2022</A>
									<DT><A HREF="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html">Tutorial 2 (JAX): Introduction to JAX+Flax ‚Äî UvA DL Notebooks v1.2 documentation</A>
									<DT><A HREF="https://uvadlc-notebooks.readthedocs.io/en/latest/index.html">Welcome to the UvA Deep Learning Tutorials! ‚Äî UvA DL Notebooks v1.2 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>Graph Neural Networks</H3>
								<DL><p>
									<DT><A HREF="http://snap.stanford.edu/graphsage/">GraphSAGE: embedding framework</A>
									<DT><A HREF="https://towardsdatascience.com/transformers-are-graph-neural-networks-bca9f75412aa">Transformers are Graph Neural Networks</A>
									<DT><A HREF="https://www.youtube.com/watch?v=7KMcXHwQzZs">Michael Bronstein | Neural diffusion PDEs, differential geometry, and graph neural networks</A>
									<DT><A HREF="https://towardsdatascience.com/manifold-learning-2-99a25eeb677d">Latent graph neural networks: Manifold learning 2.0?</A>
									<DT><A HREF="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to Graph Neural Networks</A>
									<DT><A HREF="https://bookdown.org/omarlizardo/_main/4-6-network-composition-homophily-measures.html">4.6 Network Composition-Homophily Measures</A>
									<DT><H3 FOLDED>theory</H3>
									<DL><p>
										<DT><A HREF="https://ncatlab.org/nlab/show/Lipschitz+map">Lipschitz map</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/Banach+space">Banach space</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/permutation">permutation</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/linear%20order">linear order</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/cartesian+product">cartesian product</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/hypergraph">hypergraph in nLab</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/span">span in nLab</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/Bayesian+reasoning">Bayesian reasoning in nLab</A>
										<DT><A HREF="https://ncatlab.org/nlab/show/probability+space">probability space in nLab</A>
										<DT><A HREF="https://en.wikipedia.org/wiki/Network_homophily">homophily</A>
									</DL><p>
									<DT><H3 FOLDED>PDE</H3>
									<DL><p>
										<DT><A HREF="https://blog.twitter.com/engineering/en_us/topics/insights/2021/graph-neural-networks-as-neural-diffusion-pdes">Graph Neural Networks as Neural Diffusion PDEs</A>
										<DT><A HREF="https://towardsdatascience.com/graph-neural-networks-beyond-weisfeiler-lehman-and-vanilla-message-passing-bc8605fa59a">Graph Neural Networks beyond Weisfeiler-Lehman and vanilla Message Passing</A>
										<DT><A HREF="https://www.youtube.com/watch?v=9SMbH18nMUg">Graph Neural Networks and Diffusion PDEs | Benjamin Chamberlain &amp; James Rowbottom - YouTube</A>
									</DL><p>
									<DT><A HREF="https://twitter.com/n_keriven/status/1529404489832308736">Theoretical analysis of graph (over)smoothing</A>
									<DT><A HREF="https://twitter.com/rampasek/status/1536534947825176577">Graph Transformers at scale</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Network_homophily">homophily</A>
									<DT><A HREF="https://towardsdatascience.com/predictions-and-hopes-for-geometric-graph-ml-in-2022-aa3b8b79f5cc">What does 2022 hold for Geometric &amp; Graph ML?</A>
									<DT><A HREF="https://towardsdatascience.com/using-subgraphs-for-more-expressive-gnns-8d06418d5ab">Using Subgraphs for More Expressive GNNs | by Michael Bronstein | Towards Data Science</A>
									<DT><A HREF="https://graphdeeplearning.github.io/post/benchmarking-gnns/">Benchmarking Graph Neural Networks | NTU Graph Deep Learning Lab</A>
									<DT><A HREF="https://distill.pub/2021/understanding-gnns/">Understanding Convolutions on Graphs</A>
								</DL><p>
								<DT><A HREF="https://michael-bronstein.medium.com/">Michael Bronstein ‚Äì Medium (Geometrical Deep Learning)</A>
								<DT><A HREF="https://www.quantamagazine.org/researchers-build-ai-that-builds-ai-20220125/">Researchers Build AI That Builds AI | Quanta Magazine</A>
								<DT><A HREF="https://www.youtube.com/watch?v=rie-9AEhYdY">WE MUST ADD STRUCTURE TO DEEP LEARNING BECAUSE... - YouTube</A>
								<DT><A HREF="https://x.com/PetarV_93/status/1821543305274167767">(1) Petar Veliƒçkoviƒá en X: "I don't think I've been this excited about a geometric deep learning paper in a long time ü§Ø Gibson, Tubbenhauer and Williamson: Equivariant neural networks and piecewise linear representation theory https://t.co/9DSlEnke9H" / X</A>
							</DL><p>
							<DT><A HREF="https://twitter.com/TheGregYang/status/1711803863177855033">Infinite Depth Neural Networks (Greg Yang)</A>
							<DT><A HREF="https://twitter.com/TheGregYang/status/1709700104951931077">Neural Nets: What if depth -&gt; inf as well?</A>
							<DT><A HREF="https://twitter.com/hayou_soufiane/status/1622594202042499073">Q: What happens to the neural covariance when both Width and Depth are taken to infinity?</A>
							<DT><A HREF="https://irhum.github.io/blog/spherical-harmonics/">irhum.github.io - Visual Notes on Spherical Harmonics</A>
							<DT><A HREF="https://github.com/P2333/Bag-of-Tricks-for-AT">P2333/Bag-of-Tricks-for-AT: Empirical tricks for training robust models (ICLR 2021)</A>
						</DL><p>
						<DT><H3 FOLDED>The Bitter Leasson</H3>
						<DL><p>
							<DT><A HREF="https://twitter.com/polynoamial/status/1789381426187546644">(1) Noam Brown en X: "@jxmnop The point of the Bitter Lesson is that research and clever ideas are important, but people should think about how their ideas scale with data and compute rather than just relying on One Weird Trick to get them a little farther than SOTA." / X</A>
							<DT><A HREF="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson</A>
							<DT><A HREF="https://twitter.com/polynoamial">(1) Noam Brown (@polynoamial) / X</A>
						</DL><p>
						<DT><H3 FOLDED>SDE vs ODE</H3>
						<DL><p>
							<DT><A HREF="https://twitter.com/wgilpin0/status/1737934963365056543">William Gilpin: "Can machine learning predict chaos?</A>
						</DL><p>
						<DT><H3 FOLDED>Neural Architecture Search</H3>
						<DL><p>
							<DT><A HREF="https://blog.research.google/2022/02/unlocking-full-potential-of-datacenter.html">Unlocking the Full Potential of Datacenter ML Accelerators with Platform-Aware Neural Architecture Search ‚Äì Google Research Blog</A>
							<DT><A HREF="https://x.com/antferdom/status/1799474799661691014">xLSTM won't replace the Transformer. Two bitter lessons</A>
						</DL><p>
						<DT><H3 FOLDED>differentiable neural computers</H3>
						<DL><p>
							<DT><A HREF="https://jaspock.github.io/funicular/dnc.html">A bit-by-bit guide to the equations governing differentiable neural computers</A>
							<DT><A HREF="https://gwern.net/doc/reinforcement-learning/model-free/2016-graves.pdf">https://gwern.net/doc/reinforcement-learning/model-free/2016-graves.pdf</A>
							<DT><A HREF="https://deepmind.google/discover/blog/differentiable-neural-computers/">Differentiable neural computers - Google DeepMind</A>
						</DL><p>
						<DT><H3 FOLDED>deep-learning-debugging</H3>
						<DL><p>
							<DT><H3 FOLDED>silent data corruption (SDC)</H3>
							<DL><p>
								<DT><A HREF="https://dl.acm.org/doi/abs/10.1145/3620666.3651349">Dr. DNA: Combating Silent Data Corruptions in Deep Learning using Distribution of Neuron Activations | Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3</A>
								<DT><A HREF="https://dl.acm.org/doi/pdf/10.1145/3620666.3651349">Dr. DNA: Combating Silent Data Corruptions in Deep Learning using Distribution of Neuron Activations</A>
								<DT><A HREF="https://www.youtube.com/watch?v=FVeN60d55oc">ASPLOS'24 - Lightning Talks - Session 9C - Dr DNA: Combating Silent Data Corruptions in Deep Learni - YouTube</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>deep double descent</H3>
						<DL><p>
							<DT><A HREF="https://openai.com/index/deep-double-descent/">Deep double descent | OpenAI</A>
							<DT><A HREF="https://www.youtube.com/watch?v=W_TAKJRgrbs">Ilya Sutskever on Deep Double Descent - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=5I7-ItaOZFU&t=7s">Double Descent explained by Yann LeCun - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=qRHdQz_P_Lo&t=1s">Statistical Learning: 10.7 Interpolation and Double Descent - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Kih-VPHL3gA">Deep Double Descent and Overparameterization: Classical Machine Learning vs. Modern Deep Learning - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=7L9wVeStNPA">Deep Double Descent: Where Bigger Models and More Data Hurts - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Grokking</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=dND-7llwrpw&t=230s">Grokking: Generalization beyond Overfitting on small algorithmic datasets (Paper Explained) - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Nvb_4Jj5kBo">Why "Grokking" AI Would Be A Key To AGI - YouTube</A>
							<DT><A HREF="https://colab.research.google.com/drive/1t6OOJ1dcmsESxZ_4gbaJFEdn1xe8Vrnd?usp=sharing">Grokking on the Addition-Modulo-113 Task in 43 Full-Batch Training Steps.ipynb - Colab</A>
							<DT><A HREF="https://x.com/ericjang11/status/2011611913424421149">(1) Eric Jang en X: "This is an extremely beautiful plot because it sheds light on why scaling laws are so smooth, and reconciles empirical findings from both scaling laws and grokking. Even though mean loss across all tasks (red line) decreases smoothly, we see that individual subtask losses drop" / X</A>
							<DT><A HREF="https://ericjmichaud.com/quanta/">On neural scaling and the quanta hypothesis</A>
						</DL><p>
						<DT><H3 FOLDED>Meta-Learning and Self-Play</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=9EN_HoEk3KY">Ilya Sutskever: OpenAI Meta-Learning and Self-Play | MIT Artificial General Intelligence (AGI) - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>GFlowNets</H3>
						<DL><p>
							<DT><A HREF="https://machinelearning.apple.com/research/improving-gflownets">Improving GFlowNets for Text-to-Image Diffusion Alignment - Apple Machine Learning Research</A>
						</DL><p>
						<DT><H3 FOLDED>inverse problems</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=038QxC5kTLk&list=LL&index=16&t=666s">Giannis Daras - Generative Models and Comp. Imaging: Soft Diffusion and Learning from Corrupted Data - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=9Y8NKkuPhC0&list=LL&index=17&t=4s">Hyungjin Chung - Adapting and Regularizing Diffusion Models for Inverse Problems - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Time-Series</H3>
						<DL><p>
							<DT><A HREF="https://huggingface.co/ibm-granite/granite-timeseries-patchtst">ibm-granite/granite-timeseries-patchtst ¬∑ Hugging Face</A>
							<DT><A HREF="https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/">A decoder-only foundation model for time-series forecasting</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Time_series">Time series - Wikipedia</A>
							<DT><A HREF="https://github.com/google-research/timesfm">google-research/timesfm: TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.</A>
							<DT><A HREF="https://huggingface.co/google/timesfm-1.0-200m">google/timesfm-1.0-200m ¬∑ Hugging Face</A>
							<DT><A HREF="https://arxiv.org/pdf/2310.10688">A DECODER-ONLY FOUNDATION MODEL FOR TIME-SERIES FORECASTING</A>
							<DT><A HREF="https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/">GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy - Google DeepMind</A>
							<DT><A HREF="https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting">Jane Street Real-Time Market Data Forecasting | Kaggle</A>
							<DT><A HREF="https://www.youtube.com/watch?v=SeBoia7jcnI&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=129">‚ÄúMany-model‚Äù Time Series Forecasting: Scaling PyTorch Training Across 1000s...- V. Sridhar &amp; S. Chen - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>continuous learning</H3>
						<DL><p>
							<DT><H3 FOLDED>Peilin Zhong</H3>
							<DL><p>
								<DT><A HREF="https://scholar.google.com/citations?user=l4ffN_QAAAAJ&hl=en">‚Ä™Peilin Zhong‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							</DL><p>
							<DT><H3 FOLDED>nested learning</H3>
							<DL><p>
								<DT><A HREF="https://research.google/blog/introducing-nested-learning-a-new-ml-paradigm-for-continual-learning/">Introducing Nested Learning: A new ML paradigm for continual learning</A>
							</DL><p>
							<DT><A HREF="https://adaptionlabs.ai/">Adaptable Intelligence - Building the Future</A>
							<DT><A HREF="https://x.com/giffmana/status/1980869216149619009">(1) Lucas Beyer (bl16) en X: "One sign of this being a really cool idea is that while reading, I had tons of follow-up ideas immediately come to mind, and only few "hmm but"s. Plz read thread and paper, but TLDR: add layer of input independent kv, and fine-tune only the high tfidf kvs for continual learning." / X</A>
							<DT><A HREF="https://github.com/zartbot/blog/issues">Issues ¬∑ zartbot/blog</A>
						</DL><p>
						<DT><H3 FOLDED>deep-learning-architecture</H3>
						<DL><p>
							<DT><H3 FOLDED>resnet</H3>
							<DL><p>
								<DT><A HREF="https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html">resnet50 ‚Äî Torchvision main documentation</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://x.com/MajmudarAdam/status/1794190796411027791">History of deep learning (core)</A>
						<DT><A HREF="https://gist.github.com/matijagrcic/ae8353eb1e6be84a7c85d9fdc2f9631f">Ilya Sutskever reading list.md</A>
						<DT><A HREF="https://github.com/google-research/tuning_playbook">google-research/tuning_playbook: A playbook for systematically maximizing the performance of DNN</A>
						<DT><A HREF="https://twitter.com/agikoala/status/1641838208823468032/photo/1">(1) jason en X: "Three starter pokemon in deep learning https://t.co/u6RZqrvsAJ" / X</A>
						<DT><A HREF="https://twitter.com/prateeky2806/status/1665759148380758022">Mergin diff task-specific models into a multi-task model</A>
						<DT><A HREF="https://www.youtube.com/watch?v=pA-azVdihQc&t=1890s">What is Machine Learning Good For? - Alex Davies - YouTube</A>
						<DT><A HREF="https://arxiv.org/pdf/2002.09398.pdf">It‚Äôs Not What Machines Can Learn, It‚Äôs What We Cannot Teach (DeepMind Math Reasoning)</A>
						<DT><A HREF="https://www.youtube.com/watch?v=5exL8UYxpsI&t=63s">IFML SEMINAR: 1/26/24 - Meta Optimization (Google DeepMind)</A>
						<DT><A HREF="https://starai.cs.ucla.edu/papers/ZhangIJCAI23.pdf">On the Paradox of Learning to Reason from Data</A>
						<DT><A HREF="https://github.com/gregorbachmann/scaling_mlps">gregorbachmann/scaling_mlps</A>
						<DT><A HREF="https://www.youtube.com/watch?v=1menqhfNzzo">Stanford EE364A Convex Optimization I Stephen Boyd I 2023 I Lecture 3 - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=6_v9Ogi7P6Q">Topology for Energy-Based models</A>
						<DT><A HREF="https://arxiv.org/abs/2403.14606">[2403.14606] The Elements of Differentiable Programming</A>
						<DT><A HREF="https://scholar.google.co.uk/citations?view_op=view_citation&hl=en&user=DaFHynwAAAAJ&citation_for_view=DaFHynwAAAAJ:isC4tDSrTZIC">Neural turing machines (main)</A>
						<DT><A HREF="https://www.youtube.com/watch?v=yZ-HT81qYuE">What is Differentiable Programming - YouTube</A>
						<DT><A HREF="https://twitter.com/BenTheEgg">Each new layer adds residual information,  so simple concepts are nailed early, complex ones late</A>
						<DT><A HREF="https://www.youtube.com/watch?v=EvSe0ktD95k&t=7s">A Path Towards Autonomous Machine Intelligence with Dr. Yann LeCun - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=GyKlMcsl72w">00 ‚Äì Course introduction - YouTube</A>
						<DT><A HREF="https://stanford-cs336.github.io/spring2024/">Stanford CS336 | Language Modeling from Scratch</A>
						<DT><A HREF="https://rentry.org/LocalModelsPapers">Local Models Related Papers</A>
						<DT><A HREF="https://www.youtube.com/watch?v=GxjEjy5UYJU&t=25s">AI Reading List (by Ilya Sutskever) - Part 2 - YouTube</A>
						<DT><A HREF="https://github.com/NVIDIA/DeepLearningExamples/tree/master">NVIDIA/DeepLearningExamples: State-of-the-Art Deep Learning scripts organized by models</A>
						<DT><A HREF="https://github.com/adam-maj/deep-learning">adam-maj/deep-learning: A deep-dive on the entire history of deep-learning</A>
						<DT><A HREF="https://twopug.com/interview-prep-ml-grind/">Interview Prep: The ML Grind | ‡´Æ ‚öÜÔªå‚öÜ·Éê Two Pug ‡´Æ ‚ÄìÔªå‚öÜ·Éê</A>
						<DT><A HREF="https://kexue.fm/content.html">ÂΩíÊ°£ - ÁßëÂ≠¶Á©∫Èó¥|  kexue.fm</A>
						<DT><A HREF="https://x.com/ID_AA_Carmack/status/2013818129441288687">(4) John Carmack en X: "#PaperADay 8 Beyond Gradient Averaging in Parallel Optimization: Improved Robustness through Gradient Agreement Filtering https://t.co/enOdsiBHny Recommended by @FrancoisChauba1 after yesterday‚Äôs paper. Proposes Gradient Agreement Filtering (GAF), where independent gradients" / X</A>
						<DT><A HREF="https://rohin-garg.github.io/kexue-en/index.html">Scientific Spaces - English Translations kexue.fm by Su Jianlin</A>
						<DT><A HREF="https://x.com/ID_AA_Carmack/status/2009728677718712655">(1) John Carmack en X: "#PaperADay 2 2026: Deep Delta Learning https://t.co/fcNuN6bPmt The standard residual network blocks are limited to adding on top of the existing state, which limits the expressivity of each layer. It is still a universal approximator, but we can always hope for function blocks" / X</A>
					</DL><p>
					<DT><H3 FOLDED>Reinforcement Learning</H3>
					<DL><p>
						<DT><H3 FOLDED>search-and-learning</H3>
						<DL><p>
							<DT><H3 FOLDED>Game Theory</H3>
							<DL><p>
								<DT><A HREF="https://pub.towardsai.net/deepminds-clever-idea-to-master-asymmetric-games-79c3461ef6e">DeepMind‚Äôs Clever Idea to Master Asymmetric Games</A>
							</DL><p>
							<DT><H3 FOLDED>self-play</H3>
							<DL><p>
								<DT><H3 FOLDED>self-play-spiral</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2506.24119">SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning</A>
									<DT><A HREF="https://github.com/spiral-rl/spiral">spiral-rl/spiral: SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=EY9iHSe82Hc">Self-Play by Noam Brown - YouTube</A>
								<DT><A HREF="https://x.com/_AndrewZhao/status/1939880779842298249">Self-play is so back</A>
								<DT><A HREF="https://arxiv.org/abs/2510.24684">[2510.24684] SPICE: Self-Play In Corpus Environments Improves Reasoning</A>
							</DL><p>
							<DT><H3 FOLDED>dynamic programming</H3>
							<DL><p>
								<DT><H3 FOLDED>Advanced Algorithms &amp; Data Structures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=3_o0-zPRQqw">Advanced Algorithms (COMPSCI 224), Lecture 2 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=0JUN9aDxVmI&list=PL2SOU6wwxB0uP4rJgf5ayhHWgw7akUWSf">Advanced Algorithms (COMPSCI 224), Lecture 1 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=oWgLjhM-6XE">A&amp;DS S01E01. Algorithms. Time complexity. Merge sort. - YouTube</A>
								</DL><p>
								<DT><A HREF="https://developer.nvidia.com/blog/boosting-dynamic-programming-performance-using-nvidia-hopper-gpu-dpx-instructions/">Boosting Dynamic Programming Performance Using NVIDIA Hopper GPU DPX Instructions | NVIDIA Technical Blog</A>
								<DT><A HREF="https://web.mit.edu/dimitrib/www/abstractdp_MIT.html">LESSONS FROM ALPHAZERO FOR OPTIMAL, MODEL PREDICTIVE, AND ADAPTIVE CONTROL</A>
								<DT><A HREF="https://github.com/jeffgerickson/algorithms/blob/master/Chapters/05-graphs.pdf">algorithms/Chapters/05-graphs.pdf at master ¬∑ jeffgerickson/algorithms</A>
							</DL><p>
							<DT><H3 FOLDED>Monte Carlo Tree Search</H3>
							<DL><p>
								<DT><H3 FOLDED>test-time-compute-mcts</H3>
								<DL><p>
									<DT><A HREF="https://x.com/SakanaAILabs/status/1939854145856708910">AB-MCTS</A>
									<DT><A HREF="https://github.com/SakanaAI/treequest">SakanaAI/treequest: A Tree Search Library with Flexible API for LLM Inference-Time Scaling</A>
									<DT><A HREF="https://github.com/SakanaAI/ab-mcts-arc2">SakanaAI/ab-mcts-arc2</A>
									<DT><A HREF="https://sakana.ai/ab-mcts/">Inference-Time Scaling and Collective Intelligence for Frontier AI</A>
									<DT><A HREF="https://arxiv.org/abs/2503.04412">[2503.04412] Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search</A>
								</DL><p>
								<DT><H3 FOLDED>mcts-impl</H3>
								<DL><p>
									<DT><A HREF="https://imgur.com/y3pf7eb">Imgur: The magic of the Internet</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=Fbs4lnGLS8M">Monte Carlo Tree Search (MCTS) Tutorial - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>deep-research</H3>
							<DL><p>
								<DT><H3 FOLDED>deer-flow</H3>
								<DL><p>
									<DT><A HREF="https://github.com/bytedance/deer-flow">bytedance/deer-flow: DeerFlow is a community-driven framework for deep research, combining language models with tools like web search, crawling, and Python execution, while contributing back to the open-source community.</A>
								</DL><p>
								<DT><H3 FOLDED>WebDancer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Alibaba-NLP/WebAgent/tree/main/WebDancer">WebAgent/WebDancer at main ¬∑ Alibaba-NLP/WebAgent</A>
								</DL><p>
								<DT><H3 FOLDED>tongyi-deep-research</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2510.24701">Tongyi DeepResearch Technical Report</A>
									<DT><A HREF="https://x.com/Ali_TongyiLab/status/1983528862358401025">(1) Tongyi Lab en X: "1/4 Following up on our launch of Tongyi DeepResearch: We're now releasing the full technical report! Dive deep into the technology and insights behind our 30B (A3B) open-source web agent that achieves SOTA performance: 32.9 on Humanity's Last Exam, 43.4 on BrowseComp, and 46.7 https://t.co/JvIbYHX5MQ" / X</A>
								</DL><p>
								<DT><H3 FOLDED>kimi-deep-search</H3>
								<DL><p>
									<DT><A HREF="https://github.com/MoonshotAI/Kimi-K2.5/blob/master/tech_report.pdf">Kimi-K2.5/tech_report.pdf at master ¬∑ MoonshotAI/Kimi-K2.5</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>kernel-search</H3>
							<DL><p>
								<DT><H3 FOLDED>AlphaEvolve</H3>
								<DL><p>
									<DT><H3 FOLDED>AlphaEvolve-impl</H3>
									<DL><p>
										<DT><A HREF="https://x.com/arankomatsuzaki/status/1939739752204574919">(1) Aran Komatsuzaki en X: "We've been reproducing various AlphaEvolve results and seeing early promise. Here's one from circle packing. We're also getting strong results on sphere packing, finite set sums/diffs (√† la Terry Tao), and &amp;gt;10% AIME abs. gains by mimicking Deep Think. More soon. Credits: https://t.co/2PjUAlPE2i" / X</A>
									</DL><p>
									<DT><A HREF="https://x.com/GoogleDeepMind/status/1922669321559347498">(1) Google DeepMind en X: "Introducing AlphaEvolve: a Gemini-powered coding agent for algorithm discovery. It‚Äôs able to: üîò Design faster matrix multiplication algorithms üîò Find new solutions to open math problems üîò Make data centers, chip design and AI training more efficient across @Google. üßµ https://t.co/y5QQNpKm0L" / X</A>
									<DT><A HREF="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf">AlphaEvolve: A coding agent for scientific and algorithmic discovery</A>
									<DT><A HREF="https://x.com/layer07_yuxi/status/1922892105254330704">brief notes on AlphaEvolve</A>
									<DT><A HREF="https://cloud.google.com/blog/products/ai-machine-learning/alphaevolve-on-google-cloud?utm_source=linkedin&utm_medium=unpaidsoc&utm_campaign=fy25q4-googlecloud-blog-ai-in_feed-no-brand-global&utm_content=-&utm_term=-&linkId=23669271">AlphaEvolve on Google Cloud | Google Cloud Blog</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-search</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/cc3c1e4c1456dddc2beb469154d4d1f3e34b5efa/tinygrad/opt/search.py#L142">tinygrad/tinygrad/opt/search.py beam_search</A>
								</DL><p>
								<DT><H3 FOLDED>Luminal</H3>
								<DL><p>
									<DT><A HREF="https://x.com/tenderizzation/status/1947097117299974145">(1) tender en X: "&amp;gt;browses repo and looks at flash-attention example &amp;gt;it's e-graphs, using egglog you had my curiosity, but now you have my attention https://t.co/8mTpR2n4jX" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=_aT2eo-0uWk">#63: Search-Based Deep Learning Compilers - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>e-graphs</H3>
								<DL><p>
									<DT><H3 FOLDED>egglog</H3>
									<DL><p>
										<DT><A HREF="https://docs.rs/egglog/latest/egglog/">egglog - Rust</A>
										<DT><A HREF="https://www.youtube.com/watch?v=N2RDQGRBrSY">egglog Tutorial (EGRAPHS 2023) | Next Generation Egraphs - YouTube</A>
									</DL><p>
									<DT><A HREF="https://github.com/jafioti/luminal/blob/main/flash_attention_demo/src/main.rs">luminal/flash_attention_demo/src/main.rs at main ¬∑ jafioti/luminal</A>
								</DL><p>
								<DT><A HREF="https://github.com/facebookresearch/diplomacy_cicero">facebookresearch/diplomacy_cicero: Code for Cicero, an AI agent that plays the game of Diplomacy with open-domain natural language negotiation.</A>
							</DL><p>
							<DT><A HREF="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson</A>
							<DT><A HREF="https://web.mit.edu/dimitrib/www/abstractdp_MIT.html">LESSONS FROM ALPHAZERO FOR OPTIMAL, MODEL PREDICTIVE, AND ADAPTIVE CONTROL</A>
							<DT><A HREF="https://www.umut-acar.org/self-adjusting-computation">Umut A. Acar - Self-Adjusting Computation</A>
							<DT><A HREF="https://www.youtube.com/watch?v=BJi6N4tDupk">OpenAI: Teaching AI Through Self-Play - Ilya Sutskever</A>
							<DT><A HREF="https://www.youtube.com/watch?v=uz83G-2ny8Q">DeepMind‚Äôs New AI Saw 15,000,000,000 Chess Boards! - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=EvSe0ktD95k&t=7s">A Path Towards Autonomous Machine Intelligence with Dr. Yann LeCun - YouTube</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/b36a7273c61c4315d5d01925a0d2a67534bcb965/extra/mcts_search.py#L34">tinygrad/extra/mcts_search.py at b36a7273c61c4315d5d01925a0d2a67534bcb965 ¬∑ tinygrad/tinygrad</A>
							<DT><A HREF="https://x.com/karpathy/status/1973435013875314729">(1) Andrej Karpathy en X: "Finally had a chance to listen through this pod with Sutton, which was interesting and amusing. As background, Sutton's "The Bitter Lesson" has become a bit of biblical text in frontier LLM circles. Researchers routinely talk about and ask whether this or that approach or idea" / X</A>
						</DL><p>
						<DT><H3 FOLDED>MuZero</H3>
						<DL><p>
							<DT><A HREF="https://github.com/kaesve/muzero">A clean implementation of MuZero and AlphaZero following the AlphaZero General framework. Train and Pit both algorithms against each other, and investigate reliability of learned MuZero MDP models.</A>
							<DT><A HREF="https://github.com/chiamp/muzero-cartpole">Cartpole</A>
							<DT><A HREF="https://twitter.com/DrJimFan/status/1627354160529285120?lang=en">(Jim Fan)"What‚Äôs next after open source and open model? Open training</A>
							<DT><A HREF="https://github.com/google-deepmind/mctx">google-deepmind/mctx: Monte Carlo tree search in JAX</A>
							<DT><A HREF="https://www.youtube.com/watch?v=yIrFIOx4VP8&t=21939s">George Hotz | Programming | Can MuZero play Tic Tac Toe? | Part1 | DeepMind AI - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=xc0jGZYFQLQ&t=63799s">George Hotz | Programming | Fun with MuZero and MCTS on a lovely Sunday | CartPole | DeepMind AI - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=62nq4Zsn8vc&t=1027s">Alpha Zero and Monte Carlo Tree Search - YouTube</A>
							<DT><A HREF="https://lczero.org/">Leela Chess Zero</A>
							<DT><A HREF="https://twitter.com/DrJimFan/status/1625538305889820673">mctx</A>
							<DT><A HREF="https://arxiv.org/abs/1911.08265">[1911.08265] Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model</A>
							<DT><A HREF="https://deepmind.google/technologies/alphazero-and-muzero/?_gl=1*1ai5qs2*_up*MQ..*_ga*MTk2ODY0MzQ4Ny4xNjk5MjE2MzUz*_ga_LS8HVHCNQ0*MTY5OTIxNjM1My4xLjAuMTY5OTIxNjM3My4wLjAuMA..">AlphaZero and MuZero - Google DeepMind</A>
							<DT><A HREF="https://www.youtube.com/watch?v=xc0jGZYFQLQ&t=63800s">George Hotz | Programming | Fun with MuZero and MCTS on a lovely Sunday | CartPole | DeepMind AI - YouTube</A>
							<DT><A HREF="https://github.com/xjdr-alt/muzero_sketch">xjdr-alt/muzero_sketch</A>
						</DL><p>
						<DT><H3 FOLDED>AlphaGo</H3>
						<DL><p>
						</DL><p>
						<DT><H3 FOLDED>AlphaZero</H3>
						<DL><p>
							<DT><A HREF="https://web.mit.edu/dimitrib/www/abstractdp_MIT.html">LESSONS FROM ALPHAZERO FOR OPTIMAL, MODEL PREDICTIVE, AND ADAPTIVE CONTROL</A>
						</DL><p>
						<DT><H3 FOLDED>Entity-Based Reinforcement Learning</H3>
						<DL><p>
							<DT><A HREF="https://clemenswinter.com/2023/04/14/entity-based-reinforcement-learning/">Entity-Based Reinforcement Learning | Clemens' Blog</A>
						</DL><p>
						<DT><H3 FOLDED>rl-reward-functions</H3>
						<DL><p>
							<DT><H3 FOLDED>reward-tuning</H3>
							<DL><p>
								<DT><A HREF="https://x.com/cloneofsimo/status/1917888990721749065">Simo Ryu: RL reward tuning, curriculum learning and reward functions</A>
							</DL><p>
							<DT><A HREF="https://x.com/yacineMTB/status/1950568656682831885">(1) kache en X: "The problem with neural networks is that they are extremely, extremely, extremely good at solving whatever problem you throw at them. So you can have an actual bug in your simulation, say you accidentally give the steering wheel for a car 8 bits of resolution. And it'll drive it" / X</A>
						</DL><p>
						<DT><H3 FOLDED>rl-games</H3>
						<DL><p>
							<DT><A HREF="https://drubinstein.github.io/pokerl/">Learning Pok√©mon With Reinforcement Learning | Pok√©mon RL</A>
						</DL><p>
						<DT><H3 FOLDED>multi-agent</H3>
						<DL><p>
							<DT><H3 FOLDED>IMO</H3>
							<DL><p>
								<DT><A HREF="https://x.com/SherylHsu02/status/1946478334013321231">Sheryl Hsu Watching the model solve these IMO problems and achieve gold-level performance was magical. A few thoughts</A>
								<DT><A HREF="https://x.com/alexwei_/status/1946477742855532918">(1) Alexander Wei en X: "1/N I‚Äôm excited to share that our latest @OpenAI experimental reasoning LLM has achieved a longstanding grand challenge in AI: gold medal-level performance on the world‚Äôs most prestigious math competition‚Äîthe International Math Olympiad (IMO). https://t.co/SG3k6EknaC" / X</A>
								<DT><A HREF="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/">Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad - Google DeepMind</A>
								<DT><A HREF="https://www.alphaxiv.org/abs/2507.15855v2">Gemini 2.5 Pro Capable of Winning Gold at IMO 2025 | alphaXiv</A>
							</DL><p>
							<DT><H3 FOLDED>heavy-thinking</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2510.08191">[2510.08191] Training-Free Group Relative Policy Optimization</A>
								<DT><A HREF="https://arxiv.org/abs/2507.07017">[2507.07017] First Return, Entropy-Eliciting Explore</A>
								<DT><A HREF="https://x.com/_xjdr/status/1943857070820012219">Kimi K2 heavy</A>
								<DT><A HREF="https://x.ai/news/grok-4">Grok 4 Heavy: Parallel test-time compute</A>
								<DT><A HREF="https://github.com/ByteDance-Seed/Seed-Prover/tree/main/SeedProver">Seed-Prover/SeedProver at main ¬∑ ByteDance-Seed/Seed-Prover</A>
								<DT><A HREF="https://arxiv.org/pdf/2507.23726">Seed-Geometry</A>
								<DT><A HREF="https://qwen.ai/blog?id=241398b9cd6353de490b0f82806c7848c5d2777d&from=research.latest-advancements-list">Qwen3-Max-Thinking (Heavy): integrating a code interpreter and leveraging parallel-test time compute</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/2015611610463662495">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Btw: this is an easy path to a new form of a hacky "heavy" thinking mode, adding to the current 8x+summary technique - orchestrator decomposes the task into *problem classes* and picks difficult ones (LLMs are surprisingly good at judging problem difficulty, but can be augmented https://t.co/DOrrmBmO1p" / X</A>
								<DT><A HREF="https://www.kimi.com/blog/kimi-k2-5.html">Kimi K2.5: Visual Agentic Intelligence</A>
								<DT><A HREF="https://x.com/GenAI_is_real/status/2016042118150766713">(1) Chayenne Zhao en X: "kimi k2.5 just dropped and the agent swarm beta is actually insane. 1,500 tool calls at 4.5x speed? openai is still trying to get o1 to follow simple instructions while moonshot is literally building an autonomous workforce. hle 50.2% is the new ceiling. if you aren't thinking" / X</A>
							</DL><p>
							<DT><H3 FOLDED>PARL</H3>
							<DL><p>
								<DT><A HREF="https://github.com/MoonshotAI/Kimi-K2.5/blob/master/tech_report.pdf">Kimi-K2.5/tech_report.pdf dynamic framework for parallel agent orchestration. We propose a</A>
							</DL><p>
							<DT><A HREF="https://x.com/polynoamial/status/1946480714939085301">(1) Noam Brown: OpenAI multi-agent team</A>
							<DT><A HREF="https://www.youtube.com/watch?v=33TkQ4ZCTww">GEPA REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING - YouTube</A>
						</DL><p>
						<DT><A HREF="https://www.youtube.com/playlist?list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ">DeepMind x UCL | Introduction to Reinforcement Learning 2015 - YouTube</A>
						<DT><A HREF="https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html">A Taxonomy of RL Algorithms</A>
						<DT><A HREF="https://arxiv.org/abs/1707.03497">(Deepmind) Value Prediction Network: predictions of FUTURE VALUES rather than of future observations.</A>
						<DT><A HREF="https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver">Introduction to Reinforcement Learning with David Silver (Deepmind)</A>
						<DT><A HREF="http://www.incompleteideas.net/book/the-book.html">Sutton &amp; Barto Book: Reinforcement Learning: An Introduction</A>
						<DT><A HREF="https://twitter.com/TheSequenceAI/status/1530591453243744256">Let's talk about Exploration-Exploitation Dilemma</A>
						<DT><A HREF="https://www.amazon.com/dp/0262039249/">Reinforcement Learning, second edition: An Introduction Sutton, Richard S., Barto, Andrew G</A>
						<DT><A HREF="https://arxiv.org/pdf/2201.02135.pdf">2022 June Arxiv Nature book</A>
						<DT><A HREF="http://www.incompleteideas.net/book/RLbook2020.pdf">Reinforcement Learning: An Introduction 2nd edition (Richard S. Sutton)</A>
						<DT><A HREF="https://github.com/lvwerra/rl-implementations">lvwerra/rl-implementations: This repo contains a set of notebooks to reproduce reinforcement learning algorithms.</A>
						<DT><A HREF="https://github.com/sotetsuk/pgx">sotetsuk/pgx: üé≤ Vectorized RL game environments written in JAX with end-to-end AlphaZero examples</A>
						<DT><A HREF="https://github.com/google-deepmind/dqn_zoo">google-deepmind/dqn_zoo: DQN Zoo is a collection of reference implementations of reinforcement learning agents developed at DeepMind based on the Deep Q-Network (DQN) agent.</A>
						<DT><A HREF="https://www.youtube.com/watch?v=-tZkb0vgaDk">George Hotz | Programming | RL is dumb and doesn't work | Reinforcement Learning LunarLander Part 2 - YouTube</A>
						<DT><A HREF="https://shield.ai/">Shield AI - Building The World‚Äôs Best AI Pilot</A>
						<DT><A HREF="https://x.com/RobertTLange">Rejax: JAX RL algorithms</A>
						<DT><A HREF="https://github.com/kvfrans/rlbase_stable">kvfrans/rlbase_stable</A>
						<DT><A HREF="https://github.com/openai/baselines">openai/baselines: OpenAI Baselines: high-quality implementations of reinforcement learning algorithms</A>
						<DT><A HREF="https://github.com/imbue-ai/garage">imbue-ai/garage: A toolkit for reproducible reinforcement learning research.</A>
						<DT><A HREF="https://pufferai.github.io/build/html/rst/landing.html">Emulation - PufferLib 1.0.0 documentation</A>
						<DT><A HREF="https://github.com/rl-tools/rl-tools">rl-tools/rl-tools: The Fastest Deep Reinforcement Learning Library</A>
						<DT><A HREF="https://x.com/i/bookmarks?post_id=1863436864411341112">Reward Hacking (OpenAI)</A>
						<DT><A HREF="https://lilianweng.github.io/posts/2024-11-28-reward-hacking/">Reward Hacking in Reinforcement Learning | Lil'Log</A>
						<DT><A HREF="https://naklecha.notion.site/a-reinforcement-learning-guide">a reinforcement learning guide</A>
						<DT><A HREF="https://www.youtube.com/watch?v=FgzM3zpZ55o">Stanford CS234: Reinforcement Learning | Winter 2019 | Lecture 1 - Introduction - Emma Brunskill - YouTube</A>
						<DT><A HREF="http://incompleteideas.net/rlai.cs.ualberta.ca/RLAI/richsprinciples.html">RLAI open web page</A>
						<DT><A HREF="https://x.com/tuzhaopeng/status/1906975869538914570">(1) Zhaopeng Tu en X: "Can reinforcement learning scale beyond math and coding tasks? Introducing Reinforcement Learning with Verifiable Rewards (RLVR) across diverse, less-structured domains (e.g., medicine, chemistry, psychology, economics, and education), where well-structured reference answers https://t.co/yFXnBkXdyC" / X</A>
						<DT><A HREF="https://www.youtube.com/watch?v=CNA1sb2fJS4">Inference Time Scaling for Generalist Reward Modeling - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=HVikhXjOJX0">Reinforcement Learning Dev on PufferLib - YouTube</A>
						<DT><A HREF="https://github.com/pytorch/rl">pytorch/rl: A modular, primitive-first, python-first PyTorch library for Reinforcement Learning.</A>
						<DT><A HREF="https://www.youtube.com/watch?v=-8aeywCbTt8">Horizon Reduction Makes RL Scalable - YouTube</A>
						<DT><A HREF="https://arxiv.org/abs/2506.04168">[2506.04168] Horizon Reduction Makes RL Scalable</A>
						<DT><A HREF="https://justinchiu.netlify.app/blog/sftrl/">SFT is bad RL</A>
						<DT><A HREF="http://incompleteideas.net/book/the-book-2nd.html">Sutton &amp; Barto Book: Reinforcement Learning: An Introduction</A>
						<DT><A HREF="https://x.com/syhw/status/1973109699395342520">(Gabriel Synnaeve) Everything I know in RL in one tweet: exploration&gt;exploitation, easy to leverage off-policy positive rewards, hard to leverage off-policy negative rewards, update the policy often, focus on throughput, self-play or find asymmetric grounding, clip everything but check statistics.</A>
						<DT><A HREF="https://x.com/karpathy/status/1979932716423680137">Andrej Karpathy en X: "@jsuarez5341 I very much hope you continue working on RL! I think it's a misunderstanding that I am suggesting we need some kind of a replacement for RL. That's not accurate and I tried to clear it but did so poorly - they layer. Layer 1 was base model autocomplete. Layer 2 was instruct" / X</A>
						<DT><A HREF="https://arxiv.org/abs/2412.05265">[2412.05265] Reinforcement Learning: An Overview</A>
						<DT><A HREF="https://www.youtube.com/watch?v=EvHRQhMX7_w&list=PLoROMvodv4rPwxE0ONYRa_itZFdaKCylL">Stanford CS224R Deep Reinforcement Learning | Spring 2025 | Lecture 1: Class Intro - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>Diffusion</H3>
					<DL><p>
						<DT><H3 FOLDED>diffusion-theory</H3>
						<DL><p>
							<DT><H3 FOLDED>discrete-diffusion</H3>
							<DL><p>
								<DT><A HREF="https://x.com/cloneofsimo/status/1874911222459662525">discrete diffusion</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1876159854509019574">DDPD: planner decides which tokens to denoise and denoiser decides waht to replace it with</A>
								<DT><A HREF="https://github.com/fal-ai-community/minDDPD">fal-ai-community/minDDPD</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-interpretability</H3>
							<DL><p>
								<DT><H3 FOLDED>diffusion-explorer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/helblazer811/Diffusion-Explorer">helblazer811/Diffusion-Explorer: Interactive visualizations of the geometric intuition behind diffusion models.</A>
								</DL><p>
								<DT><A HREF="https://x.com/alec_helbling/status/1999124332216226074">(1) Alec Helbling en X: "Text-to-image diffusion transformer models learn to align text and image representations as a byproduct of their conditional denoising task. By taking the dot product between the text and image representations of a DiT model (like Flux 2), you can create rich saliency maps. https://t.co/RUT6t82D6m" / X</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=iv-5mZ_9CPY">But how do AI images/videos actually work? | Guest video by ‚Ä™@WelchLabsVideo‚Ä¨ - YouTube</A>
							<DT><A HREF="https://seed.bytedance.com/en/public_papers/an-image-is-worth-32-tokens-for-reconstruction-and-generation">An Image is Worth 32 Tokens for Reconstruction and Generation - Publications - ByteDance Seed Team</A>
							<DT><A HREF="https://kexue-fm.translate.goog/archives/10567?_x_tr_sl=auto&_x_tr_tl=en&_x_tr_hl=en-US&_x_tr_pto=wapp">A brief talk on generative diffusion model (Part 26): Distillation based on id</A>
							<DT><A HREF="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">What are Diffusion Models? | Lil'Log</A>
							<DT><A HREF="https://github.com/stars/Yaofang-Liu/lists/diffusion-mdels">Yaofang-Liu's list / Diffusion Mdels</A>
							<DT><A HREF="https://iclr-blogposts.github.io/2024/blog/diffusion-theory-from-scratch/">Building Diffusion Model's theory from ground up | ICLR Blogposts 2024</A>
							<DT><A HREF="https://kexue.fm/archives/9164">A talk on generative diffusion model (Part 3): DDPM = Bayesian + denoising</A>
							<DT><A HREF="https://kexue.fm/archives/10047">A brief talk on generative diffusion model (Part 22): Signal-to-noise ratio</A>
							<DT><A HREF="https://github.com/tmabraham/diffusion_reading_group">tmabraham/diffusion_reading_group: Diffusion Reading Group at EleutherAI</A>
							<DT><A HREF="https://astralord.github.io/posts/power-of-diffusion-models/">Power of Diffusion Models | AstraBlog</A>
							<DT><A HREF="https://sander.ai/2024/09/02/spectral-autoregression.html">Diffusion is spectral autoregression ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2024/06/14/noise-schedules.html">Noise schedules considered harmful ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2023/01/09/diffusion-language.html">Diffusion language models ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2023/08/28/geometry.html">The geometry of diffusion guidance ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2023/07/20/perspectives.html">Perspectives on diffusion ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2022/05/26/guidance.html">Guidance: a cheat code for diffusion models ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2022/01/31/diffusion.html">Diffusion models are autoencoders ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://sander.ai/2024/02/28/paradox.html">The paradox of diffusion distillation ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://imagen.research.google/">Imagen: Text-to-Image Diffusion Models</A>
							<DT><A HREF="https://x.com/attentionmech/status/1923734078240571863">target: "remove fear of symbolic math"approach: go thru some equations and really NOT skip them</A>
							<DT><A HREF="https://www.youtube.com/watch?v=1pgiu--4W3I">The Breakthrough Behind Modern AI Image Generators | Diffusion Models Part 1 - YouTube</A>
							<DT><A HREF="https://sander.ai/2025/04/15/latents.html">Generative modelling in latent space ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://www.youtube.com/watch?v=hRi3ouF1vqY">all of diffusion math, from scratch - YouTube</A>
							<DT><A HREF="https://arxiv.org/abs/2505.17638">[2505.17638] Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training</A>
							<DT><A HREF="https://x.com/jcjesselai/status/1983326034796917094">(1) Chieh-Hsin (Jesse) Lai en X: "@DrYangSong @gimdong58085414 @mittu1204 @StefanoErmon ü§îWhat you‚Äôll get from this monograph: A clear and systematic walkthrough of how diffusion models emerged, how the main formulations connect, and how today‚Äôs methods achieve controllability and speed, leading to the next generation of diffusion-based generative models: the" / X</A>
							<DT><A HREF="https://www.arxiv.org/abs/2510.21890">[2510.21890] The Principles of Diffusion Models</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-lectures</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=i2qSxMVeVLI&t=430s">How I Understand Diffusion Models - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=yxVcnuRrKqQ&t=53s">Generative Modeling - Normalizing Flows - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=038QxC5kTLk&list=LL&index=4&t=661s">Giannis Daras - Generative Models and Comp. Imaging: Soft Diffusion and Learning from Corrupted Data - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=9Y8NKkuPhC0&list=LL&index=5">Hyungjin Chung - Adapting and Regularizing Diffusion Models for Inverse Problems - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=1d4r19GEVos&list=LL&index=7&t=2025s">CVPR #18546 - Denoising Diffusion Models: A Generative Learning Big Bang - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=038QxC5kTLk&list=LL&index=16&t=666s">Giannis Daras - Generative Models and Comp. Imaging: Soft Diffusion and Learning from Corrupted Data - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=9Y8NKkuPhC0&list=LL&index=17&t=4s">Hyungjin Chung - Adapting and Regularizing Diffusion Models for Inverse Problems - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=NJ72iEPRXFk">Sanjay Shakkottai: Tutorial on the Mathematical Foundations of Diffusion Models for Image Generation - YouTube</A>
							<DT><A HREF="https://github.com/ChenHsing/Awesome-Video-Diffusion-Models">ChenHsing/Awesome-Video-Diffusion-Models: [CSUR] A Survey on Video Diffusion Models</A>
							<DT><A HREF="https://madebyoll.in/posts/dino_diffusion/#why-it-works">Bare-bones Diffusion Models</A>
							<DT><A HREF="https://github.com/helblazer811/diffusion-visualizations">helblazer811/diffusion-visualizations: Visualizations of the theory behind diffusion models.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=0V96wE7lY4w">Denoising Autoencoders | Deep Learning Animated - YouTube</A>
							<DT><A HREF="https://x.com/i/bookmarks?post_id=1863080363792408864">(1) X</A>
							<DT><A HREF="https://x.com/i/bookmarks?post_id=1862843110247563343">The link between diffusion models and optimal transport</A>
							<DT><A HREF="https://github.com/wangkai930418/awesome-diffusion-categorized">wangkai930418/awesome-diffusion-categorized: collection of diffusion model papers categorized by their subareas</A>
							<DT><A HREF="https://x.com/rmsnorm/status/1864452411118514369">(1) Nick Stracke en X: "ü§î Why do we extract diffusion features from noisy images? Isn‚Äôt that destroying information? Yes, it is - but we found a way to do better. üöÄ Here‚Äôs how we unlock better features, no noise, no hassle üßµüëá https://t.co/xPj1xsytn9" / X</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-distillation</H3>
						<DL><p>
							<DT><H3 FOLDED>Imagine Flash (Meta AI)</H3>
							<DL><p>
								<DT><A HREF="https://ai.meta.com/research/publications/imagine-flash-accelerating-emu-diffusion-models-with-backward-distillation/?utm_source=linkedin&utm_medium=organic_social&utm_content=image&utm_campaign=imagineflash">Imagine Flash: Accelerating Emu Diffusion Models with Backward Distillation | Research - AI at Meta</A>
								<DT><A HREF="https://scontent.fsvq5-1.fna.fbcdn.net/v/t39.2365-6/10000000_1650715635757274_3499348867570367129_n.pdf?_nc_cat=111&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=E__oAKOcVaIQ7kNvgG2Odel&_nc_ht=scontent.fsvq5-1.fna&oh=00_AfABQIIxviDeDBA4t-0_pSaK-QGovi86kWT62uEJom-57w&oe=66355F6B">Imagine Flash: Accelerating Emu Diffusion Models with Backward Distillation</A>
							</DL><p>
							<DT><H3 FOLDED>SDXL-Lightning: Progressive Adversarial Diffusion Distillation (ByteDance)</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2402.13929">[2402.13929] SDXL-Lightning: Progressive Adversarial Diffusion Distillation</A>
								<DT><A HREF="https://arxiv.org/html/2402.13929v1">SDXL-Lightning: Progressive Adversarial Diffusion Distillation</A>
								<DT><A HREF="https://developers.cloudflare.com/workers-ai/models/stable-diffusion-xl-lightning/">stable-diffusion-xl-lightning ¬∑ Cloudflare Workers AI docs</A>
								<DT><A HREF="https://huggingface.co/ByteDance/SDXL-Lightning">ByteDance/SDXL-Lightning ¬∑ Hugging Face</A>
							</DL><p>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/11823133445">A Discussion of Generative Diffusion Models (Part 26): Distillation Based on Identities (Part 2)</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/633697346">A Review of Diffusion Model Distillation Techniques</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/1910857353349301454">Diffusion Model Distillation (Part 4)</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/1910857115012174520">Diffusion Model Distillation (Part 3)</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/1910856832320246904">Diffusion Model Distillation (Part 2)</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/1910856559136859277">Diffusion Model Distillation (Part 1)</A>
							<DT><A HREF="https://scontent.fsvq5-1.fna.fbcdn.net/v/t39.2365-6/10000000_1650715635757274_3499348867570367129_n.pdf?_nc_cat=111&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=E__oAKOcVaIQ7kNvgG2Odel&_nc_ht=scontent.fsvq5-1.fna&oh=00_AfABQIIxviDeDBA4t-0_pSaK-QGovi86kWT62uEJom-57w&oe=66355F6B">Imagine Flash: Accelerating Emu Diffusion Models with Backward Distillation</A>
							<DT><A HREF="https://arxiv.org/abs/2311.17042">[2311.17042] Adversarial Diffusion Distillation</A>
							<DT><A HREF="https://hyper-sd.github.io/">Hyper-SD: Trajectory Segmented Consistency Model for Efficient Image Synthesis</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-diffusion</H3>
						<DL><p>
							<DT><H3 FOLDED>LLaDA</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2502.09992">[2502.09992] Large Language Diffusion Models</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1897275066628665542">(1) Simo Ryu en X: "Will be speedrunning LLaDA (MDM) in 3 hours on Twitch https://t.co/doV679xISo https://t.co/d2LNZdPFaG" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=hnYn8QHR8UI">llada repro cloneofsimo - YouTube</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1897563505160851658">Simo Ryu en X: "LLaDA with muP. it just works, again. Im so tired of saying it works. Just use it, and thank me later https://t.co/gJimDN2IHj" / X</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-MMaDA</H3>
							<DL><p>
								<DT><A HREF="https://x.com/lingyang_pu/status/1925385712670830753">We present MMaDA, first diffusion that unifies text reasoning, multimodal understanding, and image generation through Mixed Long-CoT, and  unified RL - UniGRPO.</A>
								<DT><A HREF="https://huggingface.co/Gen-Verse/MMaDA-8B-Base">Gen-Verse/MMaDA-8B-Base ¬∑ Hugging Face</A>
								<DT><A HREF="https://github.com/Gen-Verse/MMaDA">Gen-Verse/MMaDA: MMaDA - Open-Sourced Multimodal Large Diffusion Language Models</A>
								<DT><A HREF="https://arxiv.org/pdf/2505.15809">MMaDA: Multimodal Large Diffusion Language Models (bytedn)</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-super data learners</H3>
							<DL><p>
								<DT><A HREF="https://x.com/NiJinjie/status/1987761119608656362">(1) Jinjie Ni en X: "@elonmusk @hyhieu226 Thrilled to see Elon is investing in DLMs! (looking forward to contribute :) Diffusion language models indeed have a better learning potential than AR models. We empirically verified that at scale in the super data learners paper: https://t.co/mXv3zEYVPz Also did the" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2511.03276">[2511.03276] Diffusion Language Models are Super Data Learners</A>
							</DL><p>
							<DT><A HREF="https://x.com/MansteinGeorg/status/1925232606838239450">(1) Georg von Manstein en X: "I‚Äôm a 19 y/o founder from Germany, and I cracked how Google‚Äôs Text Diffusion model works! There are three main approaches on this topic: https://t.co/oGDG8vxhOm" / X</A>
							<DT><A HREF="https://x.com/karpathy/status/1980347971935068380">(1) Andrej Karpathy en X: "Nice, short post illustrating how simple text (discrete) diffusion can be. Diffusion (i.e. parallel, iterated denoising, top) is the pervasive generative paradigm in image/video, but autoregression (i.e. go left to right bottom) is the dominant paradigm in text. For audio I've https://t.co/8i5Jgj7ogL" / X</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/1975631767647044023">DiRL: a practical post-training framework for Diffusion Language Models</A>
							<DT><A HREF="https://www.notion.so/Understanding-the-Limitations-of-Diffusion-LLMs-through-a-Probabilistic-Perspective-2ae0ba07baa88053b838d5bf0b0aad41#2af0ba07baa880c29fc4c8c198244cc8">Understanding the Limitations of Diffusion LLMs through a Probabilistic Perspective</A>
							<DT><A HREF="https://www.radicalnumerics.ai/blog/rnd1">RND1: Simple, Scalable AR-to-Diffusion Conversion ¬∑ Radical Numerics</A>
						</DL><p>
						<DT><H3 FOLDED>image-diffusion-autoregression</H3>
						<DL><p>
							<DT><H3 FOLDED>autoregressive-image-generation</H3>
							<DL><p>
								<DT><H3 FOLDED>GLM-Image</H3>
								<DL><p>
									<DT><A HREF="https://z.ai/blog/glm-image">GLM-Image: Auto-regressive for Dense-knowledge and High-fidelity Image Generation</A>
									<DT><A HREF="https://github.com/zai-org/GLM-Image">zai-org/GLM-Image: GLM-Image: Auto-regressive for Dense-knowledge and High-fidelity Image Generation.</A>
								</DL><p>
								<DT><H3 FOLDED>image-gpt</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/index/image-gpt/">Image GPT | OpenAI</A>
								</DL><p>
								<DT><H3 FOLDED>transfusion</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2408.11039">[2408.11039] Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model</A>
								</DL><p>
								<DT><H3 FOLDED>chameleon</H3>
								<DL><p>
									<DT><A HREF="https://ai.meta.com/blog/generative-ai-text-images-cm3leon/">Introducing CM3leon, a more efficient, state-of-the-art generative model for text and images</A>
									<DT><A HREF="https://github.com/kyegomez/CM3Leon">kyegomez/CM3Leon: An open source implementation of "Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction Tuning", an all-new multi modal AI that uses just a decoder to generate both text and images</A>
									<DT><A HREF="https://github.com/facebookresearch/chameleon">facebookresearch/chameleon: Repository for Meta Chameleon, a mixed-modal early-fusion foundation model from FAIR.</A>
									<DT><A HREF="https://arxiv.org/abs/2506.23589">[2506.23589] Transition Matching: Scalable and Flexible Generative Modeling</A>
									<DT><A HREF="https://x.com/ArmenAgha/status/2014428868636270885">(1) Armen Aghajanyan en X: "Since I started working on multimodal models 4 years ago, one harsh realization was that standard architectures don't allocate compute intelligently across modalities. We tried dense multimodal models (Chameleon) and MoE extensions (MoMA)... none felt quite right. Today we're https://t.co/4N9UgtxPEq" / X</A>
								</DL><p>
								<DT><H3 FOLDED>autoregressive-distillation-dit</H3>
								<DL><p>
									<DT><A HREF="https://ai.meta.com/research/publications/autoregressive-distillation-of-diffusion-transformers/">Autoregressive Distillation of Diffusion Transformers | Research - AI at Meta</A>
									<DT><A HREF="https://scontent.fsvq1-1.fna.fbcdn.net/v/t39.2365-6/489921800_654822090742241_4867106051645455876_n.pdf?_nc_cat=107&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=FJVUjlh6Kx0Q7kNvwE5NHi4&_nc_oc=AdmUSk3zqZprFi2186ZSkR8RpIGMeJmXCc7eMBc_L4qoNUsU4WgcgxSN126Po9YoIes&_nc_zt=14&_nc_ht=scontent.fsvq1-1.fna&_nc_gid=vNO4Ueq_YVDbyNWlU33gsQ&oh=00_AfEP6Ak5T7tle6ySM2N2HDqzdk9iIvFQI5dRGfD9bahXBA&oe=6804525A">utoregressive Distillation of Diffusion Transformers</A>
									<DT><A HREF="https://github.com/alsdudrla10/ARD">alsdudrla10/ARD: [CVPR 2025 Oral] PyTorch re-implementation for Autoregressive Distillation of Diffusion Transformers (ARD).</A>
									<DT><A HREF="https://github.com/facebookresearch/DiT">facebookresearch/DiT: Official PyTorch Implementation of "Scalable Diffusion Models with Transformers"</A>
								</DL><p>
								<DT><H3 FOLDED>4o-image-generation</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/index/introducing-4o-image-generation/">Introducing 4o Image Generation | OpenAI</A>
								</DL><p>
								<DT><H3 FOLDED>NextStep-1</H3>
								<DL><p>
									<DT><A HREF="https://x.com/StepFun_ai/status/1956275833196437756">(1) StepFun en X: "üöÄ Introducing NextStep-1: A new paradigm for autoregressive image generation. üí° Core design: A 14B Causal Transformer "artist" paired with a lightweight 157M Flow Matching "brush". We generate directly in continuous visual tokens, bypassing the information bottleneck of" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2508.10711">[2508.10711] NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale</A>
									<DT><A HREF="https://huggingface.co/stepfun-ai/NextStep-1-Large">stepfun-ai/NextStep-1-Large ¬∑ Hugging Face</A>
									<DT><A HREF="https://github.com/stepfun-ai/NextStep-1">stepfun-ai/NextStep-1</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2412.14164">[2412.14164] MetaMorph: Multimodal Understanding and Generation via Instruction Tuning</A>
								<DT><A HREF="https://x.com/_akhaliq/status/1912229925806895201">Bytedance Liquid: Language Models are Scalable and Unified Multimodal generators</A>
								<DT><A HREF="https://huggingface.co/Junfeng5/Liquid_V1_7B">Junfeng5/Liquid_V1_7B ¬∑ Hugging Face</A>
							</DL><p>
							<DT><H3 FOLDED>EMU</H3>
							<DL><p>
								<DT><H3 FOLDED>emu-3.5</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/BAAI/Emu3.5">BAAI/Emu3.5 ¬∑ Hugging Face</A>
								</DL><p>
								<DT><A HREF="https://emu.baai.ac.cn/about">Emu3</A>
								<DT><A HREF="https://arxiv.org/pdf/2409.18869">Emu3: Next-Token Prediction is All You Need</A>
							</DL><p>
							<DT><H3 FOLDED>deepseek-janus</H3>
							<DL><p>
								<DT><A HREF="https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf">Janus/janus_pro_tech_report.pdf at main ¬∑ deepseek-ai/Janus</A>
								<DT><A HREF="https://github.com/deepseek-ai/Janus">deepseek-ai/Janus: Janus-Series: Unified Multimodal Understanding and Generation Models</A>
								<DT><A HREF="https://github.com/deepseek-ai/Janus?tab=readme-ov-file#text-to-image-generation">deepseek-ai/Janus: Janus-Series: Unified Multimodal Understanding and Generation Models</A>
								<DT><A HREF="https://huggingface.co/deepseek-ai/Janus-Pro-7B/tree/main">deepseek-ai/Janus-Pro-7B at main</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-tar</H3>
							<DL><p>
								<DT><H3 FOLDED>bytedn-tar-weights</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/collections/csuhan/tar-68538273b5537d0bee712648">Tar - a csuhan Collection</A>
								</DL><p>
								<DT><A HREF="https://github.com/csuhan/Tar">csuhan/Tar: Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations</A>
								<DT><A HREF="https://tar.csuhan.com/">Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations</A>
								<DT><A HREF="https://arxiv.org/abs/2506.18898">[2506.18898] Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations</A>
							</DL><p>
							<DT><H3 FOLDED>JetFormer</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2411.19722">[2411.19722] JetFormer: An Autoregressive Generative Model of Raw Images and Text</A>
								<DT><A HREF="https://x.com/giffmana/status/1863657113953657129">(1) Lucas Beyer (bl16) en X: "The first of the cool things we* got this week! Typically, you'd train a VQ-VAE/GAN tokenizer first, and then use its tokens for your LLM/DiT/... But we all know eventually end-to-end wins over pipelines. With flow models, you can actually learn pixel-LLM-pixel end-to-end!" / X</A>
							</DL><p>
							<DT><H3 FOLDED>hart</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>llamagen</H3>
							<DL><p>
								<DT><A HREF="https://github.com/FoundationVision/LlamaGen">FoundationVision/LlamaGen: Autoregressive Model Beats Diffusion: ü¶ô Llama for Scalable Image Generation</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-autoregression-parallel-decoding</H3>
							<DL><p>
								<DT><A HREF="https://x.com/supremeZhuang/status/1868839299707502943">(1) Bohan Zhuang en X: "We'd like to share our latest simple and effective work, ZipAR, which reduces 91% of auto-regressive image generation overhead without any training. Addressing the issue of slow decoding in AR image generation models (such as Emu3, Lumina-mGPT, LlamaGen, and Janus), we propose a https://t.co/ZFUW3fy4g6" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2412.04062">[2412.04062] ZipAR: Accelerating Autoregressive Image Generation through Spatial Locality</A>
								<DT><A HREF="https://github.com/ThisisBillhe/ZipAR">ThisisBillhe/ZipAR: This is the official PyTorch implementation of "ZipAR: Accelerating Autoregressive Image Generation through Spatial Locality"</A>
							</DL><p>
							<DT><A HREF="https://x.com/sedielem/status/1820233922287919263">(1) Sander Dieleman en X: "The interpretation of diffusion as autoregression in the frequency domain seems to be stirring up a lot of thought! (I may or may not have a new blog post in the works üßê) https://t.co/XSxP27pKSt" / X</A>
							<DT><A HREF="https://sander.ai/2024/09/02/spectral-autoregression.html">Diffusion is spectral autoregression ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://x.com/nrehiew_/status/1832412663273464152">(1) wh en X: "A visualization of how I think of diffusion in frequency space Diffusion often generates the low frequencies in the earlier steps before generating the higher frequencies in the later steps https://t.co/rPebHNxozZ" / X</A>
							<DT><A HREF="https://github.com/FoundationVision/LlamaGen">FoundationVision/LlamaGen: Autoregressive Model Beats Diffusion: ü¶ô Llama for Scalable Image Generation</A>
							<DT><A HREF="https://x.com/nrehiew_/status/1863591609834615070">(1) wh en X: "The 6th highest scored paper (7,8,8,8) going into Neurips 2024 tldr: They introduce a new image generation approach that uses an autoregressive transformer to predict increasingly larger latent feature maps starting from a single pixel feature map to the final latent/image https://t.co/56m0LhV6dV" / X</A>
							<DT><A HREF="https://openreview.net/pdf?id=gojL67CfS8">Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</A>
							<DT><A HREF="https://github.com/FoundationVision/VAR">FoundationVision/VAR: [NeurIPS 2024 Oral][GPT beats diffusionüî•] [scaling laws in visual generationüìà] Official impl. of "Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction". An *ultra-simple, user-friendly yet state-of-the-art* codebase for autoregressive image generation!</A>
							<DT><A HREF="https://x.com/thjashin/status/1866916736290697421">google-deepmind/md4: Simplified and Generalized Masked Diffusion for Discrete Data</A>
							<DT><A HREF="https://arxiv.org/abs/2406.04329">[2406.04329] Simplified and Generalized Masked Diffusion for Discrete Data</A>
							<DT><A HREF="https://neurips.cc/virtual/2024/poster/93071">NeurIPS Poster Simplified and Generalized Masked Diffusion for Discrete Data</A>
							<DT><A HREF="https://arxiv.org/pdf/2404.02905">Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</A>
							<DT><A HREF="https://openai.com/index/image-gpt/">Image GPT | OpenAI</A>
							<DT><A HREF="https://x.com/Dorialexander/status/1891408227171975375">Large Language Diffusion Models</A>
							<DT><A HREF="https://x.com/DimitrisPapail/status/1906524049053827289">(1) Dimitris Papailiopoulos en X: "OK something VERY COOL is happening, and 4o+imagen CAN generate VALID mazes when they are in the shape of a rhombus, i.e., 45¬∞ rotated square Some examples below (the red squiggly line is mine). The prompt is "generate an image of a valid maze in a shape of a rhombus." https://t.co/F3EimKsBhl" / X</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-inference-optimization</H3>
						<DL><p>
							<DT><A HREF="https://github.com/vdesai2014/inference-optimization-blog-post">vdesai2014/inference-optimization-blog-post</A>
							<DT><A HREF="https://www.vrushankdes.ai/diffusion-inference-optimization">Diffusion Inference Optimization</A>
							<DT><A HREF="https://github.com/PipeFusion/PipeFusion">PipeFusion/PipeFusion: A Suite of Parallel Approaches for Inference of Diffusion Transformer Models on GPU Clusters</A>
							<DT><A HREF="https://github.com/PipeFusion/PatchVAE">PipeFusion/PatchVAE: A patch parallelism VAE implement for high resolution generation</A>
							<DT><A HREF="https://github.com/mit-han-lab/distrifuser">mit-han-lab/distrifuser: [CVPR 2024 Highlight] DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models</A>
							<DT><A HREF="https://arxiv.org/abs/2402.19481">[2402.19481] DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models</A>
							<DT><A HREF="https://github.com/czg1225/AsyncDiff">czg1225/AsyncDiff: Official implementation of "AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising"</A>
							<DT><A HREF="https://ar5iv.labs.arxiv.org/html/2312.09608">[2312.09608] Faster Diffusion: Rethinking the Role of UNet Encoder in Diffusion Models</A>
							<DT><A HREF="https://github.com/hutaiHang/Faster-Diffusion">hutaiHang/Faster-Diffusion: Official implementation of "Faster Diffusion: Rethinking the Role of UNet Encoder in Diffusion Models"</A>
							<DT><A HREF="https://machinelearning.apple.com/research/efficient-diffusion-models">Efficient Diffusion Models without Attention - Apple Machine Learning Research</A>
							<DT><A HREF="https://gist.github.com/Chillee/41baf11aac8036d25d637321c48dad20">You Could Have Invented Flash-Attention!</A>
							<DT><A HREF="https://github.com/siliconflow/onediff/blob/main/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py">onediff/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py at main ¬∑ siliconflow/onediff</A>
							<DT><A HREF="https://www.felixsanz.dev/articles/ultimate-guide-to-optimizing-stable-diffusion-xl">Ultimate guide to optimizing Stable Diffusion XL - F√©lix Sanz</A>
							<DT><A HREF="https://a-r-r-o-w.github.io/blog/3_blossom/00001_productionizing_diffusion-1/">Optimizing diffusion inference for production-ready speeds - I</A>
						</DL><p>
						<DT><H3 FOLDED>DiT</H3>
						<DL><p>
							<DT><H3 FOLDED>dit-theory</H3>
							<DL><p>
								<DT><A HREF="https://leetarxiv.substack.com/p/the-annotated-diffusion-transformer">SORA From Scratch: Diffusion Transformers for Video Generation Models</A>
								<DT><A HREF="https://github.com/lucidrains/mmdit">lucidrains/mmdit: Implementation of a single layer of the MMDiT, proposed in Stable Diffusion 3, in Pytorch</A>
							</DL><p>
							<DT><H3 FOLDED>dit-serving</H3>
							<DL><p>
								<DT><H3 FOLDED>model-deploy</H3>
								<DL><p>
									<DT><A HREF="https://github.com/chengzeyi/model-deploy">chengzeyi/model-deploy</A>
								</DL><p>
								<DT><H3 FOLDED>DiffSynth</H3>
								<DL><p>
									<DT><H3 FOLDED>DiffSynth-studio</H3>
									<DL><p>
										<DT><H3 FOLDED>DiffSynth-studio-wan</H3>
										<DL><p>
											<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/wanvideo">DiffSynth-Studio/examples/wanvideo at main ¬∑ modelscope/DiffSynth-Studio</A>
											<DT><A HREF="https://github.com/search?q=repo%3Amodelscope%2FDiffSynth-Studio+wan2.2&type=commits">WAN 2.2 model implemeantion and inference code</A>
										</DL><p>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/wanvideo">DiffSynth-Studio/examples/wanvideo at main ¬∑ modelscope/DiffSynth-Studio</A>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/commit/46d390cf8aab890c285d56490c6692a6e73d845c">Merge pull request #727 from mi804/flux.1_kera_dev ¬∑ modelscope/DiffSynth-Studio@46d390c</A>
									</DL><p>
									<DT><H3 FOLDED>DiffSynth-engine</H3>
									<DL><p>
										<DT><H3 FOLDED>diffSynth-engine-weights</H3>
										<DL><p>
											<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/issues/90">FLUXÂä†ËΩΩdiffusersÊ†ºÂºèÊùÉÈáçÊó∂ÁîüÂõæÈîôËØØ ¬∑ Issue #90 ¬∑ modelscope/DiffSynth-Engine</A>
											<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/pull/89">fix flux param by akaitsuki-ii ¬∑ Pull Request #89</A>
										</DL><p>
										<DT><H3 FOLDED>diffSynth-engine-distributed</H3>
										<DL><p>
											<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/blob/main/diffsynth_engine/models/wan/wan_dit.py">DiffSynth-Engine/diffsynth_engine/models/wan/wan_dit.py</A>
										</DL><p>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine">modelscope/DiffSynth-Engine</A>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/blob/12cc587b008ee6e0c6676a789d6e6f04a992a2be/diffsynth_engine/models/flux/flux_dit.py">DiffSynth-Engine/diffsynth_engine/models/flux/flux_dit.py</A>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/pull/41/files">supports wan fun lora by akaitsuki-ii ¬∑ Pull Request #41 ¬∑ modelscope/DiffSynth-Engine</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>xdit-server</H3>
								<DL><p>
									<DT><A HREF="https://github.com/xdit-project/xDiT/commit/68328955f79300ac0ed7f243bf6cbb2bb045a5c9#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5">add a http service demo. (#257) ¬∑ xdit-project/xDiT@6832895</A>
									<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/entrypoints/launch.py">xDiT/entrypoints/launch.py at main ¬∑ xdit-project/xDiT</A>
									<DT><A HREF="https://github.com/xdit-project/xDiT/commit/fb5c55aab778e95f538f38e5936ac2c1bf542dec">refactor http service (#465) ¬∑ xdit-project/xDiT@fb5c55a</A>
								</DL><p>
								<DT><H3 FOLDED>comfy</H3>
								<DL><p>
									<DT><H3 FOLDED>WaveSpeed</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chengzeyi/Comfy-WaveSpeed">chengzeyi/Comfy-WaveSpeed: [WIP] The all in one inference optimization solution for ComfyUl, universal, flexible, and fast.</A>
									</DL><p>
									<DT><H3 FOLDED>comfy-video</H3>
									<DL><p>
										<DT><H3 FOLDED>comfy-wan</H3>
										<DL><p>
											<DT><H3 FOLDED>comfy-kijai</H3>
											<DL><p>
												<DT><A HREF="https://github.com/kijai">kijai (Jukka Sepp√§nen)</A>
												<DT><A HREF="https://github.com/kijai/ComfyUI-WanVideoWrapper">kijai/ComfyUI-WanVideoWrapper</A>
											</DL><p>
											<DT><H3 FOLDED>WanVideoWrapper</H3>
											<DL><p>
												<DT><A HREF="https://github.com/kijai/ComfyUI-WanVideoWrapper">kijai/ComfyUI-WanVideoWrapper</A>
											</DL><p>
											<DT><H3 FOLDED>comfy-wan-steps-distill</H3>
											<DL><p>
												<DT><A HREF="https://x.com/SubhoGhosh02/status/1951628181439463801">WAN 2.2 kijai 4 step lora works better when we load on both high and low noise experts</A>
												<DT><A HREF="https://huggingface.co/Kijai/WanVideo_comfy/tree/main/Wan22-Lightning">WAN-flash: Wan2.2-Lightning_T2V-A14B-4steps-lora_HIGH_fp16.safetensors</A>
											</DL><p>
											<DT><H3 FOLDED>comfy-wan22-5090</H3>
											<DL><p>
												<DT><A HREF="https://huggingface.co/Phr00t/WAN2.2-14B-Rapid-AllInOne">Phr00t/WAN2.2-14B-Rapid-AllInOne ¬∑ Hugging Face</A>
												<DT><A HREF="https://github.com/camenduru/Wan2.1-jupyter/blob/main/workflows/wan2.2-i2i-rapid-flux-krea-dev.json">Wan2.1-jupyter/workflows/wan2.2-i2i-rapid-flux-krea-dev.json at main ¬∑ camenduru/Wan2.1-jupyter</A>
											</DL><p>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>comfy-image</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/PaddlePaddle/PaddleMIX/blob/dc863a4655debeba1a6d664125dfcf3ab2238fc9/comfyui/ComfyUI_ppdiffusers/sdxl_pipe_nodes.py">PaddleMIX/comfyui/ComfyUI_ppdiffusers/sdxl_pipe_nodes.py</A>
									<DT><A HREF="https://github.com/siliconflow/onediff_comfy_nodes">siliconflow/onediff_comfy_nodes: Just a subfolder of https://github.com/siliconflow/onediff</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/tree/main/onediff_comfy_nodes">onediff/onediff_comfy_nodes at main ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/chengzeyi/ComfyUI_stable_fast">chengzeyi/ComfyUI_stable_fast</A>
									<DT><A HREF="https://github.com/Chaoses-Ib/ComfyScript">Chaoses-Ib/ComfyScript: A Python frontend and library for ComfyUI</A>
									<DT><A HREF="https://github.com/ali1234/comfyui-node-decorator/blob/main/registry.py">comfyui-node-decorator/registry.py at main ¬∑ ali1234/comfyui-node-decorator</A>
									<DT><A HREF="https://github.com/discus0434/comfyui-flux-accelerator">discus0434/comfyui-flux-accelerator: Accelerates Flux.1 image generation, just by using this node.</A>
									<DT><A HREF="https://github.com/kijai?tab=repositories">kijai (kijai) / Repositories</A>
									<DT><A HREF="https://github.com/camenduru?tab=stars">camenduru / Starred</A>
									<DT><A HREF="https://www.youtube.com/watch?v=7DXnGrARqys">(1) TACO-DiT: Accelerating Your ComfyUI Generation Experience - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>dit-serving-lora</H3>
								<DL><p>
									<DT><A HREF="https://github.com/aredden/flux-fp8-api/blob/main/lora_loading.py">flux-fp8-api/lora_loading.py at main ¬∑ aredden/flux-fp8-api</A>
								</DL><p>
								<DT><H3 FOLDED>dit-vram_management</H3>
								<DL><p>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/de4e2703cac0aa55d4c41ea5b4b39efa75060d3f/diffsynth/vram_management/layers.py#L145">DiffSynth-Studio/diffsynth/vram_management/layers.py</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/de4e2703cac0aa55d4c41ea5b4b39efa75060d3f/diffsynth/vram_management/gradient_checkpointing.py">DiffSynth-Studio/diffsynth/vram_management/gradient_checkpointing.py</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/de4e2703cac0aa55d4c41ea5b4b39efa75060d3f/diffsynth/vram_management/layers.py">DiffSynth-Studio/diffsynth/vram_management/layers.py</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/main/examples/vram_management/flux_text_to_image.py">DiffSynth-Studio/examples/vram_management/flux_text_to_image.py</A>
								</DL><p>
								<DT><H3 FOLDED>wan2.2-fast</H3>
								<DL><p>
									<DT><A HREF="https://x.com/wavespeed_ai/status/1951167573640487378">wan2.2 flash: diffusion steps = 4 instead of 8</A>
									<DT><A HREF="https://github.com/ModelTC/Wan2.2-Lightning">ModelTC/Wan2.2-Lightning: Wan2.2-Lightning: Speed up wan2.2 model with distillation</A>
								</DL><p>
								<DT><H3 FOLDED>cache-dit-server</H3>
								<DL><p>
									<DT><A HREF="https://github.com/vipshop/cache-dit/blob/853df893347fddcda5026a2401e9b89619b2a4eb/src/cache_dit/serve/api_server.py#L4">cache-dit/src/cache_dit/serve/api_server.py Adapted from SGLang's HTTP server: https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/entrypoints/http_server.py</A>
								</DL><p>
								<DT><A HREF="https://github.com/aredden/flux-fp8-api/tree/main">aredden/flux-fp8-api: Flux diffusion model implementation using quantized fp8 matmul &amp; remaining layers use faster half precision accumulate, which is ~2x faster on consumer devices.</A>
								<DT><A HREF="https://github.com/cccntu/vFLUX">cccntu/vFLUX</A>
								<DT><A HREF="https://jonathanc.net/blogs/maximizing_pytorch_throughput">Maximizing PyTorch Throughput with FastAPI ‚Äì Jonathan Chang‚Äôs Blog</A>
								<DT><A HREF="https://blog.vllm.ai/2024/09/05/perf-update.html">vLLM v0.6.0: 2.7x Throughput Improvement and 5x Latency Reduction | vLLM Blog</A>
								<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio">modelscope/DiffSynth-Studio: Enjoy the magic of Diffusion models!</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-multimodal</H3>
							<DL><p>
								<DT><H3 FOLDED>qwen2vl-flux</H3>
								<DL><p>
									<DT><A HREF="https://chatgpt.com/c/67e5cc46-6074-800c-80e0-953c72f3adcd">Qwen-2.5-VL Text Encoder Analysis</A>
									<DT><A HREF="https://github.com/erwold/qwen2vl-flux/blob/main/technical-report.pdf">qwen2vl-flux/technical-report.pdf at main ¬∑ erwold/qwen2vl-flux</A>
									<DT><A HREF="https://github.com/erwold/qwen2vl-flux">erwold/qwen2vl-flux</A>
								</DL><p>
								<DT><H3 FOLDED>X2I</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/OPPOer/X2I">OPPOer/X2I ¬∑ Hugging Face</A>
									<DT><A HREF="https://arxiv.org/html/2503.06134v2#S6">X2I: Seamless Integration of Multimodal Understanding into Diffusion Transformer via Attention Distillation</A>
									<DT><A HREF="https://chatgpt.com/c/67e5cc46-6074-800c-80e0-953c72f3adcd">Qwen-2.5-VL Text Encoder Analysis</A>
									<DT><A HREF="https://github.com/OpenBMB/MiniCPM-o">OpenBMB/MiniCPM-o: MiniCPM-o 2.6: A GPT-4o Level MLLM for Vision, Speech and Multimodal Live Streaming on Your Phone</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>MM DiT</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/cloneofsimo/809b036a65be317163dd81ba824d67aa">MM DiT model that was proposed by SD3 paper.</A>
								<DT><A HREF="https://carpedm30.notion.site/Diffusion-Optimization-276fde0aed9745f99000a7fea6e9c40b?p=cab3bc1752084addbbe18b68a8edf8ba&pm=s">MM DiT Analysis</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1822271687649546274">How it handles attention compared to traditional Cross attention (diagram)</A>
								<DT><A HREF="https://github.com/Stability-AI/sd3-ref">Stability-AI/sd3-ref</A>
								<DT><A HREF="https://github.com/lucidrains/mmdit">lucidrains/mmdit: Implementation of a single layer of the MMDiT, proposed in Stable Diffusion 3, in Pytorch</A>
							</DL><p>
							<DT><H3 FOLDED>Denoising Diffusion Probabilistic Models</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2006.11239">[2006.11239] Denoising Diffusion Probabilistic Models</A>
								<DT><A HREF="https://github.com/SonicCodes/hyperada">SonicCodes/hyperada: Linear hypernetwork ada</A>
								<DT><A HREF="https://github.com/cloneofsimo/minDiffusion">cloneofsimo/minDiffusion: Self-contained, minimalistic implementation of diffusion models with Pytorch.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=0V96wE7lY4w">Denoising Autoencoders | Deep Learning Animated - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>dit-lora</H3>
							<DL><p>
								<DT><H3 FOLDED>lora-merge</H3>
								<DL><p>
									<DT><H3 FOLDED>clora</H3>
									<DL><p>
										<DT><A HREF="https://github.com/gemlab-vt/clora">gemlab-vt/clora</A>
									</DL><p>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>dit-architecture</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=nrKKLJXBSw0">TUM AI Lecture Series - FLUX: Flow Matching for Content Creation at Scale (Robin Rombach) - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>dit-moe</H3>
							<DL><p>
							</DL><p>
							<DT><A HREF="https://github.com/flixmk/LightningDiT_TREAD">flixmk/LightningDiT_TREAD: LightningDiT Fork with TREAD implementation</A>
							<DT><A HREF="https://github.com/thu-nics/DiTFastAttn">thu-nics/DiTFastAttn</A>
							<DT><A HREF="https://github.com/Tencent/HunyuanDiT/">Tencent/HunyuanDiT: Hunyuan-DiT : A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding</A>
							<DT><A HREF="https://dit.hunyuan.tencent.com/">ËÖæËÆØÊ∑∑ÂÖÉDiT</A>
							<DT><A HREF="https://github.com/kvfrans/jax-diffusion-transformer/?tab=readme-ov-file">kvfrans/jax-diffusion-transformer: Implementation of Diffusion Transformer (DiT) in JAX</A>
							<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/tensorrt_llm/models/dit/model.py">TensorRT-LLM/tensorrt_llm/models/dit/model.py at main ¬∑ NVIDIA/TensorRT-LLM</A>
							<DT><A HREF="https://github.com/black-forest-labs/flux/blob/main/src/flux/model.py">flux/src/flux/model.py at main ¬∑ black-forest-labs/flux</A>
							<DT><A HREF="https://github.com/facebookresearch/DiT/blob/main/models.py">DiT/models.py at main ¬∑ facebookresearch/DiT</A>
							<DT><A HREF="https://github.com/openai/glide-text2im">openai/glide-text2im: GLIDE: a diffusion-based text-conditional image synthesis model</A>
							<DT><A HREF="https://github.com/facebookresearch/mae/blob/main/models_mae.py">mae/models_mae.py at main ¬∑ facebookresearch/mae</A>
							<DT><A HREF="https://github.com/xdit-project/xDiT">xdit-project/xDiT: xDiT: A Scalable Inference Engine for Diffusion Transformers (DiTs) on multi-GPU Clusters</A>
							<DT><A HREF="https://github.com/oahzxl/OpenDiT">oahzxl/OpenDiT: OpenDiT: An Easy, Fast and Memory-Efficient System for DiT Training and Inference</A>
							<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys">NUS-HPC-AI-Lab/VideoSys: VideoSys: An easy and efficient system for video generation</A>
							<DT><A HREF="https://github.com/Anima-Lab/MaskDiT">Anima-Lab/MaskDiT: Code for Fast Training of Diffusion Models with Masked Transformers</A>
							<DT><A HREF="https://github.com/willisma/SiT">willisma/SiT: Official PyTorch Implementation of "SiT: Exploring Flow and Diffusion-based Generative Models with Scalable Interpolant Transformers"</A>
							<DT><A HREF="https://x.com/JXQNHZr1yUAj5Be/status/1854317183960309995">Scaling Laws For Diffusion Transformers</A>
							<DT><A HREF="https://www.youtube.com/watch?v=vXtapCFctTI">Stanford CS25: V5 I Transformers in Diffusion Models for Image Generation and Beyond - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=L45iAba2DAw">Diffusion in Transformers Tutorial and Explainer - YouTube</A>
							<DT><A HREF="https://x.com/sainingxie/status/1957842855587639369">(1) Saining Xie en X: "I know op is click-baiting, but let me bite... fwiw every researcher‚Äôs DREAM is to find out their architecture is wrong. If it‚Äôs never wrong, that‚Äôs a bigger problem. we try to break DiT every day w/ SiT, REPA, REPA-E etc. but you gotta form hypotheses, run experiments, test, not" / X</A>
							<DT><A HREF="https://github.com/facebookresearch/DiT">facebookresearch/DiT: Official PyTorch Implementation of "Scalable Diffusion Models with Transformers"</A>
							<DT><A HREF="https://arxiv.org/abs/2212.09748">[2212.09748] Scalable Diffusion Models with Transformers</A>
						</DL><p>
						<DT><H3 FOLDED>image-training</H3>
						<DL><p>
							<DT><H3 FOLDED>diffusion-training-multimodal</H3>
							<DL><p>
								<DT><H3 FOLDED>bytedn-bagel-training</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ByteDance-Seed/Bagel/commit/738a570d27115a982fe01030a824a1cc01db59c1">add train doc and fix eval ¬∑ ByteDance-Seed/Bagel@738a570</A>
									<DT><A HREF="https://github.com/ByteDance-Seed/Bagel/tree/main/train">Bagel/train at main ¬∑ ByteDance-Seed/Bagel</A>
									<DT><A HREF="https://github.com/bytedance/USO">bytedance/USO: üî•üî• Open-sourced unified customization model</A>
								</DL><p>
								<DT><H3 FOLDED>bytedn-bagel-evaluation</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ByteDance-Seed/Bagel/tree/main/eval/gen">Bagel/eval/gen at main ¬∑ ByteDance-Seed/Bagel</A>
									<DT><A HREF="https://github.com/ByteDance-Seed/Bagel/blob/main/eval/gen/geneval/prompts/object_names.txt">Bagel/eval/gen/geneval/prompts/object_names.txt at main ¬∑ ByteDance-Seed/Bagel</A>
									<DT><A HREF="https://gist.github.com/cloneofsimo/b50f159ad7588ef41f2abeee9aee0df3">Set of wildly complex image descriptions &amp; atomic factual statements.</A>
									<DT><A HREF="https://github.com/ByteDance-Seed/Bagel/blob/main/eval/gen/geneval/prompts/create_prompts.py">Bagel/eval/gen/geneval/prompts/create_prompts.py</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>dit-training-mup</H3>
							<DL><p>
								<DT><H3 FOLDED>bytedn-dit-mup</H3>
								<DL><p>
									<DT><A HREF="https://x.com/papers_anon/status/1925466031285588069">(1) PapersAnon en X: "Scaling Diffusion Transformers Efficiently via ŒºP Generalizes standard ¬µP to diffusion Transformers and validates its effectiveness through large-scale experiments. Saw DiT-XL-2-¬µP with transferred learning rate achieves 2.9√ó faster convergence than the original DiT-XL-2. Links https://t.co/TnISR4ihpX" / X</A>
									<DT><A HREF="https://github.com/ML-GSAI/Scaling-Diffusion-Transformers-muP">ML-GSAI/Scaling-Diffusion-Transformers-muP: Official implementation for our paper "Scaling Diffusion Transformers Efficiently via ŒºP".</A>
									<DT><A HREF="https://arxiv.org/pdf/2505.15270">Scaling Diffusion Transformers Efficiently via ¬µP</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>image-training-MoE</H3>
							<DL><p>
								<DT><A HREF="https://github.com/feizc/DiT-MoE">feizc/DiT-MoE: Scaling Diffusion Transformers with Mixture of Experts</A>
								<DT><A HREF="https://arxiv.org/abs/2407.11633">[2407.11633] Scaling Diffusion Transformers to 16 Billion Parameters</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-training-amp</H3>
							<DL><p>
								<DT><H3 FOLDED>diffusion-amp-fp8</H3>
								<DL><p>
									<DT><A HREF="https://github.com/graphcore-research/out-of-the-box-fp8-training/blob/main/out_of_the_box_fp8_training.ipynb">out-of-the-box-fp8-training/out_of_the_box_fp8_training.ipynb at main ¬∑ graphcore-research/out-of-the-box-fp8-training</A>
									<DT><A HREF="https://github.com/PaddlePaddle/PaddleMIX/blob/dc863a4655debeba1a6d664125dfcf3ab2238fc9/ppdiffusers/examples/class_conditional_image_generation/DiT/diffusion/dit.py#L371">PaddleMIX/ppdiffusers/examples/class_conditional_image_generation/DiT/diffusion/dit.py at dc863a4655debeba1a6d664125dfcf3ab2238fc9 ¬∑ PaddlePaddle/PaddleMIX</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>mosaicml-diffusion</H3>
							<DL><p>
								<DT><A HREF="https://github.com/mosaicml/diffusion">mosaicml/diffusion</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-lora</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cloneofsimo/lora">cloneofsimo/lora: Using Low-rank adaptation to quickly fine-tune diffusion models.</A>
							</DL><p>
							<DT><H3 FOLDED>REPA</H3>
							<DL><p>
								<DT><A HREF="https://sihyun.me/REPA/">Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think</A>
								<DT><A HREF="https://github.com/cloneofsimo/repa-rf">cloneofsimo/repa-rf</A>
							</DL><p>
							<DT><H3 FOLDED>image-generation-dataset</H3>
							<DL><p>
								<DT><H3 FOLDED>FFmpeg</H3>
								<DL><p>
									<DT><H3 FOLDED>ffmpeg-av</H3>
									<DL><p>
										<DT><H3 FOLDED>av-video</H3>
										<DL><p>
											<DT><A HREF="https://github.com/chengzeyi/model-deploy/blob/e64d93f2025adb6d498a0f40fb93809cc5764ed9/runpod/dishi_video_upscaler/handler.py#L68">def _setup_streams(self, input_container: InputContainer):</A>
											<DT><A HREF="https://github.com/chengzeyi/model-deploy/blob/e64d93f2025adb6d498a0f40fb93809cc5764ed9/runpod/dishi_video_upscaler/handler.py#L126C13-L126C60">ffmpeg av video buffer stream manipulation</A>
										</DL><p>
										<DT><A HREF="https://pypi.org/project/av/">av¬∑PyPI</A>
									</DL><p>
									<DT><H3 FOLDED>ffmpeg-codec</H3>
									<DL><p>
										<DT><A HREF="https://x.com/mike64_t/status/1975737784557314378">low complexity codec designed to be run at 1200 fps</A>
									</DL><p>
									<DT><A HREF="https://ffmpeg.org/">FFmpeg</A>
									<DT><A HREF="https://github.com/FFmpeg/FFmpeg">FFmpeg/FFmpeg: Mirror of https://git.ffmpeg.org/ffmpeg.git</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/blob/main/diffsynth_engine/utils/video.py">DiffSynth-Engine/diffsynth_engine/utils/video.py at main VideoReader</A>
									<DT><A HREF="https://github.com/antferdom/deployment-dev/commit/09c7ea640f1f23a54a390424ba06b6f9af25376c#diff-2451f8a9ce450cb8e8b9c8371b6cb04cf95b2c7484f5228435b7e6c5f7741313">add misc_worker ¬∑ antferdom/deployment-dev@09c7ea6</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Aspect_ratio_(image)">Aspect ratio (image) - Wikipedia</A>
								</DL><p>
								<DT><H3 FOLDED>imageio</H3>
								<DL><p>
									<DT><A HREF="https://github.com/imageio/imageio">imageio/imageio: Python library for reading and writing image data</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/blob/main/diffsynth_engine/utils/video.py">DiffSynth-Engine/diffsynth_engine/utils/video.py</A>
									<DT><A HREF="https://imageio.readthedocs.io/en/stable/index.html">Welcome to imageio‚Äôs documentation! ‚Äî imageio 2.37.0 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>opencv</H3>
								<DL><p>
									<DT><H3 FOLDED>cv2-resize</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chengzeyi/model-deploy/blob/72bad1281b246d3ce4145671c7e0a38131bff50a/runpod/mystic_upscaler/patches/controlnet.py#L492">model-deploy/runpod/mystic_upscaler/patches/controlnet.py:  def high_quality_resize(x, size):</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>frame-interpolation</H3>
								<DL><p>
									<DT><H3 FOLDED>rife</H3>
									<DL><p>
										<DT><A HREF="https://github.com/hzwer/Practical-RIFE">hzwer/Practical-RIFE: More practical frame interpolation approach.</A>
										<DT><A HREF="https://github.com/HolyWu/vs-rife/blob/master/vsrife/__init__.py">vs-rife/vsrife/__init__.py at master ¬∑ HolyWu/vs-rife</A>
										<DT><A HREF="https://github.com/vladmandic/rife">vladmandic/rife: Video frame interpolation using RIFE</A>
										<DT><A HREF="https://github.com/hzwer/ECCV2022-RIFE">hzwer/ECCV2022-RIFE: ECCV2022 - Real-Time Intermediate Flow Estimation for Video Frame Interpolation</A>
										<DT><A HREF="https://github.com/hzwer/Practical-RIFE?tab=readme-ov-file">hzwer/Practical-RIFE: More practical frame interpolation approach.</A>
										<DT><A HREF="https://arxiv.org/abs/2011.06294">[2011.06294] Real-Time Intermediate Flow Estimation for Video Frame Interpolation</A>
										<DT><A HREF="https://arxiv.org/abs/2310.17294">[2310.17294] Scale-Adaptive Feature Aggregation for Efficient Space-Time Video Super-Resolution</A>
										<DT><A HREF="https://www.youtube.com/watch?v=QII2KQSBBwk">Video Enhancement SAFAv0.5 Demo - YouTube</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>imgdataset_process</H3>
								<DL><p>
									<DT><A HREF="https://github.com/cloneofsimo/imgdataset_process/tree/main">cloneofsimo/imgdataset_process</A>
									<DT><A HREF="https://stackoverflow.com/questions/35392594/getting-facebook-original-image-url">python - Getting Facebook original image url - Stack Overflow</A>
									<DT><A HREF="https://meyerweb.com/eric/tools/dencoder/">URL Decoder/Encoder</A>
									<DT><A HREF="https://gist.github.com/cloneofsimo/d31eee8a5352655cb45869694adf0880">MDS-Multiprocessed-datamerging to NFS, because writing is async this is faster</A>
									<DT><A HREF="https://github.com/allenai/cached_path">allenai/cached_path: A file utility for accessing both local and remote files through a unified interface.</A>
									<DT><A HREF="https://github.com/carpedm20/dreamsim">DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data</A>
								</DL><p>
								<DT><H3 FOLDED>image-captioning</H3>
								<DL><p>
									<DT><H3 FOLDED>LAION-POP</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/datasets/Ejafa/ye-pop">Ejafa/ye-pop ¬∑ Datasets at Hugging Face</A>
										<DT><A HREF="https://laion.ai/blog/laion-pop/">LAION POP: 600,000 high-resolution images with detailed descriptions | LAION</A>
									</DL><p>
									<DT><H3 FOLDED>better-captions</H3>
									<DL><p>
										<DT><A HREF="https://cdn.openai.com/papers/dall-e-3.pdf">Improving Image Generation with Better Captions</A>
										<DT><A HREF="https://gligen.github.io/">GLIGEN:Open-Set Grounded Text-to-Image Generation.</A>
										<DT><A HREF="https://arxiv.org/html/2311.12342v2">LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis</A>
										<DT><A HREF="https://github.com/lllyasviel/Omost">lllyasviel/Omost: Your image is almost there!</A>
									</DL><p>
									<DT><A HREF="https://huggingface.co/datasets/google/imageinwords">google/imageinwords ¬∑ Datasets at Hugging Face</A>
									<DT><A HREF="https://www.microsoft.com/en-us/research/publication/florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks - Microsoft Research</A>
									<DT><A HREF="https://x.com/gytdau/status/1804266728781943003">(1) Gytis Daujotas en X: "Excited to release a research preview of Feature Lab, a playground where you can sculpt images by editing their features. It uses a SAE to extract the sparse features from an image embeddings model, and allows us to finely sculpt and tweak images. https://t.co/0Nv6f7dX2P" / X</A>
									<DT><A HREF="https://gist.github.com/cloneofsimo/b50f159ad7588ef41f2abeee9aee0df3">Set of wildly complex image descriptions &amp; atomic factual statements.</A>
									<DT><A HREF="https://gist.github.com/cloneofsimo/87cfa71a7c4e2a5f9748cb8812eb0536">siglip_mds.py</A>
									<DT><A HREF="https://github.com/rom1504/img2dataset/">rom1504/img2dataset: Easily turn large sets of image urls to an image dataset. Can download, resize and package 100M urls in 20h on one machine.</A>
								</DL><p>
								<DT><H3 FOLDED>WebDataset</H3>
								<DL><p>
									<DT><A HREF="https://github.com/webdataset/webdataset">webdataset/webdataset: A high-performance Python-based I/O system for large (and small) deep learning problems, with strong support for PyTorch.</A>
								</DL><p>
								<DT><H3 FOLDED>o1-edit-dataset</H3>
								<DL><p>
									<DT><A HREF="https://ucsc-vlaa.github.io/GPT-Image-Edit/">GPT-IMAGE-EDIT-1.5M</A>
									<DT><A HREF="https://arxiv.org/abs/2507.21033">[2507.21033] GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</A>
									<DT><A HREF="https://github.com/wyhlovecpp/GPT-Image-Edit/tree/main">wyhlovecpp/GPT-Image-Edit: GPT-IMAGE-EDIT-1.5M: A Million-Scale, GPT-Generated Image Dataset</A>
									<DT><A HREF="https://huggingface.co/datasets/UCSC-VLAA/GPT-Image-Edit-1.5M">UCSC-VLAA/GPT-Image-Edit-1.5M ¬∑ Datasets at Hugging Face</A>
									<DT><A HREF="https://huggingface.co/UCSC-VLAA/gpt-image-edit-training">UCSC-VLAA/gpt-image-edit-training ¬∑ Hugging Face</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>minRF</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cloneofsimo/minRF">cloneofsimo/minRF: Minimal implementation of scalable rectified flow transformers, based on SD3's approach</A>
								<DT><A HREF="https://github.com/cloneofsimo/minDiffusion">cloneofsimo/minDiffusion: Self-contained, minimalistic implementation of diffusion models with Pytorch.</A>
							</DL><p>
							<DT><H3 FOLDED>diffusion-rl</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2505.05470">[2505.05470] Flow-GRPO: Training Flow Matching Models via Online RL</A>
							</DL><p>
							<DT><H3 FOLDED>qwen-image-training</H3>
							<DL><p>
								<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/commit/8d2f6ad32ea8dae5d65bd8e39d95ea4f67ede06d">Merge pull request #735 from modelscope/qwen-image</A>
								<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/8d2f6ad32ea8dae5d65bd8e39d95ea4f67ede06d/examples/qwen_image/model_training/train.py">DiffSynth-Studio/examples/qwen_image/model_training/train.py at 8d2f6ad32ea8dae5d65bd8e39d95ea4f67ede06d ¬∑ modelscope/DiffSynth-Studio</A>
								<DT><A HREF="https://www.alphaxiv.org/abs/2508.02324">Qwen-Image Technical Report | alphaXiv</A>
							</DL><p>
							<DT><A HREF="https://gist.github.com/cloneofsimo/73db5aaa6d74b1b3eebce31333083afa">SDXL_trainer</A>
							<DT><A HREF="https://arxiv.org/abs/2407.15811">[2407.15811] Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget</A>
							<DT><A HREF="https://snap-research.github.io/BitsFusion/">BitsFusion</A>
							<DT><A HREF="https://github.com/PaddlePaddle/PaddleMIX/tree/dc863a4655debeba1a6d664125dfcf3ab2238fc9">PaddlePaddle/PaddleMIX</A>
							<DT><A HREF="https://github.com/cloneofsimo/minRF">cloneofsimo/minRF: Minimal implementation of scalable rectified flow transformers, based on SD3's approach</A>
							<DT><A HREF="https://github.com/cloneofsimo/minDiffusion">cloneofsimo/minDiffusion: Self-contained, minimalistic implementation of diffusion models with Pytorch.</A>
							<DT><A HREF="https://github.com/Kwai-Kolors/Kolors">Kwai-Kolors/Kolors: Kolors Team</A>
							<DT><A HREF="https://github.com/Anima-Lab/MaskDiT">Anima-Lab/MaskDiT: Code for Fast Training of Diffusion Models with Masked Transformers</A>
							<DT><A HREF="https://github.com/bghira/SimpleTuner?tab=readme-ov-file#flux1">bghira/SimpleTuner: A general fine-tuning kit geared toward diffusion models.</A>
							<DT><A HREF="https://github.com/fal-ai/diffusion-speedrun">fal-ai/diffusion-speedrun</A>
							<DT><A HREF="https://github.com/fal-ai-community/nano-mdm">fal-ai-community/nano-mdm: Tiny re-implementation of MDM in style of LLaDA and nano-gpt speedrun</A>
							<DT><A HREF="https://github.com/fal-ai-community/minDDPD">fal-ai-community/minDDPD</A>
							<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-flux-is-here-experience-diffusion-model-training-on-torchtitan/221119">[Distributed w/ TorchTitan] FLUX is Here: Experience Diffusion Model Training on TorchTitan - distributed / torchtitan - PyTorch Forums</A>
							<DT><A HREF="https://www.krea.ai/blog/flux-krea-open-source-release">Releasing Open Weights for FLUX.1 Krea DiT image post-training model colapse</A>
							<DT><A HREF="https://x.com/swaystar123/status/2000826634409320918?s=12">SpeedrunDiT: speedrunning imagenet diffusion training</A>
							<DT><A HREF="https://github.com/SwayStar123/SpeedrunDiT">SwayStar123/SpeedrunDiT: SR-DiT Speedrunning ImageNet Diffusion</A>
						</DL><p>
						<DT><H3 FOLDED>image-generation</H3>
						<DL><p>
							<DT><H3 FOLDED>raw-pixel-space</H3>
							<DL><p>
								<DT><A HREF="https://x.com/skywalkeryxc/status/1992815287104938442">(1) Xinchen Yan en X: "For years, RAW pixel space pretraining has been sidelined: too compute-expensive. Our new @GoogleDeepMind paper üìú dives into the scaling trends of raw pixel models to answer the question ‚Äúhow far are we from scaling up next-pixel prediction?‚Äù https://t.co/gMirFBlu5p https://t.co/ehIw7IMwqj" / X</A>
								<DT><A HREF="https://arxiv.org/pdf/2511.08704">Rethinking generative image pretraining: How far are we from scaling up next-pixel prediction?</A>
							</DL><p>
							<DT><H3 FOLDED>WAN-image</H3>
							<DL><p>
								<DT><A HREF="https://www.reddit.com/r/StableDiffusion/comments/1lu7nxx/wan_21_txt2img_is_amazing/">WAN 2.1 generated only one frame, becoming image-generator model</A>
								<DT><A HREF="https://x.com/chengzeyi/status/1945054929355149428">WAN text to image is NOT plastic</A>
								<DT><A HREF="https://pastebin.com/Mt56bMCJ">Wan 2.2 Text to Image</A>
							</DL><p>
							<DT><H3 FOLDED>Qwen-Image</H3>
							<DL><p>
								<DT><H3 FOLDED>qwen-image-weights</H3>
								<DL><p>
									<DT><H3 FOLDED>Qwen-Image-fp8</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/wavespeed/Qwen-Image-e4m3/tree/main">wavespeed/Qwen-Image-e4m3 at main</A>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/commit/32cf5d32cebedf4992ebc742cd15fc0901b2f2b1">Qwen-Image FP8 (#761) ¬∑ modelscope/DiffSynth-Studio@32cf5d3</A>
									</DL><p>
									<DT><A HREF="https://huggingface.co/Qwen/Qwen-Image">Qwen/Qwen-Image ¬∑ Hugging Face</A>
								</DL><p>
								<DT><A HREF="https://github.com/QwenLM/Qwen-Image">QwenLM/Qwen-Image: Qwen-Image is a powerful image generation foundation model capable of complex text rendering and precise image editing.</A>
								<DT><A HREF="https://qwenlm.github.io/blog/qwen-image/">Qwen-Image: Crafting with Native Text Rendering | Qwen</A>
								<DT><A HREF="https://wavespeed.ai/models/wavespeed-ai/qwen-image/text-to-image">Qwen-Image Text To Image Online - WavespeedAI</A>
								<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/commit/c35f2d8bda5199b59d6285c753b6941b3e2143d3">qwen-image ¬∑ modelscope/DiffSynth-Studio@c35f2d8</A>
							</DL><p>
							<DT><H3 FOLDED>Z-image</H3>
							<DL><p>
								<DT><H3 FOLDED>z-image-undistilled</H3>
								<DL><p>
									<DT><A HREF="https://tongyilab.substack.com/p/jan-30-2026-the-tongyi-weekly?utm_campaign=post&triedRedirect=true">Jan 30, 2026 | The Tongyi Weekly - Tongyi Lab</A>
									<DT><A HREF="https://huggingface.co/Tongyi-MAI/Z-Image">Tongyi-MAI/Z-Image ¬∑ Hugging Face</A>
								</DL><p>
								<DT><A HREF="https://github.com/Tongyi-MAI/Z-Image">Tongyi-MAI/Z-Image</A>
								<DT><A HREF="https://arxiv.org/abs/2511.22699">[2511.22699] Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer</A>
							</DL><p>
							<DT><H3 FOLDED>HunyuanImage-2.1</H3>
							<DL><p>
								<DT><A HREF="https://x.com/bdsqlsz/status/1965293660058386484">ÈùíÈæçËÅñËÄÖ en X: "Officially announced! The open-source is HunyuanImage-2.1 from Tencent. 17B,2K resolution. DIT:Double stream like FLUX TE:MLLM+ ByT5 32 √ó 32 VAE base+refine model with meanflow distilled version GRPO https://t.co/xiMDORplSp" / X</A>
								<DT><A HREF="https://github.com/Tencent-Hunyuan/HunyuanImage-2.1">Tencent-Hunyuan/HunyuanImage-2.1</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/1972469371839860954">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "This open model is their 80B-13AB LLM augmented into, basically, JanusFlow (VAE downsampling raw pixels, jointly conditioned diffusion). They don't hype very much but the report claims SoTA level (&amp;gt;Seedream 4, Nano-Banana!) Well... it *is* at least up there, and it's high res. https://t.co/YBB3YVueVo" / X</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-Seedream</H3>
							<DL><p>
								<DT><H3 FOLDED>Seedream-3</H3>
								<DL><p>
									<DT><A HREF="https://x.com/bdsqlsz/status/1912347074479419781">Just now, ByteDance publicly released the technical report of their latest SOTA image model Seedream 3.0.</A>
									<DT><A HREF="https://team.doubao.com/en/tech/seedream3_0">Doubao Team</A>
									<DT><A HREF="https://arxiv.org/pdf/2504.11346">Seedream 3.0 Technical Report</A>
								</DL><p>
								<DT><H3 FOLDED>Seedream-2</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2503.07703">Seedream 2.0: A Native Chinese-English Bilingual Image Generation Foundation Model</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>Flux-dev</H3>
							<DL><p>
								<DT><H3 FOLDED>flux-impl</H3>
								<DL><p>
									<DT><H3 FOLDED>flux-architecture</H3>
									<DL><p>
										<DT><A HREF="https://x.com/i/bookmarks?post_id=1820404554795802684">Flux's Architecture diagram</A>
										<DT><A HREF="https://www.youtube.com/watch?v=nrKKLJXBSw0">TUM AI Lecture Series - FLUX: Flow Matching for Content Creation at Scale (Robin Rombach) - YouTube</A>
									</DL><p>
									<DT><A HREF="https://github.com/black-forest-labs/flux">black-forest-labs/flux: Official inference repo for FLUX.1 models</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/pull/6334">Flux.1 by samm393 ¬∑ Pull Request #6334 ¬∑ tinygrad/tinygrad</A>
								</DL><p>
								<DT><H3 FOLDED>flux-lora</H3>
								<DL><p>
									<DT><A HREF="https://github.com/aredden/flux-fp8-api/blob/main/lora_loading.py#L332">flux-fp8-api/lora_loading.py at main ¬∑ aredden/flux-fp8-api</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/tree/7c325253d4e280e470613be43fa3e582a476923e/onediff_diffusers_extensions">onediff/onediff_diffusers_extensions at 7c325253d4e280e470613be43fa3e582a476923e ¬∑ siliconflow/onediff</A>
								</DL><p>
								<DT><H3 FOLDED>flux-tools</H3>
								<DL><p>
									<DT><A HREF="https://blackforestlabs.ai/flux-1-tools/">Introducing FLUX.1 Tools - Black Forest Labs</A>
									<DT><A HREF="https://x.com/EHuanglu/status/1859949254107902169">(1) el.cine en X: "Why FLUX.1 Tools Are So Important! I‚Äôve been using these tools since they were released, I knew it‚Äôs super powerful, but honestly, I never thought about it this way. A great explanation by Heather: ‚ÄúI used depth maps generated with FLUX Depth Pro, and asked Claude how I could https://t.co/OFc8expjB7" / X</A>
									<DT><A HREF="https://x.com/kuer5ord/status/1861040066170335492">(1) StableKirito en X: "üéâ Excited to open source Qwen2vl-Flux! A powerful image generation model combining FLUX with Qwen2VL's vision-language understanding. Create, transform, and control images like never before! https://t.co/M3D1Hjcb0j" / X</A>
									<DT><A HREF="https://huggingface.co/Djrango/Qwen2vl-Flux">Djrango/Qwen2vl-Flux ¬∑ Hugging Face</A>
									<DT><A HREF="https://x.com/bdsqlsz/status/1861007594024050824">(1) ÈùíÈæçËÅñËÄÖ en X: "OminiControl: Minimal and Universal Control for Diffusion Transformer Flux 1. model Code:https://t.co/8jVB1KSrpP Demo:https://t.co/RP1IgGDYlh https://t.co/51P3TqHWqp" / X</A>
								</DL><p>
								<DT><H3 FOLDED>flux-quantization</H3>
								<DL><p>
									<DT><A HREF="https://www.pruna.ai/blog/benchmark-fal-replicate-together-fireworks">FLUX inference providers comparision: Replicate model degradation go_fast=True</A>
								</DL><p>
								<DT><H3 FOLDED>flux-kontext</H3>
								<DL><p>
									<DT><H3 FOLDED>flux-kontext-weights</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/black-forest-labs/FLUX.1-Kontext-dev">black-forest-labs/FLUX.1-Kontext-dev ¬∑ Hugging Face</A>
									</DL><p>
									<DT><A HREF="https://www.notion.so/Alpha-Access-Flux-Kontext-API-1eec370222d5800da3fce6b850e6dc5d">[Alpha-Access] Flux Kontext API</A>
									<DT><A HREF="https://accessible-coneflower-adf.notion.site/Kontext-Image-to-Image-1fcc370222d580e2af0df93271590e2b">Kontext - Image-to-Image</A>
									<DT><A HREF="https://openai.com/index/introducing-4o-image-generation/">Introducing 4o Image Generation | OpenAI</A>
									<DT><A HREF="https://cdn.sanity.io/files/gsvmb6gz/production/880b072208997108f87e5d2729d8a8be481310b5.pdf">FLUX.1 Kontext: Flow Matching for In-Context Image Generation and Editing in Latent Space</A>
									<DT><A HREF="https://arxiv.org/abs/2506.15742">[2506.15742] FLUX.1 Kontext: Flow Matching for In-Context Image Generation and Editing in Latent Space</A>
									<DT><A HREF="https://bfl.ai/announcements/flux-1-kontext">Black Forest Labs - Frontier AI Lab</A>
									<DT><A HREF="https://www.reddit.com/r/itrunsdoom/">Will it run DOOM?</A>
									<DT><A HREF="https://bfl.ai/announcements/flux-1-kontext-dev">FLUX.1 Kontext [dev] - Open Weights for Image Editing</A>
								</DL><p>
								<DT><H3 FOLDED>flux-krea</H3>
								<DL><p>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/commit/46d390cf8aab890c285d56490c6692a6e73d845c">Merge pull request #727 from mi804/flux.1_kera_dev ¬∑ modelscope/DiffSynth-Studio@46d390c</A>
								</DL><p>
								<DT><A HREF="https://x.com/cloneofsimo/status/1820379637937275380">(1) Simo Ryu en X: "Flux uses AuraFlow's arch btw (mixture of MMDiT -&amp;gt; single large DiT) feels good to make contributions without actual paper https://t.co/RXrvOYHIKh" / X</A>
								<DT><A HREF="https://x.com/ErwannMillon/status/1821467403982917674">(1) Erwann Millon en X: "flux + flash attention 3 go brrr ~11% speedup on H100, but output images are slightly different. may be because of using bf16 which fa3 hopper beta doesn't officially support to use this build flash attention 3 hopper from src and change below https://t.co/NQ8Uug6zCK" / X</A>
								<DT><A HREF="https://gist.github.com/drisspg/16c060c93c069d779958ef1438dfc813">flux torch native benchmarking</A>
								<DT><A HREF="https://www.reddit.com/r/StableDiffusion/comments/1p6w1tj/3_women_hugging_each_other_flux_2_dev_test_3/">3 women hugging each other. Flux 2 dev test &lt;3 : r/StableDiffusion</A>
								<DT><A HREF="https://huggingface.co/wavespeed/FLUX.1-dev-e4m3">wavespeed/FLUX.1-dev-e4m3 fp8</A>
								<DT><A HREF="https://huggingface.co/wavespeed/FLUX.1-dev-int8">wavespeed/FLUX.1-dev-int8</A>
							</DL><p>
							<DT><H3 FOLDED>SD3</H3>
							<DL><p>
								<DT><H3 FOLDED>SD-3.5</H3>
								<DL><p>
									<DT><A HREF="https://stabilityai.notion.site/Stable-Diffusion-3-5-fine-tuning-guide-11a61cdcd1968027a15bdbd7c40be8c6">Stable Diffusion 3.5 fine-tuning guide</A>
									<DT><A HREF="https://github.com/Stability-AI/sd3.5">Stability-AI/sd3.5</A>
								</DL><p>
								<DT><A HREF="https://gist.github.com/cloneofsimo/809b036a65be317163dd81ba824d67aa">MM DiT model that was proposed by SD3 paper.</A>
								<DT><A HREF="https://github.com/cloneofsimo/minRF">cloneofsimo/minRF: Minimal implementation of scalable rectified flow transformers, based on SD3's approach</A>
								<DT><A HREF="https://www.youtube.com/watch?v=yTXMK2TZOZc">Stable Diffusion 3: Architectural analsys</A>
								<DT><A HREF="https://github.com/Stability-AI/sd3-ref/blob/master/sd3_impls.py#L173">sd3-ref/sd3_impls.py at master ¬∑ Stability-AI/sd3-ref</A>
							</DL><p>
							<DT><H3 FOLDED>CogView4</H3>
							<DL><p>
								<DT><A HREF="https://github.com/huggingface/diffusers/pull/10959/files">Fix Graph Breaks When Compiling CogView4 by chengzeyi ¬∑ Pull Request #10959 ¬∑ huggingface/diffusers</A>
								<DT><A HREF="https://github.com/THUDM/CogView4">THUDM/CogView4: CogView4, CogView3-Plus and CogView3(ECCV 2024)</A>
							</DL><p>
							<DT><H3 FOLDED>HiDream-I1</H3>
							<DL><p>
								<DT><H3 FOLDED>HiDream-E1</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HiDream-ai/HiDream-E1">HiDream-ai/HiDream-E1</A>
								</DL><p>
								<DT><A HREF="https://github.com/HiDream-ai/HiDream-I1">HiDream-ai/HiDream-I1</A>
								<DT><A HREF="https://huggingface.co/HiDream-ai/HiDream-I1-Full">HiDream-ai/HiDream-I1-Full ¬∑ Hugging Face</A>
								<DT><A HREF="https://x.com/linoy_tsaban/status/1909570114309308539">HiDream text encoder dependency test: Llama 3 8B</A>
							</DL><p>
							<DT><H3 FOLDED>image-generation-unified</H3>
							<DL><p>
								<DT><H3 FOLDED>bytedn-bagel</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ByteDance-Seed/Bagel">ByteDance-Seed/Bagel</A>
									<DT><A HREF="https://bagel-ai.org/">BAGEL: The Open-Source Unified Multimodal Model</A>
									<DT><A HREF="https://arxiv.org/pdf/2505.14683">Emerging Properties in Unified Multimodal Pretraining</A>
									<DT><A HREF="https://huggingface.co/ByteDance-Seed/BAGEL-7B-MoT">ByteDance-Seed/BAGEL-7B-MoT bytedn Bagel model weights</A>
									<DT><A HREF="https://github.com/bytedance/USO">bytedance/USO: üî•üî• Open-sourced unified customization model</A>
								</DL><p>
								<DT><H3 FOLDED>Ovis-U1</H3>
								<DL><p>
									<DT><A HREF="https://github.com/AIDC-AI/Ovis-U1?tab=readme-ov-file">AIDC-AI/Ovis-U1: An unified model that seamlessly integrates multimodal understanding, text-to-image generation, and image editing within a single powerful framework.</A>
									<DT><A HREF="https://github.com/AIDC-AI/Ovis-U1/blob/main/docs/Ovis_U1_Report.pdf">Ovis-U1/docs/Ovis_U1_Report.pdf at main ¬∑ AIDC-AI/Ovis-U1</A>
									<DT><A HREF="https://huggingface.co/AIDC-AI/Ovis-U1-3B">AIDC-AI/Ovis-U1-3B ¬∑ Hugging Face</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1939696550873096321">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "There is a tech report on Ovis-U1 and if you care about multimodality I recommend you to read it. It's more interesting than Seed's BAGEL, I think. They've been very good since the first version, and people are failing to notice. https://t.co/cd5WDsD9H8" / X</A>
								</DL><p>
								<DT><H3 FOLDED>MetaQuery</H3>
								<DL><p>
									<DT><A HREF="https://x.com/xichen_pan/status/1938679822084878703">The code and instruction-tuning data for MetaQuery are now open-sourced!</A>
									<DT><A HREF="https://arxiv.org/pdf/2504.06256">Transfer between Modalities with MetaQueries</A>
									<DT><A HREF="https://xichenpan.com/metaquery/">Transfer between Modalities with MetaQueries</A>
									<DT><A HREF="https://huggingface.co/collections/xcpan/metaquery-instruction-tuning-data-685b0f16d81ce54bcb7ea3a8">MetaQuery Instruction Tuning Data - a xcpan Collection</A>
									<DT><A HREF="https://github.com/facebookresearch/metaquery">facebookresearch/metaquery: Official Implementation of Paper Transfer between Modalities with MetaQueries</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>image-generation-edit</H3>
							<DL><p>
								<DT><H3 FOLDED>In-Context Edit</H3>
								<DL><p>
									<DT><H3 FOLDED>bytedn-VINCIE-3B</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/ByteDance-Seed/VINCIE-3B">ByteDance-Seed/VINCIE-3B ¬∑ Hugging Face</A>
										<DT><A HREF="https://arxiv.org/abs/2506.10941">[2506.10941] VINCIE: Unlocking In-context Image Editing from Video</A>
									</DL><p>
									<DT><A HREF="https://github.com/River-Zhang/ICEdit">River-Zhang/ICEdit: Repository for paper "In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer"</A>
								</DL><p>
								<DT><H3 FOLDED>seededit</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>controlnet</H3>
								<DL><p>
									<DT><A HREF="https://github.com/liming-ai/ControlNet_Plus_Plus">liming-ai/ControlNet_Plus_Plus: Official PyTorch implementation of ECCV 2024 Paper: ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback.</A>
								</DL><p>
								<DT><H3 FOLDED>Stable Flow</H3>
								<DL><p>
									<DT><A HREF="https://x.com/OmriAvr/status/1859838000143925678">(1) Omri Avrahami en X: "[1/10] üö® We present our recent @Snap project: Stable Flow --- A training-free method that performs various types of image editing operations (e.g., non-rigid editing, object addition and replacement) using flow models. Project page: https://t.co/g0Naul2hoQ https://t.co/G6t4yyGgbT" / X</A>
									<DT><A HREF="https://omriavrahami.com/stable-flow/">Stable Flow</A>
									<DT><A HREF="https://arxiv.org/abs/2411.14430">[2411.14430] Stable Flow: Vital Layers for Training-Free Image Editing</A>
								</DL><p>
								<DT><H3 FOLDED>FLUX-tools</H3>
								<DL><p>
									<DT><A HREF="https://blackforestlabs.ai/flux-1-tools/">Introducing FLUX.1 Tools - Black Forest Labs</A>
								</DL><p>
								<DT><A HREF="https://omriavrahami.com/stable-flow/">Stable Flow: Vital Layers for Training-Free Image Editing</A>
							</DL><p>
							<DT><H3 FOLDED>image-generation-filter</H3>
							<DL><p>
								<DT><A HREF="https://higgsfield.ai/soul">Higgsfield Soul</A>
							</DL><p>
							<DT><A HREF="https://github.com/haoosz/BiGR?tab=readme-ov-file">haoosz/BiGR: The official code for "BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities"</A>
							<DT><A HREF="https://github.com/ziqihuangg/Awesome-Evaluation-of-Visual-Generation">ziqihuangg/Awesome-Evaluation-of-Visual-Generation: A list of works on evaluation of visual generation models, including evaluation metrics, models, and systems</A>
							<DT><A HREF="https://www.youtube.com/watch?v=fy153-yXSQk">TL#006 Robin Rombach Taming Transformers for High Resolution Image Synthesis - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>video-training</H3>
						<DL><p>
							<DT><H3 FOLDED>wan-training</H3>
							<DL><p>
								<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/tree/main/examples/wanvideo/model_training">DiffSynth-Studio/examples/wanvideo/model_training at main ¬∑ modelscope/DiffSynth-Studio</A>
								<DT><A HREF="https://github.com/NVlabs/FastGen/blob/main/fastgen/configs/experiments/WanI2V/config_sft_causal_14b.py">FastGen/fastgen/configs/experiments/WanI2V/config_sft_causal_14b.py at main ¬∑ NVlabs/FastGen</A>
								<DT><A HREF="https://github.com/NVlabs/FastGen/blob/main/fastgen/networks/Wan/network.py">FastGen/fastgen/networks/Wan/network.py at main ¬∑ NVlabs/FastGen</A>
							</DL><p>
							<DT><H3 FOLDED>video-data</H3>
							<DL><p>
								<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun/blob/7157cdd48a0bf0c3baacd337cd711aff01675c22/videox_fun/data/dataset_video.py#L80">VideoX-Fun/videox_fun/data/dataset_video.py at 7157cdd48a0bf0c3baacd337cd711aff01675c22 ¬∑ aigc-apps/VideoX-Fun</A>
							</DL><p>
							<DT><H3 FOLDED>video-training-lora</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ostris/ai-toolkit">ostris/ai-toolkit: The ultimate training toolkit for finetuning diffusion models</A>
								<DT><A HREF="https://github.com/kohya-ss/musubi-tuner">kohya-ss/musubi-tuner: training LoRA scripts for WAN 2.1/2.2</A>
								<DT><A HREF="https://github.com/kohya-ss/musubi-tuner/blob/main/.ai/context/overview.md">musubi-tuner/.ai/context/overview.md at main ¬∑ kohya-ss/musubi-tuner</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>video-generation</H3>
						<DL><p>
							<DT><H3 FOLDED>video-inference-optimization</H3>
							<DL><p>
								<DT><H3 FOLDED>dit-inference</H3>
								<DL><p>
									<DT><H3 FOLDED>video-real-time</H3>
									<DL><p>
										<DT><H3 FOLDED>seaweed-apt2</H3>
										<DL><p>
											<DT><A HREF="https://seaweed-apt.com/2">Seaweed APT2</A>
											<DT><A HREF="https://arxiv.org/pdf/2506.09350">Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation</A>
										</DL><p>
										<DT><H3 FOLDED>LTX-2</H3>
										<DL><p>
											<DT><A HREF="https://x.com/ArtificialAnlys/status/2012256702788153604">(2) Artificial Analysis en X: "LTX-2 is the new leading open weights video model, surpassing Wan 2.2 A14B in both Text to Video and Image to Video in the Artificial Analysis Video Arena! LTX-2, originally released in November by @Lightricks, was recently open sourced with both the base 19B model</A>
											<DT><A HREF="https://huggingface.co/Lightricks/LTX-2">Lightricks/LTX-2 ¬∑ Hugging Face</A>
											<DT><A HREF="https://github.com/Lightricks/LTX-2">Lightricks/LTX-2: Official Python inference and LoRA trainer package for the LTX-2 audio‚Äìvideo generative model.</A>
											<DT><A HREF="https://github.com/search?q=repo%3Avipshop%2Fcache-dit%20ltx2&type=code">cache-dit ltx-2</A>
											<DT><A HREF="https://artificialanalysis.ai/video/leaderboard/image-to-video">Image to Video Leaderboard | Artificial Analysis</A>
										</DL><p>
										<DT><H3 FOLDED>LTX-Video</H3>
										<DL><p>
											<DT><A HREF="https://x.com/yoavhacohen/status/1897295194426355815">LTX-Video upgrade (03-03-25)</A>
											<DT><A HREF="https://www.lightricks.com/">Lightricks: LTXV</A>
											<DT><A HREF="https://github.com/Lightricks/LTX-Video">Lightricks/LTX-Video: Official repository for LTX-Video: DiT-based video generation model that can generate high-quality videos in real-time</A>
										</DL><p>
										<DT><H3 FOLDED>DiT-depth-pruning</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://github.com/THUDM/CogVideo/issues/48">Jiarui Fang To achieve real-time generation, the DiT model must be deployed in parallel across multiple devices, and xDiT is designed to address this challenge.</A>
										<DT><A HREF="https://arxiv.org/abs/2506.03099">[2506.03099] TalkingMachines: Real-Time Audio-Driven FaceTime-Style Video via Autoregressive Diffusion Models</A>
										<DT><A HREF="https://x.com/wayfarerlabs/status/1949517715347050785">(1) OWL en X: "Does your DiT really need all those layers? We found that ODE regression can enable extreme pruning for DiT that in our setup enabled a 70x speedup on the model side alone. [Image 1] is teacher, [Image 2] is student 1/2 https://t.co/q24MIAZlBU" / X</A>
										<DT><A HREF="https://x.com/krea_ai/status/1980358158376988747">(4) KREA AI en X: "today we're open-sourcing Krea Realtime. this 14B autoregressive model is 10x larger than any open-source equivalent, and it can generate long-form videos at 11 fps on a single B200. weights and technical report below üëá https://t.co/nJiHpClpzK" / X</A>
										<DT><A HREF="https://huggingface.co/lightx2v/Wan2.1-T2V-14B-StepDistill-CfgDistill">lightx2v/Wan2.1-T2V-14B-StepDistill-CfgDistill ¬∑ Hugging Face</A>
										<DT><A HREF="https://github.com/krea-ai/realtime-video">krea-ai/realtime-video: Krea Realtime 14B. An open-source realtime AI video model.</A>
									</DL><p>
									<DT><H3 FOLDED>diffusers</H3>
									<DL><p>
										<DT><H3 FOLDED>diffusers-imports</H3>
										<DL><p>
											<DT><A HREF="https://github.com/optuna/optuna/blob/master/optuna/integration/__init__.py">optuna/optuna/integration/__init__.py at master</A>
											<DT><A HREF="https://github.com/huggingface/diffusers/blob/42cae93b942ec904ead46c26c42be24422adc92c/src/diffusers/utils/import_utils.py#L760">diffusers/src/diffusers/utils/import_utils.py</A>
											<DT><A HREF="https://github.com/huggingface/diffusers/blob/67bef2027cc461af5bbe73b3c0f35bb1350f5aa8/src/diffusers/pipelines/consistency_models/__init__.py">diffusers/src/diffusers/pipelines/consistency_models/__init__.py</A>
										</DL><p>
										<DT><H3 FOLDED>diffusers-patch</H3>
										<DL><p>
											<DT><A HREF="https://github.com/chengzeyi/piflux/blob/main/src/piflux/adapters/diffusers.py">piflux/src/piflux/adapters/diffusers.py at main ¬∑ chengzeyi/piflux</A>
										</DL><p>
										<DT><H3 FOLDED>diffusers-qwen-image</H3>
										<DL><p>
											<DT><A HREF="https://github.com/huggingface/diffusers/pull/12072">optimize QwenImagePipeline to reduce unnecessary CUDA synchronization by chengzeyi ¬∑ Pull Request #12072 ¬∑ huggingface/diffusers</A>
										</DL><p>
										<DT><A HREF="https://github.com/huggingface/image_gen_aux">huggingface/image_gen_aux: Set of auxiliary tools to use with image and video generation libaries. Mainly created to be used with diffusers</A>
									</DL><p>
									<DT><H3 FOLDED>xelerate</H3>
									<DL><p>
										<DT><H3 FOLDED>xelerate-blackwell</H3>
										<DL><p>
											<DT><A HREF="https://github.com/datacrunch-research/blogs/blob/main/wavespeed-flux-blackwell-technical-report/flux_blackwell_b200_technical_report.md">blogs/wavespeed-flux-blackwell-technical-report/flux_blackwell_b200_technical_report.md at main ¬∑ datacrunch-research/blogs</A>
										</DL><p>
										<DT><A HREF="https://github.com/huggingface/flux-fast">huggingface/flux-fast: Making Flux go brrr on GPUs.</A>
									</DL><p>
									<DT><H3 FOLDED>dit-quantization</H3>
									<DL><p>
										<DT><H3 FOLDED>diffusion-quantization</H3>
										<DL><p>
											<DT><H3 FOLDED>diffusion-quantization-people</H3>
											<DL><p>
												<DT><A HREF="https://htqin.github.io/">Haotong Qin</A>
												<DT><A HREF="https://github.com/LeiWang1999">Lei Wang: BitBLAS</A>
											</DL><p>
											<DT><A HREF="https://arxiv.org/abs/2302.04304">[2302.04304] Q-Diffusion: Quantizing Diffusion Models</A>
											<DT><A HREF="https://arxiv.org/abs/2305.10657">[2305.10657] PTQD: Accurate Post-Training Quantization for Diffusion Models</A>
											<DT><A HREF="https://github.com/ziplab/PTQD">ziplab/PTQD: The official implementation of PTQD: Accurate Post-Training Quantization for Diffusion Models</A>
											<DT><A HREF="https://arxiv.org/pdf/2310.03270">EFFICIENTDM: EFFICIENT QUANTIZATION-AWARE FINE-TUNING OF LOW-BIT DIFFUSION MODELS</A>
											<DT><A HREF="https://github.com/IST-DASLab/QUIK">IST-DASLab/QUIK: Repository for the QUIK project, enabling the use of 4bit kernels for generative inference</A>
											<DT><A HREF="https://github.com/ThisisBillhe/torch_quantizer?tab=readme-ov-file">ThisisBillhe/torch_quantizer: torch_quantizer is a out-of-box quantization tool for PyTorch models on CUDA backend, specially optimized for Diffusion Models.</A>
											<DT><A HREF="https://arxiv.org/abs/2310.09259">[2310.09259] QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language Models</A>
											<DT><A HREF="https://github.com/IST-DASLab/marlin">IST-DASLab/marlin: FP16xINT4 LLM inference kernel that can achieve near-ideal ~4x speedups up to medium batchsizes of 16-32 tokens.</A>
											<DT><A HREF="https://github.com/snap-research/BitsFusion">snap-research/BitsFusion</A>
											<DT><A HREF="https://github.com/microsoft/BitBLAS">microsoft/BitBLAS: BitBLAS is a library to support mixed-precision matrix multiplications, especially for quantized LLM deployment.</A>
											<DT><A HREF="https://github.com/htqin/awesome-model-quantization">htqin/awesome-model-quantization: A list of papers, docs, codes about model quantization. This repo is aimed to provide the info for model quantization research, we are continuously improving the project. Welcome to PR the works (papers, repositories) that are missed by the repo.</A>
											<DT><A HREF="https://github.com/bytedance/decoupleQ">bytedance/decoupleQ: A quantization algorithm for LLM</A>
											<DT><A HREF="https://github.com/bytedance/AffineQuant">bytedance/AffineQuant: Official implementation of the ICLR 2024 paper AffineQuant</A>
											<DT><A HREF="https://github.com/Xiuyu-Li/q-diffusion">Xiuyu-Li/q-diffusion: [ICCV 2023] Q-Diffusion: Quantizing Diffusion Models.</A>
											<DT><A HREF="https://github.com/aredden/flux-fp8-api/blob/main/float8_quantize.py">flux-fp8-api/float8_quantize.py at main ¬∑ aredden/flux-fp8-api</A>
										</DL><p>
										<DT><H3 FOLDED>diffusers-torchao</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sayakpaul/diffusers-torchao">sayakpaul/diffusers-torchao: End-to-end recipes for optimizing diffusion models with torchao and diffusers (inference and FP8 training).</A>
										</DL><p>
										<DT><H3 FOLDED>Nunchaku</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mit-han-lab/nunchaku">mit-han-lab/nunchaku: SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models</A>
										</DL><p>
										<DT><H3 FOLDED>flux-fp4</H3>
										<DL><p>
											<DT><A HREF="https://huggingface.co/mit-han-lab/svdq-fp4-flux.1-dev">mit-han-lab/svdq-fp4-flux.1-dev ¬∑ Hugging Face</A>
										</DL><p>
										<DT><A HREF="https://hanlab.mit.edu/projects/svdquant">SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models</A>
										<DT><A HREF="https://github.com/mit-han-lab/deepcompressor">mit-han-lab/deepcompressor: Model Compression Toolbox for Large Language Models and Diffusion Models</A>
									</DL><p>
									<DT><H3 FOLDED>dit-cache</H3>
									<DL><p>
										<DT><H3 FOLDED>AdaCache</H3>
										<DL><p>
											<DT><A HREF="https://github.com/AdaCache-DiT/AdaCache">AdaCache-DiT/AdaCache: Adaptive Caching for Faster Video Generation with Diffusion Transformers</A>
											<DT><A HREF="https://adacache-dit.github.io/clarity/adacache_meta.pdf">Adaptive Caching for Faster Video Generation with Diffusion Transformers</A>
										</DL><p>
										<DT><H3 FOLDED>ToCa</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Shenyi-Z/ToCa">Shenyi-Z/ToCa: Accelerating Diffusion Transformers with Token-wise Feature Caching</A>
											<DT><A HREF="https://github.com/Shenyi-Z/ToCa/commit/d0ef7e114c7bcc825c3aac809f22a25b6758df86">New version of DiT-ToCa ¬∑ Shenyi-Z/ToCa@d0ef7e1</A>
											<DT><A HREF="https://arxiv.org/pdf/2410.05317#page=19">ACCELERATING DIFFUSION TRANSFORMERS WITH TOKEN-WISE FEATURE CACHING</A>
										</DL><p>
										<DT><H3 FOLDED>FORA</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2407.01425">[2407.01425] FORA: Fast-Forward Caching in Diffusion Transformer Acceleration</A>
											<DT><A HREF="https://github.com/prathebaselva/FORA">prathebaselva/FORA: FORA introduces simple yet effective caching mechanism in Diffusion Transformer Architecture for faster inference sampling.</A>
										</DL><p>
										<DT><H3 FOLDED>FasterCache</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Vchitect/FasterCache">Vchitect/FasterCache: FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality</A>
											<DT><A HREF="https://arxiv.org/abs/2410.19355">[2410.19355] FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality</A>
											<DT><A HREF="https://vchitect.github.io/FasterCache/">FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality</A>
											<DT><A HREF="https://arxiv.org/pdf/2410.19355">FASTERCACHE: TRAINING-FREE VIDEO DIFFUSION
MODEL ACCELERATION WITH HIGH QUALITY</A>
										</DL><p>
										<DT><H3 FOLDED>ParaAttention-caching</H3>
										<DL><p>
											<DT><H3 FOLDED>fbcache</H3>
											<DL><p>
												<DT><A HREF="https://github.com/alexarmbr/ParaAttention/pull/1/commits/db3309716ac2d8f2f10c8fa2ea72aeb41f5f76d3">Fbcache logging by alexarmbr ¬∑ Pull Request #1 ¬∑ alexarmbr/ParaAttention</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/pull/12">Dev first block cache by chengzeyi ¬∑ Pull Request #12 ¬∑ chengzeyi/ParaAttention</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/tree/5ae75fe7201528e97fbef5a377b80d12496fb499/src/para_attn/first_block_cache">ParaAttention/src/para_attn/first_block_cache</A>
												<DT><A HREF="https://github.com/chengzeyi/model-deploy/commit/a002cd336673c1d81b74d535dcfc0ae44a049b17">support fbcache ¬∑ chengzeyi/model-deploy@a002cd3</A>
												<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/blob/12cc587b008ee6e0c6676a789d6e6f04a992a2be/diffsynth_engine/models/flux/flux_dit_fbcache.py">DiffSynth-Engine/diffsynth_engine/models/flux/flux_dit_fbcache.py</A>
												<DT><A HREF="https://github.com/huggingface/diffusers/blob/4b17fa2a2ee1929999470f11f1379f74967dab9a/src/diffusers/hooks/first_block_cache.py#L194">diffusers/src/diffusers/hooks/first_block_cache.py</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/7a266123671b55e7e5a2fe9af3121f07a36afc78/README.md#first-block-cache-our-dynamic-caching">ParaAttention/README.md First Block Cache: Dynamic activation caching</A>
												<DT><A HREF="https://huggingface.co/posts/a-r-r-o-w/278025275110164">@a-r-r-o-w on Hugging Face: "Caching is an essential technique used in diffusion inference serving for..."</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-taylorseer</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/commit/9530eba38b160cf17b5cdb468f2d75cd13c148b0">implement taylorseer Test case to predict y = x^2</A>
											</DL><p>
											<DT><A HREF="https://huggingface.co/blog/NagaSaiAbhinay/transformer-layers-as-painters-dit">Extending *Transformer layers as Painters* to DiT's</A>
										</DL><p>
										<DT><H3 FOLDED>TeaCache</H3>
										<DL><p>
											<DT><A HREF="https://github.com/LiewFeng/TeaCache">LiewFeng/TeaCache: Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model</A>
											<DT><A HREF="https://github.com/MingXiangL/Teacache-xDiT">MingXiangL/Teacache-xDiT: Combining Teacache with xDiT to Accelerate Visual Generation Models</A>
											<DT><A HREF="https://github.com/MingXiangL/Teacache-xDiT/blob/c86f95a36f7727f8d0c41705474dca559595a99d/examples/teacache/flux_teacache.py">Teacache-xDiT/examples/teacache/flux_teacache.py at c86f95a36f7727f8d0c41705474dca559595a99d ¬∑ MingXiangL/Teacache-xDiT</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2411.13588">[2411.13588] Unveiling Redundancy in Diffusion Transformers (DiTs): A Systematic Study</A>
										<DT><A HREF="https://github.com/Tammytcl/Awesome-Diffusion-Acceleration-Cache">Tammytcl/Awesome-Diffusion-Acceleration-Cache: A curated list of research papers, resources, and advancements on Diffusion Cache and related efficient diffusion model acceleration techniques.</A>
									</DL><p>
									<DT><H3 FOLDED>dit-linear-attention</H3>
									<DL><p>
										<DT><H3 FOLDED>Sana</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/pdf/2410.10629">SANA: EFFICIENT HIGH-RESOLUTION IMAGE SYNTHESIS WITH LINEAR DIFFUSION TRANSFORMERS</A>
											<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:activity:7251843706310275072/">NVIDIA Research, Efficient AI</A>
											<DT><A HREF="https://github.com/NVlabs/Sana">NVlabs/Sana: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer</A>
											<DT><A HREF="https://arxiv.org/html/2411.10958v1">SageAttention2 Technical Report: Accurate 4 Bit Attention for Plug-and-play Inference Acceleration</A>
											<DT><A HREF="https://x.com/nrehiew_/status/1861605525558812880">(2) wh en X: "9th highest scored ICLR 2025 paper 8,8,8,10. Worth noting all reviewers increased their scores by 2 after rebuttals tldr: they introduce a bunch of architectural changes to a diffusion transformer, getting 100x speed improvements with no real quality impacts https://t.co/SKNMLiV6rL" / X</A>
											<DT><A HREF="https://github.com/huggingface/diffusers/pull/9982">[Sana] Add Sana, including `SanaPipeline`, `SanaPAGPipeline`, `LinearAttentionProcessor`, `Flow-based DPM-sovler` and so on. by lawrence-cj ¬∑ Pull Request #9982 ¬∑ huggingface/diffusers</A>
											<DT><A HREF="https://github.com/huggingface/diffusers/pull/9982/files#diff-d908866bff59e8dee0188bcff59bd36ca51ecb8f262e5f6893b9224f1b4dde89">[Sana] Add Sana, including `SanaPipeline`, `SanaPAGPipeline`, `LinearAttentionProcessor`, `Flow-based DPM-sovler` and so on. by lawrence-cj ¬∑ Pull Request #9982 ¬∑ huggingface/diffusers</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/html/2501.12976v1">LiT: Delving into a Simplified Linear Diffusion Transformer for Image Generation</A>
									</DL><p>
									<DT><H3 FOLDED>dit-distributed-inference</H3>
									<DL><p>
										<DT><H3 FOLDED>ParaAttention</H3>
										<DL><p>
											<DT><H3 FOLDED>_templated_ring_attention</H3>
											<DL><p>
												<DT><A HREF="https://gist.github.com/a-r-r-o-w/87926a348703e55f008f259a1778e4f3">sequential and templated ring/ulysses/unified attention implementation</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/16ab3b17c415b80bb757fe48fa6e95d0adda9430/src/para_attn/para_attn_interface.py#L13">ParaAttention/src/para_attn/para_attn_interface.py at 16ab3b17c415b80bb757fe48fa6e95d0adda9430 ¬∑ chengzeyi/ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>op_replace</H3>
											<DL><p>
												<DT><A HREF="https://github.com/Vchitect/Vchitect-2.0/blob/master/op_replace.py">Vchitect-2.0/op_replace.py at master ¬∑ Vchitect/Vchitect-2.0</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-primitives</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/4de137c5b96416489f06e43e19f2c14a772e28fd/src/para_attn/primitives.py">ParaAttention/src/para_attn/primitives.py at 4de137c5b96416489f06e43e19f2c14a772e28fd ¬∑ chengzeyi/ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-interface</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/main/src/para_attn/para_attn_interface.py">ParaAttention/src/para_attn/para_attn_interface.py at main ¬∑ chengzeyi/ParaAttention</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/16ab3b17c415b80bb757fe48fa6e95d0adda9430/src/para_attn/para_attn_interface.py#L13">ParaAttention/src/para_attn/para_attn_interface.py</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-dynamo</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/pull/25/files">fix compability with torch 2.6.0 dynamo by chengzeyi ¬∑ Pull Request #25 ¬∑ chengzeyi/ParaAttention</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/9ac562bc9b4a2a3f0f7c12fffda869516bb45d9d/src/para_attn/para_attn_interface.py#L304">ParaAttention/src/para_attn/para_attn_interface.py at 9ac562bc9b4a2a3f0f7c12fffda869516bb45d9d ¬∑ chengzeyi/ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-inductor</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/issues/22">cannot torch.compile the HunyuanVideo video transformer ¬∑ Issue #22 ¬∑ chengzeyi/ParaAttention</A>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/commit/46bf9e762a8470fbe1adedb2c3add1e662cdc170">fix hunyuanvideo context parallel with compile ¬∑ chengzeyi/ParaAttention@46bf9e7</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-kernels</H3>
											<DL><p>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-ulysses</H3>
											<DL><p>
												<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/50ee1f0aac02768c859b4b5f0a1cf84b311a922d/kernels/parallel/ulysses_attn/benchmark.py#L188">ThunderKittens/kernels/parallel/ulysses_attn/benchmark.py at 50ee1f0aac02768c859b4b5f0a1cf84b311a922d ¬∑ HazyResearch/ThunderKittens</A>
												<DT><A HREF="https://zhuanlan.zhihu.com/p/1939640210221671459">A diagram of Async Ulysses CP</A>
												<DT><A HREF="https://github.com/ByteDance-Seed/VeOmni/blob/09938f63f49ca02db745327f40365ea03db7eb57/veomni/distributed/sequence_parallel/ulysses.py#L4">VeOmni/veomni/distributed/sequence_parallel/ulysses.py</A>
												<DT><A HREF="https://github.com/ByteDance-Seed/VeOmni/blob/09938f63f49ca02db745327f40365ea03db7eb57/docs/key_features/ulysses.md#L4">VeOmni/docs/key_features/ulysses.md</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-server</H3>
											<DL><p>
												<DT><H3 FOLDED>ParaAttention-distributed-server</H3>
												<DL><p>
													<DT><A HREF="https://github.com/chengzeyi/ParaAttention/pull/21/files">http server for distributed inference by alexarmbr ¬∑ Pull Request #21 ¬∑ chengzeyi/ParaAttention</A>
												</DL><p>
												<DT><A HREF="https://github.com/antferdom/ParaAttention/tree/main/server">ParaAttention/server at main ¬∑ antferdom/ParaAttention</A>
												<DT><A HREF="https://github.com/xdit-project/xDiT/tree/main/http-service">xDiT/http-service at main ¬∑ xdit-project/xDiT</A>
												<DT><A HREF="https://github.com/WaveSpeedAI/Step-Video-T2V-ParaAttention/blob/main/api/call_remote_server.py">Step-Video-T2V-ParaAttention/api/call_remote_server.py at main ¬∑ WaveSpeedAI/Step-Video-T2V-ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-benchmark</H3>
											<DL><p>
												<DT><A HREF="https://docs.google.com/spreadsheets/d/18araPIxeeIGbS9BNooUCYsC4RkfnhIe4kcAqkscQGL4/edit?gid=0#gid=0">attention roofline - Google Sheets</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-test</H3>
											<DL><p>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-hf-checkpoint</H3>
											<DL><p>
												<DT><A HREF="https://huggingface.co/docs/huggingface_hub/en/guides/cli">Command Line Interface (CLI)</A>
												<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B">huggingface-cli download Wan-AI/Wan2.1-T2V-14B --local-dir ./Wan2.1-T2V-14B</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-stepVideo</H3>
											<DL><p>
												<DT><A HREF="https://github.com/WaveSpeedAI/Step-Video-T2V-ParaAttention/blob/main/api/call_remote_server.py">Step-Video-T2V-ParaAttention/api/call_remote_server.py at main ¬∑ WaveSpeedAI/Step-Video-T2V-ParaAttention</A>
												<DT><A HREF="https://github.com/WaveSpeedAI/Step-Video-T2V-ParaAttention">WaveSpeedAI/Step-Video-T2V-ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>MPDistRunner</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/4de137c5b96416489f06e43e19f2c14a772e28fd/src/para_attn/distributed/mp_runner.py#L16">ParaAttention/src/para_attn/distributed/mp_runner.py</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-examples</H3>
											<DL><p>
												<DT><A HREF="https://github.com/xdit-project/xDiT/blob/7ed13e9bd2f90a563439afbd305330857f7380bf/examples/hunyuan_video_usp_example.py">xDiT/examples/hunyuan_video_usp_example.py at 7ed13e9bd2f90a563439afbd305330857f7380bf ¬∑ xdit-project/xDiT</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-Wan</H3>
											<DL><p>
												<DT><H3 FOLDED>wan-flow-shift</H3>
												<DL><p>
													<DT><A HREF="https://github.com/datacrunch-research/cortex/blob/64b1c9bb59c8bdadb831f2dc437fe9a906104bf2/extra/libs/wan22/wan_i2v_a14b_runner.py#L143">cortex/extra/libs/wan22/wan_i2v_a14b_runner.py at 64b1c9bb59c8bdadb831f2dc437fe9a906104bf2 ¬∑ datacrunch-research/cortex</A>
													<DT><A HREF="https://github.com/chengzeyi/ParaAttention/pull/36/commits/c2aca30af9a5fa71fbcd874e0a104d03cbb64b6f">flow shift should be 3.0 for 480p images, 5.0 for 720p images</A>
												</DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/pull/36">wan i2v and t2v by alexarmbr ¬∑ Pull Request #36 ¬∑ chengzeyi/ParaAttention</A>
												<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/examples/wan_example.py#L44">xDiT/examples/wan_example.py at main ¬∑ xdit-project/xDiT</A>
												<DT><A HREF="https://github.com/gradjitta/ParaAttention/blob/630157e5918f481f44af8b75369a94ec56dc0d45/src/para_attn/context_parallel/diffusers_adapters/wan.py">ParaAttention/src/para_attn/context_parallel/diffusers_adapters/wan.py at 630157e5918f481f44af8b75369a94ec56dc0d45 ¬∑ gradjitta/ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>ParaAttention-Hunyuan-video</H3>
											<DL><p>
												<DT><A HREF="https://github.com/chengzeyi/ParaAttention/pull/10">Support Hunyuan Video by chengzeyi ¬∑ Pull Request #10 ¬∑ chengzeyi/ParaAttention</A>
											</DL><p>
											<DT><H3 FOLDED>PipeFusion</H3>
											<DL><p>
												<DT><A HREF="https://arxiv.org/pdf/2405.14430">PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference</A>
												<DT><A HREF="https://arxiv.org/abs/2405.14430">[2405.14430] PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference</A>
											</DL><p>
											<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/main/examples/run_flux.py">ParaAttention/examples/run_flux.py at main ¬∑ chengzeyi/ParaAttention</A>
											<DT><A HREF="https://github.com/chengzeyi/ParaAttention">chengzeyi/ParaAttention: [WIP] Context parallel attention that works with torch.compile</A>
											<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/main/src/para_attn/para_attn_interface.py">ParaAttention/src/para_attn/para_attn_interface.py:  from torch.distributed.tensor.experimental._attention</A>
											<DT><A HREF="https://github.com/Tencent/HunyuanVideo/pull/68/commits/d227cb7c034f246251359a50ff292e300e692927">parallel inference using xdit by feifeibear ¬∑ Pull Request #68: test_attention.py</A>
											<DT><A HREF="https://github.com/chengzeyi/ParaAttention/commit/9ac562bc9b4a2a3f0f7c12fffda869516bb45d9d">fix compability with torch 2.6.0 dynamo (#25) ¬∑ chengzeyi/ParaAttention@9ac562b</A>
											<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/9ac562bc9b4a2a3f0f7c12fffda869516bb45d9d/src/para_attn/para_attn_interface.py#L304">ParaAttention/src/para_attn/para_attn_interface.py at 9ac562bc9b4a2a3f0f7c12fffda869516bb45d9d ¬∑ chengzeyi/ParaAttention</A>
											<DT><A HREF="https://github.com/huggingface/diffusers/pull/11941/files">Context Parallel w/ Ring &amp; Ulysses &amp; Unified Attention by a-r-r-o-w ¬∑ Pull Request #11941 ¬∑ huggingface/diffusers</A>
										</DL><p>
										<DT><H3 FOLDED>piflux</H3>
										<DL><p>
											<DT><A HREF="https://github.com/chengzeyi/piflux">chengzeyi/piflux: (WIP) Parallel inference for black-forest-labs' FLUX model.</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>cache-dit</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vipshop/cache-dit">vipshop/cache-dit: A Unified and Flexible Inference Engine with Hybrid Cache Acceleration and Parallelism for ü§óDiTs.</A>
										<DT><A HREF="https://github.com/DefTruth?tab=repositories">DefTruth (DefTruth) / Repositories</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/pull/459/files">fix: move .to(device) to reduce tp mem by BBuf ¬∑ Pull Request #459 ¬∑ vipshop/cache-dit</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/commit/abac1e5d2df695992aa0281081c33c82c25010db">memory tracker: example: support more overrided args and memory tracker</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/blob/abac1e5d2df695992aa0281081c33c82c25010db/examples/utils.py#L13">cache-dit/examples/utils.py</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/pull/501">Add profiler for flux tp and cp example by BBuf ¬∑ Pull Request #501 ¬∑ vipshop/cache-dit</A>
										<DT><A HREF="https://github.com/BBuf/cache-dit/blob/9bc5ae0d68c106f209c2298f8c42eb8212fdc128/examples/utils.py#L296">create_profiler_from_args</A>
										<DT><A HREF="https://github.com/DefTruth">DefTruth (DefTruth)</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/blob/main/src/cache_dit/caching/cache_contexts/cache_manager.py#L495-L523">cache-dit/src/cache_dit/caching/cache_contexts/cache_manager.py: condition_thresh</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/pull/739/changes">Refine profiler and serving docs by BBuf ¬∑ Pull Request #739 ¬∑ vipshop/cache-dit</A>
									</DL><p>
									<DT><H3 FOLDED>xfuser</H3>
									<DL><p>
										<DT><H3 FOLDED>xfuser-dev</H3>
										<DL><p>
											<DT><H3 FOLDED>xdit-docker</H3>
											<DL><p>
												<DT><A HREF="https://hub.docker.com/r/thufeifeibear/xdit-dev/tags">thufeifeibear/xdit-dev Tags | Docker Hub</A>
												<DT><A HREF="https://github.com/xdit-project/HunyuanVideo/blob/main/docker/Dockerfile_xDiT">HunyuanVideo/docker/Dockerfile_xDiT at main ¬∑ xdit-project/HunyuanVideo</A>
											</DL><p>
											<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/docs/developer/The_implement_design_of_xdit_framework.md">xDiT/docs/developer/The_implement_design_of_xdit_framework.md at main ¬∑ xdit-project/xDiT</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/docs/developer/Http_Service.md">xDiT/docs/developer/Http_Service.md at main ¬∑ xdit-project/xDiT</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/docs/developer/Manual_for_Adding_New_Models.md">xDiT/docs/developer/Manual_for_Adding_New_Models.md at main ¬∑ xdit-project/xDiT</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/commit/251a7ba111252f48f53f3cc9ac323e61688c812c#diff-11e309e9b0185cf90cff5f7e301cccd5ec80b9ca75de069df2417ea07e15d3e3">[Tests]: Context and Sequence Parallel (#438) ¬∑ xdit-project/xDiT@251a7ba</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/commit/a4757c9b169f9f10e87875e4171bb57af90e588f">[Bugfix] Fix for only one DIT worker and a separate VAE worker. (#443) ¬∑ xdit-project/xDiT@a4757c9</A>
										</DL><p>
										<DT><H3 FOLDED>xfuser-attention</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ai-compiler-study/flux/blob/main/src/flux/math.py">flux/src/flux/math.py at main ¬∑ ai-compiler-study/flux</A>
											<DT><A HREF="https://github.com/facebookresearch/xformers/blob/77c1da7fe5c9a25f613bd4045bb1da4856310aab/xformers/ops/fmha/flash3.py#L57">xformers/xformers/ops/fmha/flash3.py: torch custom op wrapper logic FA3</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/commit/0cbdf4a00122a63ca654a6eb898f48901474e9cf">closes #334; prefer newer version of flash-attn (#394) ¬∑ xdit-project/xDiT@0cbdf4a</A>
										</DL><p>
										<DT><H3 FOLDED>xfuser-sequence-parallelism</H3>
										<DL><p>
											<DT><H3 FOLDED>YunChang</H3>
											<DL><p>
												<DT><H3 FOLDED>deepspeed-ulysses</H3>
												<DL><p>
													<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-ulysses/README.md">DeepSpeed/blogs/deepspeed-ulysses/README.md at master ¬∑ microsoft/DeepSpeed</A>
												</DL><p>
												<DT><A HREF="https://github.com/feifeibear/long-context-attention">feifeibear/long-context-attention: USP: Unified (a.k.a. Hybrid, 2D) Sequence Parallel Attention for Long Context Transformers Model Training and Inference</A>
												<DT><A HREF="https://github.com/zhuzilin/ring-flash-attention">zhuzilin/ring-flash-attention: Ring attention implementation with flash attention</A>
												<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-ulysses/README.md">DeepSpeed/blogs/deepspeed-ulysses/README.md at master ¬∑ microsoft/DeepSpeed</A>
												<DT><A HREF="https://arxiv.org/pdf/2405.07719">USP: A Unified Sequence Parallelism Approach for Long Context Generative AI</A>
											</DL><p>
											<DT><H3 FOLDED>xdit-usp</H3>
											<DL><p>
												<DT><A HREF="https://github.com/xdit-project/xDiT/commit/ca94011acb0a1699222431bfafce8720ef9d743d#diff-f5328dbf6a5ced8a82574ec233924b8ee3fa7ee69d56706dee83314ca38f2bd8">Support optimized USP in Flux (#368) ¬∑ xdit-project/xDiT@ca94011</A>
											</DL><p>
											<DT><A HREF="https://github.com/xdit-project/xDiT/commit/ca94011acb0a1699222431bfafce8720ef9d743d#diff-f5328dbf6a5ced8a82574ec233924b8ee3fa7ee69d56706dee83314ca38f2bd8">Support optimized USP in Flux (#368) ¬∑ xdit-project/xDiT@ca94011</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/xfuser/model_executor/layers/usp_legacy.py">xDiT/xfuser/model_executor/layers/usp_legacy.py at main</A>
											<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/xfuser/model_executor/layers/usp.py">xDiT/xfuser/model_executor/layers/usp.py at main</A>
										</DL><p>
										<DT><H3 FOLDED>xfuser-wan</H3>
										<DL><p>
											<DT><A HREF="https://github.com/xdit-project/xDiT/commit/78cb759d85bfd88967b76024042b260027fffeef">Support Wan 2.X T2V/TI2V (#589)</A>
										</DL><p>
										<DT><H3 FOLDED>xfuser-flux</H3>
										<DL><p>
											<DT><A HREF="https://github.com/xdit-project/xDiT/commit/b1d68888f3dba25ffcfe550876eae601eceb0158">add fluxcontrolpipeline support (#527) ¬∑ xdit-project/xDiT@b1d6888</A>
										</DL><p>
										<DT><H3 FOLDED>PipeFusion</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2411.01738">[2411.01738] xDiT: an Inference Engine for Diffusion Transformers (DiTs) with Massive Parallelism</A>
										<DT><A HREF="https://arxiv.org/abs/2405.07719">[2405.07719] USP: A Unified Sequence Parallelism Approach for Long Context Generative AI</A>
										<DT><A HREF="https://arxiv.org/abs/2405.14430">[2405.14430] PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference</A>
										<DT><A HREF="https://github.com/xdit-project/xDiT/tree/main">xdit-project/xDiT: xDiT: A Scalable Inference Engine for Diffusion Transformers (DiTs) on multi-GPU Clusters</A>
										<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/xfuser/model_executor/layers/attention_processor.py">xDiT/xfuser/model_executor/layers/attention_processor.py at main ¬∑ xdit-project/xDiT</A>
										<DT><A HREF="https://gist.github.com/gradjitta/9afcdf70fee07a172cdf0de30e67ca82">report_hotswap.md</A>
										<DT><A HREF="https://www.youtube.com/watch?v=7DXnGrARqys">(1) TACO-DiT: Accelerating Your ComfyUI Generation Experience - YouTube</A>
										<DT><A HREF="https://github.com/thu-ml/RIFLEx/blob/multi-gpu/HunyuanVideo/hyvideo/inference.py">RIFLEx/HunyuanVideo/hyvideo/inference.py at multi-gpu ¬∑ thu-ml/RIFLEx</A>
									</DL><p>
									<DT><H3 FOLDED>dit-torch-compile</H3>
									<DL><p>
										<DT><A HREF="https://github.com/aredden/flux-fp8-api/blob/49c776c9185a2c87e38c57be6e4d41cd20e86021/flux_pipeline.py#L166">flux_pipeline.py#L166</A>
										<DT><A HREF="https://github.com/discus0434/faster-flux/blob/main/src/faster_flux/pipeline_wrapper.py">faster-flux/src/faster_flux/pipeline_wrapper.py at main ¬∑ discus0434/faster-flux</A>
									</DL><p>
									<DT><H3 FOLDED>step-distilled-lora</H3>
									<DL><p>
										<DT><H3 FOLDED>dit-one-step</H3>
										<DL><p>
											<DT><A HREF="https://seaweed-apt.com/">Seaweed-APT</A>
										</DL><p>
										<DT><H3 FOLDED>flux-turbo</H3>
										<DL><p>
											<DT><A HREF="https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha">alimama-creative/FLUX.1-Turbo-Alpha ¬∑ Hugging Face</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>dit-distillation</H3>
									<DL><p>
										<DT><A HREF="https://github.com/TencentARC/FluxKits">TencentARC/FluxKits</A>
										<DT><A HREF="https://x.com/krea_ai/status/1980358158376988747">WAN 2.1 14B Krea distillation real-time</A>
										<DT><A HREF="https://huggingface.co/krea/krea-realtime-video">krea/krea-realtime-video ¬∑ Hugging Face</A>
										<DT><A HREF="https://www.krea.ai/blog/krea-realtime-14b">Krea Realtime 14B: Real-Time, Long-Form AI Video Generation</A>
										<DT><A HREF="https://huggingface.co/lightx2v/Wan2.1-T2V-14B-StepDistill-CfgDistill">lightx2v/Wan2.1-T2V-14B-StepDistill-CfgDistill ¬∑ Hugging Face</A>
										<DT><A HREF="https://www.zhihu.com/people/bright109">[DiT Distillation] DMD &amp; DMD2: Distribution Matching Distillation Diffusion Model</A>
									</DL><p>
									<DT><H3 FOLDED>dit-sparsity</H3>
									<DL><p>
										<DT><H3 FOLDED>sparse-videogen2</H3>
										<DL><p>
											<DT><A HREF="https://x.com/HaochengXiUCB/status/1971219731140182423">(1) Haocheng Xi en X: "üöÄ Introducing Sparse VideoGen2 (SVG2) ‚Äî Pareto-frontier video generation acceleration with semantic-aware sparse attention! üèÜSpotlight paper accepted by #NeurIPS2025 ‚úÖ Training-free &amp;amp; plug-and-play ‚úÖ Up to 2.5√ó faster on HunyuanVideo, 1.9√ó faster on Wan 2.1 ‚úÖ SOTA quality https://t.co/kJhxktekY0" / X</A>
											<DT><A HREF="https://arxiv.org/abs/2505.18875">[2505.18875] Sparse VideoGen2: Accelerate Video Generation with Sparse Attention via Semantic-Aware Permutation</A>
											<DT><A HREF="https://github.com/svg-project/Sparse-VideoGen">svg-project/Sparse-VideoGen: [ICML2025, NeurIPS2025 Spotlight] Sparse VideoGen 1 &amp; 2: Accelerating Video Diffusion Transformers with Sparse Attention</A>
											<DT><A HREF="https://svg-project.github.io/v2/">Sparse VideoGen 2</A>
											<DT><A HREF="https://docs.flashinfer.ai/api/sparse.html">flashinfer.sparse - FlashInfer 0.3.1 documentation</A>
										</DL><p>
										<DT><H3 FOLDED>Chipmunk</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sandyresearch/chipmunk">sandyresearch/chipmunk: üé¨¬†3.7√ó faster video¬†generation E2E üñºÔ∏è¬†1.6√ó faster image¬†generation E2E ‚ö°¬†ColumnSparseAttn¬†9.3√ó vs¬†FlashAttn‚Äë3 üí®¬†ColumnSparseGEMM¬†2.5√ó vs¬†cuBLAS</A>
											<DT><A HREF="https://github.com/SohamGovande">SohamGovande (soham govande)</A>
											<DT><A HREF="https://www.youtube.com/watch?v=Rg9enIRSXmo">Chipmunk: Training-Free Acceleration of Diffusion Transformers | How to Integrate into Mochi - YouTube</A>
											<DT><A HREF="https://github.com/sandyresearch/chipmunk/blob/master/examples/YOUR-MODEL-HERE/README.md">chipmunk/examples/YOUR-MODEL-HERE/README.md at master ¬∑ sandyresearch/chipmunk</A>
											<DT><A HREF="https://arxiv.org/abs/2506.03275">[2506.03275] Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas</A>
										</DL><p>
										<DT><A HREF="https://github.com/hao-ai-lab/Awesome-Video-Attention">hao-ai-lab/Awesome-Video-Attention: A curated list of recent papers on efficient video attention for video diffusion models, including sparsification, quantization, and caching, etc.</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1956397310125807513">[DiT+Sparse] Bidriional Attention: How to achieve sparseness in a query?</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1927145409899401307">Sparse vDiT</A>
										<DT><A HREF="https://arxiv.org/pdf/2506.03065">Sparse-vDiT: Unleashing the Power of Sparse Attention to Accelerate Video Diffusion Transformers</A>
									</DL><p>
									<DT><H3 FOLDED>thu-nics</H3>
									<DL><p>
										<DT><A HREF="https://github.com/thu-nics">NICS-EFC Lab of Tsinghua University</A>
										<DT><A HREF="https://github.com/thu-nics/ViDiT-Q">thu-nics/ViDiT-Q: ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation</A>
										<DT><A HREF="https://github.com/thu-nics/DiTFastAttn">thu-nics/DiTFastAttn</A>
									</DL><p>
									<DT><H3 FOLDED>pai_fuser</H3>
									<DL><p>
										<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun/blob/main/examples/wan2.2/predict_i2v.py#L15">VideoX-Fun/examples/wan2.2/predict_i2v.py at main ¬∑ aigc-apps/VideoX-Fun</A>
										<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun/blob/main/videox_fun/dist/wan_xfuser.py#L78">VideoX-Fun/videox_fun/dist/wan_xfuser.py at main ¬∑</A>
									</DL><p>
									<DT><H3 FOLDED>TurboDiffusion</H3>
									<DL><p>
										<DT><A HREF="https://github.com/thu-ml/TurboDiffusion">thu-ml/TurboDiffusion: TurboDiffusion: 100‚Äì205√ó Acceleration of Video Diffusion Models</A>
										<DT><A HREF="https://jt-zhang.github.io/files/TurboDiffusion_Technical_Report.pdf">TurboDiffusion: Accelerating Video Diffusion Models by 100‚Äì205 Times</A>
									</DL><p>
									<DT><A HREF="https://github.com/xdit-project/xDiT/tree/main">xdit-project/xDiT: xDiT: A Scalable Inference Engine for Diffusion Transformers (DiTs) on multi-GPU Clusters</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/main/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py">onediff/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py at main ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/thu-nics/DiTFastAttn">thu-nics/DiTFastAttn</A>
									<DT><A HREF="https://github.com/aredden/flux-fp8-api/blob/main/float8_quantize.py#L273">flux-fp8-api/float8_quantize.py at main ¬∑ aredden/flux-fp8-api</A>
									<DT><A HREF="https://github.com/aredden/flux-fp8-api/blob/main/float8_quantize.py">flux-fp8-api/float8_quantize.py at main ¬∑ aredden/flux-fp8-api</A>
									<DT><A HREF="https://github.com/discus0434/comfyui-flux-accelerator">discus0434/comfyui-flux-accelerator: Accelerates Flux.1 image generation, just by using this node.</A>
									<DT><A HREF="https://github.com/discus0434/faster-flux/blob/main/src/faster_flux/pipeline_wrapper.py">faster-flux/src/faster_flux/pipeline_wrapper.py at main ¬∑ discus0434/faster-flux</A>
									<DT><A HREF="https://arxiv.org/html/2406.01125v1">Œî-DiT: A Training-Free Acceleration Method Tailored for Diffusion Transformers</A>
									<DT><A HREF="https://github.com/discus0434/comfyui-flux-accelerator/blob/main/__init__.py">comfyui-flux-accelerator/__init__.py at main</A>
									<DT><A HREF="https://github.com/hustvl/DiG">hustvl/DiG: DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention</A>
									<DT><A HREF="https://github.com/gojasper/flash-diffusion">gojasper/flash-diffusion: Official implementation of ‚ö° Flash Diffusion ‚ö°: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation</A>
									<DT><A HREF="https://github.com/kabachuha/OpenMMDiT">kabachuha/OpenMMDiT: Open(MM)DiT: An Easy, Fast and Memory-Efficient System for (MM)DiT Training and Inference</A>
									<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys">NUS-HPC-AI-Lab/VideoSys: VideoSys: An easy and efficient system for video generation</A>
									<DT><A HREF="https://github.com/sayakpaul/diffusers-torchao/blob/main/inference/benchmark_image.py">diffusers-torchao/inference/benchmark_image.py at main ¬∑ sayakpaul/diffusers-torchao</A>
									<DT><A HREF="https://www.outerport.com/blog/fast-flux-load">How fast can you load a FLUX (LoRA) model?</A>
									<DT><A HREF="https://x.com/PY_Z001/status/1944184006897242160">(1) Perry Zhang en X: "üöÄ Attention is the bottleneck in video DiTs‚Äî5‚ÄØs of 720p = 100K+ tokens, quadratic cost blows up fast. Sparse/linear attention is  for long-context world models. üß† Track relavent papers in our awsome-video-attention repo ‚Üí https://t.co/nJJyfadLgo #WorldModel #VideoAI" / X</A>
									<DT><A HREF="https://a-r-r-o-w.github.io/blog/3_blossom/00001_productionizing_diffusion-1/">Optimizing diffusion inference for production-ready speeds - I</A>
									<DT><A HREF="https://github.com/Overworldai/world_engine">Overworldai/world_engine: World Model Inference Engine</A>
								</DL><p>
								<DT><H3 FOLDED>xdit</H3>
								<DL><p>
									<DT><H3 FOLDED>mochi-xdit</H3>
									<DL><p>
										<DT><A HREF="https://github.com/xdit-project/mochi-xdit?tab=readme-ov-file">xdit-project/mochi-xdit: faster parallel inference of mochi video generation model</A>
										<DT><A HREF="https://medium.com/@xditproject/exploring-the-power-of-xdit-in-speeding-up-mochis-video-generation-19f71d4f8f97">Enhancing Parallelism and Speedup for xDiT in Serving the Mochi-1 Video Generation Model | by xdit-project | Nov, 2024 | Medium</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>FastWan</H3>
								<DL><p>
									<DT><A HREF="https://hao-ai-lab.github.io/blogs/fastvideo_post_training/">FastWan: Generating a 5-Second Video in 5 Seconds via Sparse Distillation | Hao AI Lab @ UCSD</A>
								</DL><p>
								<DT><H3 FOLDED>FastVideo</H3>
								<DL><p>
									<DT><A HREF="https://github.com/hao-ai-lab/FastVideo">hao-ai-lab/FastVideo: FastVideo is an open-source framework for accelerating large video diffusion model.</A>
									<DT><A HREF="https://x.com/haoailab/status/1891943972442079545">Sliding Tile Attention (STA)</A>
									<DT><A HREF="https://hao-ai-lab.github.io/blogs/fastvideo/">FastVideo V1: A Unified Framework for Accelerated Video Generation | Hao AI Lab @ UCSD</A>
								</DL><p>
								<DT><H3 FOLDED>LightX2V</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ModelTC/LightX2V/">ModelTC/LightX2V: Light Image Video Generation Inference Framework</A>
									<DT><A HREF="https://github.com/triple-Mu">triple-Mu (triple-mu)</A>
								</DL><p>
								<DT><H3 FOLDED>video-distillation</H3>
								<DL><p>
									<DT><A HREF="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/distillation.md">FastVideo/docs/distillation.md at main ¬∑ hao-ai-lab/FastVideo</A>
									<DT><A HREF="https://arxiv.org/abs/2405.14867">[2405.14867] Improved Distribution Matching Distillation for Fast Image Synthesis</A>
									<DT><A HREF="https://arxiv.org/abs/2412.07772">[2412.07772] From Slow Bidirectional to Fast Autoregressive Video Diffusion Models</A>
									<DT><A HREF="https://wayfarerlabs.ai/blog/fast-audio-video-world-models-part-2">Fast Audio Video World Models: Part 2 | OWL Blog</A>
								</DL><p>
								<DT><H3 FOLDED>sliding-tile-attention</H3>
								<DL><p>
									<DT><A HREF="https://x.com/haoailab/status/1891943986245533993">Sliding Tile Attention (STA): notes</A>
									<DT><A HREF="https://hao-ai-lab.github.io/blogs/sta/">Fast Video Generation with Sliding Tile Attention | Hao AI Lab @ UCSD</A>
									<DT><A HREF="https://arxiv.org/abs/2502.04507">[2502.04507] Fast Video Generation with Sliding Tile Attention</A>
									<DT><A HREF="https://github.com/hao-ai-lab/FastVideo/blob/a3ec969397a0c87124ca8d958e57b6d2960eef61/csrc/sliding_tile_attention/README.md">FastVideo/csrc/sliding_tile_attention/README.md at a3ec969397a0c87124ca8d958e57b6d2960eef61 ¬∑ hao-ai-lab/FastVideo</A>
									<DT><A HREF="https://github.com/fal-ai-community/NativeSparseAttention">fal-ai-community/NativeSparseAttention: research impl of Native Sparse Attention (2502.11089)</A>
								</DL><p>
								<DT><H3 FOLDED>video-long-generation</H3>
								<DL><p>
									<DT><H3 FOLDED>frame-interpolation</H3>
									<DL><p>
										<DT><H3 FOLDED>VFI</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Fannovel16/ComfyUI-Frame-Interpolation/blob/main/__init__.py">ComfyUI-Frame-Interpolation/__init__.py at main ¬∑ Fannovel16/ComfyUI-Frame-Interpolation</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>RIFLEx</H3>
									<DL><p>
										<DT><A HREF="https://github.com/thu-ml/RIFLEx">thu-ml/RIFLEx: Official implementation for "RIFLEx: A Free Lunch for Length Extrapolation in Video Diffusion Transformers" (ICML 2025)</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2510.02283">[2510.02283] Self-Forcing++: Towards Minute-Scale High-Quality Video Generation</A>
									<DT><A HREF="https://github.com/vita-epfl/Stable-Video-Infinity">vita-epfl/Stable-Video-Infinity: [ArXiv 25] Stable Video Infinity: Infinite-Length Video Generation with Error Recycling</A>
								</DL><p>
								<DT><A HREF="https://www.zhihu.com/question/1934635266095703079/answer/1934784517186499611">What opportunities remain for video generation inference acceleration frameworks in 2025?</A>
								<DT><A HREF="https://github.com/THUDM/CogVideo/issues/48">Jiarui Fang To achieve real-time generation, the DiT model must be deployed in parallel across multiple devices, and xDiT is designed to address this challenge.</A>
								<DT><A HREF="https://github.com/Vchitect/VEnhancer">Vchitect/VEnhancer: Official codes of VEnhancer: Generative Space-Time Enhancement for Video Generation</A>
								<DT><A HREF="https://github.com/hao-ai-lab/FastVideo">hao-ai-lab/FastVideo: FastVideo is an open-source framework for accelerating large video diffusion model.</A>
								<DT><A HREF="https://github.com/G-U-N/Phased-Consistency-Model">G-U-N/Phased-Consistency-Model: [NeurIPS 2024] Boosting the performance of consistency models with PCM!</A>
								<DT><A HREF="https://github.com/LiewFeng/TeaCache">LiewFeng/TeaCache: Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model</A>
								<DT><A HREF="https://www.arxiv.org/pdf/2505.16864">Training-Free Efficient Video Generation via Dynamic Token Carving</A>
							</DL><p>
							<DT><H3 FOLDED>video-world-models</H3>
							<DL><p>
								<DT><H3 FOLDED>wm-sampling-physics</H3>
								<DL><p>
									<DT><H3 FOLDED>self-refine-video</H3>
									<DL><p>
										<DT><A HREF="https://agwmon.github.io/self-refine-video/">Self-Refining Video Sampling</A>
										<DT><A HREF="https://arxiv.org/abs/2601.18577">[2601.18577] Self-Refining Video Sampling</A>
										<DT><A HREF="https://github.com/agwmon/self-refine-video">agwmon/self-refine-video: Pytorch implementation of Self-Refining Video Sampling</A>
										<DT><A HREF="https://github.com/agwmon/self-refine-video/blob/main/inference_i2v_pnp.py">self-refine-video/inference_i2v_pnp.py at main ¬∑ agwmon/self-refine-video</A>
										<DT><A HREF="https://www.diffchecker.com/6AW86VhP/">wan_self_refine_sampling_diff - Diffchecker</A>
										<DT><A HREF="https://x.com/sainingxie/status/2017014680812724718">temporal consistency pins videos to a low-dimensional manifold in the total pixel space.  compare to UniPC</A>
									</DL><p>
									<DT><A HREF="https://github.com/ClownsharkBatwing/RES4LYF">ClownsharkBatwing/RES4LYF</A>
								</DL><p>
								<DT><H3 FOLDED>Genie</H3>
								<DL><p>
									<DT><H3 FOLDED>Genie 2</H3>
									<DL><p>
										<DT><A HREF="https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/">Genie 2: A large-scale foundation world model - Google DeepMind</A>
										<DT><A HREF="https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/">A generalist AI agent for 3D virtual environments - Google DeepMind</A>
										<DT><A HREF="https://github.com/lucidrains/genie2-pytorch">lucidrains/genie2-pytorch: Implementation of a framework for Genie2 in Pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>Genie 3</H3>
									<DL><p>
										<DT><A HREF="https://x.com/Almondgodd/status/1971314283184259336">(1) anandmaj en X: "I spent the past month reimplementing DeepMind‚Äôs Genie 3 world model from scratch Ended up making TinyWorlds, a 3M parameter world model capable of generating playable game environments demo below + everything I learned in thread (full repo at the end)üëáüèº https://t.co/ISUKbiV4LF" / X</A>
										<DT><A HREF="https://github.com/AlmondGod/tinyworlds">AlmondGod/tinyworlds: minimal reimplementation of deepmind's genie 3 world model</A>
										<DT><A HREF="https://github.com/Robbyant/lingbot-world">Robbyant/lingbot-world: Advancing Open-source World Models</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2402.15391">[2402.15391] Genie: Generative Interactive Environments</A>
									<DT><A HREF="https://x.com/GoogleDeepMind/status/1989024090414309622">Google DeepMind en X: "SIMA 2 ü§ù Genie 3 We tested SIMA 2‚Äôs abilities in simulated 3D worlds created by our world model Genie 3. It demonstrated unprecedented adaptability by navigating its surroundings and took meaningful steps toward goals. https://t.co/9M9bVMqD6e" / X</A>
								</DL><p>
								<DT><H3 FOLDED>lingbot-world</H3>
								<DL><p>
									<DT><H3 FOLDED>lingbot-world-weights</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/robbyant/lingbot-world-base-cam">robbyant/lingbot-world-base-cam ¬∑ Hugging Face</A>
									</DL><p>
									<DT><A HREF="https://github.com/Robbyant/lingbot-world">Robbyant/lingbot-world: Advancing Open-source World Models</A>
									<DT><A HREF="https://github.com/Robbyant/lingbot-world/blob/main/LingBot_World_paper.pdf">lingbot-world/LingBot_World_paper.pdf at main ¬∑ Robbyant/lingbot-world</A>
									<DT><A HREF="https://grok.com/c/5ab58a00-d0b2-43d7-8018-ce044a784d99?rid=944af2ea-cd1b-4e78-bfb6-c4927a8206b5">Transforming WAN 2.2 into Real-Time Video World Model - Grok</A>
									<DT><A HREF="https://www.diffchecker.com/2PRCqg6p/">wan22_i2v_world I2V inference changes adding conditioning and plukcker embeddings</A>
								</DL><p>
								<DT><H3 FOLDED>Waypoint-1</H3>
								<DL><p>
									<DT><A HREF="https://over.world/blog/the-path-to-real-time-worlds-and-why-it-matters">The Path to Real-Time Worlds and Why It Matters</A>
									<DT><A HREF="https://x.com/overworld_ai/status/2013673088748245188?s=12">(1) Overworld en X: "Today, we‚Äôre releasing a research preview of our real-time, local-first world model built for interactive, playable AI-worlds 60fps, locally run, all on consumer-grade hardware. Come take a look ‚¨áÔ∏è https://t.co/QFmZNzhrr0" / X</A>
									<DT><A HREF="https://huggingface.co/blog/waypoint-1">Introducing Waypoint-1: Real-time interactive video diffusion from Overworld</A>
									<DT><A HREF="https://github.com/Overworldai/world_engine">Overworldai/world_engine: World Model Inference Engine</A>
								</DL><p>
								<DT><H3 FOLDED>dreamer4</H3>
								<DL><p>
									<DT><A HREF="https://danijar.com/project/dreamer4/">Training Agents Inside of Scalable World¬†Models</A>
									<DT><A HREF="https://arxiv.org/abs/2509.24527">[2509.24527] Training Agents Inside of Scalable World Models</A>
								</DL><p>
								<DT><H3 FOLDED>Cosmos</H3>
								<DL><p>
									<DT><H3 FOLDED>cosmos-predict2</H3>
									<DL><p>
										<DT><A HREF="https://github.com/nvidia-cosmos/cosmos-predict2">nvidia-cosmos/cosmos-predict2: Cosmos-Predict2 is a collection of general-purpose world foundation models for Physical AI that can be fine-tuned into customized world models for downstream applications.</A>
									</DL><p>
									<DT><H3 FOLDED>Cosmos Policy</H3>
									<DL><p>
										<DT><A HREF="https://x.com/moo_jin_kim/status/2015113423831630241?s=12">(1) Moo Jin Kim en X: "We release Cosmos Policy üí´: a state-of-the-art robot policy built on a video diffusion model backbone. - policy + world model + value function ‚Äî in 1 model - no architectural changes to the base video model - SOTA in LIBERO (98.5%), RoboCasa (67.1%), &amp;amp; ALOHA tasks (93.6%) üßµüëá https://t.co/cz9L3ziJ6x" / X</A>
										<DT><A HREF="https://github.com/nvlabs/cosmos-policy">NVlabs/cosmos-policy: Cosmos Policy</A>
										<DT><A HREF="https://arxiv.org/abs/2601.16163">[2601.16163] Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning</A>
									</DL><p>
									<DT><A HREF="https://x.com/DrJimFan/status/1876516972512559170">(1) Jim Fan en X: "Introducing NVIDIA Cosmos, an open-source, open-weight Video World Model. It's trained on 20M hours of videos and weighs from 4B to 14B. Cosmos offers two flavors: diffusion (continuous tokens) and autoregressive (discrete tokens); and two generation modes: text-&amp;gt;video and https://t.co/onplT711Fy" / X</A>
									<DT><A HREF="https://github.com/NVIDIA/Cosmos-Tokenizer">NVIDIA/Cosmos-Tokenizer: A suite of image and video neural tokenizers</A>
									<DT><A HREF="https://github.com/NVIDIA/Cosmos">NVIDIA/Cosmos: Cosmos is a world model development platform that consists of world foundation models, tokenizers and video processing pipeline to accelerate the development of Physical AI at Robotics &amp; AV labs. Cosmos is purpose built for physical AI. The Cosmos repository will enable end users to run the Cosmos models, run inference scripts and generate videos.</A>
								</DL><p>
								<DT><H3 FOLDED>mineworld</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/microsoft/mineworld">microsoft/mineworld ¬∑ Hugging Face</A>
									<DT><A HREF="https://github.com/microsoft/mineworld">microsoft/mineworld: MineWorld: A Real-time interactive world model on Minecraft</A>
									<DT><A HREF="https://arxiv.org/pdf/2504.08388">MINEWORLD: A REAL-TIME AND OPEN-SOURCE INTERAC- TIVE WORLD MODEL ON MINECRAFT</A>
								</DL><p>
								<DT><H3 FOLDED>bytedn-videoWorld</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ByteDance-Seed/VideoWorld">ByteDance-Seed/VideoWorld: [CVPR 2025] VideoWorld is a simple generative model that learns purely from unlabeled videos‚Äîmuch like how babies learn by observing their environment.</A>
									<DT><A HREF="https://arxiv.org/pdf/2501.09781">VideoWorld: Exploring Knowledge Learning from Unlabeled Videos</A>
									<DT><A HREF="https://huggingface.co/datasets/maverickrzw/VideoGo-Bench">maverickrzw/VideoGo-Bench ¬∑ Datasets at Hugging Face</A>
								</DL><p>
								<DT><H3 FOLDED>bytedn-phyworld</H3>
								<DL><p>
									<DT><A HREF="https://seed.bytedance.com/en/public_papers/how-far-is-video-generation-from-world-model-a-physical-law-perspective">How Far is Video Generation from World Model: A Physical Law Perspective - Publications - ByteDance Seed Team (bytedn)</A>
									<DT><A HREF="https://github.com/phyworld/phyworld">phyworld/phyworld</A>
								</DL><p>
								<DT><H3 FOLDED>openpilot</H3>
								<DL><p>
									<DT><H3 FOLDED>learning to drive</H3>
									<DL><p>
										<DT><A HREF="https://x.com/___Harald___/status/1919438867666473453">(1) Harald Sch√§fer en X: "Our models at @comma_ai have always been open-source. But now we're also publishing all the loss graphs, metrics, and reports. You can now see everything we do when evaluating the quality of a driving model! https://t.co/NafwwIZq5W" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2504.19077">[2504.19077] Learning to Drive from a World Model</A>
										<DT><A HREF="https://blog.comma.ai/mlsim">Learning to Drive from a World Model</A>
										<DT><A HREF="https://www.youtube.com/watch?v=XCoz_oqpDw0">Ep#19 Learning to Drive from a World Model - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=FnFksQo-yEY">How AI Powers Self-Driving Tesla with Elon Musk and Andrej Karpathy - YouTube</A>
									</DL><p>
									<DT><A HREF="https://github.com/commaai/openpilot">commaai/openpilot: openpilot is an operating system for robotics. Currently, it upgrades the driver assistance system on 300+ supported cars.</A>
									<DT><A HREF="https://commaai.github.io/model_reports/">Index of . model training logs report</A>
									<DT><A HREF="https://www.xiaomiev.com/pilot">https://www.xiaomiev.com/pilot</A>
									<DT><A HREF="https://x.com/___Harald___/status/1981033221275172896">Harald Sch√§fer en X: "The models running in openpilot can run on different GPU architectures with one-line config changes because it uses @__tinygrad__ tinygrad isn't perfect yet, but it's so refreshing do do ML and not worry about GPU drivers and hardware specific code for once. https://t.co/SJuoHFG0dd" / X</A>
									<DT><A HREF="https://yassineyousfi.github.io/">Yassine Yousfi</A>
									<DT><A HREF="https://www.youtube.com/watch?v=f0kOu25WHas">comma ai | Touring comma HQ + launching the new jobs page comma.ai/jobs - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=NRqtA7uvkOA">comma ai | You've been asking for this... | github.com/commaai/opendbc | a Python API for your car - YouTube</A>
									<DT><A HREF="https://x.com/Tesla/status/1982255564974641628">(1) Tesla en X: "To push self-driving into situations wilder than reality, we built a neural network world simulator that can create entirely synthetic worlds for the Tesla to drive in. Video below is fully generated &amp;amp; not a real video https://t.co/uqQEqO03lY" / X</A>
									<DT><A HREF="https://x.com/comma_ai/status/1982162517297442977">(1) comma en X: "While everyone else is moving to Rust, openpilot is becoming more Python over time. openpilot is so good because it's written in Python, not despite it. Self-driving cars is so far from being solved, and Python allows us to iterate as quickly as possible. Don't fall for the" / X</A>
									<DT><A HREF="https://x.com/comma_ai/status/1981601036579356699">comma en X: "We discussed our version of this, called MLSIM, at CVPR in June. And since then, we‚Äôve shipped it to openpilot release. Come see @___Harald___ and @yassineyousfi_‚Äôs reveal all the secrets at COMMA_CON!" / X</A>
									<DT><A HREF="https://www.linkedin.com/posts/harald-sch%C3%A4fer-567830132_tried-alpamayo-in-our-testing-stack-they-activity-7415087952495726595-g5ZK/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">Tried alpamayo in our testing stack. They use great abstractions like us (img -&gt; 3D traj in meters). So it was easy to port.</A>
								</DL><p>
								<DT><H3 FOLDED>Jasmine</H3>
								<DL><p>
									<DT><A HREF="https://x.com/maharajamihir/status/1985417597463007357?s=12">(1) Mihir Mahajan en X: "Overall we make everything as reproducible as possible and ablate every decision we made. Checkpoints + datasets are on HF, hparams are in appendix, run instructions in readme. Paper link: https://t.co/xULUsmCrqP Repo: https://t.co/CY2zyHMjke HF link: https://t.co/fmasKpiDBR" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2510.27002">[2510.27002] Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase</A>
								</DL><p>
								<DT><H3 FOLDED>1X-challenge</H3>
								<DL><p>
									<DT><A HREF="https://github.com/edchangy11/1x-challenge">edchangy11/1x-challenge</A>
								</DL><p>
								<DT><H3 FOLDED>video-world-models-data</H3>
								<DL><p>
									<DT><A HREF="https://sergeylevine.substack.com/p/sporks-of-agi">Sporks of AGI - by Sergey Levine - Learning and Control</A>
								</DL><p>
								<DT><H3 FOLDED>DecartAI</H3>
								<DL><p>
									<DT><A HREF="https://x.com/DecartAI">A new era of real-time generative experiences, enabled by cutting-edge AI efficiency.</A>
								</DL><p>
								<DT><A HREF="https://github.com/eloialonso/diamond">eloialonso/diamond: DIAMOND (DIffusion As a Model Of eNvironment Dreams) is a reinforcement learning agent trained in a diffusion world model. NeurIPS 2024 Spotlight.</A>
								<DT><A HREF="https://www.1x.tech/discover/1x-world-model-sampling-challenge">1X World Model: Sampling Challenge Update</A>
								<DT><A HREF="https://x.com/___Harald___/status/1866345938639548513">Harald Sch√§fer en X: "Our worldmodel at @comma_ai doesn't make the prettiest videos. But it may be the most physically accurate ML-based driving simulator in existence today. Here is what a deviation and recovery of exactly 1m to the left and right looks like. https://t.co/ZBN8KpoZWR" / X</A>
								<DT><A HREF="https://x.com/zhou_xian_/status/1869511650782658846">(1) Zhou Xian en X: "Everything you love about generative models ‚Äî now powered by real physics! Announcing the Genesis project ‚Äî after a 24-month large-scale research collaboration involving over 20 research labs ‚Äî a generative physics engine able to generate 4D dynamical worlds powered by a physics https://t.co/4HRaTp5Gbs" / X</A>
								<DT><A HREF="https://github.com/Genesis-Embodied-AI/Genesis">Genesis-Embodied-AI/Genesis: A generative world for general-purpose robotics &amp; embodied AI learning.</A>
								<DT><A HREF="https://github.com/NJU-PCALab/STAR">NJU-PCALab/STAR: STAR: Spatial-Temporal Augmentation with Text-to-Video Models for Real-World Video Super-Resolution</A>
								<DT><A HREF="https://x.com/JackMonas/status/1836257177453105445">(1) Jack Monas en X: "Some initial results from our @1x_tech world model, a learned simulator that can predict how the world responds to our robot's actions. Below are comparisons of real videos vs our generations, both of which start from the same initial frames. See our blog post for more details! https://t.co/l27rYNphcZ" / X</A>
								<DT><A HREF="https://x.com/___Harald___/status/1919438867666473453">CommaAI end-to-end driving model: loss graphs, metrics and reports</A>
								<DT><A HREF="https://commaai.github.io/model_reports/">commaAI driving model reports</A>
								<DT><A HREF="https://seed.bytedance.com/en/public_papers/how-far-is-video-generation-from-world-model-a-physical-law-perspective">How Far is Video Generation from World Model: A Physical Law Perspective - Publications - ByteDance Seed Team (bytedn)</A>
								<DT><A HREF="https://x.com/_akhaliq/status/1936984538632061061">Hunyuan-GameCraft</A>
								<DT><A HREF="https://www.1x.tech/1x-world-model.pdf">1X World Model: Evaluating Bits, not Atoms</A>
								<DT><A HREF="https://wayfarerlabs.ai/blog/fast-audio-video-world-models-part-2">Fast Audio Video World Models: Part 2 | OWL Blog</A>
								<DT><A HREF="https://x.com/wayfarerlabs/status/1949517715347050785">(1) OWL en X: "Does your DiT really need all those layers? We found that ODE regression can enable extreme pruning for DiT that in our setup enabled a 70x speedup on the model side alone. [Image 1] is teacher, [Image 2] is student 1/2 https://t.co/q24MIAZlBU" / X</A>
								<DT><A HREF="https://x.com/giffmana/status/1952983093624582437">(1) Lucas Beyer (bl16) en X: "Good question: when did "world model" change its meaning to "action conditioned video model" - it used to be "minimal model needed to plan in an environment". My take is that there is no change in meaning! The world model needs to be enough for the task you're trying to solve. https://t.co/ozgH6pN4yn" / X</A>
								<DT><A HREF="https://openai.com/index/video-generation-models-as-world-simulators/">Video generation models as world simulators | OpenAI</A>
								<DT><A HREF="https://www.alphaxiv.org/pdf/2509.24527">Training Agents Inside of Scalable World Models | alphaXiv</A>
								<DT><A HREF="https://x.com/SchmidhuberAI/status/1991605057989521758">(1) J√ºrgen Schmidhuber en X: "25 years later, @ylecun's 2015 slide rehashed the 1990 paper on a recurrent neural "world model" that predicts all sensory inputs including pixels and multi-dimensional reward signals &amp;amp; pain signals: J. Schmidhuber. Making the world differentiable: On using fully recurrent https://t.co/2J903TtUe5" / X</A>
								<DT><A HREF="https://www.youtube.com/live/CkOSMqwvFiQ">TUM AI Lecture Series - Building generative world models: progress and challenges (Ruiqi Gao) - YouTube</A>
								<DT><A HREF="https://x.com/liuziwei7/status/2000590345952788927">(1) Ziwei Liu en X: "üó∫Ô∏èTowards A Roadmap of Video World Modelüó∫Ô∏è We conceptualize the progression of video generation through **four generations**, in which the core capabilities ultimately culminating in a world model. üè° https://t.co/Cr9T4Uq7QP üìú https://t.co/NvXmw6JbbG üßë‚Äçüíª https://t.co/lv4QuAW08m https://t.co/VYYR8Yk239" / X</A>
								<DT><A HREF="https://world-model-roadmap.github.io/">Simulating the Visual World with Artificial Intelligence: A Roadmap</A>
								<DT><A HREF="https://arxiv.org/pdf/2511.08585">Simulating the Visual World with Artificial Intelligence: A Roadmap</A>
								<DT><A HREF="https://www.youtube.com/watch?v=IRu-cPkpiFk">A Peek into Tesla‚Äôs Autonomous Future: Core Tech Revealed by VP Ashok Elluswamy at ICCV25 WDFM-AD - YouTube</A>
								<DT><A HREF="https://arxiv.org/pdf/2512.15840">LARGE VIDEO PLANNER ENABLES GENERALIZABLE ROBOT CONTROL</A>
								<DT><A HREF="https://www.youtube.com/watch?v=_2NijXqBESI">The Physical Turing Test: Jim Fan on Nvidia's Roadmap for Embodied AI - YouTube</A>
								<DT><A HREF="https://dagroup-pku.github.io/ReVidgen.github.io/">Rethinking Video Generation Model for the Embodied World</A>
								<DT><A HREF="https://www.1x.tech/discover/world-model-self-learning">1X World Model | From Video to Action: A New Way Robots Learn</A>
								<DT><A HREF="https://x.com/TheHumanoidHub/status/2011632089708576793">AI engineer, world modeling &amp; video generation, Tesla AI</A>
								<DT><A HREF="https://x.com/TheHumanoidHub/status/2010828834418147827">(1) The Humanoid Hub en X: "Six months ago, on the first-ever episode of The Humanoid Hub, Eric Jang discussed World Models as something that wasn't being taken seriously as the core of AI systems. Today, 1X introduced a robotics policy that turns that vision into reality, converting video generation from https://t.co/Ac0wTbaoyw" / X</A>
								<DT><A HREF="https://x.com/tianyuanzhang99/status/2008274812649767039">Tianyuan Zhang en X: "Robot foundation models face a fundamental data bottleneck. Current paradigms (e.g., VLA / LBM) are data-bound and may require years, or decades, of real-world action data to reach the scale of MLLMs. We explore a different scaling path: video policies, i.e. actions are" / X</A>
								<DT><A HREF="https://github.com/Robbyant/lingbot-world">Robbyant/lingbot-world: Advancing Open-source World Models</A>
							</DL><p>
							<DT><H3 FOLDED>video-understanding</H3>
							<DL><p>
								<DT><H3 FOLDED>VideoPrism</H3>
								<DL><p>
									<DT><A HREF="https://x.com/HuggingPapers/status/1945336507402694701">VideoPrism: video encoder SOTA</A>
									<DT><A HREF="https://arxiv.org/abs/2402.13217">[2402.13217] VideoPrism: A Foundational Visual Encoder for Video Understanding</A>
								</DL><p>
								<DT><H3 FOLDED>apollo</H3>
								<DL><p>
									<DT><A HREF="https://apollo-lmms.github.io/">Apollo: An Exploration of Video Understanding in Large Multimodal Models</A>
									<DT><A HREF="https://arxiv.org/abs/2412.10360">[2412.10360] Apollo: An Exploration of Video Understanding in Large Multimodal Models</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>video-training</H3>
							<DL><p>
								<DT><H3 FOLDED>Pusa</H3>
								<DL><p>
									<DT><H3 FOLDED>Pusa-v1</H3>
									<DL><p>
										<DT><A HREF="https://yaofang-liu.github.io/Pusa_Web/">PUSA V1.0: Surpassing Wan-I2V-14B with $500 Training Cost</A>
										<DT><A HREF="https://github.com/Yaofang-Liu/Pusa-VidGen">Yaofang-Liu/Pusa-VidGen: Pusa: Thousands Timesteps Video Diffusion Model</A>
									</DL><p>
									<DT><A HREF="https://github.com/Yaofang-Liu/Pusa-VidGen">Yaofang-Liu/Pusa-VidGen: Pusa: Thousands-handed Video Diffusion Model</A>
									<DT><A HREF="https://huggingface.co/RaphaelLiu/Pusa-V0.5">RaphaelLiu/Pusa-V0.5 ¬∑ Hugging Face</A>
									<DT><A HREF="https://huggingface.co/datasets/RaphaelLiu/PusaV0.5_Training">RaphaelLiu/PusaV0.5_Training ¬∑ Datasets at Hugging Face</A>
									<DT><A HREF="https://github.com/stars/Yaofang-Liu/lists/diffusion-mdels">Yaofang-Liu's list / Diffusion Mdels</A>
								</DL><p>
								<DT><H3 FOLDED>VideoX-Fun</H3>
								<DL><p>
									<DT><H3 FOLDED>wan-training</H3>
									<DL><p>
										<DT><A HREF="https://github.com/bghira/SimpleTuner/blob/main/documentation/quickstart/WAN.md">SimpleTuner/documentation/quickstart/WAN.md at main ¬∑ bghira/SimpleTuner</A>
										<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/main/examples/wanvideo/model_training/full/Wan2.2-T2V-A14B.sh">DiffSynth-Studio/examples/wanvideo/model_training/full/Wan2.2-T2V-A14B.sh at main ¬∑ modelscope/DiffSynth-Studio</A>
									</DL><p>
									<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun">aigc-apps/VideoX-Fun: üìπ A more flexible framework that can generate videos at any resolution and creates videos from images.</A>
								</DL><p>
								<DT><H3 FOLDED>video-dataloader</H3>
								<DL><p>
									<DT><H3 FOLDED>video-load-utils</H3>
									<DL><p>
										<DT><A HREF="https://github.com/antferdom/deployment-dev/blob/41f498a538e1b22b12bb2ada0f56f9c229bdaf6c/src/mdeploy/utils/loading_utils.py#L132">utils/loading_utils.py</A>
									</DL><p>
									<DT><A HREF="https://x.com/mike64_t/status/1975737784557314378">(1) mike64_t en X: "just so you guys know the bottleneck for getting data out of Minecraft is literally FFmpeg and I can guarantee this model is both slower and worse than actually being ingame. The timer speed can be increased, frame capture can happen in game at scaled rate, and the thing that" / X</A>
									<DT><A HREF="https://x.com/___Harald___/status/1976048791611658455">(1) Harald Sch√§fer en X: "Video decoding is also a big bottleneck in training our models. Our new datasets are 30k hours of video, too much to store uncompressed. So we made the trainers decode during training, we get about ~10k fps per 8GPU machine. Was a big effort to keep it all fast." / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/VideoVerses/VideoTuna">VideoVerses/VideoTuna: Let's finetune video generation models!</A>
								<DT><A HREF="https://github.com/Vchitect/LiteGen">Vchitect/LiteGen: A light-weight and high-efficient training framework for accelerating diffusion tasks.</A>
								<DT><A HREF="https://github.com/sihyun-yu/REPA">sihyun-yu/REPA: Official Pytorch Implementation of Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think</A>
								<DT><A HREF="https://apollo-lmms.github.io/">Apollo: An Exploration of Video Understanding in Large Multimodal Models</A>
								<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun">aigc-apps/VideoX-Fun: üìπ A more flexible framework that can generate videos at any resolution and creates videos from images.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=54cpserQGmw&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=12">Efficient Training of Video Generation Foundation Model at ByteDance - Xiaonan Nie &amp; Heng Zhang - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>video-test-time-training</H3>
							<DL><p>
								<DT><H3 FOLDED>ttt-thunderkittens</H3>
								<DL><p>
									<DT><A HREF="https://github.com/test-time-training/ttt-video-dit">test-time-training/ttt-video-dit</A>
									<DT><A HREF="https://x.com/karansdalal/status/1909393559981375574">TP at SM level</A>
								</DL><p>
								<DT><A HREF="https://test-time-training.github.io/video-dit/">One-Minute Video Generation with Test-Time Training</A>
								<DT><A HREF="https://arxiv.org/abs/2504.05298">[2504.05298] One-Minute Video Generation with Test-Time Training</A>
								<DT><A HREF="https://x.com/karansdalal/status/1909393559981375574">TT layers for training and video generation</A>
								<DT><A HREF="https://github.com/test-time-training/ttt-tk/tree/353b6c8346544458fb38bf1fe8de4f1675299ed1">test-time-training/ttt-tk at 353b6c8346544458fb38bf1fe8de4f1675299ed1</A>
							</DL><p>
							<DT><H3 FOLDED>video-generation-long</H3>
							<DL><p>
								<DT><H3 FOLDED>LongLive</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVlabs/LongLive">NVlabs/LongLive: Real-time Interactive Long Video Generation</A>
									<DT><A HREF="https://huggingface.co/papers/2509.22622">Paper page - LongLive: Real-time Interactive Long Video Generation</A>
									<DT><A HREF="https://www.youtube.com/watch?v=CO1QC7BNvig">LongLive: Real-time Interactive Long Video Generation - YouTube</A>
								</DL><p>
								<DT><A HREF="https://www.arxiv.org/abs/2508.21058">[2508.21058] Mixture of Contexts for Long Video Generation</A>
								<DT><A HREF="https://primecai.github.io/moc/">Mixture of Contexts for Long Video Generation</A>
								<DT><A HREF="https://github.com/vita-epfl/Stable-Video-Infinity?tab=readme-ov-file">vita-epfl/Stable-Video-Infinity: [ArXiv 25] Stable Video Infinity: Infinite-Length Video Generation with Error Recycling</A>
							</DL><p>
							<DT><H3 FOLDED>video-generation-reasoning</H3>
							<DL><p>
								<DT><A HREF="https://video-zero-shot.github.io/">Video models are zero-shot learners and reasoners</A>
								<DT><A HREF="https://arxiv.org/abs/2509.20328">[2509.20328] Video models are zero-shot learners and reasoners</A>
							</DL><p>
							<DT><H3 FOLDED>Wan</H3>
							<DL><p>
								<DT><H3 FOLDED>CausVid-wan</H3>
								<DL><p>
									<DT><A HREF="https://www.reddit.com/r/StableDiffusion/comments/1knuafk/causvid_lora_massive_speedup_for_wan21_made_by/">Causvid Lora, massive speedup for Wan2.1 made by Kijai : r/StableDiffusion</A>
									<DT><A HREF="https://huggingface.co/lightx2v/Wan2.1-T2V-14B-CausVid">lightx2v/Wan2.1-T2V-14B-CausVid ¬∑ Hugging Face</A>
									<DT><A HREF="https://github.com/tianweiy/CausVid">tianweiy/CausVid: (CVPR 2025) From Slow Bidirectional to Fast Autoregressive Video Diffusion Models</A>
									<DT><A HREF="https://huggingface.co/Kijai/WanVideo_comfy/blob/main/Wan21_CausVid_14B_T2V_lora_rank32.safetensors">Wan21_CausVid_14B_T2V_lora_rank32.safetensors ¬∑ Kijai/WanVideo_comfy at main</A>
								</DL><p>
								<DT><H3 FOLDED>wan2.5</H3>
								<DL><p>
									<DT><A HREF="https://wavespeed.ai/collections/wan-2-5">Wan-2-5 - Wan-2-5 model collection - WaveSpeedAI</A>
								</DL><p>
								<DT><H3 FOLDED>wan2.2-V2V</H3>
								<DL><p>
									<DT><H3 FOLDED>VideoX-Fun</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/alibaba-pai/Wan2.2-Fun-A14B-Control">alibaba-pai/Wan2.2-Fun-A14B-Control ¬∑ Hugging Face</A>
										<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun">aigc-apps/VideoX-Fun: üìπ A more flexible framework that can generate videos at any resolution and creates videos from images.</A>
										<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun/commit/5631a8cac4866c45cbbc2a22803a0c9f3042e5bf">Update Wan2.2 Fun (#279) ¬∑ aigc-apps/VideoX-Fun@5631a8c</A>
									</DL><p>
									<DT><A HREF="https://github.com/Wan-Video/Wan2.2/blob/main/wan/distributed/fsdp.py">Wan2.2/wan/distributed/fsdp.py at main ¬∑ Wan-Video/Wan2.2</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/pull/41/files">supports wan fun lora by akaitsuki-ii ¬∑ Pull Request #41 ¬∑ modelscope/DiffSynth-Engine</A>
								</DL><p>
								<DT><H3 FOLDED>wan2.2-T2V</H3>
								<DL><p>
									<DT><H3 FOLDED>wan2.2.-T2V-weights</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B">Wan-AI/Wan2.2-T2V-A14B</A>
										<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B">Wan-AI/Wan2.2-TI2V-5B</A>
										<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.2-T2V-A14B-Diffusers">Wan-AI/Wan2.2-T2V-A14B-Diffusers</A>
									</DL><p>
									<DT><A HREF="https://github.com/Wan-Video/Wan2.2">Wan-Video/Wan2.2</A>
									<DT><A HREF="https://gist.github.com/a-r-r-o-w/451e6ed5de1c635165c308d1098ddf84">Lossless system-level only optimizations benchmark for Wan</A>
									<DT><A HREF="https://www.diffchecker.com/aHgUrbsU/">wan_t2v_21_to_22_modelling_diffs - Diffchecker</A>
								</DL><p>
								<DT><H3 FOLDED>wan2.2-I2V</H3>
								<DL><p>
									<DT><H3 FOLDED>wan2.2-I2V-weights</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B">Wan-AI/Wan2.2-I2V-A14B ¬∑ Hugging Face</A>
										<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers">Wan-AI/Wan2.2-I2V-A14B-Diffusers ¬∑ Hugging Face</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>wan2.1-I2V</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>wan2.1-V2V</H3>
								<DL><p>
									<DT><H3 FOLDED>wan-V2V-noise-video</H3>
									<DL><p>
										<DT><A HREF="https://chatgpt.com/c/681e1ba3-3794-800c-8861-27fd6d443916">WAN Video-to-Video Modification</A>
									</DL><p>
									<DT><A HREF="https://x.com/Kijaidesign/status/1897019853883760777">(1) Jukka Sepp√§nen en X: "WanVideo2video fun, 129 frames with sliding context windows using the 14B model. https://t.co/a1U4pc0Slm" / X</A>
									<DT><A HREF="https://github.com/kijai/ComfyUI-WanVideoWrapper">kijai/ComfyUI-WanVideoWrapper</A>
									<DT><A HREF="https://github.com/aigc-apps/VideoX-Fun/blob/main/examples/wan2.1_fun/predict_v2v_control.py">VideoX-Fun/examples/wan2.1_fun/predict_v2v_control.py at main ¬∑ aigc-apps/VideoX-Fun</A>
									<DT><A HREF="https://github.com/search?q=repo%3Amodelscope%2FDiffSynth-Studio%20video-to-video&type=code">WAN 2.1 video-to-video: input_video</A>
								</DL><p>
								<DT><H3 FOLDED>wan2.1-fp4</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/lightx2v/Wan-NVFP4">lightx2v/Wan-NVFP4 ¬∑ Hugging Face</A>
									<DT><A HREF="https://x.com/OHatTartine">(1) X</A>
								</DL><p>
								<DT><H3 FOLDED>wan-transformer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/transformers/transformer_wan.py">diffusers/src/diffusers/models/transformers/transformer_wan.py at main ¬∑ huggingface/diffusers</A>
									<DT><A HREF="https://github.com/NVlabs/FastGen/blob/main/scripts/inference/video_model_inference.py">FastGen/scripts/inference/video_model_inference.py at main ¬∑ NVlabs/FastGen</A>
									<DT><A HREF="https://github.com/NVlabs/FastGen/blob/main/fastgen/networks/Wan/network.py">FastGen/fastgen/networks/Wan/network.py at main ¬∑ NVlabs/FastGen</A>
								</DL><p>
								<DT><H3 FOLDED>wan-VACE</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2503.07598">VACE: All-in-One Video Creation and Editing</A>
									<DT><A HREF="https://github.com/Wan-Video/Wan2.1/commit/18d53feb7ae946a4661e582a24551090dfd123fd">[feature] Add VACE (#389) ¬∑ Wan-Video/Wan2.1@18d53fe</A>
									<DT><A HREF="https://x.com/Alibaba_Wan/status/1922655324919779604">(1) Wan en X: "‚ú® All in One, Wan for All‚ú® We are excited to introduce our latest model to our talented community creators: Wan2.1-VACE, All-in-One Video Creation and Editing model. Model size: 1.3B, 14B License: Apache-2.0 üìå Wan2.1-VACE provides solutions for various tasks, including https://t.co/yiQRVhXpop" / X</A>
									<DT><A HREF="https://huggingface.co/Wan-AI">Wan-AI (Wan-AI): VACE model weights</A>
								</DL><p>
								<DT><H3 FOLDED>wan-pro</H3>
								<DL><p>
									<DT><H3 FOLDED>wan-prompt-extend</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Wan-Video/Wan2.1/blob/main/wan/utils/prompt_extend.py">Wan2.1/wan/utils/prompt_extend.py at main ¬∑ Wan-Video/Wan2.1</A>
									</DL><p>
									<DT><A HREF="https://github.com/ali-vilab/VACE/blob/0897c6d055d7d9ea9e191dce763006664d9780f8/vace/configs/prompt_preprocess.py#L42">VACE/vace/configs/prompt_preprocess.py</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2503.20314">[2503.20314] Wan: Open and Advanced Large-Scale Video Generative Models</A>
								<DT><A HREF="https://x.com/Alibaba_WanX">(1) WanX (@Alibaba_WanX) / X</A>
								<DT><A HREF="https://tongyi.aliyun.com/wanxiang/">ÈÄö‰πâ‰∏áÁõ∏_AIÂàõÊÑè‰ΩúÁîª_AIÁªòÁîª_‰∫∫Â∑•Êô∫ËÉΩ-ÈòøÈáå‰∫ë</A>
								<DT><A HREF="https://huggingface.co/Wan-AI/Wan2.1-T2V-14B">Wan-AI/Wan2.1-T2V-14B ¬∑ Hugging Face</A>
								<DT><A HREF="https://github.com/Wan-Video/Wan2.1">Wan-Video/Wan2.1: Wan: Open and Advanced Large-Scale Video Generative Models</A>
								<DT><A HREF="https://wanxai.com/">Wan_AI Creative Drawing_AI Painting_Artificial Intelligence_Large Model</A>
								<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio">modelscope/DiffSynth-Studio: Enjoy the magic of Diffusion models!</A>
								<DT><A HREF="https://gist.github.com/a-r-r-o-w/451e6ed5de1c635165c308d1098ddf84">Lossless system-level only optimizations benchmark for Wan</A>
								<DT><A HREF="https://x.com/aryanvs_/status/1957271148896653708">Directly call into optimized cuBLAS with `torch.addmm`, `http://torch.mv`, `torch.addcmul`, `torch._addmm_activation` and similar</A>
								<DT><A HREF="https://gist.github.com/a-r-r-o-w/a4a9d889857d1b36a52fadfdc1aca249">Wan 2.2 5B T2V benchmarks</A>
								<DT><A HREF="https://arxiv.org/abs/2509.14055v1">[2509.14055v1] Wan-Animate: Unified Character Animation and Replacement with Holistic Replication</A>
								<DT><A HREF="https://github.com/gau-nernst/flow-matching/blob/main/modelling/wan/model.py">flow-matching/modelling/wan/model.py WAN model architecture</A>
								<DT><A HREF="https://github.com/NVlabs/FastGen/blob/main/scripts/inference/video_model_inference.py">FastGen/scripts/inference/video_model_inference.py at main ¬∑ NVlabs/FastGen</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-Seaweed-7B</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2504.08685v1">Seaweed-7B: Cost-Effective Training of Video Generation Foundation Model</A>
								<DT><A HREF="https://seaweed.video/">Seaweed</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-waver</H3>
							<DL><p>
								<DT><A HREF="https://github.com/FoundationVision/Waver">FoundationVision/Waver: A video foundation model for unified Text-to-Video (T2V) and Image-to-Video (I2V) generation.</A>
								<DT><A HREF="http://www.waver.video/">Waver</A>
								<DT><A HREF="https://arxiv.org/pdf/2508.15761">WAVER: WAVE YOUR WAY TO LIFELIKE VIDEO GENERATION</A>
								<DT><A HREF="https://arxiv.org/pdf/2410.02416">APG: ELIMINATING OVERSATURATION AND ARTIFACTS OF HIGH GUIDANCE SCALES IN DIFFUSION MODELS</A>
							</DL><p>
							<DT><H3 FOLDED>grok-imagine</H3>
							<DL><p>
								<DT><A HREF="https://x.com/elonmusk/status/1950251710141567110?s=12">‚Äúfastest time to make a fun, shareable video‚Äù, rather than visual/auditory perfection.</A>
								<DT><A HREF="https://x.com/elonmusk/status/1950590957424111902?s=12">Grok Imagine is super fun üòé</A>
							</DL><p>
							<DT><H3 FOLDED>HunyuanVideo</H3>
							<DL><p>
								<DT><H3 FOLDED>HunyuanVideo-distributed</H3>
								<DL><p>
									<DT><H3 FOLDED>xDiT-HunyuanVideo</H3>
									<DL><p>
										<DT><A HREF="https://github.com/xdit-project/xDiT/blob/172905f8894668c8588c2a98ffc415f02d84ea86/docs/performance/hunyuanvideo.md">xDiT/docs/performance/hunyuanvideo.md</A>
										<DT><A HREF="https://github.com/xdit-project/xDiT/commit/1b589b76b6503278de3e18285f0df838d60bee53">add hunyuan_video_usp_example.py (#401) ¬∑ xdit-project/xDiT@1b589b7</A>
									</DL><p>
									<DT><A HREF="https://github.com/Tencent/HunyuanVideo/pull/68/files">Commits ¬∑ Tencent/HunyuanVideo: parallel inference using xdit #68</A>
								</DL><p>
								<DT><H3 FOLDED>HunyuanVideo-fp8</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Tencent/HunyuanVideo/pull/136/files">update fp8 infer by mboboGO ¬∑ Pull Request #136 ¬∑ Tencent/HunyuanVideo</A>
								</DL><p>
								<DT><H3 FOLDED>Hunyuan-diffusers</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/diffusers/issues/10106">Add HunyuanVideo ¬∑ Issue #10106 ¬∑ huggingface/diffusers</A>
									<DT><A HREF="https://huggingface.co/docs/diffusers/main/api/pipelines/hunyuan_video">HunyuanVideo pipeline</A>
								</DL><p>
								<DT><H3 FOLDED>HunyuanCustom</H3>
								<DL><p>
									<DT><A HREF="https://x.com/TencentHunyuan/status/1920679422379913330">(1) Hunyuan en X: "üöÄ Introducing HunyuanCustom: An open-source, multimodal-driven architecture for customized video generation, powered by HunyuanVideo-13B. Outperforming existing open-source models, it rivals top closed-source solutions! üé• Highlights: ‚úÖSubject Consistency: Maintains identity https://t.co/FwpJrHncdL" / X</A>
									<DT><A HREF="https://hunyuancustom.github.io/">HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation</A>
									<DT><A HREF="https://arxiv.org/pdf/2505.04512">HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation</A>
									<DT><A HREF="https://github.com/Tencent/HunyuanCustom">Tencent/HunyuanCustom: HunyuanCustom: A Multimodal-Driven Architecture for Customized Video Generation</A>
								</DL><p>
								<DT><A HREF="https://github.com/Tencent/HunyuanVideo">Tencent/HunyuanVideo</A>
								<DT><A HREF="https://arxiv.org/abs/2412.03603">[2412.03603] HunyuanVideo: A Systematic Framework For Large Video Generative Models</A>
								<DT><A HREF="https://aivideo.hunyuan.tencent.com/">Tencent Hunyuan video</A>
								<DT><A HREF="https://github.com/kijai/ComfyUI-HunyuanVideoWrapper">kijai/ComfyUI-HunyuanVideoWrapper</A>
								<DT><A HREF="https://github.com/Saiyan-World/goku">Saiyan-World/goku: Video Generation Foundation Models: https://saiyan-world.github.io/goku/</A>
							</DL><p>
							<DT><H3 FOLDED>StepFun</H3>
							<DL><p>
								<DT><H3 FOLDED>StepVideo</H3>
								<DL><p>
									<DT><H3 FOLDED>ParaAttention-StepVideo</H3>
									<DL><p>
										<DT><A HREF="https://github.com/WaveSpeedAI/Step-Video-T2V-ParaAttention/pull/1/files">support para_attn by chengzeyi ¬∑ Pull Request #1 ¬∑ WaveSpeedAI/Step-Video-T2V-ParaAttention</A>
									</DL><p>
									<DT><A HREF="https://x.com/bdsqlsz/status/1891348664460714425">tepFun open-sources Step-Video-T2V, SOTA 30B text-to-video model Step-Video-T2V 544px992px204frame Step-Video-T2V-turbo 544px992px136frame 80G VRAM needs</A>
									<DT><A HREF="https://arxiv.org/abs/2502.10248">[2502.10248] Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</A>
									<DT><A HREF="https://arxiv.org/pdf/2502.10248">Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model</A>
									<DT><A HREF="https://www.stepfun.com/">Èò∂Ë∑ÉÊòüËæ∞</A>
									<DT><A HREF="https://github.com/stepfun-ai/Step1X-Edit">stepfun-ai/Step1X-Edit: A SOTA open-source image editing model, which aims to provide comparable performance against the closed-source models like GPT-4o and Gemini 2 Flash.</A>
								</DL><p>
								<DT><A HREF="https://github.com/stepfun-ai/Step-Audio?tab=readme-ov-file">stepfun-ai/Step-Audio</A>
							</DL><p>
							<DT><H3 FOLDED>mochi</H3>
							<DL><p>
								<DT><H3 FOLDED>AsymmDiT-optimization</H3>
								<DL><p>
									<DT><A HREF="https://github.com/cccntu/mochi-1">hide communication overhead with compute pipelining</A>
									<DT><A HREF="https://github.com/xdit-project/mochi-xdit">xdit-project/mochi-xdit: parallel and faster mochi video generation model</A>
								</DL><p>
								<DT><H3 FOLDED>mochi-finetuning</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Yaofang-Liu/Mochi-Full-Finetuner">Yaofang-Liu/Mochi-Full-Finetuner: Code for full fintuing Mochi model with FSDP (and CP)</A>
								</DL><p>
								<DT><A HREF="https://github.com/genmoai/models/blob/main/src/genmo/lib/attn_imports.py">models/src/genmo/lib/attn_imports.py at main ¬∑ genmoai/models</A>
								<DT><A HREF="https://github.com/genmoai/models">genmoai/models: The best OSS video generation models</A>
								<DT><A HREF="https://github.com/kijai/ComfyUI-MochiWrapper">kijai/ComfyUI-MochiWrapper</A>
								<DT><A HREF="https://www.genmo.ai/blog/mochi-1-a-new-sota-in-open-text-to-video">Mochi 1: A new SOTA in open text-to-video | Genmo Blog</A>
							</DL><p>
							<DT><H3 FOLDED>MovieGen</H3>
							<DL><p>
								<DT><A HREF="https://x.com/AIatMeta/status/1842188252541043075">Meta Movie Gen</A>
								<DT><A HREF="https://github.com/kyegomez/movie-gen">kyegomez/movie-gen: An open source community implementation of the model from the paper: "Movie Gen: A Cast of Media Foundation Models". Join our community to help implement this model!</A>
							</DL><p>
							<DT><H3 FOLDED>LongCat-Video</H3>
							<DL><p>
								<DT><A HREF="https://github.com/meituan-longcat/LongCat-Video">meituan-longcat/LongCat-Video</A>
								<DT><A HREF="https://meituan-longcat.github.io/LongCat-Video/">https://meituan-longcat.github.io/LongCat-Video/</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/1982013157926125724">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Meituan continues its revenge on Alibaba. Now, video, ‚âàWan 2.1 level. Once again, it's not just a bog standard me-too training, they're doing serious research there. Good notes on RL, GRPO, block-sparse attention. I'm still surprised at how competent they are. https://t.co/zB5HWKSYvs" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2510.22200">[2510.22200] LongCat-Video Technical Report</A>
								<DT><A HREF="https://arxiv.org/abs/2511.00279">[2511.00279] LongCat-Flash-Omni Technical Report</A>
							</DL><p>
							<DT><H3 FOLDED>sana-video</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVlabs/Sana">NVlabs/Sana: SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer</A>
								<DT><A HREF="https://x.com/xieenze_jr/status/1984479799780532289">(1) Enze Xie en X: "The training/ Inference code and checkpoints are released. Welcome to try! https://t.co/wl9dfP5qIe" / X</A>
								<DT><A HREF="https://nvlabs.github.io/Sana/Video/">SANA Video</A>
							</DL><p>
							<DT><H3 FOLDED>Goku</H3>
							<DL><p>
								<DT><A HREF="https://github.com/Saiyan-World/goku">Saiyan-World/goku: Video Generation Foundation Models: https://saiyan-world.github.io/goku/</A>
								<DT><A HREF="https://saiyan-world.github.io/goku/">Goku</A>
								<DT><A HREF="https://huggingface.co/datasets/saiyan-world/Goku-MovieGenBench">saiyan-world/Goku-MovieGenBench ¬∑ Datasets at Hugging Face</A>
								<DT><A HREF="https://arxiv.org/abs/2502.04896">[2502.04896] Goku: Flow Based Video Generative Foundation Models</A>
								<DT><A HREF="https://github.com/Saiyan-World/goku/commit/e29a217bdb9195fa26b2db6add9f1848472a1bf9">:waxing_crescent_moon: model ¬∑ Saiyan-World/goku@e29a217</A>
							</DL><p>
							<DT><H3 FOLDED>Vchitect</H3>
							<DL><p>
								<DT><A HREF="https://github.com/Vchitect">Vchitect</A>
								<DT><A HREF="https://vchitect.intern-ai.org.cn/">Vchitect 2.0: text-to-video 20-second video generation, flexible aspect ratios, generative space-time enhancent, long video evaluation</A>
								<DT><A HREF="https://github.com/Vchitect/VEnhancer">Vchitect/VEnhancer: Official codes of VEnhancer: Generative Space-Time Enhancement for Video Generation</A>
								<DT><A HREF="https://huggingface.co/Vchitect">Vchitect (Vchitect) Huggingface</A>
								<DT><A HREF="https://github.com/Vchitect/Vchitect-2.0/blob/master/op_replace.py">Vchitect-2.0/op_replace.py at master ¬∑ Vchitect/Vchitect-2.0</A>
							</DL><p>
							<DT><H3 FOLDED>videogen-eval</H3>
							<DL><p>
								<DT><H3 FOLDED>GenEval</H3>
								<DL><p>
									<DT><A HREF="https://github.com/djghosh13/geneval">djghosh13/geneval: GenEval: An object-focused framework for evaluating text-to-image alignment</A>
								</DL><p>
								<DT><A HREF="https://github.com/Vchitect/VBench">Vchitect/VBench: [CVPR2024 Highlight] VBench - We Evaluate Video Generation</A>
							</DL><p>
							<DT><H3 FOLDED>videoSys</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>v2v</H3>
							<DL><p>
								<DT><A HREF="https://github.com/wenhao728/awesome-diffusion-v2v">wenhao728/awesome-diffusion-v2v: Awesome diffusion Video-to-Video (V2V). A collection of paper on diffusion model-based video editing, aka. video-to-video (V2V) translation. And a video editing benchmark code.</A>
								<DT><A HREF="https://github.com/kijai/ComfyUI-WanVideoWrapper">kijai/ComfyUI-WanVideoWrapper</A>
								<DT><A HREF="https://github.com/antferdom/Wan2.1/blob/1336bdc38205179e991f2bfbe65d90e14add3ee5/wan_vace_runner.py#L60">Wan2.1/wan_vace_runner.py WAN VACE V2V</A>
							</DL><p>
							<DT><H3 FOLDED>ar-video-generation</H3>
							<DL><p>
								<DT><H3 FOLDED>CausVid</H3>
								<DL><p>
									<DT><H3 FOLDED>CausalWan-MoE</H3>
									<DL><p>
										<DT><A HREF="https://hao-ai-lab.github.io/blogs/fastvideo_causalwan_preview/">CausalWan-MoE Preview: Applying Self-Forcing Distillation To Wan2.2 | Hao AI Lab @ UCSD</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/6afe3963997014f656e613602693769aece88b27/python/sglang/multimodal_gen/runtime/models/dits/causal_wanvideo.py">sglang/python/sglang/multimodal_gen/runtime/models/dits/causal_wanvideo.py at 6afe3963997014f656e613602693769aece88b27 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><A HREF="https://github.com/tianweiy/CausVid">tianweiy/CausVid: (CVPR 2025) From Slow Bidirectional to Fast Autoregressive Video Diffusion Models</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1979311625560404778">CausVid &amp; Self-Forcing: Distilled Autoregressive Video Generation Model</A>
									<DT><A HREF="https://arxiv.org/pdf/2412.07772v1">From Slow Bidirectional to Fast Causal Video Generators</A>
								</DL><p>
								<DT><H3 FOLDED>Self-Forcing</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2506.08009">Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion</A>
									<DT><A HREF="https://self-forcing.github.io/">Self Forcing</A>
									<DT><A HREF="https://github.com/guandeh17/Self-Forcing">guandeh17/Self-Forcing: Official codebase for "Self Forcing: Bridging Training and Inference in Autoregressive Video Diffusion" (NeurIPS 2025 Spotlight)</A>
								</DL><p>
								<DT><H3 FOLDED>RealVideo</H3>
								<DL><p>
									<DT><A HREF="https://z.ai/blog/realvideo">RealVideo: A Real-Time Streaming Conversational System Powered by Autoregressive Diffusion Video Generation</A>
									<DT><A HREF="https://github.com/zai-org/RealVideo">zai-org/RealVideo: A real-time streaming conversational video system that transforms text interactions into continuous, high-fidelity video responses using autoregressive diffusion.</A>
									<DT><A HREF="https://huggingface.co/blog/waypoint-1">Introducing Waypoint-1: Real-time interactive video diffusion from Overworld</A>
								</DL><p>
								<DT><H3 FOLDED>MAGI-1</H3>
								<DL><p>
									<DT><H3 FOLDED>magiAttention</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2505.13211">[2505.13211] MAGI-1: Autoregressive Video Generation at Scale</A>
									<DT><A HREF="https://github.com/SandAI-org/MAGI-1">SandAI-org/MAGI-1: MAGI-1: Autoregressive Video Generation at Scale</A>
								</DL><p>
								<DT><H3 FOLDED>block-diffusion</H3>
								<DL><p>
									<DT><A HREF="https://github.com/alibaba-damo-academy/Inferix">alibaba-damo-academy/Inferix: Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation</A>
									<DT><A HREF="https://arxiv.org/abs/2511.20714">[2511.20714] Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation</A>
								</DL><p>
								<DT><A HREF="https://github.com/hao-ai-lab/Awesome-Video-Attention?tab=readme-ov-file">hao-ai-lab/Awesome-Video-Attention: A curated list of recent papers on efficient video attention for video diffusion models, including sparsification, quantization, and caching, etc.</A>
								<DT><A HREF="https://huggingface.co/krea/krea-realtime-video">krea/krea-realtime-video: WAN 2.1 real-time distillation</A>
								<DT><A HREF="https://arxiv.org/abs/2512.15702">[2512.15702] End-to-End Training for Autoregressive Video Diffusion via Self-Resampling</A>
								<DT><A HREF="https://arxiv.org/abs/2511.20714">[2511.20714] Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation</A>
							</DL><p>
							<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys">NUS-HPC-AI-Lab/VideoSys: VideoSys: An easy and efficient system for video generation</A>
							<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/Awesome-Efficient-Video-Generation">NUS-HPC-AI-Lab/Awesome-Efficient-Video-Generation</A>
							<DT><A HREF="https://x.com/AIatMeta/status/1842188252541043075">Meta Movie Gen</A>
							<DT><A HREF="https://ai.meta.com/static-resource/movie-gen-research-paper">Movie Gen: A Cast of Media Foundation Models</A>
							<DT><A HREF="https://arxiv.org/abs/2410.19355">[2410.19355] FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality</A>
							<DT><A HREF="https://github.com/Vchitect/FasterCache">Vchitect/FasterCache: FasterCache: Training-Free Video Diffusion Model Acceleration with High Quality</A>
							<DT><A HREF="https://github.com/VectorSpaceLab/OmniGen">VectorSpaceLab/OmniGen: OmniGen: Unified Image Generation. https://arxiv.org/pdf/2409.11340</A>
							<DT><A HREF="https://github.com/pytorch/torchcodec">pytorch/torchcodec: PyTorch video decoding</A>
							<DT><A HREF="https://github.com/Tencent/DepthCrafter">Tencent/DepthCrafter: DepthCrafter: Generating Consistent Long Depth Sequences for Open-world Videos</A>
							<DT><A HREF="https://x.com/papers_anon/status/1858754606601564459">PapersAnon en X: "Everything is a Video: Unifying Modalities through Next-Frame Prediction Reformulate diverse multimodal tasks into a unified next-frame prediction. Evaluated on a range of tasks, including text-to-text, image-to-text, video-to-video, video-to-text, and audio-to-text</A>
							<DT><A HREF="https://arxiv.org/abs/2411.10503">[2411.10503] Everything is a Video: Unifying Modalities through Next-Frame Prediction</A>
							<DT><A HREF="https://sihyun.me/CMD/">Efficient Video Diffusion Models via Content-Frame Motion-Latent Decomposition</A>
							<DT><A HREF="https://github.com/Tencent/HunyuanVideo">Tencent/HunyuanVideo</A>
							<DT><A HREF="https://x.com/nrehiew_/status/1864677276731777136">(1) wh en X: "1 of the top papers from ICLR 2024 (honourable mention) tldr: introduce a new self-supervised learning method for vision. Training on a single video matches models trained on imagenet https://t.co/kF84CoBPy2" / X</A>
							<DT><A HREF="https://openreview.net/pdf?id=Yen1lGns2o">IS IMAGENET WORTH 1 VIDEO? LEARNING STRONG IMAGE ENCODERS FROM 1 LONG UNLABELLED VIDEO</A>
							<DT><A HREF="https://research.google/blog/extending-video-masked-autoencoders-to-128-frames/">Extending video masked autoencoders to 128 frames</A>
							<DT><A HREF="https://arxiv.org/abs/2410.20280">[2410.20280] MarDini: Masked Autoregressive Diffusion for Video Generation at Scale</A>
							<DT><A HREF="https://lilianweng.github.io/posts/2024-04-12-diffusion-video/">Diffusion Models for Video Generation | Lil'Log</A>
							<DT><A HREF="https://storydiffusion.github.io/">StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</A>
							<DT><A HREF="https://www.moonvalley.com/#features">moonvalley - the imagination research company</A>
							<DT><A HREF="https://x.com/karpathy/status/1945979830740435186">diffusion video models but now realtime</A>
							<DT><A HREF="https://github.com/SHI-Labs/T2I-Copilot">SHI-Labs/T2I-Copilot: T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation (ICCV'25)</A>
							<DT><A HREF="https://www.youtube.com/watch?v=spn_eTODPg8">DeepMind‚Äôs AI Just Solved Video Generation In A Way Nobody Expected - YouTube</A>
							<DT><A HREF="https://huggingface.co/ByteDance/BindWeave">ByteDance/BindWeave ¬∑ Hugging Face</A>
							<DT><A HREF="https://github.com/hao-ai-lab/Awesome-Video-Attention">hao-ai-lab/Awesome-Video-Attention: A curated list of recent papers on efficient video attention for video diffusion models, including sparsification, quantization, and caching, etc.</A>
						</DL><p>
						<DT><H3 FOLDED>video-upscale</H3>
						<DL><p>
							<DT><H3 FOLDED>FlashVSR</H3>
							<DL><p>
								<DT><A HREF="https://github.com/OpenImagingLab/FlashVSR">OpenImagingLab/FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution ‚Äî An efficient one-step diffusion framework for streaming VSR with locality-constrained sparse attention and a tiny conditional decoder.</A>
								<DT><A HREF="https://huggingface.co/JunhaoZhuang/FlashVSR-v1.1">JunhaoZhuang/FlashVSR-v1.1 ¬∑ Hugging Face</A>
							</DL><p>
							<DT><H3 FOLDED>SeedVR</H3>
							<DL><p>
								<DT><H3 FOLDED>seedvr-weights</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/collections/ByteDance-Seed/seedvr-6849deeb461c4e425f3e6f9e">SeedVR - a ByteDance-Seed Collection</A>
									<DT><A HREF="https://huggingface.co/spaces/ByteDance-Seed/SeedVR2-3B">SeedVR2-3B - a Hugging Face Space by ByteDance-Seed</A>
								</DL><p>
								<DT><A HREF="https://iceclear.github.io/projects/seedvr/">SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration</A>
								<DT><A HREF="https://arxiv.org/abs/2501.01320">[2501.01320] SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration</A>
								<DT><A HREF="https://www.youtube.com/watch?v=aPpBs_B2iCY">SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration - YouTube</A>
								<DT><A HREF="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler">numz/ComfyUI-SeedVR2_VideoUpscaler: Official SeedVR2 Video Upscaler for ComfyUI</A>
							</DL><p>
							<DT><H3 FOLDED>SeedVR2</H3>
							<DL><p>
								<DT><H3 FOLDED>seedvr-weights</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/collections/ByteDance-Seed/seedvr-6849deeb461c4e425f3e6f9e">SeedVR - a ByteDance-Seed Collection</A>
								</DL><p>
								<DT><A HREF="https://iceclear.github.io/projects/seedvr2/">SeedVR2</A>
								<DT><A HREF="https://arxiv.org/abs/2506.05301">[2506.05301] SeedVR2: One-Step Video Restoration via Diffusion Adversarial Post-Training</A>
								<DT><A HREF="https://github.com/ByteDance-Seed/SeedVR">ByteDance-Seed/SeedVR: Repo for SeedVR2 &amp; SeedVR (CVPR2025 Highlight)</A>
								<DT><A HREF="https://arxiv.org/abs/2501.01320">[2501.01320] SeedVR: Seeding Infinity in Diffusion Transformer Towards Generic Video Restoration</A>
								<DT><A HREF="https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler">numz/ComfyUI-SeedVR2_VideoUpscaler: Official SeedVR2 Video Upscaler for ComfyUI</A>
								<DT><A HREF="https://github.com/eddyhhlure1Eddy/seedVR2_cudafull">eddyhhlure1Eddy/seedVR2_cudafull</A>
							</DL><p>
							<DT><A HREF="https://github.com/freepik-company/mystic-upscaler-shared">freepik-company/mystic-upscaler-shared</A>
							<DT><A HREF="https://github.com/Eyeline-Labs/CineScale">Eyeline-Labs/CineScale: Code for CineScale, higher-resolution video generation based on Wan</A>
							<DT><A HREF="https://github.com/dc-ai-projects/DC-Gen">dc-ai-projects/DC-Gen: DC-Gen: Post-Training Diffusion Acceleration with Deeply Compressed Latent Space</A>
							<DT><A HREF="https://github.com/wimmerth/anyup">wimmerth/anyup: Repository of the paper "AnyUp: Universal Feature Upsampling".</A>
						</DL><p>
						<DT><H3 FOLDED>Latent Consistency Models</H3>
						<DL><p>
							<DT><H3 FOLDED>Mean Flows</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2505.13447">Mean Flows for One-step Generative Modeling</A>
							</DL><p>
							<DT><A HREF="https://gsunshine.notion.site/Consistency-Models-Made-Easy-954205c0b4a24c009f78719f43b419cc?pvs=4">üí´ Consistency Models Made Easy</A>
							<DT><A HREF="https://twitter.com/ZhengyangGeng/status/1773069621211415003">Zhengyang Geng: fast Consistency Models inference</A>
							<DT><A HREF="https://twitter.com/DrYangSong">(1) Yang Song (@DrYangSong) / X</A>
							<DT><A HREF="https://sander.ai/2024/02/28/paradox.html">The paradox of diffusion distillation ‚Äì Sander Dieleman</A>
							<DT><A HREF="https://github.com/locuslab/ect">locuslab/ect: Consistency Models Made Easy</A>
							<DT><A HREF="https://arxiv.org/pdf/2410.11081">simplifying, stabilizing and scaling continous tiem consistency models</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gHYy0zalMSA">MAJOR inference efficiency gain for diffusion models - YouTube</A>
							<DT><A HREF="https://huggingface.co/OPPOer/TLCMFlux">OPPOer/TLCMFlux ¬∑ Hugging Face</A>
							<DT><A HREF="https://github.com/luosiallen/latent-consistency-model?tab=readme-ov-file">luosiallen/latent-consistency-model: Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference</A>
							<DT><A HREF="https://arxiv.org/abs/2410.11081">[2410.11081] Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models</A>
						</DL><p>
						<DT><H3 FOLDED>image-eval</H3>
						<DL><p>
							<DT><H3 FOLDED>image-eval-metrics</H3>
							<DL><p>
								<DT><H3 FOLDED>GRADE</H3>
								<DL><p>
									<DT><A HREF="https://x.com/RoyiRassin/status/1854576025679577098">(1) Royi Rassin @ EMNLP 2024 en X: "How diverse are the outputs of text-to-image models and how can we measure that? In our new work, we propose a measure based on LLMs and Visual-QA (VQA), and show NONE of the 12 models we experiment with are diverse. üßµ 1/11 https://t.co/PyWkodbrVZ" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2410.22592">[2410.22592] GRADE: Quantifying Sample Diversity in Text-to-Image Models</A>
								</DL><p>
								<DT><H3 FOLDED>FID</H3>
								<DL><p>
									<DT><A HREF="https://github.com/GaParmar/clean-fid">GaParmar/clean-fid: PyTorch - FID calculation with proper image resizing and quantization steps [CVPR 2022]</A>
									<DT><A HREF="https://github.com/xdit-project/xDiT/commit/be43f787ec0ac6b764ff08913539b4decafcfa1a#diff-ba47e7474645cbefcfdb7cb5f554d376a0610c28e2d112620ae50e00d3e4e207R4">FID metrics evalutions for Pixart and Flux.1 (#327) ¬∑ xdit-project/xDiT@be43f78</A>
								</DL><p>
								<DT><H3 FOLDED>DreamSim</H3>
								<DL><p>
									<DT><A HREF="https://github.com/carpedm20/dreamsim">DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data</A>
									<DT><A HREF="https://github.com/ssundaram21/dreamsim">ssundaram21/dreamsim: DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data (NeurIPS 2023 Spotlight) / / / / When Does Perceptual Alignment Benefit Vision Representations? (NeurIPS 2024)</A>
									<DT><A HREF="https://github.com/replicate/img-quality-eval">replicate/img-quality-eval: Automatic quality evaluation web app for generative text-to-image models</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>image-eval-datasets</H3>
							<DL><p>
								<DT><H3 FOLDED>parti-prompts</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/datasets/nateraw/parti-prompts">nateraw/parti-prompts ¬∑ Datasets at Hugging Face</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>img-quality-eval</H3>
							<DL><p>
								<DT><A HREF="https://github.com/replicate/img-quality-eval">replicate/img-quality-eval: Automatic quality evaluation web app for generative text-to-image models</A>
								<DT><A HREF="https://gemini.google.com/u/3/app/7ed967c8f1773501">Refactoring for Simpler Output Comparison (No Scores) miminal impl</A>
								<DT><A HREF="https://repo2txt.simplebasedomain.com/">GitHub to Plain Text Converter: img-quality-eval</A>
							</DL><p>
							<DT><H3 FOLDED>image-eval-arena</H3>
							<DL><p>
								<DT><A HREF="https://imgsys.org/">imgsys.org | an image model arena by fal.ai</A>
								<DT><A HREF="https://github.com/fal-ai/imgsys-public">fal-ai/imgsys-public: imgsys backend</A>
							</DL><p>
							<DT><A HREF="https://github.com/carpedm20/dreamsim">DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data</A>
							<DT><A HREF="https://gist.github.com/cloneofsimo/525bcbf30b6f0185a30181e6ef46d562">vibecheckgen.py</A>
							<DT><A HREF="https://github.com/thu-nics/FlashEval">thu-nics/FlashEval</A>
							<DT><A HREF="https://github.com/rosinality/stylegan2-pytorch/blob/master/inception.py">stylegan2-pytorch/inception.py at master ¬∑ rosinality/stylegan2-pytorch</A>
							<DT><A HREF="https://blbadger.github.io/feature-visualization.html">Feature Visualization I: Feature Maps | Form and Formula</A>
							<DT><A HREF="https://github.com/blbadger/nnetworks">blbadger/nnetworks: Deep learning model implementations and interpretations.</A>
							<DT><A HREF="https://github.com/THUDM/ImageReward">THUDM/ImageReward: [NeurIPS 2023] ImageReward: Learning and Evaluating Human Preferences for Text-to-image Generation</A>
							<DT><A HREF="https://github.com/discus0434/aesthetic-predictor-v2-5">discus0434/aesthetic-predictor-v2-5: SigLIP-based Aesthetic Score Predictor</A>
							<DT><A HREF="https://huggingface.co/blog/burtenshaw/image-preferences">Let‚Äôs make a generation of amazing image generation models</A>
							<DT><A HREF="https://arxiv.org/abs/2306.04675">[2306.04675] Exposing flaws of generative model evaluation metrics and their unfair treatment of diffusion models</A>
							<DT><A HREF="https://github.com/djghosh13/geneval">djghosh13/geneval: GenEval: An object-focused framework for evaluating text-to-image alignment</A>
							<DT><A HREF="https://arxiv.org/abs/2310.11513">[2310.11513] GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment</A>
							<DT><A HREF="https://img-quality-eval.onrender.com/">Image quality evaluation - generate and evaluate</A>
							<DT><A HREF="https://cdn.openai.com/papers/dall-e-3.pdf">https://cdn.openai.com/papers/dall-e-3.pdf</A>
						</DL><p>
						<DT><H3 FOLDED>cloneofsimo</H3>
						<DL><p>
							<DT><H3 FOLDED>minRF</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cloneofsimo/minRF">cloneofsimo/minRF: Minimal implementation of scalable rectified flow transformers, based on SD3's approach</A>
								<DT><A HREF="https://arxiv.org/abs/2406.07480">[2406.07480] Image Neural Field Diffusion Models</A>
								<DT><A HREF="https://cdn.openai.com/papers/dall-e-3.pdf">https://cdn.openai.com/papers/dall-e-3.pdf</A>
								<DT><A HREF="https://arxiv.org/abs/2310.20550">[2310.20550] CapsFusion: Rethinking Image-Text Data at Scale</A>
								<DT><A HREF="https://google.github.io/imageinwords/">ImageInWords</A>
								<DT><A HREF="https://huggingface.co/datasets/graph-based-captions/GBC10M">graph-based-captions/GBC10M ¬∑ Datasets at Hugging Face</A>
								<DT><A HREF="https://arxiv.org/abs/1812.06162">[1812.06162] An Empirical Model of Large-Batch Training</A>
								<DT><A HREF="https://x.com/_xjdr/status/1801063628298412239">(2) xjdr en X: "Megablox, splash attention, pallas and automatically sharded named axis come free and built in with Jax and y'all are still using pytorch in production?!?!" / X</A>
								<DT><A HREF="https://github.com/google/jax/blob/main/jax/experimental/pallas/ops/tpu/splash_attention/splash_attention_kernel.py">jax/jax/experimental/pallas/ops/tpu/splash_attention/splash_attention_kernel.py at main ¬∑ google/jax</A>
							</DL><p>
							<DT><A HREF="https://x.com/cloneofsimo/status/1803802198348103781">(1) Simo Ryu en X: "Lavenderflow-pretrained-256x256-6.8B Hybrid MMDiT just reached 0.597 on GenEval! ü•≥ It took me and @isidentical less than 7 weeks of part-time effort + 4k h100 hours to get to SDXL-level (and this is just pretrained model) Does two of us worth 1B valuation? https://t.co/mD3cSpOyvM" / X</A>
							<DT><A HREF="https://github.com/cloneofsimo/efae">cloneofsimo/efae</A>
							<DT><A HREF="https://gligen.github.io/">GLIGEN:Open-Set Grounded Text-to-Image Generation.</A>
							<DT><A HREF="https://arxiv.org/html/2311.12342v2">LoCo: Locally Constrained Training-Free Layout-to-Image Synthesis</A>
							<DT><A HREF="https://github.com/lllyasviel/Omost">lllyasviel/Omost: Your image is almost there!</A>
							<DT><A HREF="https://cloneofsimo.notion.site/What-to-do-to-scale-up-09e469d7c3444d6a90305397c38a46f5">What to do to scale up?</A>
							<DT><A HREF="https://github.com/cloneofsimo/minSDXL/blob/master/sdxl_rewrite.py">minSDXL/sdxl_rewrite.py at master ¬∑ cloneofsimo/minSDXL</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-data</H3>
						<DL><p>
							<DT><H3 FOLDED>diffusion-data-loader</H3>
							<DL><p>
								<DT><H3 FOLDED>mds</H3>
								<DL><p>
									<DT><H3 FOLDED>mds-examples</H3>
									<DL><p>
										<DT><H3 FOLDED>mds-LAION-400M</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/diffusion-benchmark/blob/main/data.py">diffusion-benchmark/data.py at main ¬∑ mosaicml/diffusion-benchmark</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/tree/main/streaming/multimodal/convert/laion/laion400m">streaming/streaming/multimodal/convert/laion/laion400m at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-WebVid</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/multimodal/webvid.py">streaming/streaming/multimodal/webvid.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-C4</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/text/c4.py">streaming/streaming/text/c4.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/text/convert/c4.py">streaming/streaming/text/convert/c4.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-EnWiki</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/text/enwiki.py">streaming/streaming/text/enwiki.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/tree/main/streaming/text/convert/enwiki">streaming/streaming/text/convert/enwiki at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/text/pile.py">streaming/streaming/text/pile.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-Pile</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/text/pile.py">streaming/streaming/text/pile.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/text/convert/pile.py">streaming/streaming/text/convert/pile.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-ADE20K</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/ade20k.py">streaming/streaming/vision/ade20k.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/ade20k.py">streaming/streaming/vision/convert/ade20k.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-CIFAR10</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/cifar10.py">streaming/streaming/vision/cifar10.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/cifar10.py">streaming/streaming/vision/convert/cifar10.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-COCO</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/coco.py">streaming/streaming/vision/coco.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/coco.py">streaming/streaming/vision/convert/coco.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><H3 FOLDED>mds-ImageNet</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/imagenet.py">streaming/streaming/vision/imagenet.py at main ¬∑ mosaicml/streaming</A>
											<DT><A HREF="https://github.com/mosaicml/streaming/blob/main/streaming/vision/convert/imagenet.py">streaming/streaming/vision/convert/imagenet.py at main ¬∑ mosaicml/streaming</A>
										</DL><p>
										<DT><A HREF="https://github.com/cloneofsimo/imgdataset_process/tree/main">cloneofsimo/imgdataset_process</A>
										<DT><A HREF="https://gist.github.com/cloneofsimo/87cfa71a7c4e2a5f9748cb8812eb0536">siglip_mds.py</A>
										<DT><A HREF="https://gist.github.com/cloneofsimo/e41d5718905a5023df7bab494cede051">vae_preprocess</A>
										<DT><A HREF="https://gist.github.com/cloneofsimo/5830ed223b94d55f1609270d129c623b">hr.py</A>
									</DL><p>
									<DT><A HREF="https://gist.github.com/cloneofsimo/d31eee8a5352655cb45869694adf0880">MDS-Multiprocessed-datamerging to NFS, because writing is async this is faster</A>
									<DT><A HREF="https://github.com/allenai/cached_path">allenai/cached_path: A file utility for accessing both local and remote files through a unified interface.</A>
									<DT><A HREF="https://github.com/mosaicml/streaming">mosaicml/streaming: A Data Streaming Library for Efficient Neural Network Training</A>
									<DT><A HREF="https://github.com/geohot/minikeyvalue">geohot/minikeyvalue: A distributed key value store in under 1000 lines. Used in production at comma.ai</A>
									<DT><A HREF="https://github.com/search?q=repo%3Acoreweave%2Ftensorizer+mmap&type=code">mmap: coreweave tensorizer</A>
								</DL><p>
								<DT><H3 FOLDED>WebDataset</H3>
								<DL><p>
									<DT><A HREF="https://webdataset.github.io/webdataset/">webdataset</A>
									<DT><A HREF="https://gist.github.com/cloneofsimo/e41d5718905a5023df7bab494cede051">vae_preprocess</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=Ayt0PTaoovI">AWS re:Invent 2021 - Large-scale distributed training of media ML models with Amazon FSx - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>lance</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/cloneofsimo/cefe61fb4b437ce366e4f25f37fbb7b8">lance dataset concurrent writes?</A>
							</DL><p>
							<DT><A HREF="https://gist.github.com/cloneofsimo/6d1d8e98ce25fb88cd95565cef18ddf4">Got confused by Unfold operation, yet again LOL</A>
						</DL><p>
						<DT><H3 FOLDED>media-generation</H3>
						<DL><p>
							<DT><H3 FOLDED>media-generation-advertising</H3>
							<DL><p>
								<DT><A HREF="https://ltx.studio/solutions/advertising-agencies">Advertising Agencies | LTX Studio</A>
								<DT><A HREF="https://x.com/karpathy/status/1929634696474120576">4. For the first time, video is directly optimizable.</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>VAE</H3>
						<DL><p>
							<DT><H3 FOLDED>RAE</H3>
							<DL><p>
								<DT><H3 FOLDED>scale-RAE</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ZitengWangNYU/Scale-RAE">ZitengWangNYU/Scale-RAE: Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders</A>
									<DT><A HREF="https://rae-dit.github.io/scale-rae/">Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders</A>
									<DT><A HREF="https://x.com/TongPetersb/status/2014818640072475128">(1) Peter Tong en X: "Last October, we introduced Representation Autoencoders (RAE), showing that training diffusion on frozen semantic representations works and outperforms VAEs on ImageNet. We received many questions: Can this scale to complex settings like T2I? Do the advantages hold? The answer is https://t.co/OsWxEPcKGW" / X</A>
									<DT><A HREF="https://cambrian-mllm.github.io/blog/tpu-training-experiments.html">TPU Training Experiments | Cambrian</A>
								</DL><p>
								<DT><A HREF="https://x.com/sainingxie/status/1977936710135669130">(1) Saining Xie en X: "three years ago, DiT replaced the legacy unet with a transformer-based denoising backbone. we knew the bulky VAEs would be the next to go -- we just waited until we could do it right. today, we introduce Representation Autoencoders (RAE). &amp;gt;&amp;gt; Retire VAEs. Use RAEs. üëá(1/n) https://t.co/NrQcW37hYL" / X</A>
								<DT><A HREF="https://x.com/sedielem/status/2015056859963564324">As I said in my blog post about latent representations last year: "representation learning and reconstruction are two separate tasks, and while it is convenient to do both at once, this might not be optimal." More evidence that treating them as separate tasks is worthwhile!</A>
								<DT><A HREF="https://x.com/genai_is_real/status/2014930743978557617">(1) Chayenne Zhao en X: "peter is right on the money here. rae isn‚Äôt just an imagenet toy anymore‚Äîscaling it to real t2i proves that high-dimensional semantic latents are the superior way to train diffusion. the tpu optimization blog is a goldmine for anyone fighting with xla in academia. people keep" / X</A>
								<DT><A HREF="https://x.com/TongPetersb/status/2014818640072475128">(1) Peter Tong en X: "Last October, we introduced Representation Autoencoders (RAE), showing that training diffusion on frozen semantic representations works and outperforms VAEs on ImageNet. We received many questions: Can this scale to complex settings like T2I? Do the advantages hold? The answer is https://t.co/OsWxEPcKGW" / X</A>
							</DL><p>
							<DT><H3 FOLDED>representation-reconstruction-learning</H3>
							<DL><p>
								<DT><A HREF="https://x.com/sedielem/status/2015056859963564324">As I said in my blog post about latent representations last year: "representation learning and reconstruction are two separate tasks, and while it is convenient to do both at once, this might not be optimal." More evidence that treating them as separate tasks is worthwhile!</A>
							</DL><p>
							<DT><A HREF="https://github.com/PipeFusion/PatchVAE">PipeFusion/PatchVAE: A patch parallelism VAE implement for high resolution generation</A>
							<DT><A HREF="https://github.com/xdit-project/DistVAE">xdit-project/DistVAE: A parallelism VAE avoids OOM for high resolution image generation</A>
							<DT><A HREF="https://www.youtube.com/watch?v=0V96wE7lY4w">Denoising Autoencoders | Deep Learning Animated - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=qJeaCHQ1k2w&t=397s">Variational Autoencoders | Generative AI Animated - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=hZ4a4NgM3u0">Autoencoders | Deep Learning Animated - YouTube</A>
							<DT><A HREF="https://x.com/mtschannen/status/1863622784376586499">(1) Michael Tschannen en X: "Have you ever wondered how to train an autoregressive generative transformer on text and raw pixels, without a pretrained visual tokenizer (e.g. VQ-VAE)? We have been pondering this during summer and developed a new model: JetFormer üåäü§ñ https://t.co/ngvPzZvUYW A thread üëá 1/ https://t.co/04R4a1nbMu" / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=fnULFOyNZn8">Variational Autoencoders For Image Generation - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Rectified Flow</H3>
						<DL><p>
							<DT><A HREF="https://www.cs.utexas.edu/~lqiang/rectflow/html/intro.html">Rectified Flow ‚Äî Rectified Flow</A>
							<DT><A HREF="https://github.com/cloneofsimo/rectified-flow">cloneofsimo/rectified-flow</A>
							<DT><A HREF="https://github.com/TongTong313/rectified-flow">TongTong313/rectified-flow: ‰ªéÈõ∂ÊâãÊêìFlow MatchingÔºàRectified FlowÔºâ</A>
							<DT><A HREF="https://www.youtube.com/watch?v=fSawkqR51tc">George Hotz | Programming | cozy diffusion stream (rectified flow) | tinycorp.myshopify.com - YouTube</A>
							<DT><A HREF="https://alechelbling.com/blog/rectified-flow/">Visualizing Rectified Flows</A>
						</DL><p>
						<DT><H3 FOLDED>Flow matching</H3>
						<DL><p>
							<DT><H3 FOLDED>Conditional Flow Matching</H3>
							<DL><p>
								<DT><A HREF="https://dl.heeere.com/conditional-flow-matching/blog/conditional-flow-matching/">A Visual Dive into Conditional Flow Matching | ICLR Blogposts 2025</A>
								<DT><A HREF="https://drive.google.com/file/d/1-QKAT8IPbqOpCq42DUeEqrgIP7f7f4TH/view">fm_tutotial_combined.pdf - Google Drive</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=5ZSwYogAxYg">Flow Matching: Simplifying and Generalizing Diffusion Models | Yaron Lipman - YouTube</A>
							<DT><A HREF="https://x.com/i/bookmarks?post_id=1803004045084197186">code snipet: conditional_flow_matching_loss</A>
							<DT><A HREF="https://bm371613.github.io/conditional-flow-matching/">conditional-flow-matching</A>
							<DT><A HREF="https://arxiv.org/abs/2210.02747">[2210.02747] Flow Matching for Generative Modeling</A>
							<DT><A HREF="https://www.youtube.com/watch?v=DDq_pIfHqLs">How I Understand Flow Matching - YouTube</A>
							<DT><A HREF="https://drscotthawley.github.io/blog/posts/FlowModels.html">blog - Flow With What You Know</A>
							<DT><A HREF="https://x.com/RickyTQChen/status/1866470185307459722">Flow Matching Guide and Code (Meta, Yaron, Ricky)</A>
							<DT><A HREF="https://github.com/facebookresearch/flow_matching">facebookresearch/flow_matching: A PyTorch library for implementing flow matching algorithms, featuring continuous and discrete flow matching implementations. It includes practical examples for both text and image modalities.</A>
							<DT><A HREF="https://x.com/cgarciae88/status/1867340873136038293">Flow Matching Facebook Research's Standalone Flow Matching notebook 50 lines of JAX</A>
							<DT><A HREF="https://x.com/dome_271/status/1878082477064880565">(1) dome | Outlier en X: "Tomorrow! :D https://t.co/zAG2931FSH" / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=7cMzfkWFWhI&t=344s">Flow Matching | Explanation + PyTorch Implementation - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=GCoP2w-Cqtg">MIT 6.S184: Flow Matching and Diffusion Models - Lecture 01 - Generative AI with SDEs - YouTube</A>
							<DT><A HREF="https://x.com/attentionmech/status/1925401918802993228">Discrete Flow Matching paper reading</A>
							<DT><A HREF="https://nrehiew.github.io/blog/flow_matching/">Flow Matching in 5 Minutes | wh</A>
							<DT><A HREF="https://decentralizeddiffusion.github.io/">Decentralized Diffusion</A>
							<DT><A HREF="https://zhuanlan.zhihu.com/p/1917570380329120727">Flow matching and score matching: from the perspective of differential equations</A>
							<DT><A HREF="https://arxiv.org/abs/2511.22475">[2511.22475] Adversarial Flow Models</A>
							<DT><A HREF="https://x.com/sedielem/status/2012590036689056156">(1) Sander Dieleman en X: "Great interactive blog post on reflow, which reduces the number of steps required to sample from diffusion models by "straightening" paths from noise to data. My favourite part is the intuitive explanation for why standard diffusion / flow matching ends up learning curved" / X</A>
							<DT><A HREF="https://alechelbling.com/blog/rectified-flow/">Visualizing Rectified Flows</A>
						</DL><p>
						<DT><H3 FOLDED>guidances-schedules</H3>
						<DL><p>
							<DT><A HREF="https://x.com/_clashluke/status/1815672877259051392">(1) Lucas Nestler en X: "Seems like @nico_dufour tested guidances schedules very rigorously at https://t.co/l1TehowhgL. If you're interested in different schedules and want to better understand their induced differences, or if you would like to see thorough evaluations with actionable advice, read the https://t.co/FpHIu7XZ2d" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2404.13040">[2404.13040] Analysis of Classifier-Free Guidance Weight Schedulers</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-people</H3>
						<DL><p>
							<DT><A HREF="https://www.linkedin.com/in/sanderdieleman/">Sander Dieleman | LinkedIn</A>
							<DT><A HREF="https://x.com/Ethan_smith_20/status/1767570870598279181">Ethan Smith</A>
							<DT><A HREF="https://x.com/cloneofsimo">(1) Simo Ryu (@cloneofsimo) / X</A>
							<DT><A HREF="https://x.com/allnoteson">(1) Andreas Jansson (@allnoteson) / X</A>
							<DT><A HREF="https://www.linkedin.com/in/carpedm20/">Taehoon Kim | LinkedIn</A>
							<DT><A HREF="https://github.com/cszy98">cszy98 (Lyu Zhengyao)</A>
						</DL><p>
						<DT><H3 FOLDED>cfg</H3>
						<DL><p>
							<DT><A HREF="https://x.com/haotian_yeee/status/1859672842658512908">(1) Haotian Ye en X: "üí° From prediction to generation: Training-Free Guidance for Diffusion (NeurIPS Spotlight) How do we use any off-the-shelf predictor and unconditional diffusion sampler for conditional generation without any training? Our framework, TFG, boosts performance works across 7 models, https://t.co/6i5qIq2ecJ" / X</A>
							<DT><A HREF="https://x.com/sedielem/status/2002007451105910873">(1) Sander Dieleman en X: "@max_simchowitz Overgeneralisation is probably the main reason why we're still so reliant on it. I think we are also intentionally collapsing the distribution towards its more canonical examples (guidance is just one way to do that, various forms of post-training are also used for this). The https://t.co/6kF5765M9j" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2406.02507">[2406.02507] Guiding a Diffusion Model with a Bad Version of Itself</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-test-time-compute</H3>
						<DL><p>
							<DT><H3 FOLDED>video-test-time-compute</H3>
							<DL><p>
								<DT><A HREF="https://agwmon.github.io/self-refine-video/">Self-Refining Video Sampling</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/html/2501.09732v1">Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps</A>
							<DT><A HREF="https://github.com/sayakpaul/tt-scale-flux">sayakpaul/tt-scale-flux: Inference-time scaling of Flux beyond denoising steps.</A>
							<DT><A HREF="https://arxiv.org/pdf/2501.09732">Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps</A>
							<DT><A HREF="https://x.com/ma_nanye/status/1880105038132990054">Willis (Nanye) Ma: X thread -&gt; Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps</A>
							<DT><A HREF="https://x.com/li78658171/status/1939887158833422441">Reflect-DiT</A>
							<DT><A HREF="https://github.com/jacklishufan/Reflect-DiT">jacklishufan/Reflect-DiT: Reflect-DiT: Inference-Time Scaling for Text-to-Image Diffusion Transformers via In-Context Reflection</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-high-resolution</H3>
						<DL><p>
							<DT><H3 FOLDED>RectifiedHR</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=VcykV0Cdo7U">High Resolution Image Generation via Energy Rectification - YouTube</A>
								<DT><A HREF="https://colab.research.google.com/drive/1Ls6xfJOHbWkTW1ftynuesKw5CV0h0zGM?usp=sharing#scrollTo=9AS0L283btwY">RectifiedHR Diffusion - Colab</A>
								<DT><A HREF="https://arxiv.org/abs/2503.02537">[2503.02537] RectifiedHR: Enable Efficient High-Resolution Image Generation via Energy Rectification</A>
								<DT><A HREF="https://zhenyangcs.github.io/RectifiedHR-Diffusion/">RectifiedHR: Enable Efficient High Resolution Image Generation via Energy Rectification</A>
								<DT><A HREF="https://github.com/EnVision-Research/RectifiedHR">EnVision-Research/RectifiedHR: Official PyTorch/Diffusers implementation of "RectifiedHR: Enable Efficient High Resolution Image Generation via Energy Rectification"</A>
							</DL><p>
							<DT><H3 FOLDED>FluxSR</H3>
							<DL><p>
								<DT><A HREF="https://github.com/JianzeLi-114/FluxSR">JianzeLi-114/FluxSR</A>
							</DL><p>
							<DT><H3 FOLDED>Spandrel</H3>
							<DL><p>
								<DT><A HREF="https://github.com/chaiNNer-org/spandrel">chaiNNer-org/spandrel: Spandrel gives your project support for various PyTorch architectures meant for AI Super-Resolution, restoration, and inpainting. Based on the model support implemented in chaiNNer.</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>virtual-avatar</H3>
						<DL><p>
							<DT><H3 FOLDED>seamless-interaction</H3>
							<DL><p>
								<DT><A HREF="https://ai.meta.com/research/seamless-interaction/?tab=Controllability%0A">Seamless Interaction</A>
								<DT><A HREF="https://www.aidemos.meta.com/seamless_interaction_dataset">Meta FAIR AI Demos</A>
								<DT><A HREF="https://ai.meta.com/research/publications/seamless-interaction-dyadic-audiovisual-motion-modeling-and-large-scale-dataset/">Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset | Research - AI at Meta</A>
								<DT><A HREF="https://github.com/facebookresearch/seamless_interaction">facebookresearch/seamless_interaction: Foundation Models and Data for Human-Human and Human-AI interactions.</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>music-generation</H3>
						<DL><p>
							<DT><H3 FOLDED>seed-music</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2409.09214">[2409.09214] Seed-Music: A Unified Framework for High Quality and Controlled Music Generation</A>
								<DT><A HREF="https://seed.bytedance.com/en/special/seed-music">Hi, Seed music - Doubao Team</A>
							</DL><p>
							<DT><A HREF="https://ace-step.github.io/">ACE-Step: A Step Towards Music Generation Foundation Model</A>
						</DL><p>
						<DT><H3 FOLDED>diffusion-jit</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2511.13720">[2511.13720] Back to Basics: Let Denoising Generative Models Denoise</A>
							<DT><A HREF="https://kexue.fm/archives/11428">My undestanding of JiT (Jianlin)</A>
						</DL><p>
						<DT><A HREF="https://iclr-blogposts.github.io/2024/blog/diffusion-theory-from-scratch/">Building Diffusion Model's theory from ground up | ICLR Blogposts 2024</A>
						<DT><A HREF="https://kexue.fm/archives/9164">A talk on generative diffusion model (Part 3): DDPM = Bayesian + denoising</A>
						<DT><A HREF="https://kexue.fm/archives/10047">A brief talk on generative diffusion model (Part 22): Signal-to-noise ratio</A>
						<DT><A HREF="https://github.com/tmabraham/diffusion_reading_group">tmabraham/diffusion_reading_group: Diffusion Reading Group at EleutherAI</A>
						<DT><A HREF="https://astralord.github.io/posts/power-of-diffusion-models/">Power of Diffusion Models | AstraBlog</A>
						<DT><A HREF="https://sander.ai/2024/09/02/spectral-autoregression.html">Diffusion is spectral autoregression ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2024/06/14/noise-schedules.html">Noise schedules considered harmful ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2023/01/09/diffusion-language.html">Diffusion language models ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2023/08/28/geometry.html">The geometry of diffusion guidance ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2023/07/20/perspectives.html">Perspectives on diffusion ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2022/05/26/guidance.html">Guidance: a cheat code for diffusion models ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2022/01/31/diffusion.html">Diffusion models are autoencoders ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://sander.ai/2024/02/28/paradox.html">The paradox of diffusion distillation ‚Äì Sander Dieleman</A>
						<DT><A HREF="https://imagen.research.google/">Imagen: Text-to-Image Diffusion Models</A>
						<DT><A HREF="https://arxiv.org/pdf/2205.09991.pdf">Planning with Diffusion for Flexible Behavior Synthesis</A>
						<DT><A HREF="https://arxiv.org/abs/2206.01714">Compositional Visual Generation with Composable Diffusion Models</A>
						<DT><A HREF="https://twitter.com/finbarrtimbers/status/1643283063017971713">diffusion-based models into 11 modular parts</A>
						<DT><A HREF="https://arxiv.org/abs/2206.00364">[2206.00364] Elucidating the Design Space of Diffusion-Based Generative Models</A>
						<DT><A HREF="https://github.com/NVIDIA/TensorRT/blob/3aaa97b91ee1dd61ea46f78683d9a3438f26192e/demo/experimental/HuggingFace-Diffusers/TensorRT-diffusers-txt2img.ipynb">TensorRT/demo/experimental/HuggingFace-Diffusers/TensorRT-diffusers-txt2img.ipynb</A>
						<DT><A HREF="https://twitter.com/_akhaliq/status/1742255547741544602">DIffusion Model with Perceptual Loss (ByteDance)</A>
						<DT><A HREF="https://huggingface.co/papers/2312.02696">Paper page - Analyzing and Improving the Training Dynamics of Diffusion Models</A>
						<DT><A HREF="https://www.youtube.com/watch?v=HoKDTa5jHvg">Diffusion Models | Paper Explanation | Math Explained - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=ogJsCPqgFMk">Efficient Text-to-Image Training (16x cheaper than Stable Diffusion) | Paper Explained - YouTube</A>
						<DT><A HREF="https://github.com/neelnanda-io/Stable-Diffusion-Interp/blob/main/w3d5_part2_stablediff_solution.py">Stable-Diffusion-Interp/w3d5_part2_stablediff_solution.py at main ¬∑ neelnanda-io/Stable-Diffusion-Interp</A>
						<DT><A HREF="https://github.com/neelnanda-io/Stable-Diffusion-Interp/tree/main">neelnanda-io/Stable-Diffusion-Interp</A>
						<DT><A HREF="https://www.slideshare.net/slideshow/embed_code/key/BoSrT1r6h4kDTJ">ex-OpenAI slides</A>
						<DT><A HREF="https://twitter.com/PreetumNakkiran/status/1767268109784940867">Projection onto manifold perspective</A>
						<DT><A HREF="https://chenyang.co/diffusion.html">Chenyyang Yuan: Diffusion models from scratch, from a new theoretical perspective</A>
						<DT><A HREF="https://github.com/yuanchenyang/smalldiffusion">yuanchenyang/smalldiffusion: Simple and readable code for training and sampling from diffusion models</A>
						<DT><A HREF="https://arxiv.org/abs/2403.18103">[2403.18103] Tutorial on Diffusion Models for Imaging and Vision</A>
						<DT><A HREF="https://github.com/neelnanda-io/Stable-Diffusion-Interp/blob/main/w3d5_part2_stablediff_solution.py">Stable-Diffusion-Interp/w3d5_part2_stablediff_solution.py</A>
						<DT><A HREF="https://twitter.com/rm_rafailov/status/1781145364810350689">hybrid auto-regressive + diffusion video generation models</A>
						<DT><A HREF="https://twitter.com/BenTheEgg/status/1783972218772373708">(1) Benjamin Lefaudeux en X: "And.. we're back in business ! Possibly placebo, but I can feel the heat just looking at the screen https://t.co/s6bO10acjA" / X</A>
						<DT><A HREF="https://github.com/bytedance">Bytedance Inc.</A>
						<DT><A HREF="https://github.com/cloneofsimo/imagenet.int8">cloneofsimo/imagenet.int8</A>
						<DT><A HREF="https://carpedm30.notion.site/SHIFT-UP-AI-Labs-2cc71f48eb1140d09a439ab0b10bdb7b?p=642900de802c444caf4e3b51d34079aa&pm=s">SHIFT UP AI Labs</A>
						<DT><A HREF="https://www.youtube.com/watch?v=zc5NTeJbk-k&t=124s">Why Does Diffusion Work Better than Auto-Regression? - YouTube</A>
						<DT><A HREF="https://github.com/snap-research/BitsFusion">snap-research/BitsFusion</A>
						<DT><A HREF="https://github.com/snap-research/HyperHuman">snap-research/HyperHuman: [ICLR 2024] Github Repo for "HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion"</A>
						<DT><A HREF="https://www.microsoft.com/en-us/research/publication/florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks - Microsoft Research</A>
						<DT><A HREF="https://mettyz.github.io/DiffusionEngine/">DiffusionEngine: Diffusion Model is Scalable Data Engine for Object Detection</A>
						<DT><A HREF="https://github.com/diff-usion/Awesome-Diffusion-Models">diff-usion/Awesome-Diffusion-Models: A collection of resources and papers on Diffusion Models</A>
						<DT><A HREF="https://blog.csdn.net/xd_wjc/article/details/134441396">Stable Diffusion1.5ÁΩëÁªúÁªìÊûÑ-Ë∂ÖËØ¶ÁªÜÂéüÂàõ_stable diffusion unet ÁªìÊûÑ-CSDNÂçöÂÆ¢</A>
						<DT><A HREF="https://machinelearning.apple.com/research/autoregressive-image-models">Scalable Pre-training of Large Autoregressive Image Models - Apple Machine Learning Research</A>
						<DT><A HREF="https://github.com/apple/ml-aim">apple/ml-aim: This repository provides the code and model checkpoints of the research paper: Scalable Pre-training of Large Autoregressive Image Models</A>
						<DT><A HREF="https://github.com/SonicCodes/hyperada">SonicCodes/hyperada: Linear hypernetwork ada</A>
						<DT><A HREF="https://arxiv.org/abs/2006.11239">[2006.11239] Denoising Diffusion Probabilistic Models</A>
						<DT><A HREF="https://huggingface.co/papers/2408.07009">Imagen 3</A>
						<DT><A HREF="https://x.com/Ethan_smith_20/status/1767570870598279181">Ethan (SF til 8th) en X: "Created a new method of generative model (although kinda crappy lol) that works by autoregressive sequencing fourier coefficients. Inspired by the coarse to fine generation by Diffusion models. Full write up here: https://t.co/voD78qVwIB and tldr in thread üßµ (flowers102) https://t.co/VyhR0WA4vs" / X</A>
						<DT><A HREF="https://github.com/lucidrains/transfusion-pytorch">lucidrains/transfusion-pytorch: Pytorch implementation of Transfusion, "Predict the Next Token and Diffuse Images with One Multi-Modal Model", from MetaAI</A>
						<DT><A HREF="https://huggingface.co/rain1011">rain1011 (Yang Jin)</A>
						<DT><A HREF="https://github.com/eloialonso/diamond">eloialonso/diamond: DIAMOND (DIffusion As a Model Of eNvironment Dreams) is a reinforcement learning agent trained in a diffusion world model. NeurIPS 2024 Spotlight.</A>
						<DT><A HREF="https://www.markov.bio/research/mech-interp-path-to-e2e-biology">Through a Glass Darkly | Markov Bio</A>
						<DT><A HREF="https://x.com/i/bookmarks?post_id=1862843110247563343">The link between diffusion models and optimal transport</A>
						<DT><A HREF="https://huggingface.co/papers/2411.16318">Paper page - One Diffusion to Generate Them All</A>
						<DT><A HREF="https://x.com/thjashin/status/1800870255146979595">(1) Jiaxin Shi en X: "Discrete diffusion models made simple &amp;amp; competitive on both language and pixel-level image modeling! https://t.co/G3AnUVQzOD ‚úÖNew variational objective (integrate cross-entropy!) ‚úÖBeating prior diffusion language models &amp;amp; matching best AR on pixel-level image modeling ...(1/n) https://t.co/Aw8R9mgJ5l" / X</A>
						<DT><A HREF="https://arxiv.org/abs/2406.04329">[2406.04329] Simplified and Generalized Masked Diffusion for Discrete Data</A>
						<DT><A HREF="https://www.youtube.com/watch?v=VcykV0Cdo7U">High Resolution Image Generation via Energy Rectification - YouTube</A>
						<DT><A HREF="https://github.com/ronaldnetawat/stable-diffusion/tree/main/stable_diffusion">stable-diffusion/stable_diffusion at main ¬∑ ronaldnetawat/stable-diffusion</A>
					</DL><p>
					<DT><H3 FOLDED>Vision</H3>
					<DL><p>
						<DT><H3 FOLDED>perception</H3>
						<DL><p>
							<DT><A HREF="https://x.com/YunTaTsai1/status/1938972417403097166">Only three things matter in perception ‚Äî frame rate, acuity and dynamic range in a given unit of time.</A>
							<DT><A HREF="https://sites.google.com/site/marclevoylectures/home">How cameras work, and how to take good pictures using them</A>
							<DT><A HREF="https://www.youtube.com/playlist?list=PL7ddpXYvFXspUN0N-gObF1GXoCA-DA-7i">Lectures on Digital Photography - YouTube</A>
							<DT><A HREF="https://zeyofu.github.io/">Xingyu Fu</A>
						</DL><p>
						<DT><H3 FOLDED>clip-based-models</H3>
						<DL><p>
							<DT><H3 FOLDED>CLIP</H3>
							<DL><p>
								<DT><H3 FOLDED>perception-encoder</H3>
								<DL><p>
									<DT><A HREF="https://x.com/gabriberton/status/1922542722558067079">(1) Gabriele Berton en X: "While everyone is hating on Meta for the Llama 4 debacle, they dropped some very impressive CLIP-like models and VLMs They came out in two twin papers, released on the same day Here's a summary, some honest thoughts, and some things I personally liked and disliked of them [1/n] https://t.co/HDFsn5bxxG" / X</A>
									<DT><A HREF="https://ai.meta.com/research/publications/perception-encoder-the-best-visual-embeddings-are-not-at-the-output-of-the-network/">Perception Encoder: The best visual embeddings are not at the output of the network | Research - AI at Meta</A>
									<DT><A HREF="https://github.com/facebookresearch/perception_models">facebookresearch/perception_models: State-of-the-art Image &amp; Video CLIP, Multimodal Large Language Models, and More!</A>
								</DL><p>
								<DT><A HREF="https://x.com/JinaAI_/status/1859659764281782420">(1) Jina AI en X: "Jina-CLIP-v2: a 0.9B multilingual multimodal embedding model that supports 89 languages, 512x512 image resolution, 8192 token-length, and Matryoshka representations down to 64-dim for both images and text. https://t.co/TpUnvamf0z With of course strong performance on retrieval &amp;amp;" / X</A>
								<DT><A HREF="https://x.com/RicardoMonti9/status/1932437311649882618">(1) Ricardo Monti en X: ". @datologyai is back: state of the art CLIP model performance using data curation alone üöÄ ‚úÖ state-of-the-art ViT-B/32 performance: ImageNet 1k 76.9% vs 74% reported by SigLIP2 ‚úÖ¬†8x training efficiency gains ‚úÖ¬†2x inference efficiency gains ‚úÖ¬†Public model release Details in https://t.co/aPUAOA55zR" / X</A>
							</DL><p>
							<DT><H3 FOLDED>DINO</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>sigLIP</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2303.15343">[2303.15343] Sigmoid Loss for Language Image Pre-Training</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1939642045720883567">esidual stream is proportional to magnitude of initial emb, but its not the case for activations on MLP / attention due to normalizations</A>
							</DL><p>
							<DT><H3 FOLDED>PaliGemma</H3>
							<DL><p>
								<DT><A HREF="https://x.com/papers_anon/status/1859807437081149928">Multimodal Autoregressive Pre-training of Large Vision Encoders From Apple. V2 of the AIM generalist vision encoders (L/H/1B/3B). Pairs the vision encoder with a multimodal decoder that autoregressively generates raw image patches and text tokens. Outperforms CLIP, SigLIP</A>
								<DT><A HREF="https://x.com/A_K_Nain/status/1865949459563082009">(1) Aakash Kumar Nain en X: "Google DeepMind announced PaliGemma 2 last week. It is an upgrade of the PaliGemma open Vision-Language Model (VLM) based on the Gemma 2 family of language models. What does this generation of PaliGemma bring to the table? I finished reading the technical report, and here is a https://t.co/30evk6VTIo" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2412.03555">[2412.03555] PaliGemma 2: A Family of Versatile VLMs for Transfer</A>
								<DT><A HREF="https://huggingface.co/blog/paligemma2">Welcome PaliGemma 2 ‚Äì New vision language models by Google</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2103.00020">CLIP: Learning Transferable Visual Models From Natural Language Supervision</A>
							<DT><A HREF="https://arxiv.org/abs/2310.09199">[2310.09199] PaLI-3 Vision Language Models: Smaller, Faster, Stronger</A>
							<DT><A HREF="https://github.com/NVIDIA/JAX-Toolbox/tree/main/rosetta/rosetta/projects/imagen">JAX-Toolbox/rosetta/rosetta/projects/imagen</A>
							<DT><A HREF="https://x.com/BenTheEgg/status/1788596702380769616">MobileCLIP (Apple)</A>
							<DT><A HREF="https://x.com/i/bookmarks?post_id=1805149804059607366">SigLIP SO400</A>
							<DT><A HREF="https://x.com/olivierhenaff/status/1805995802352910557">(1) Olivier H√©naff en X: "Thrilled to announce our latest work on active data curation: joint example selection (JEST) drastically accelerates large-scale multimodal pretraining, surpassing previous SoTA (SigLIP) with 10x fewer iterations and FLOPS: https://t.co/NFPSrPIs4C https://t.co/Ggkg2Pn5qS" / X</A>
							<DT><A HREF="https://github.com/mlfoundations/open_clip">mlfoundations/open_clip: An open source implementation of CLIP.</A>
							<DT><A HREF="https://github.com/LAION-AI/CLIP-based-NSFW-Detector">LAION-AI/CLIP-based-NSFW-Detector</A>
							<DT><A HREF="https://vinija.ai/models/CLIP/">Vinija's Notes ‚Ä¢ Models ‚Ä¢ CLIP</A>
							<DT><A HREF="https://x.com/cloneofsimo/status/1827964161311363240">(1) Simo Ryu en X: "HF PALIGEMMA SNEAKY BUG?? If you ever wanted to do continued-generation with paligemma-3b-224, it adds EOS token at end of suffix by default. (I guess suffix was only intended for fine-tuning) Therefore unless you temporarily make that not-eos, it will generate gibberish! https://t.co/iZJEivVfSV" / X</A>
						</DL><p>
						<DT><H3 FOLDED>ViT</H3>
						<DL><p>
							<DT><H3 FOLDED>EoMT</H3>
							<DL><p>
								<DT><A HREF="https://x.com/giffmana/status/1940514113374830945">Encoder-only Mask Transformer: basically removing all the belss and whistles, and doing panoptic segmentation with an almost vanilla ViT</A>
								<DT><A HREF="https://github.com/NielsRogge/Transformers-Tutorials/tree/master/EoMT">Transformers-Tutorials/EoMT at master ¬∑ NielsRogge/Transformers-Tutorials</A>
								<DT><A HREF="https://www.tue-mps.org/eomt/">Your ViT is Secretly an Image Segmentation Model (CVPR 2025 Highlight)</A>
								<DT><A HREF="https://github.com/tue-mps/eomt">tue-mps/eomt: [CVPR 2025 Highlight] Official code and models for Encoder-only Mask Transformer (EoMT).</A>
								<DT><A HREF="https://arxiv.org/abs/2503.19108">[2503.19108] Your ViT is Secretly an Image Segmentation Model</A>
							</DL><p>
							<DT><H3 FOLDED>NATTEN</H3>
							<DL><p>
								<DT><H3 FOLDED>generalized-neighborhood-attention</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://x.com/AliHassaniJr/status/1636558575421263872">(1) Ali Hassani en X: "We upgraded NATTEN today to extend support to @PyTorch 2.0 (+ SM89/SM90), allowing users to enjoy all the goodies in the new release. We're seeing up to 20% throughput improvement in Neighborhood Attention based models with torch.compile! https://t.co/CnmXAj4R2R https://t.co/P40giqHlP0" / X</A>
								<DT><A HREF="https://x.com/alihassanijr/status/1915263363631742982?s=12">(1) Ali Hassani en X: "Wondering what's happening with NATTEN in 2025? Check out Generalized Neighborhood Attention! Spoiler: NATTEN gets a new stride parameter, we made a simulator for all your analytical studies, AND a Blackwell kernel! Keep reading for more... (1 / 5) https://t.co/b43t2l70P7" / X</A>
								<DT><A HREF="https://github.com/SHI-Labs/NATTEN">SHI-Labs/NATTEN: Neighborhood Attention Extension. Bringing attention to a neighborhood near you!</A>
								<DT><A HREF="https://arxiv.org/abs/2504.16922">[2504.16922] Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light</A>
							</DL><p>
							<DT><H3 FOLDED>vit-theory</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=ma3NYVo8Im0">All Things ViTs || CVPR 2023 Tutorial || Hila Chefer and Sayak Paul - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=vsqKGZT8Qn8">Vision Transformer Basics - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=j3VNqtJUoz0">Vision Transformer Quick Guide</A>
							</DL><p>
							<DT><H3 FOLDED>spatial-temporal-transformer</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2001.02908">[2001.02908] Spatial-Temporal Transformer Networks for Traffic Flow Forecasting</A>
								<DT><A HREF="https://arxiv.org/abs/1607.06450">[1607.06450] Layer Normalization</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2010.11929">[2010.11929] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</A>
							<DT><A HREF="https://arxiv.org/abs/2302.05442">[2302.05442] Scaling Vision Transformers to 22 Billion Parameters</A>
							<DT><A HREF="https://github.com/mit-han-lab/efficientvit">mit-han-lab/efficientvit: EfficientViT is a new family of vision models for efficient high-resolution vision.</A>
							<DT><A HREF="https://x.com/AliHassaniJr/status/1785686867758718991">(1) Ali Hassani en X: "Fused neighborhood attention now supports backward pass! Upgrade today to get all the features and all the speed. Get up to 844%, 385% and 447% improvement in 1D/2D/3D forward+backward pass at the op level. Training w/ spatio-temporal attention should be a breeze now. https://t.co/yBdWPT1eyp" / X</A>
							<DT><A HREF="https://x.com/WenhaoLi29/status/1846217448678207556">(1) Wenhao Li en X: "We trained a Vision Transformer to solve ONE single task from @fchollet and @mikeknoop‚Äôs @arcprize. Unexpectedly, it failed to produce the test output, even when using 1 MILLION examples! Why is this the case? ü§î https://t.co/lsS6PKiHa3" / X</A>
							<DT><A HREF="https://alessiodevoto.github.io/ViT-in-pure-JAX/">Vision Transformer in pure JAX. - Alessio Devoto</A>
							<DT><A HREF="https://x.com/rchoudhury997/status/1857514021014081583">(1) Rohan Choudhury en X: "Excited to finally release our NeurIPS 2024 (spotlight) paper! We introduce Run-Length Tokenization (RLT), a simple way to significantly speed up your vision transformer on video with no loss in performance! https://t.co/jERT4LxOJw" / X</A>
							<DT><A HREF="https://x.com/MistralAI/status/1858565550450065920">Pixtral Large: new SOTA vision model</A>
							<DT><A HREF="https://github.com/AmericanPresidentJimmyCarter/test-torch-bfloat16-vit-training">AmericanPresidentJimmyCarter/test-torch-bfloat16-vit-training</A>
							<DT><A HREF="https://www.artfintel.com/p/papers-ive-read-this-week-vision">Papers I've read this week: vision language models</A>
							<DT><A HREF="https://x.com/tommiekerssies/status/1906793027911250027">(1) Tommie Kerssies en X: "Image segmentation doesn‚Äôt have to be rocket science. üöÄ Why build a rocket engine full of bolted-on subsystems when one elegant unit does the job? üí° That‚Äôs what we did for segmentation. ‚úÖ Meet the Encoder-only Mask Transformer (EoMT): https://t.co/LWZXyeR4by (CVPR 2025) (1/6) https://t.co/gqyQ70qldp" / X</A>
							<DT><A HREF="https://lucasb.eyer.be/articles/vit_cnn_speed.html">On the speed of ViTs and CNNs</A>
						</DL><p>
						<DT><H3 FOLDED>GAN</H3>
						<DL><p>
							<DT><H3 FOLDED>gan-visualization</H3>
							<DL><p>
								<DT><A HREF="https://poloclub.github.io/ganlab/">GAN Lab: Play with Generative Adversarial Networks in Your Browser!</A>
							</DL><p>
							<DT><A HREF="https://lilianweng.github.io/posts/2017-08-20-gan/">From GAN to WGAN | Lil'Log</A>
							<DT><A HREF="https://arxiv.org/pdf/1406.2661">Generative Adversarial Nets</A>
							<DT><A HREF="https://twitter.com/anand_bhattad/status/1664798414318518274">(1) Anand Bhattad en X: "1/ SUPER excited to share our latest paper! Would you believe it if I told you that a StyleGAN, trained only to generate images, can also generate normals, depth, albedo, shading &amp;amp; segmentation? We show that it can! ü§Ø w/ @danielbmckee , @HoiemDerek &amp;amp; David Forsyth @IllinoisCS https://t.co/ae6pNn9r03" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2306.00987">[2306.00987] StyleGAN knows Normal, Depth, Albedo, and More</A>
							<DT><A HREF="https://blog.fal.ai/introducing-aurasr-an-open-reproduction-of-the-gigagan-upscaler-2/">Introducing AuraSR - An open reproduction of the GigaGAN Upscaler</A>
						</DL><p>
						<DT><H3 FOLDED>image-tokens</H3>
						<DL><p>
							<DT><A HREF="https://github.com/lucidrains/titok-pytorch">lucidrains/titok-pytorch: Implementation of TiTok, proposed by Bytedance in "An Image is Worth 32 Tokens for Reconstruction and Generation"</A>
						</DL><p>
						<DT><H3 FOLDED>Florence-2</H3>
						<DL><p>
							<DT><A HREF="https://huggingface.co/microsoft/Florence-2-large-ft">microsoft/Florence-2-large-ft ¬∑ Hugging Face</A>
							<DT><A HREF="https://arxiv.org/abs/2311.06242">[2311.06242] Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</A>
						</DL><p>
						<DT><H3 FOLDED>CIFAR</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/html/2404.00498v1">94% on CIFAR-10 in 3.29 Seconds on a Single GPU</A>
							<DT><A HREF="https://x.com/kellerjordan0/status/1978502058023031214">Keller Jordan en X: "New CIFAR-10 training speed record: 94% in 1.99 seconds on one A100 Previous record: 2.59 seconds (Nov. 10th 2024) New record-holder: Algorithmic discovery engine developed by @hivergeai Changelog: - Muon: Vectorize NS iter and reduce frequency of 'normalize weights' step 1/3 https://t.co/OTY73p32JC" / X</A>
						</DL><p>
						<DT><A HREF="https://arxiv.org/abs/2310.05737">[2310.05737] Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation</A>
						<DT><A HREF="https://segment-anything.com/demo#">Segment Anything | Meta AI</A>
						<DT><A HREF="https://towardsdatascience.com/metas-hiera-reduce-complexity-to-increase-accuracy-30f7a147ad0b">META‚Äôs Hiera: reduce complexity to increase accuracy</A>
						<DT><A HREF="https://twitter.com/skalskip92/status/1728867156681732229">GPT-4V &amp; SLAM</A>
						<DT><A HREF="https://arxiv.org/abs/2309.16588">[2309.16588] Vision Transformers Need Registers</A>
						<DT><A HREF="https://x.com/borisdayma/status/1806092526572503533">attention registers</A>
						<DT><A HREF="https://machinelearning.apple.com/research/autoregressive-image-models">Scalable Pre-training of Large Autoregressive Image Models - Apple Machine Learning Research</A>
						<DT><A HREF="https://x.com/bfl_ml/status/1819003686011449788">(1) Black Forest Labs en X: "We are excited to announce the launch of Black Forest Labs. Our mission is to develop and advance state-of-the-art generative deep learning models for media and to push the boundaries of creativity, efficiency and diversity. https://t.co/ilcWvJgmsX" / X</A>
						<DT><A HREF="https://github.com/PKU-YuanGroup/LLaVA-o1">PKU-YuanGroup/LLaVA-o1</A>
						<DT><A HREF="https://github.com/salesforce/LAVIS">salesforce/LAVIS: LAVIS - A One-stop Library for Language-Vision Intelligence</A>
						<DT><A HREF="https://x.com/giffmana/status/1863739511638774095">BIG_VISION GPU tutorial</A>
						<DT><A HREF="https://lucasb.eyer.be/articles/bv_tuto.html">Using big_vision on GPUs</A>
					</DL><p>
					<DT><H3 FOLDED>Language Models</H3>
					<DL><p>
						<DT><A HREF="https://github.com/Tencent/Tencent-Hunyuan-Large">Tencent/Tencent-Hunyuan-Large</A>
						<DT><A HREF="https://github.com/lucidrains/x-transformers">lucidrains/x-transformers: A simple but complete full-attention transformer with a set of promising experimental features from various papers</A>
						<DT><A HREF="https://arxiv.org/pdf/2005.14165.pdf">(Brown, 2020) Language Models are Few-Shot Learners</A>
						<DT><A HREF="https://arxiv.org/pdf/1910.10683.pdf">(T5): Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</A>
						<DT><A HREF="https://arxiv.org/abs/2001.08361">(Kaplan) Scaling Laws for Neural Language Models</A>
						<DT><A HREF="https://arxiv.org/pdf/2307.09288.pdf">Llama 2: Open Foundation and Fine-Tuned Chat Models</A>
						<DT><A HREF="https://arxiv.org/abs/2312.11805">Gemini: A Family of Highly Capable Multimodal Models</A>
						<DT><A HREF="https://arxiv.org/abs/2310.06825">[2310.06825] Mistral 7B</A>
						<DT><A HREF="https://arxiv.org/abs/2401.04088">[2401.04088] Mixtral of Experts</A>
						<DT><A HREF="https://arxiv.org/abs/2204.02311">[2204.02311] PaLM: Scaling Language Modeling with Pathways</A>
						<DT><A HREF="https://arxiv.org/abs/2205.05131">[Abletative &amp; Pareto-frontier] UL2: Unifying Language Learning Paradigms</A>
						<DT><A HREF="https://openreview.net/pdf?id=gEZrGCozdqR">FLAN: Finetuned Language Models are Zero-Shot Learners</A>
						<DT><A HREF="https://arxiv.org/abs/2205.01068">[2205.01068] OPT: Open Pre-trained Transformer Language Models</A>
						<DT><A HREF="https://arxiv.org/pdf/2203.02155.pdf">(OpenAI, 2022) Training language models to follow instructions</A>
						<DT><A HREF="https://arxiv.org/abs/1301.3781">Efficient Estimation of Word Representations in Vector Space (word2vec)</A>
						<DT><A HREF="https://arxiv.org/abs/2204.07705">Super-NaturalInstructions: Generalization via Instructions (Allen AI)</A>
						<DT><A HREF="https://arxiv.org/pdf/2303.17568.pdf">CodeGeeX</A>
						<DT><A HREF="https://papers.labml.ai/paper/18eb0daa07cb11edb9b9d35608ee6155">Formal Algorithms for Transformers</A>
						<DT><A HREF="https://arxiv.org/abs/2103.00020">CLIP: Learning Transferable Visual Models From Natural Language Supervision</A>
						<DT><A HREF="https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Supplemental.pdf">Supplement GPT-3 few-shot generalizable learners</A>
						<DT><A HREF="https://arxiv.org/abs/2307.09793">[2307.09793] On the Origin of LLMs: An Evolutionary Tree and Graph</A>
						<DT><A HREF="https://arxiv.org/pdf/2307.06435.pdf">2023 Summary</A>
						<DT><A HREF="https://huggingface.co/transformers/v4.8.0/glossary.html">Glossary ‚Äî transformers 4.7.0 documentation</A>
						<DT><H3 FOLDED>language-theory</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=PngHcmMmwWI">Nicholas Carlini - Are LLMs worth it? - YouTube</A>
							<DT><A HREF="https://arxiv.org/abs/2601.02907">[2601.02907] Beyond the Black Box: Theory and Mechanism of Large Language Models</A>
						</DL><p>
						<DT><H3 FOLDED>language-lectures</H3>
						<DL><p>
							<DT><H3 FOLDED>language-slides</H3>
							<DL><p>
								<DT><A HREF="https://docs.google.com/presentation/d/1u05yQQaw4QXLVYGLI6o3YoFHv6eC3YN8GvWD8JMumpE/edit?slide=id.g2885e521b53_0_0#slide=id.g2885e521b53_0_0">Shaping the Future of AI from the History of Transformer (Hyung Won)</A>
								<DT><A HREF="https://docs.google.com/presentation/d/1JKpqsbkr5Fg-bj1iElPaC-ToTVpRmRLKZmN89krwl04/edit?resourcekey=0-VPgp_Yc4krPPW3Mxv6UjgQ&slide=id.g16197112905_0_0#slide=id.g16197112905_0_0">Intuitions on Language Models (Jason)</A>
								<DT><A HREF="https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0">Language Language Models (in 2023) - Google Slides</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=3gb-ZkVRemQ&list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&index=28">Stanford CS25: V4 I Jason Wei &amp; Hyung Won Chung of OpenAI - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=orDKvo8h71o">Stanford CS25: V4 I Hyung Won Chung of OpenAI - YouTube</A>
							<DT><A HREF="https://people.cs.umass.edu/~miyyer/cs685/">Advanced NLP - CS 685, Spring 2024, UMass Amherst</A>
							<DT><A HREF="https://people.cs.umass.edu/~miyyer/cs685/schedule.html">Schedule - CS 685, Spring 2022, UMass Amherst</A>
							<DT><A HREF="https://stanford-cs324.github.io/winter2022/">CS324 - Large Language Models</A>
							<DT><A HREF="https://www.cs.princeton.edu/courses/archive/fall22/cos597G/">COS 597G: Understanding Large Language Models</A>
							<DT><A HREF="https://www.youtube.com/watch?v=AKMuA_TVz3A">Ilya Sutskever (OpenAI): An observation on Generalization</A>
							<DT><A HREF="https://phontron.com/class/anlp2024/assets/slides/anlp-15-tourofllms.pdf">CS11-711 Advanced NLP Tour of Modern LLMs</A>
							<DT><A HREF="https://phontron.com/class/anlp2024/lectures/">Lectures | 11-711 ANLP</A>
							<DT><A HREF="https://www.youtube.com/watch?v=RciT5fcuN1E">High Performance LLMs in Jax 2024 -- Session 2 - YouTube</A>
							<DT><A HREF="https://github.com/karpathy/makemore">karpathy/makemore: An autoregressive character-level language model for making more things</A>
							<DT><A HREF="https://x.com/lileics/status/1860174527994692082">(1) Lei Li en X: "I will teach Large Language Model Systems again in Spring 2025. (11868 for CMU folks) The course syllabus (tentative) is online at https://t.co/6AmKDbdHt6 CMU ppl are welcome to enroll. For others, I will release the materials online. Or apply to CMU LLM/GenAI certificate program" / X</A>
							<DT><A HREF="https://phontron.com/class/anlp-fall2024/">CMU Advanced NLP Fall 2024 | 11-711 ANLP</A>
							<DT><A HREF="https://llmsystem.github.io/llmsystem2025spring/">LLM Systems | Large Language Model Systems</A>
							<DT><A HREF="https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness">Training great LLMs entirely from ground up in the wilderness as a startup ‚Äî Yi Tay</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-people</H3>
						<DL><p>
							<DT><A HREF="https://www.yitay.net/papers">Papers ‚Äî Yi Tay</A>
							<DT><A HREF="https://scholar.google.com/citations?hl=en&user=wsGvgA8AAAAJ&view_op=list_works&citft=1&email_for_op=antonio.jfdominguez%40gmail.com&gmla=AOV7GLN3W4O6NIDNdCcBkV_iDC21-xJFgE9EtTcF0RmBzdcKrEF46210Wvjs822ZRzG_SBibT3xddH6GJgU3SPO710DKm_SctPk3WkFFHzFwhDdat8yKJ1X7TYY8-WYpbAyAHud1T-e8q4oYIVEKVcszYYDshws0si2Wiyf2DLsvrAwbWUqybXjXFvwMczvMx_ckXdir3sbM9FRUTfFY9wB3nYllfhw3gwJzC_k1AsIXvsdXsn4XioWf4Ik">‚Ä™Noam Shazeer‚Ä¨ - (Transformers author)</A>
							<DT><A HREF="https://scholar.google.com/citations?hl=en&user=oR9sCGYAAAAJ&view_op=list_works&citft=1&email_for_op=antonio.jfdominguez%40gmail.com&gmla=AOV7GLOU01RwzH9ABWVgReuJ4vYIX-R16ZT_WjsIZt7HhK2cY3eb5fbOdZNkOCbIlM91bVmTEhMFcavI9r8QcGTItl1zpC_q0beRNBvJIqorFTZN7iChYoX3jUywwyJ5CwLvpFYruduPtNhAPsDXUg7xpsGLiSh45meJipgi3nKsNJzMieDISepUsp8-3hmuKU7cdrhNGNZp3ztviA_HkpQpZQa3cuL70CtXUOwgBmAIue-nEexRvwjcglc">‚Ä™Ashish Vaswani‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
							<DT><A HREF="https://twitter.com/ThomasScialom">MetaAI: Thomas Scialom (Llama)</A>
						</DL><p>
						<DT><H3 FOLDED>capabilities</H3>
						<DL><p>
							<DT><H3 FOLDED>frontier-capabilities</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=E22AOHAEtu4">Advancing the Frontier of Silicon Intelligence: the Past, Open Problems, and the Future - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=LCEmiRjPEtQ">Andrej Karpathy: Software Is Changing (Again) - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>interpretability</H3>
							<DL><p>
								<DT><H3 FOLDED>attention-maps</H3>
								<DL><p>
									<DT><A HREF="https://github.com/doomslide/attention-graph?tab=readme-ov-file">doomslide/attention-graph: A graph visualization of attention</A>
									<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</A>
									<DT><A HREF="https://github.com/gemlab-vt/clora/blob/main/notebook.ipynb">clora attention_maps visualization</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/commit/a267286256c4e7f835227c4c5767393ac586431a">model_extraction from layers</A>
								</DL><p>
								<DT><H3 FOLDED>mechanistic interpretability</H3>
								<DL><p>
									<DT><H3 FOLDED>mechanistic-interpretability-people</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/NeelNanda5">(1) Neel Nanda (@NeelNanda5) / Twitter</A>
										<DT><A HREF="https://github.com/saprmarks">saprmarks</A>
									</DL><p>
									<DT><H3 FOLDED>mechanistic-interpretability-lectures</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=OI1we2bUseI&list=PL7m7hLIqA0hr4dVOgjNwP2zjQGVHKeB7T">Real-Time Research Walkthrough: Addition in GPT-J - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=KV5gbOmHbjU&list=PL7m7hLIqA0hoIUPhC26ASCVs_VrqcDpAz&index=3">A Walkthrough of A Mathematical Framework for Transformer Circuits - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=yo4QvDn-vsU">Real-Time Research Recording: Can a Transformer Re-Derive Positional Info? - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=pC4zRb_5noQ">CS25 I Stanford Seminar 2022 - Transformer Circuits, Induction Heads, In-Context Learning - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=4JKuyfejWTU&list=LL&index=3">Mor Geva: Transformer Feed Forward Layers are Key-Value Memories, and Build Predictions - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=m8tzXelUTLo">Real-Time Research Walkthrough: Mover Heads Part 1/2 - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=I1ELSZNFeHc">David Bau - Direct Model Editing and Mechanistic Interpretability - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=2Rdp9GvcYOE">Chris Olah - Looking Inside Neural Networks with Mechanistic Interpretability - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=_Ygf0GnlwmY&t=5193s">Mechanistic Interpretability - NEEL NANDA (DeepMind) - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>transformer debugger</H3>
									<DL><p>
										<DT><A HREF="https://github.com/openai/transformer-debugger?tab=readme-ov-file">openai/transformer-debugger</A>
										<DT><A HREF="https://github.com/neelnanda-io/TransformerLens">TransformerLens: A library for mechanistic interpretability of language models</A>
										<DT><A HREF="https://www.loom.com/share/6bd8c6bde84b42a98f9a26a969d4a3ad?sid=4a09ac29-58a2-433e-b55d-762414d9a7fa">4. TDB worked example: name mover heads, part 2</A>
										<DT><A HREF="https://github.com/joennlae/tensorli">joennlae/tensorli: Absolute minimalistic implementation of a GPT-like transformer using only numpy (&lt;650 lines).</A>
										<DT><A HREF="https://explainextended.com/2023/12/31/happy-new-year-15/">Happy New Year: GPT in 500 lines of SQL - EXPLAIN EXTENDED at EXPLAIN EXTENDED</A>
										<DT><A HREF="https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html">Language models can explain neurons in language models</A>
									</DL><p>
									<DT><H3 FOLDED>cot-mech-interp</H3>
									<DL><p>
										<DT><A HREF="https://x.com/NeelNanda5/status/1938296379946012950">(1) Neel Nanda en X: "I'm very excited about our vision for "mech interp" of CoT: Study reasoning steps and their connections - analogous to activations Don't just read it: study attn, causally intervene, and, crucially, resampling - study the distn over CoTs, not just this one There's lots to do! https://t.co/JvPN1VNult" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2506.19143">[2506.19143] Thought Anchors: Which LLM Reasoning Steps Matter?</A>
									</DL><p>
									<DT><H3 FOLDED>SPD</H3>
									<DL><p>
										<DT><A HREF="https://x.com/GoodfireAI/status/1939028559768723571">SPD, decomposes the *parameters* of neural networks, rather than their activations</A>
										<DT><A HREF="https://www.goodfire.ai/papers/stochastic-param-decomp">Towards Scalable Parameter Decomposition</A>
									</DL><p>
									<DT><H3 FOLDED>SAE</H3>
									<DL><p>
										<DT><A HREF="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</A>
										<DT><A HREF="https://blog.withmartian.com/post/scaling-ai-interpret">Scaling AI Interpretability</A>
										<DT><A HREF="https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html">An Intuitive Explanation of Sparse Autoencoders for LLM Interpretability | Adam Karvonen</A>
										<DT><A HREF="https://thesephist.com/posts/prism/">Prism: mapping interpretable concepts and features in a latent space of language | thesephist.com</A>
										<DT><A HREF="https://x.com/livgorton/status/1813253322582925821">(1) Liv en X: "Early work on InceptionV1 found that many individual neurons seemed monosemantic. Of course, there were also polysemantic neurons, and in my recent paper, I used SAEs to attack this. But what do SAEs do with all those apparently monosemantic neurons?" / X</A>
										<DT><A HREF="https://distill.pub/2020/circuits/branch-specialization/">Branch Specialization</A>
										<DT><A HREF="https://distill.pub/2020/circuits/visualizing-weights/">Visualizing Weights</A>
										<DT><A HREF="https://www.youtube.com/watch?v=o_cAOa5fMhE">Latent Space Visualisation: PCA, t-SNE, UMAP | Deep Learning Animated - YouTube</A>
										<DT><A HREF="https://x.com/i/bookmarks?post_id=1834251979771564368">The hope is that just optimizing something to be sparse without optimizing it to be interpretable will stumble across that interpretable decomposition</A>
										<DT><A HREF="https://www.cs.utexas.edu/~flame/pubs/GotoTOMS_revision.pdf?ref=broutonlab.com">Anatomy of High-Performance Matrix Multiplication</A>
										<DT><A HREF="https://x.com/i/bookmarks?post_id=1863487582631547027">minSAE</A>
										<DT><A HREF="https://github.com/cloneofsimo/minSAE">cloneofsimo/minSAE</A>
										<DT><A HREF="https://github.com/callummcdougall/sae_vis">callummcdougall/sae_vis: Create feature-centric and prompt-centric visualizations for sparse autoencoders (like those from Anthropic's published research).</A>
										<DT><A HREF="https://x.com/NeelNanda5/status/1904988240542834724?t=SqE4zcoGYd8EiGW-Ice8Pw&s=09">We study if SAEs help probes generalise OOD (they don't üò¢). Based on this + parallel negative results on real-world tasks, we're de-prioritising SAE work.</A>
									</DL><p>
									<DT><H3 FOLDED>mechanistic-interpretability-dit</H3>
									<DL><p>
										<DT><A HREF="https://x.com/alec_helbling/status/1894833831724884193">ConceptAttention: An approach to interpreting DiT</A>
										<DT><A HREF="https://github.com/helblazer811/ConceptAttention">helblazer811/ConceptAttention: ConceptAttention: A method for interpreting multi-modal diffusion transformers.</A>
										<DT><A HREF="https://arxiv.org/abs/2502.04320">[2502.04320] ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features</A>
									</DL><p>
									<DT><H3 FOLDED>steer-vectors</H3>
									<DL><p>
										<DT><A HREF="https://x.com/mlpowered/status/1950963512307753020">(1) Emmanuel Ameisen en X: "Earlier this year, we showed a method to interpret the intermediate steps a model takes to produce an answer. But we were missing a key bit of information: explaining why the model attends to specific concepts. Today, we do just that üßµ https://t.co/JCElfAVhpy" / X</A>
									</DL><p>
									<DT><A HREF="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html">Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet</A>
									<DT><A HREF="https://twitter.com/NeelNanda5/status/1682827872191348736">GPT-J arithmetic addtion</A>
									<DT><A HREF="https://transformer-circuits.pub/2023/monosemantic-features/index.html">Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</A>
									<DT><A HREF="https://transformer-circuits.pub/2024/april-update/index.html#scaling-laws">Scaling Laws for Dictionary Learning</A>
									<DT><A HREF="https://github.com/saprmarks/dictionary_learning">saprmarks/dictionary_learning</A>
									<DT><A HREF="https://transformer-circuits.pub/2023/toy-double-descent/index.html">Superposition, Memorization, and Double Descent</A>
									<DT><A HREF="https://transformer-circuits.pub/2022/toy_model/index.html#demonstrating">Toy Models of Superposition</A>
									<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html#def-privileged-basis">Privileged Bases in the Transformer Residual Stream</A>
									<DT><A HREF="https://github.com/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb">toy-models-of-superposition/toy_models.ipynb</A>
									<DT><A HREF="https://github.com/alan-cooney/CircuitsVis">CircuitsVis: Mechanistic Interpretability Visualizations using React</A>
									<DT><A HREF="https://arxiv.org/pdf/2307.09458.pdf">Does Circuit Analysis Interpretability Scale? Evidence from Multiple Choice Capabilities in Chincilla (DeepMind)</A>
									<DT><A HREF="https://copy-suppression.streamlit.app/">LLM: copy-supression</A>
									<DT><A HREF="https://github.com/ArthurConmy/Automatic-Circuit-Discovery">ArthurConmy/Automatic-Circuit-Discovery</A>
									<DT><A HREF="https://github.com/neelnanda-io/Exploring-2L-SAE">neelnanda-io/Exploring-2L-SAE</A>
									<DT><A HREF="https://github.com/yizhe-ang/interactive-transformer">interactive-transformer: A visual interface for understanding Transformers</A>
									<DT><A HREF="https://www.youtube.com/watch?v=PnwC74s1nmc">Theoretical and Practical Insights from Linear Transformers</A>
									<DT><A HREF="https://github.com/neelnanda-io/neelutils">neelnanda-io/neelutils: Random utils for personal use</A>
									<DT><A HREF="https://github.com/neelnanda-io/Grokking">Grokking: A Mechanistic Interpretability Analysis of Grokking</A>
									<DT><A HREF="https://github.com/neelnanda-io/TransformerLens">TransformerLens: A library for mechanistic interpretability of language models</A>
									<DT><A HREF="https://github.com/google-deepmind/tracr">(DeepMind) Tracr: TRAnsformer Compiler for RASP</A>
									<DT><A HREF="https://twitter.com/DrJimFan/status/1613918800444899328?lang=en">We train Transformers to encode algorithms in their weights, such as sorting, counting, and balancing parentheses from lots of data. I never thought we may also go in the *reverse* direction: *compile* Transformer weights directly from explicit code</A>
									<DT><A HREF="https://twitter.com/DrJimFan/status/1613966404721729536">Thinking Like Transformers</A>
									<DT><A HREF="https://srush.github.io/raspy/">Thinking like Transformer</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zUCoxhExe0o">Stanford Seminar - Computing with High-Dimensional Vectors</A>
									<DT><A HREF="https://github.com/saprmarks/geometry-of-truth">saprmarks/geometry-of-truth</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XuFWN0xcM_U">[short] Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs//2401.06102">[2401.06102] Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models</A>
									<DT><A HREF="https://arxiv.org/abs/2401.05566">[2401.05566] Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</A>
									<DT><A HREF="https://alan-cooney.github.io/CircuitsVis/?path=/docs/attention-attentionheads--induction-heads-layer">attention / AttentionHeads - Induction Heads Layer ‚ãÖ Storybook</A>
									<DT><A HREF="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens">interpreting GPT: the logit lens ‚Äî LessWrong</A>
									<DT><A HREF="https://x.com/mlpowered/status/1792948212728524917">dictonary learning working on a fronteir model</A>
									<DT><A HREF="https://www.anthropic.com/news/mapping-mind-language-model">Mapping the Mind of a Large Language Model \ Anthropic</A>
									<DT><A HREF="https://x.com/TransluceAI/status/1849142531906547779">Transluce en X: "Announcing Transluce, a nonprofit research lab building open source, scalable technology for understanding AI systems and steering them in the public interest. Read a letter from the co-founders Jacob Steinhardt and Sarah Schwettmann: https://t.co/IUIhBjpYhS https://t.co/jl91xv7Vsc" / X</A>
									<DT><A HREF="https://www.markov.bio/research/mech-interp-path-to-e2e-biology">Through a Glass Darkly | Markov Bio</A>
									<DT><A HREF="https://www.youtube.com/watch?v=YpFaPKOeNME">NEURAL NETWORKS ARE REALLY WEIRD... - YouTube</A>
									<DT><A HREF="https://github.com/neelnanda-io/Qwen-MLP-Exploration">neelnanda-io/Qwen-MLP-Exploration</A>
									<DT><A HREF="https://github.com/neelnanda-io/neelutils/blob/master/setup.py">neelutils/setup.py at master ¬∑ neelnanda-io/neelutils</A>
									<DT><A HREF="https://www.goodfire.ai/papers/mapping-latent-spaces-llama/">Mapping the Latent Space of Llama 3.3 70B - Goodfire Papers</A>
									<DT><A HREF="https://x.com/arankomatsuzaki/status/1884452248660717644">Open Problems in Mechanistic Interpretability This forward-facing review discusses the current frontier of mechanistic interpretability and the open problems</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Bj9BD2D3DzA">Tracing the thoughts of a large language model - YouTube</A>
									<DT><A HREF="https://x.com/GoodfireAI/status/1939028559768723571">(1) Goodfire en X: "(1/7) New research: how can we understand how an AI model actually works? Our method, SPD, decomposes the *parameters* of neural networks, rather than their activations - akin to understanding a program by reverse-engineering the source code vs. inspecting runtime behavior. https://t.co/Q3cHA1jteq" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=kkfLHmujzO8">A Stylised History of Mech Interp - YouTube</A>
									<DT><A HREF="https://x.com/teortaxestex/status/1999559676866724272">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Rare and very interesting gift from OpenAI. In principle, inherently sparse-activation models with large nominal dimensions are preferable to MoEs with their isolated low-capacity experts. Though maybe inter-layer expert communication is another viable path. https://t.co/cWAQcRzMTM" / X</A>
									<DT><A HREF="https://github.com/openai/circuit_sparsity">openai/circuit_sparsity: Open-source release accompanying Gao et al. 2025</A>
								</DL><p>
								<DT><H3 FOLDED>Patchscopes</H3>
								<DL><p>
									<DT><A HREF="https://pair.withgoogle.com/explorables/patchscopes/">Can Large Language Models Explain Their Internal Mechanisms?</A>
								</DL><p>
								<DT><A HREF="https://thesephist.com/posts/prism/">Prism: mapping interpretable concepts and features in a latent space of language | thesephist.com</A>
								<DT><A HREF="https://research.google/blog/patchscopes-a-unifying-framework-for-inspecting-hidden-representations-of-language-models/">Patchscopes: A unifying framework for inspecting hidden representations of language models</A>
								<DT><A HREF="https://x.com/pascalefung/status/1824665235179049027">(1) Pascale Fung en X: "We always knew that Chomsky was wrong about language models, it‚Äôs nice to have a paper showing you just how wrong he was! #ACL2024 best papsr. https://t.co/bpzRX10l8F" / X</A>
								<DT><A HREF="https://blbadger.github.io/llm-invertibility.html">Information between tokens | Form and Formula</A>
							</DL><p>
							<DT><H3 FOLDED>compression</H3>
							<DL><p>
								<DT><H3 FOLDED>compression-people</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/drjwrae">(1) Jack Rae (@drjwrae) / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=boiW5qhrGH4">(George Hotz) Hutter Prize: Intelligence as Compression</A>
									<DT><A HREF="http://www.hutter1.net/">Homepage of Marcus Hutter</A>
									<DT><A HREF="https://arxiv.org/abs/2308.07037">[Alex Graves] Bayesian Flow Networks</A>
									<DT><A HREF="https://jveness.info/">Homepage of Joel Veness</A>
								</DL><p>
								<DT><H3 FOLDED>entropy</H3>
								<DL><p>
									<DT><A HREF="https://apaz.dev/blog/Thoughts_About_Entropy_and_Objectives.html">Thoughts About Entropy and Objectives</A>
								</DL><p>
								<DT><H3 FOLDED>solomonoff-induction</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google-deepmind/neural_networks_solomonoff_induction">google-deepmind/neural_networks_solomonoff_induction: Learning Universal Predictors</A>
									<DT><A HREF="https://www.lesswrong.com/posts/Kyc5dFDzBg4WccrbK/an-intuitive-explanation-of-solomonoff-induction">An Intuitive Explanation of Solomonoff Induction ‚Äî LessWrong</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Solomonoff%27s_theory_of_inductive_inference">Solomonoff's theory of inductive inference - Wikipedia</A>
									<DT><A HREF="https://www.sciencedirect.com/science/article/pii/S0019995864902232">A formal theory of inductive inference. Part I - ScienceDirect</A>
								</DL><p>
								<DT><H3 FOLDED>compression-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=AKMuA_TVz3A&t=1851s">Ilya Sutskever: An Observation on Generalization</A>
									<DT><A HREF="https://www.youtube.com/watch?v=dO4TPJkeaaU&t=1234s">Compression for AGI - (Jack Rae)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=OPZxs6IXH00&t=10s">Ilya Sutskever - Opening Remarks: Confronting the Possibility of AGI</A>
								</DL><p>
								<DT><H3 FOLDED>Kolmogorov-compressor</H3>
								<DL><p>
									<DT><A HREF="https://en.wikipedia.org/wiki/Kolmogorov_complexity#Compression">Kolmogorov complexity - Wikipedia</A>
									<DT><A HREF="https://www.youtube.com/watch?v=AKMuA_TVz3A&t=1851s">Ilya Sutskever: An Observation on Generalization</A>
									<DT><A HREF="https://x.com/iamgingertrash/status/1980744728833585273">(1) simp 4 satoshi en X: "Of course, the Father of CNN‚Äôs (Yann) believes AGI needs a strong vision component (JEPA) And the father of RL (Sutton) believes AGI needs a live-action-reward loop (OaK) But only one, instead says that intelligence is a simple, elegant compression algorithm, in context https://t.co/wVstVO8TPP" / X</A>
									<DT><A HREF="https://x.com/ptshaw2/status/1973388346823966809">(1) Pete Shaw en X: "Excited to share a new paper that aims to narrow the conceptual gap between the idealized notion of Kolmogorov complexity and practical complexity measures for neural networks. https://t.co/CM3qcflVr8" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2509.22445">[2509.22445] Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers</A>
									<DT><A HREF="https://x.com/ericjang11/status/2011611913424421149">(1) Eric Jang en X: "This is an extremely beautiful plot because it sheds light on why scaling laws are so smooth, and reconciles empirical findings from both scaling laws and grokking. Even though mean loss across all tasks (red line) decreases smoothly, we see that individual subtask losses drop" / X</A>
								</DL><p>
								<DT><H3 FOLDED>memorize</H3>
								<DL><p>
									<DT><A HREF="https://x.com/jxmnop/status/1971282231940551111">(1) Jack Morris en X: "by the way. recently wrote a paper on this! for transformers, the number is about 3.6 bits-per-parameter so you would need 25GB √∑ 3.6 bits ‚âà 56.9B parameters to exactly memorize Wikipedia that‚Äôs a pretty big model actually https://t.co/CJXFMAOieC" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2505.24832">[2505.24832] How much do language models memorize?</A>
									<DT><A HREF="https://arxiv.org/pdf/2601.15394">Memorization Dynamics in Knowledge Distillation for Language Models</A>
								</DL><p>
								<DT><H3 FOLDED>openzl</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebook/openzl">facebook/openzl: A novel data compression framework</A>
									<DT><A HREF="https://www.youtube.com/watch?v=_BsjI3IUtlg">Meta Just Changed Data Compression FOREVER (OpenZL Explained) - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Drnt6rkeA9c&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=133&pp=iAQB">Lightning Talk: Model Checkpoint Compression With OpenZL - Nick Terrell &amp; Teja Rao, Meta - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>token-entropy</H3>
								<DL><p>
									<DT><A HREF="https://x.com/apaz_cli/status/2006481025270948240">(1) apaz en X: "I have been staring at entropy plots of pretrained versus finetuned models. This staring confirms my feeling that there is some "finetuning overhead resource" we are managing, and it shows up in entropy. When you look at the plots of which tokens' entropy falls the most as a https://t.co/nLwavxs5Gi" / X</A>
								</DL><p>
								<DT><H3 FOLDED>epiplexity</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2601.03220">[2601.03220] From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence</A>
									<DT><A HREF="https://apaz.dev/blog/Thoughts_About_Entropy_and_Objectives.html">Thoughts About Entropy and Objectives</A>
								</DL><p>
								<DT><A HREF="https://deepmind.google/research/publications/39768/">Language Modeling Is Compression - Google DeepMind</A>
								<DT><A HREF="https://github.com/Ma-Lab-Berkeley/CRATE">Ma-Lab-Berkeley/CRATE: Code for CRATE (Coding RAte reduction TransformEr).</A>
								<DT><A HREF="https://twitter.com/YiMaTweets/status/1693302230664020449/photo/1">rate reduction flow equation for maximizing information gain</A>
								<DT><A HREF="https://arxiv.org/abs/2306.01129">[2306.01129] White-Box Transformers via Sparse Rate Reduction</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Sx2PVCAiGhQ">George Hotz | Programming | Context Tree Weighting: compression = AI</A>
								<DT><A HREF="https://github.com/GFNOrg/gfn-lm-tuning">Amortizing Intractable Inference in Large Language Models (uTransfer creator)</A>
								<DT><A HREF="https://bellard.org/">Fabrice Bellard's Home Page</A>
								<DT><A HREF="https://bellard.org/nncp/">NNCP: Lossless Data Compression with Neural Networks</A>
								<DT><A HREF="https://bellard.org/nncp/nncp_v2.1.pdf">NNCP v2: Lossless Data Compression with Transformer</A>
								<DT><A HREF="https://blog.research.google/2022/12/accelerating-text-generation-with.html?m=1">Accelerating text generation with Confident Adaptive Language Modeling (CALM) ‚Äì Google Research Blog</A>
								<DT><A HREF="https://twitter.com/a_stadt/status/1737849248560066794">Sample-Efficient Pre-training</A>
								<DT><A HREF="https://twitter.com/arankomatsuzaki/status/1780073500536872990">Compression Represents Intelligence Linearly</A>
								<DT><A HREF="https://github.com/hkust-nlp/llm-compression-intelligence">hkust-nlp/llm-compression-intelligence: Official github repo for the paper "Compression Represents Intelligence Linearly"</A>
								<DT><A HREF="https://arxiv.org/abs/2404.09937">[2404.09937] Compression Represents Intelligence Linearly</A>
								<DT><A HREF="https://www.youtube.com/watch?v=xjnp42BuxOo">Compression Represents Intelligence Linearly HKU &amp; Tencent 2024 - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2401.14953">[2401.14953] Learning Universal Predictors</A>
								<DT><A HREF="https://github.com/google-deepmind/neural_networks_solomonoff_induction">google-deepmind/neural_networks_solomonoff_induction: Learning Universal Predictors</A>
								<DT><A HREF="https://github.com/KindXiaoming/pykan">KindXiaoming/pykan: Kolmogorov Arnold Networks</A>
								<DT><A HREF="https://github.com/cedrickchee/awesome-ml-model-compression">cedrickchee/awesome-ml-model-compression: Awesome machine learning model compression research papers, tools, and learning material.</A>
								<DT><A HREF="https://www.artfintel.com/p/papers-ive-read-this-week-713">Artificial Fintelligence | Finbarr Timbers | Substack</A>
								<DT><A HREF="https://github.com/google-deepmind/language_modeling_is_compression">google-deepmind/language_modeling_is_compression</A>
								<DT><A HREF="https://github.com/nadavrot/compressor">nadavrot/compressor: An educational implementation of a modern compressor in Rust</A>
								<DT><A HREF="https://github.com/zipnn/zipnn">zipnn/zipnn: A lossless and near-lossless compression method optimized for numbers/tensors in the Foundation Models environment</A>
								<DT><A HREF="https://github.com/facebook/zstd">facebook/zstd: Zstandard - Fast real-time compression algorithm</A>
								<DT><A HREF="https://www.youtube.com/watch?v=WWz8P-yevJk">Either Transformers Leak Entropy Or They Violate Physics: Which One Do You Think Is True? - YouTube</A>
								<DT><A HREF="https://zirui-ray-liu.github.io/blog/2024/llmzip/">LLMs are secretly lossless text compressor and how to use it like¬†one | Zirui's Homepage</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/1980165682516869575">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Whale insanity. ¬´Theoretically unlimited context architectures¬ª through turning old text into ¬´vision¬ª tokens at 10x and higher ratios. How crazy is that? But actually I think... we need to go even further beyond. Fully multimodal encoders. Language for intelligent machines. https://t.co/gv6dFYoJ6N" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2601.03220">[2601.03220] From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence</A>
								<DT><A HREF="https://mp.weixin.qq.com/s/HYlU3ldZn_79GJol17s9xQ">30T tokens, when the information compression ratio reaches 10:1, the upper limit of the total model parameter size is roughly estimated to be 3T parameters.</A>
							</DL><p>
							<DT><H3 FOLDED>reasoning</H3>
							<DL><p>
								<DT><H3 FOLDED>In-Context Learning</H3>
								<DL><p>
									<DT><H3 FOLDED>chain-of-thought</H3>
									<DL><p>
										<DT><H3 FOLDED>test-time-compute</H3>
										<DL><p>
											<DT><H3 FOLDED>parallel-test-time-compute</H3>
											<DL><p>
												<DT><H3 FOLDED>Quiet-STaR</H3>
												<DL><p>
													<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
													<DT><A HREF="https://github.com/facebookresearch/xformers/blob/c909f0d6a3f991c547bebe24b312286632a73473/xformers/ops/fmha/flash3.py#L56">xformers/xformers/ops/fmha/flash3.py at c909f0d6a3f991c547bebe24b312286632a73473 ¬∑ facebookresearch/xformers</A>
													<DT><A HREF="https://gist.github.com/Chillee/2e270fc5413dbbce58c779f8c4eac66c">flex_attention_tutorial.py</A>
													<DT><A HREF="https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit">The Custom Operators Manual - Google Docs</A>
													<DT><A HREF="https://github.com/sgl-project/sglang/blob/a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0/python/sglang/srt/layers/prefill_attention.py#L147">sglang/python/sglang/srt/layers/prefill_attention.py at a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0 ¬∑ sgl-project/sglang</A>
													<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/flash/flash_attention.py#L340">transformer_nuggets/transformer_nuggets/flash/flash_attention.py at 83f754eb670b73aa789a924b6b9fab67784ca28f ¬∑ drisspg/transformer_nuggets</A>
													<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173/6">Getting Triton to generate all kernels - torch.compile / torch._inductor - PyTorch Forums</A>
													<DT><A HREF="https://gist.github.com/gradjitta/550f6a7666228c8539ca11fc78f4ec95">custom op for flash attention 3 (compatible with torch.compile)</A>
													<DT><A HREF="https://gist.github.com/antferdom/f7874ab68f4c1183d2b8196d2ace3ffc">FlashAttention v3 within torch.compile compatible</A>
													<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/e2182cc21d5be2a1d71c8ca7eb1bc425563041f1/hopper/benchmark_attn.py#L236">flash-attention/hopper/benchmark_attn.py at e2182cc21d5be2a1d71c8ca7eb1bc425563041f1 ¬∑ Dao-AILab/flash-attention</A>
													<DT><A HREF="https://github.com/search?q=repo%3Apytorch%2Fpytorch%20scaled_dot_product_attention&type=code">Code search results</A>
													<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-894/developer-guide/index.html">Developer Guide :: NVIDIA cuDNN Documentation</A>
													<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/issues/52">What's the difference of flash attention implement between cudnn and Dao-AILab? ¬∑ Issue #52 ¬∑ NVIDIA/cudnn-frontend</A>
													<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/1.0/release/samples/python/test_mhas.py#L431">cudnn-frontend/samples/python/test_mhas.py at 1.0/release ¬∑ NVIDIA/cudnn-frontend</A>
													<DT><A HREF="https://drive.google.com/drive/u/3/home">Home - Google Drive</A>
													<DT><A HREF="https://pytorch.org/tutorials/advanced/cpp_custom_ops.html#testing-an-operator">Custom C++ and CUDA Operators ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
													<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html">torch.nn.functional.scaled_dot_product_attention ‚Äî PyTorch 2.4 documentation</A>
													<DT><A HREF="https://www.youtube.com/watch?v=-adYfpAenvo&t=117s">Pearl Harbor - Japanese Empire - Theme Suite - YouTube</A>
													<DT><A HREF="https://x.com/i/bookmarks?post_id=1835352391648158189">(1) Guardados / X</A>
													<DT><A HREF="https://arxiv.org/pdf/2403.09629">https://arxiv.org/pdf/2403.09629</A>
												</DL><p>
												<DT><H3 FOLDED>Grok-4-heavy</H3>
												<DL><p>
													<DT><A HREF="https://x.ai/news/grok-4">Grok 4 | xAI</A>
												</DL><p>
												<DT><H3 FOLDED>non-linear-chain-of-thought</H3>
												<DL><p>
													<DT><H3 FOLDED>Deep Think</H3>
													<DL><p>
														<DT><A HREF="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/">Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad - Google DeepMind</A>
													</DL><p>
												</DL><p>
												<DT><H3 FOLDED>Recursive Self-Aggregation</H3>
												<DL><p>
													<DT><A HREF="https://x.com/siddarthv66/status/2015201413928751215">(1) Siddarth Venkatraman en X: "Recursive Self-Aggregation &amp;gt; Gemini DeepThink. it really is the best test-time scaling algorithm does that claim sound too bold? well, we just crushed ARC-AGI 2 public evals with Gemini 3 Flash and RSA. stay tuned, more details tomorrow :) @arcprize https://t.co/DFWYvKk4z7" / X</A>
													<DT><A HREF="https://rsa-llm.github.io/">Recursive Self-Aggregation: Deep Thinking and Test-Time Scaling for LLM Reasoning | RSA</A>
													<DT><A HREF="https://arxiv.org/abs/2509.26626">[2509.26626] Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models</A>
													<DT><A HREF="https://github.com/HyperPotatoNeo/RSA">HyperPotatoNeo/RSA</A>
													<DT><A HREF="https://x.com/jm_alexia/status/2015458368375103870">(1) Alexia Jolicoeur-Martineau en X: "Incredibly simple, but powerful idea : ask a model to combine or take inspirations from multiple previous answers in order to generate the next ones. Its very akin to population-based genetic algorithms." / X</A>
												</DL><p>
												<DT><A HREF="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/">Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad - Google DeepMind</A>
												<DT><A HREF="https://moonshotai.github.io/Kimi-K2/thinking.html#footnote-3-2">Heavy Mode‚Äã: K2 Thinking Heavy Mode employs an efficient parallel strategy: it first rolls out eight trajectories simultaneously, then reflectively aggregates all outputs to generate the final result.</A>
											</DL><p>
											<DT><H3 FOLDED>test-time-scaling</H3>
											<DL><p>
												<DT><A HREF="https://arxiv.org/pdf/2507.23726">https://arxiv.org/pdf/2507.23726</A>
											</DL><p>
											<DT><A HREF="https://arxiv.org/html/2408.03314v1">Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters</A>
											<DT><A HREF="https://x.com/i/bookmarks?post_id=1834689621956886921">Elephant in the room: O1's ‚ÄòReasoning‚Äô might not be CoT itself as many may think of, but rather CoT is used to represent/monitoring the Reasoning result and as a means for RL. Might not be able to achieve 'strawberry' by trainin on CoT, which is a misconception.</A>
											<DT><A HREF="https://arxiv.org/abs/2305.20050">[2305.20050] Let's Verify Step by Step</A>
											<DT><A HREF="https://arxiv.org/abs/2112.00114">[2112.00114] Show Your Work: Scratchpads for Intermediate Computation with Language Models</A>
											<DT><A HREF="https://www.youtube.com/watch?v=_Bw5o55SRL8">Inference Time Compute - YouTube</A>
											<DT><A HREF="https://github.com/Dereck0602/Awesome_Test_Time_LLMs">Dereck0602/Awesome_Test_Time_LLMs</A>
											<DT><A HREF="https://x.com/heyyalexwang/status/1882128373515952202">(1) Alex Wang en X: "did you know you've been doing test-time learning this whole time? transformers, SSMs, RNNs, are all test-time regressors but with different design choices we present a unifying framework that derives sequence layers (and higher-order attentionüëÄ) from a *single* equation üßµ https://t.co/BEemnpWeeW" / X</A>
										</DL><p>
										<DT><H3 FOLDED>NaturalThoughts</H3>
										<DL><p>
											<DT><A HREF="https://x.com/jaseweston/status/1940656092054204498">Introducing NaturalThoughts</A>
											<DT><A HREF="https://arxiv.org/abs/2507.01921">[2507.01921] NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks</A>
											<DT><A HREF="https://x.com/paulcbogdan/status/1938287361525436864">What happens when a LLM reasons?</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2210.09261">[2210.09261] Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them</A>
										<DT><A HREF="https://github.com/FranxYao/chain-of-thought-hub">FranxYao/chain-of-thought-hub: Benchmarking large language models' complex reasoning ability with chain-of-thought prompting</A>
										<DT><A HREF="https://arxiv.org/pdf/2310.07923.pdf">THE EXPRESSIVE POWER OF TRANSFORMERS WITH CHAIN OF THOUGHT</A>
										<DT><A HREF="https://arxiv.org/abs/2310.10845">[2310.10845] CoTFormer: More Tokens With Attention Make Up For Less Depth</A>
										<DT><A HREF="https://arxiv.org/pdf/2311.01460.pdf">IMPLICIT CHAIN OF THOUGHT REASONING VIA KNOWLEDGE DISTILLATION (Microsoft)</A>
										<DT><A HREF="https://twitter.com/ZeyuanAllenZhu/status/1706829354888798296">Physics of Language Models: Part 3.2, knowledge manipulation</A>
										<DT><A HREF="https://github.com/neelnanda-io/CoT-Interp">neelnanda-io/CoT-Interp</A>
										<DT><A HREF="https://www.youtube.com/watch?v=9B_YxazMAY0">Fine, I'll talk about the Meta papers y'all keep sending me - YouTube</A>
										<DT><A HREF="https://arxiv.org/abs/2411.11984">[2411.11984] Understanding Chain-of-Thought in LLMs through Information Theory</A>
									</DL><p>
									<DT><H3 FOLDED>icl-continuous</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/daniel_m_cer/status/1528655068010106881/photo/1">(Lester, 2022)SPoT:  SOFT PROMPT</A>
										<DT><A HREF="https://ai.googleblog.com/2022/02/guiding-frozen-language-models-with.html">Google AI Blog: Guiding Frozen Language Models with Learned Soft Prompts</A>
										<DT><A HREF="https://arxiv.org/abs/2110.07904">LESTER SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer</A>
										<DT><A HREF="https://arxiv.org/abs/2104.08691">(Lester, 2021) The Power of Scale for Parameter-Efficient Prompt Tuning</A>
										<DT><A HREF="https://arxiv.org/abs/2106.07704">HTP Text Generation with Efficient (Soft) Q-Learning</A>
										<DT><A HREF="https://arxiv.org/abs/2104.05240">Soft-prompt: Factual Probing Is [MASK]: Learning vs. Learning to Recall</A>
										<DT><A HREF="https://arxiv.org/abs/2104.06599">Soft Prompts: Learning How to Ask: Querying LMs with Mixtures of Soft Prompts</A>
										<DT><A HREF="https://arxiv.org/abs/2101.00190">HT: (0.1%params) Prefix-Tuning: Optimizing Continuous Prompts</A>
									</DL><p>
									<DT><H3 FOLDED>icl-notes</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/tuvuumass">Tu Vu (@tuvuumass) / Twitter</A>
										<DT><A HREF="https://twitter.com/sangmichaelxie/status/1554553711241805824">In-Context Learning as Bayesian Inference</A>
										<DT><A HREF="https://twitter.com/quocleix/status/1532072473763532802">Least-to-most prompting: Teach How To Breakdown Complex Problems</A>
										<DT><A HREF="https://twitter.com/_jasonwei/status/1529292177414799361">Self-Supervised Chain Of Thought by introducing "Step by step" reasoning</A>
										<DT><A HREF="https://twitter.com/AkariAsai/status/1528996269280022528">Akari Asai en Twitter: "Introducing ùóîùóßùóßùóòùó†ùó£ùóß, a new modular, multi-task, and parameter-efficient approach to combine knowledge from multiple tasks to solve a new task using a small trainable of parameters üî• while keeping the original LM *frozen* üßä [1/9] Paper üìú: https://t.co/IgJvwCX5tU https://t.co/u26WVGCwsc" / Twitter</A>
										<DT><A HREF="https://twitter.com/tsiprasd/status/1555302289824366592">LLMs can do in-context learning, but are they "learning" new tasks</A>
										<DT><A HREF="https://twitter.com/Fortune_VY/status/1550819534940114946">(Q,A,R): what should be learned to achieve the correct answer (VERIFIERS)</A>
									</DL><p>
									<DT><H3 FOLDED>icl-vision</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2203.05557.pdf">Conditional Prompt Learning for Vision-Language Models</A>
										<DT><A HREF="https://arxiv.org/abs/2109.01134">[2109.01134] Learning to Prompt for Vision-Language Models</A>
										<DT><A HREF="https://arxiv.org/abs/2110.08484">A Good Prompt Is Worth Millions of Parameters</A>
									</DL><p>
									<DT><H3 FOLDED>icl-gradient-descent</H3>
									<DL><p>
										<DT><A HREF="https://x.com/askalphaxiv/status/1949437718066573429">In-context learning is just gradient descent without explicit training</A>
										<DT><A HREF="https://www.alphaxiv.org/pdf/2507.16003">Learning without training: The implicit dynamics of in-context learning | alphaXiv</A>
									</DL><p>
									<DT><H3 FOLDED>system prompt</H3>
									<DL><p>
										<DT><A HREF="https://x.com/NorthstarBrain/status/1804823489632723057">claude 3.5 Sonnet: system prompt</A>
										<DT><A HREF="https://x.com/_xjdr/status/1955134631378030806">self-reflection: are you sure about that?</A>
										<DT><A HREF="https://x.com/cloneofsimo/status/1965263486357045567">(1) Simo Ryu en X: "* Dont use try-except, like ever * Dont use cringy emojis, like ever * make sure to remove any artifacts you generated * Dont make readme after youve done your job * Think of the test you would need to pass, write that test, and test your implementation against it. * Dont fucking" / X</A>
									</DL><p>
									<DT><H3 FOLDED>context distillation</H3>
									<DL><p>
										<DT><H3 FOLDED>context-xml</H3>
										<DL><p>
											<DT><A HREF="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags#example-generating-financial-reports">Use XML tags to structure your prompts - Anthropic</A>
										</DL><p>
										<DT><H3 FOLDED>gitingest</H3>
										<DL><p>
											<DT><H3 FOLDED>shell-tree</H3>
											<DL><p>
												<DT><A HREF="https://www.geeksforgeeks.org/linux-unix/tree-command-unixlinux/">tree Command in Linux with Examples - GeeksforGeeks</A>
											</DL><p>
											<DT><A HREF="https://gitingest.com/">Gitingest</A>
											<DT><A HREF="https://claude.ai/chat/9608d203-e447-4472-9a1e-037f522aac85">Context Engineering for Code Ingestion - Claude</A>
											<DT><A HREF="https://github.com/coderamp-labs/gitingest">coderamp-labs/gitingest: Replace 'hub' with 'ingest' in any GitHub URL to get a prompt-friendly extract of a codebase</A>
											<DT><A HREF="https://github.com/microsoft/markitdown">microsoft/markitdown: Python tool for converting files and office documents to Markdown.</A>
											<DT><A HREF="https://x.com/nrehiew_/status/1987160874671538344">(1) wh en X: "1 example is the task of turning a part of the codebase into a minimal self-contained gist that can be run in a standalone manner. Evaluates coding ability, code understanding and the ability to extract only relevant parts from a code base https://t.co/Hr0PWj8BQb" / X</A>
										</DL><p>
										<DT><H3 FOLDED>agentic-code-search</H3>
										<DL><p>
											<DT><A HREF="https://benanderson.work/blog/agentic-search-for-dummies/">Agentic Search for Dummies</A>
										</DL><p>
										<DT><A HREF="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview">Prompt engineering overview - Anthropic</A>
										<DT><A HREF="https://arxiv.org/abs/2507.13334">[2507.13334] A Survey of Context Engineering for Large Language Models</A>
										<DT><A HREF="https://www.youtube.com/watch?v=33TkQ4ZCTww">GEPA REFLECTIVE PROMPT EVOLUTION CAN OUTPERFORM REINFORCEMENT LEARNING - YouTube</A>
										<DT><A HREF="https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus">Context Engineering for AI Agents: Lessons from Building Manus</A>
										<DT><A HREF="https://x.com/karpathy/status/1961128638725923119">(1) Andrej Karpathy en X: "Transforming human knowledge, sensors and actuators from human-first and human-legible to LLM-first and LLM-legible is a beautiful space with so much potential and so much can be done... One example I'm obsessed with recently - for every textbook pdf/epub, there is a perfect https://t.co/KmIdMI96ws" / X</A>
										<DT><A HREF="https://www.primeintellect.ai/blog/rlm">Recursive Language Models: the paradigm of 2026</A>
										<DT><A HREF="https://x.com/_alyxya">IMO the obvious next step towards AGI is scaling context distillation. I believe it's substantially better than reinforcement learning for training, and online context distillation enables continually learning LLMs</A>
										<DT><A HREF="https://x.com/itsclivetime/status/2015709176530669633">codex  TWELVE context compactions</A>
										<DT><A HREF="https://x.com/primeintellect/status/2006834561637036272?s=12">(1) Prime Intellect en X: "We believe the next breakthrough in long-horizon agents is training models to manage their own context. Introducing our new research direction on Recursive Language Models. We are sharing our initial experiments showing the promise of RLMs. https://t.co/NwgFbn6kwa" / X</A>
										<DT><A HREF="https://x.com/a1zhang/status/2007198916073136152">(1) Alex L Zhang en X: "Much like the switch in 2025 from language models to reasoning models, we think 2026 will be all about the switch to Recursive Language Models (RLMs). It turns out that models can be far more powerful if you allow them to treat *their own prompts* as an object in an external https://t.co/6jCyZiLeQl" / X</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2208.01066">[Universal Approximator] What Can Transformers Learn In-Context?</A>
									<DT><A HREF="https://openreview.net/forum?id=8p3fu56lKc&referrer=%5Bthe%20profile%20of%20Tengyu%20Ma%5D(%2Fprofile%3Fid%3D~Tengyu_Ma1)">One Step of Gradient Descent is Provably the Optimal In-Context Learner with One Layer of Linear Self-Attention | OpenReview</A>
									<DT><A HREF="https://arxiv.org/pdf/2212.07677.pdf">Transformers Learn In-Context by Gradient Descent</A>
									<DT><A HREF="https://arxiv.org/abs/2305.08298">Symbol tuning improves in-context learning in language models</A>
									<DT><A HREF="https://arxiv.org/pdf/2206.07682.pdf">(Wei, 2022) Emergent Abilities of Large Language Models</A>
									<DT><A HREF="https://arxiv.org/pdf/2201.11903.pdf">(Wei, 2022) CHAIN OF THOUGHT</A>
									<DT><A HREF="https://arxiv.org/pdf/2005.14165.pdf">(Brown, 2020) Language Models are Few-Shot Learners</A>
									<DT><A HREF="https://rylanschaeffer.github.io/blog_posts/2022-01-20-google-brain-flan.html">FLAN: Finetuned Language Models are Zero-Shot Learners</A>
									<DT><A HREF="https://arxiv.org/abs/2401.14953">[2401.14953] Learning Universal Predictors</A>
									<DT><A HREF="https://github.com/google-deepmind/neural_networks_solomonoff_induction">google-deepmind/neural_networks_solomonoff_induction</A>
									<DT><A HREF="https://arxiv.org/html/2311.07772v4#bib.bib13">In-context Learning and Gradient Descent Revisited</A>
									<DT><A HREF="https://paperswithcode.com/paper/finetuned-language-models-are-zero-shot">Finetuned Language Models Are Zero-Shot Learners</A>
									<DT><A HREF="https://openreview.net/pdf?id=NiEtU7blzN">LARGE LANGUAGE MODELS CAN SELF-IMPROVE</A>
									<DT><A HREF="https://www.lesswrong.com/posts/qwqowdhnMreKQvxLv/paper-large-language-models-can-self-improve-linkpost">Large Language Models Can Self-improve (Semi-Supervised Learning)</A>
									<DT><A HREF="https://arxiv.org/pdf/2102.07350.pdf">Prompt Programming for Large Language Models</A>
									<DT><A HREF="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">(OpenAI GPT2, 2019) Language Models are Unsupervised Multitask Learners</A>
									<DT><A HREF="https://arxiv.org/pdf/2107.13586.pdf">MAIN (Liu, 2021) Pre-train, Prompt, and Predict: Systematic Survey</A>
									<DT><A HREF="https://arxiv.org/pdf/2012.15723.pdf">(Gao, 2021) Making Pre-LLM Better Few-shot Learners</A>
									<DT><A HREF="http://pretrain.nlpedia.ai/">PRETRAIN LANGUAGE MODELS</A>
									<DT><A HREF="http://pretrain.nlpedia.ai/data/pdf/basics.pdf">Formalization of Prompting</A>
									<DT><A HREF="https://arxiv.org/abs/2112.00114">(Nye, 2021) SCRATCHPADS for Intermediate Computation</A>
									<DT><A HREF="https://arxiv.org/abs/2110.08207">(Prompt Training, 2021) Multitask Prompted Training Enables Zero-Shot Task Generalization</A>
									<DT><A HREF="https://aclanthology.org/2022.acl-long.60.pdf">(THEORY, 2022) An Information-theoretic Approach</A>
									<DT><A HREF="https://arxiv.org/abs/2103.10385">(Liu, 2021) P-Tuning: GPT Understands, Too</A>
									<DT><A HREF="https://arxiv.org/abs/2104.08786">Overcoming Few-Shot Prompt ORDER SENSITIVITY</A>
									<DT><A HREF="https://arxiv.org/abs/2205.12548">[2205.12548] RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning</A>
									<DT><A HREF="https://www.youtube.com/watch?v=8HwHGGb1zpQ&t=2474s">Prompt-based learning</A>
									<DT><A HREF="https://arxiv.org/abs/2203.06566">PromptChainer: Visual Programming</A>
									<DT><A HREF="https://arxiv.org/abs/2103.08493">HT How Many Data Points is a Prompt Worth?</A>
									<DT><A HREF="https://arxiv.org/abs/2101.06804">(Liu, 2021) What Makes Good In-Context Examples for GPT-3?</A>
									<DT><A HREF="https://github.com/microsoft/semantic-kernel/blob/main/python/README.md">semantic-kernel/README.md at main</A>
									<DT><A HREF="https://arxiv.org/pdf/2303.03846.pdf">LARGER LANGUAGE MODELS DO IN-CONTEXT LEARNING DIFFERENTLY</A>
									<DT><A HREF="https://arxiv.org/abs/2210.09261">Challenging BIG-Bench Tasks and Whether CoT Can Solve Them</A>
									<DT><A HREF="https://twitter.com/_akhaliq/status/1736581357705314731">ReST meets ReAct: Self-Improvement for Multi-Step Reasoning</A>
									<DT><A HREF="https://docs.google.com/document/d/1x3TRnRXz8PCHAWAgb7pzNfgAfBuKPxsyvBVZKXKeBFc/edit#">Experimentation Prompts: Infographics - Google Docs</A>
									<DT><A HREF="https://x.com/davidsamuelcz/status/1800213563124097476">(1) David Samuel en X: "BERTs are not dead!üßü But just misunderstood and overshadowed by their GPT siblings. In this paper, we travel back into 2020 and speculate on an alternative history where DeBERTa is the first model to show in-context learning abilities. Paper: https://t.co/vTPxC3UtqU 1/6 https://t.co/ipVu3bAQvx" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2406.04823">[2406.04823] BERTs are Generative In-Context Learners</A>
									<DT><A HREF="https://x.com/EricElmoznino/status/1848416471795614076">Lens of Occam's Razon, giving a normative account of next token prediction objectives</A>
									<DT><A HREF="https://www.youtube.com/watch?v=qR56cyMdDXg">Every attention head explained - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>sampling</H3>
								<DL><p>
									<DT><H3 FOLDED>parallel-test-time-compute</H3>
									<DL><p>
										<DT><H3 FOLDED>Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking</H3>
										<DL><p>
											<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
											<DT><A HREF="https://github.com/facebookresearch/xformers/blob/c909f0d6a3f991c547bebe24b312286632a73473/xformers/ops/fmha/flash3.py#L56">xformers/xformers/ops/fmha/flash3.py at c909f0d6a3f991c547bebe24b312286632a73473 ¬∑ facebookresearch/xformers</A>
											<DT><A HREF="https://gist.github.com/Chillee/2e270fc5413dbbce58c779f8c4eac66c">flex_attention_tutorial.py</A>
											<DT><A HREF="https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit">The Custom Operators Manual - Google Docs</A>
											<DT><A HREF="https://github.com/sgl-project/sglang/blob/a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0/python/sglang/srt/layers/prefill_attention.py#L147">sglang/python/sglang/srt/layers/prefill_attention.py at a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0 ¬∑ sgl-project/sglang</A>
											<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/flash/flash_attention.py#L340">transformer_nuggets/transformer_nuggets/flash/flash_attention.py at 83f754eb670b73aa789a924b6b9fab67784ca28f ¬∑ drisspg/transformer_nuggets</A>
											<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173/6">Getting Triton to generate all kernels - torch.compile / torch._inductor - PyTorch Forums</A>
											<DT><A HREF="https://gist.github.com/gradjitta/550f6a7666228c8539ca11fc78f4ec95">custom op for flash attention 3 (compatible with torch.compile)</A>
											<DT><A HREF="https://gist.github.com/antferdom/f7874ab68f4c1183d2b8196d2ace3ffc">FlashAttention v3 within torch.compile compatible</A>
											<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/e2182cc21d5be2a1d71c8ca7eb1bc425563041f1/hopper/benchmark_attn.py#L236">flash-attention/hopper/benchmark_attn.py at e2182cc21d5be2a1d71c8ca7eb1bc425563041f1 ¬∑ Dao-AILab/flash-attention</A>
											<DT><A HREF="https://github.com/search?q=repo%3Apytorch%2Fpytorch%20scaled_dot_product_attention&type=code">Code search results</A>
											<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-894/developer-guide/index.html">Developer Guide :: NVIDIA cuDNN Documentation</A>
											<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/issues/52">What's the difference of flash attention implement between cudnn and Dao-AILab? ¬∑ Issue #52 ¬∑ NVIDIA/cudnn-frontend</A>
											<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/1.0/release/samples/python/test_mhas.py#L431">cudnn-frontend/samples/python/test_mhas.py at 1.0/release ¬∑ NVIDIA/cudnn-frontend</A>
											<DT><A HREF="https://drive.google.com/drive/u/3/home">Home - Google Drive</A>
											<DT><A HREF="https://pytorch.org/tutorials/advanced/cpp_custom_ops.html#testing-an-operator">Custom C++ and CUDA Operators ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
											<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html">torch.nn.functional.scaled_dot_product_attention ‚Äî PyTorch 2.4 documentation</A>
											<DT><A HREF="https://www.youtube.com/watch?v=-adYfpAenvo&t=117s">Pearl Harbor - Japanese Empire - Theme Suite - YouTube</A>
											<DT><A HREF="https://x.com/i/bookmarks?post_id=1835352391648158189">(1) Guardados / X</A>
											<DT><A HREF="https://arxiv.org/pdf/2403.09629">https://arxiv.org/pdf/2403.09629</A>
										</DL><p>
										<DT><A HREF="https://x.com/i/bookmarks?post_id=1835352391648158189">This is my current mental model for how o1 works (replace batch for parallel generation in the last picture)</A>
									</DL><p>
									<DT><H3 FOLDED>Contrastive Search</H3>
									<DL><p>
										<DT><A HREF="https://github.com/yxuansu/SimCTG">yxuansu/SimCTG: [NeurIPS'22] A Contrastive Framework for Neural Text Generation</A>
										<DT><A HREF="https://arxiv.org/abs/2210.14140">[2210.14140] Contrastive Search Is What You Need For Neural Text Generation</A>
										<DT><A HREF="https://twitter.com/joao_gante/status/1590293010385760256">Contastive Search</A>
										<DT><A HREF="https://huggingface.co/blog/introducing-csearch">Generating Human-level Text with Contrastive Search in Transformers ü§ó</A>
									</DL><p>
									<DT><H3 FOLDED>deterministic</H3>
									<DL><p>
										<DT><H3 FOLDED>Greedy Search</H3>
										<DL><p>
											<DT><A HREF="https://en.wikipedia.org/wiki/Beam_search">Beam search - Wikipedia</A>
											<DT><A HREF="https://twitter.com/cwolferesearch/status/1659608476455256078">Greedy decoding steps and theory</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>stochastic</H3>
									<DL><p>
										<DT><H3 FOLDED>top-k</H3>
										<DL><p>
											<DT><A HREF="https://x.com/elliotarledge/status/1975369732112216207/photo/1">(1) Elliot Arledge (h/eng) en X: "TOP_P vs TOP_K https://t.co/o7O00jKITE" / X</A>
										</DL><p>
										<DT><H3 FOLDED>nNucleus-top-p</H3>
										<DL><p>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>grammar-based</H3>
									<DL><p>
										<DT><H3 FOLDED>xgrammar</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mlc-ai/xgrammar">mlc-ai/xgrammar</A>
											<DT><A HREF="https://arxiv.org/abs/2411.15100">[2411.15100] XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models</A>
										</DL><p>
										<DT><A HREF="https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/lmsys_1st_meetup_xgrammar.pdf">sgl-learning-materials/slides/lmsys_1st_meetup_xgrammar.pdf at main ¬∑ sgl-project/sgl-learning-materials</A>
										<DT><A HREF="https://github.com/outlines-dev/outlines">outlines-dev/outlines: Structured Text Generation</A>
										<DT><A HREF="https://github.com/outlines-dev/outlines/blob/main/outlines/grammars/arithmetic.lark">outlines/outlines/grammars/arithmetic.lark at main ¬∑ outlines-dev/outlines</A>
										<DT><A HREF="https://github.com/ggerganov/llama.cpp/issues/4218">llama : speed-up grammar sampling ¬∑ Issue #4218 ¬∑ ggerganov/llama.cpp</A>
										<DT><A HREF="https://lmsys.org/blog/2024-02-05-compressed-fsm/">Fast JSON Decoding for Local LLMs with Compressed Finite State Machine | LMSYS Org</A>
										<DT><A HREF="https://huggingface.co/docs/text-generation-inference/en/conceptual/guidance">Guidance</A>
										<DT><A HREF="https://github.com/rhohndorf/pydantic-gbnf-grammar-generator">rhohndorf/pydantic-gbnf-grammar-generator: Generates llama.cpp compatible grammars from pydantic objects</A>
										<DT><A HREF="https://saibo-creator.github.io/uploads/NexThink_talk_2024_06_18.pdf">Grammar-Constrained Decoding for Large Language Models</A>
										<DT><A HREF="https://arxiv.org/html/2312.07104v2">SGLang: Efficient Execution of Structured Language Model Programs</A>
										<DT><A HREF="https://www.aidancooper.co.uk/constrained-decoding/">A Guide to Structured Outputs Using Constrained Decoding</A>
										<DT><A HREF="https://x.com/mrsiipa/status/1860642562517913742">(1) maharshi en X: "what an amazing read: converting json to regex then regex to finite state machines, and then optimising it is brilliant! https://t.co/K0232ncNe8" / X</A>
									</DL><p>
									<DT><H3 FOLDED>entropy-decoding</H3>
									<DL><p>
										<DT><H3 FOLDED>entropix</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Pleias/Quest-Best-Tokens/blob/main/New%20physics%20of%20LLM.pdf">Quest-Best-Tokens/New physics of LLM.pdf at main ¬∑ Pleias/Quest-Best-Tokens</A>
											<DT><A HREF="https://x.com/Dorialexander/status/1868284566055821672">(1) Alexander Doria en X: "I'm releasing my ongoing experiments of using attention score to enhance the reliability of retrieval-augmented generation. https://t.co/9bHuRmhKJd Similarly to the entropix/softmax is not enough reproduction, code provides a slow dive into LLM internals using pytorch directly. https://t.co/6iCiM40CMs" / X</A>
											<DT><A HREF="https://github.com/xjdr-alt/entropix">xjdr-alt/entropix: Entropy Based Sampling and Parallel CoT Decoding</A>
										</DL><p>
										<DT><H3 FOLDED>DeepThink</H3>
										<DL><p>
											<DT><A HREF="https://jiaweizzhao.github.io/deepconf/">Deep Think with Confidence</A>
											<DT><A HREF="https://github.com/vllm-project/vllm/pull/23201">[Misc][Feature] confidence based early stopping by Viol2000 ¬∑ Pull Request #23201 ¬∑ vllm-project/vllm</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/math/0211159">[math/0211159] The entropy formula for the Ricci flow and its geometric applications</A>
										<DT><A HREF="https://x.com/_xjdr/status/1859658343587119463">(1) xjdr en X: "large scale synthetic data generation post training without humans in the loop test time steering with external verifiers this is the way to the frontier" / X</A>
										<DT><A HREF="https://github.com/xjdr-alt/llmri/blob/main/plots.ipynb">llmri/plots.ipynb at main ¬∑ xjdr-alt/llmri</A>
										<DT><A HREF="https://arxiv.org/abs/2601.03220">[2601.03220] From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=AvHLJqtmQkE">Typical Decoding for Natural Language Generation</A>
									<DT><A HREF="https://huggingface.co/blog/how-to-generate">Basics</A>
									<DT><A HREF="https://arxiv.org/abs/2307.15337">[2307.15337] Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding</A>
									<DT><A HREF="https://arxiv.org/pdf/1905.00174.pdf">Unsupervised Temperature Scaling</A>
									<DT><A HREF="https://blog.research.google/2024/01/introducing-aspire-for-selective.html">Introducing ASPIRE for selective prediction in LLMs ‚Äì Google Research Blog</A>
									<DT><A HREF="https://arxiv.org/abs/2406.16838">[2406.16838] From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models</A>
									<DT><A HREF="https://x.com/wellecks/status/1806326626546036802">(1) Sean Welleck en X: "What do nucleus sampling, tree-of-thought, and PagedAttention have in common? They're all part of our new survey: "From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models" https://t.co/faHwQcxLUX https://t.co/eY9cNstBbd" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2408.04220">[2408.04220] Diffusion Guided Language Modeling</A>
									<DT><A HREF="https://github.com/spcl/graph-of-thoughts">spcl/graph-of-thoughts: Official Implementation of "Graph of Thoughts: Solving Elaborate Problems with Large Language Models"</A>
									<DT><A HREF="https://github.com/codelion/optillm">codelion/optillm: Optimizing inference proxy for LLMs</A>
									<DT><A HREF="https://blog.dottxt.co/coalescence.html">Coalescence: making LLM inference 5x faster</A>
								</DL><p>
								<DT><H3 FOLDED>reasoning-latent-space</H3>
								<DL><p>
									<DT><H3 FOLDED>coconut</H3>
									<DL><p>
										<DT><A HREF="https://x.com/OhadRubin/status/1922904474042933470">COCONUT: is slow and not scalable</A>
										<DT><A HREF="https://arxiv.org/pdf/2412.06769">Training Large Language Models to Reason in a Continuous Latent Space</A>
										<DT><A HREF="https://x.com/nrehiew_/status/1866488228607582503">(1) wh en X: "This paper from Meta proposes a method to not have the model reason in token space but directly model its reasoning using its hidden state. The authors also do a lot of cool interpretability work in this paper. Aesthetically, I like it alot and its simple to implement https://t.co/QafTwY542x" / X</A>
										<DT><A HREF="https://x.com/nrehiew_/status/1866846473138421930">(1) wh en X: "So my idea is that &amp;gt; We don't want to just naively concat the last hidden state &amp;gt; The latent that we concat back should be dynamic based on the current state &amp;gt; its literally what attention is used for https://t.co/aT5M0Y9HHe" / X</A>
										<DT><A HREF="https://x.com/RidgerZhu/status/1983732551404679632">Scaling Latent Reasoning via Looped Language Models.</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=MAC544dQ9no">A Framework to Leverage Latent Space Exploration for Novelty Discovery - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>hierarchical-reasoning</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2506.21734">[2506.21734] Hierarchical Reasoning Model</A>
									<DT><A HREF="https://x.com/Dorialexander/status/1951954826545238181">Also they include multiple baselines, including a standard transformer which performs surprisingly well but clearly not to the point where it would have memorized the test set.</A>
								</DL><p>
								<DT><A HREF="https://lilianweng.github.io/posts/2025-05-01-thinking/">Why We Think | Lil'Log</A>
								<DT><A HREF="https://arxiv.org/abs/2311.11045">[2311.11045] Orca 2: Teaching Small Language Models How to Reason</A>
								<DT><A HREF="https://www.youtube.com/watch?v=pA-azVdihQc&t=1890s">What is Machine Learning Good For? - Alex Davies (DeepMind)</A>
								<DT><A HREF="https://huggingface.co/microsoft/Orca-2-13b">microsoft/Orca-2-13b ¬∑ Hugging Face</A>
								<DT><A HREF="https://www.youtube.com/watch?v=QDkm_BU9Deo">[short] Generative AI for Math: Part I MATHPILE: A Billion-Token-Scale Pretraining Corpus for Math - YouTube</A>
								<DT><A HREF="https://x.com/deepseek_ai/status/1859200141355536422">DeepSeek-R1-Lite-Preview</A>
								<DT><A HREF="https://github.com/ethansmith2000/neurallambda">ethansmith2000/neurallambda: Reasoning Computers. Lambda Calculus, Fully Differentiable. Also Neural Stacks, Queues, Arrays, Lists, Trees, and Latches.</A>
								<DT><A HREF="https://x.com/nrehiew_/status/1866488228607582503">(1) wh en X: "This paper from Meta proposes a method to not have the model reason in token space but directly model its reasoning using its hidden state. The authors also do a lot of cool interpretability work in this paper. Aesthetically, I like it alot and its simple to implement https://t.co/QafTwY542x" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=_Bw5o55SRL8">Inference Time Compute - YouTube</A>
								<DT><A HREF="https://docs.google.com/document/d/16SXbrv9-9L5ANnXxQJlFeXy6AQHYSymvmSDJxB4yudc/edit?tab=t.0#heading=h.goep0zm9mhkk">26dec24 - spot check of reasoning systems - Google Docs</A>
								<DT><A HREF="https://www.youtube.com/watch?v=7Gfn4eK8myg">REFT Reasoning with REinforced Fine TuningByteDance 2024 - YouTube</A>
								<DT><A HREF="https://x.com/_xjdr/status/1875295492906828005">(1) xjdr en X: "if you will forgive a bit of anthropomorphizing, to the extent models think, they do not think in tokens. tokens are merely our samplers' best interpretation of the probability distributions that emerge from the actual 'thinking' process. they're an incredibly low bandwidth" / X</A>
								<DT><A HREF="https://x.com/hxiao/status/1886250705415229627">OpenAI's Deep Research</A>
								<DT><A HREF="https://x.com/_akhaliq/status/1912803526255800369">ReTool: Reinforment Learning for Strategic Tool use in LLMs, ByteDance Seed</A>
								<DT><A HREF="https://arxiv.org/abs/2504.11536">[2504.11536] ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</A>
								<DT><A HREF="https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning">microsoft/Phi-4-mini-flash-reasoning ¬∑ Hugging Face</A>
								<DT><A HREF="https://x.com/novasarc01/status/1952313092786073784">(1) Œªux en X: "i) adding more reasoning steps doesn‚Äôt always improve final accuracy ii) sampling multiple reasoning paths and voting doesn‚Äôt scale efficiently iii) asking a model to critique its own answer repeatedly often leads to redundancy or contradiction" / X</A>
								<DT><A HREF="https://github.com/richards199999/Thinking-Claude">richards199999/Thinking-Claude: Let your Claude able to think</A>
								<DT><A HREF="https://x.com/hyhieu226/status/1969545587076055153">Hieu Pham en X: "Non-reasoning LLMs today are like blitz chess players. Their answers are not necessarily the best, but mostly good enough, and are generated almost instantly. Reasoning LLMs are like rapid chess players. They think longer and give better answers. Then we have the classical" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2510.06828">[2510.06828] Recurrence-Complete Frame-based Action Models</A>
								<DT><A HREF="https://x.com/jeanfrancois287/status/1921955463156883901">(1) Jean-Fran√ßois Ton en X: "üì¢New Paper on Process Reward Modelling üì¢ Ever wondered about the pathologies of existing PRMs and how they could be remedied? In our latest paper, we investigate this through the lens of Information theory! #icml2025 Here‚Äôs a üßµon how it works üëá https://t.co/nzDr4Wrl15 https://t.co/XOAg6C0MVu" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2411.11984">[2411.11984] Understanding Chain-of-Thought in LLMs through Information Theory</A>
								<DT><A HREF="https://x.com/_AndrewZhao/status/1986816053851087097">video reasoning</A>
								<DT><A HREF="https://www.linkedin.com/posts/natolambert_deepseek-r1-incentivizing-reasoning-capability-activity-7412895062390538240-fS4Y/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">list of reasoning models with solid tech reports for 2025</A>
							</DL><p>
							<DT><H3 FOLDED>aligment</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/@AlignmentWorkshop">Alignment Workshop - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-8mKJd2SwI4">Owain Evans - Out-of-context Reasoning in LLMs - YouTube</A>
								<DT><A HREF="https://x.com/Dorialexander/status/1951954826545238181">Also they include multiple baselines, including a standard transformer which performs surprisingly well but clearly not to the point where it would have memorized the test set.</A>
							</DL><p>
							<DT><H3 FOLDED>NEXT-TOKEN PREDICTION</H3>
							<DL><p>
								<DT><H3 FOLDED>multi-token-prediction</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/facebook/multi-token-prediction">facebook/multi-token-prediction ¬∑ Hugging Face</A>
									<DT><A HREF="https://x.com/syhw/status/1803112949566799902">facebook/multi-token-prediction</A>
								</DL><p>
								<DT><H3 FOLDED>token trajectory trees</H3>
								<DL><p>
									<DT><A HREF="https://x.com/voooooogel/status/1920595250986295554/photo/1">(1) thebes en X: "announcing an open beta of logitloomüå±, the tool i've been working on for exploring token trajectory trees (aka looming) on base and instruct models! https://t.co/y9RfEGJmHJ" / X</A>
									<DT><A HREF="https://github.com/vgel/logitloom">vgel/logitloom: explore token trajectory trees on instruct and base models</A>
								</DL><p>
								<DT><H3 FOLDED>logprobs</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>next-token-prediction-fractal</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2402.01825">[2402.01825] Fractal Patterns May Illuminate the Success of Next-Token Prediction</A>
									<DT><A HREF="https://x.com/attentionmech/status/1921852374693327040">(1) attentionmech en X: "paper reading thread (old paper) https://t.co/Z36SR3Avsz" / X</A>
								</DL><p>
								<DT><A HREF="https://yongzx.substack.com/p/rl-vs-next-token-prediction-why-should">RL vs next-token-prediction: why should it be a dichotomy?</A>
								<DT><A HREF="https://arxiv.org/pdf/2403.06963.pdf">THE PITFALLS OF NEXT-TOKEN PREDICTION</A>
								<DT><A HREF="https://arxiv.org/abs/2411.00660">[2411.00660] Physics in Next-token Prediction</A>
								<DT><A HREF="https://github.com/gregorbachmann/Next-Token-Failures">gregorbachmann/Next-Token-Failures</A>
								<DT><A HREF="https://www.youtube.com/watch?v=OF8A_b-3q84">The mean and variance of inputs through the layers of a deep narrow neural network - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=MFOb9sh9geY">Multi-token Prediction and RemoteCLIP - YouTube</A>
								<DT><A HREF="https://moultano.wordpress.com/2023/06/28/the-many-ways-that-digital-minds-can-know/">The Many Ways that Digital Minds Can Know ‚Äì Ryan Moulton's Articles</A>
								<DT><A HREF="https://x.com/alesstolfo/status/1805976764705038708">LLMs don‚Äôt just output the next token, they also output confidence. How is this computed?</A>
							</DL><p>
							<DT><H3 FOLDED>generalization</H3>
							<DL><p>
								<DT><H3 FOLDED>transfer-learning</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://x.com/lilianweng/status/1944507067806720430">(1) Lilian Weng en X: "I still find it mysterious whether and how intelligence and capabilities transfer between domains and skills - from meta learning during early days to more recent question like whether solving maths helps writing a good essay. Sometime I feel a bit pessimistic given not enough" / X</A>
								<DT><A HREF="https://arxiv.org/pdf/2511.21692">Revisiting Generalization Across Difficulty Levels: It‚Äôs Not So Easy</A>
							</DL><p>
							<DT><H3 FOLDED>emergence</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>hallucinations</H3>
							<DL><p>
								<DT><A HREF="https://openai.com/index/why-language-models-hallucinate/">Why language models hallucinate | OpenAI</A>
								<DT><A HREF="https://www.youtube.com/watch?v=0dRouBLcvMs">Why Language Models Hallucinate - Adam Kalai - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2509.04664">[2509.04664] Why Language Models Hallucinate</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=E22AOHAEtu4">Advancing the Frontier of Silicon Intelligence: the Past, Open Problems, and the Future - YouTube</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Kolmogorov_complexity#Compression">Kolmogorov complexity - Wikipedia</A>
							<DT><A HREF="https://arxiv.org/pdf/1911.12543.pdf">How Can We Know What Language Models Know?</A>
							<DT><A HREF="https://openai.com/research/unsupervised-sentiment-neuron">Unsupervised sentiment neuron</A>
							<DT><A HREF="https://www.youtube.com/watch?v=KV5gbOmHbjU">A Mathematical Framework for Transformer Circuits</A>
							<DT><A HREF="https://towardsdatascience.com/visualizing-word-embedding-with-pca-and-t-sne-961a692509f5">Visualizing Word Embedding with PCA and t-SNE</A>
							<DT><A HREF="https://arxiv.org/pdf/2105.12202.pdf">LM Transformer based: Context Sensitive Models (Attention Mechanism)</A>
							<DT><A HREF="https://twitter.com/wesg52/status/1653750337373880322">What features are neurons in LLMs actualy extracting?</A>
							<DT><A HREF="https://www.youtube.com/watch?v=t5LjgczaS80&t=741s">Gail Weiss: Thinking Like Transformers</A>
							<DT><A HREF="https://arxiv.org/pdf/2211.03495.pdf">How Much Does Attention Actually Attend?</A>
							<DT><A HREF="https://arxiv.org/abs/2310.10348">[2310.10348] Attribution Patching Outperforms Automated Circuit Discovery</A>
							<DT><A HREF="https://twitter.com/aaquib_syed1/status/1714386165237776653">ttribution Patching Outperforms Automated Circuit Discovery (Thread)</A>
							<DT><A HREF="https://papers.labml.ai/paper/7719e8e6c2cf11edb95839eec3084ddd">Eliciting Latent Predictions from Transformers with the Tuned Lens</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Ohl5AGUOLXk">Quantifying and Understanding Memorization in DNN</A>
							<DT><A HREF="https://twitter.com/val_kharvd/status/1655397456652140545">Transformerlens</A>
							<DT><A HREF="https://www.youtube.com/watch?v=VY7SCl_DFho">Interpretable vs Explainable Machine Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2301.04589?utm_source=substack&utm_medium=email">Memory Augmented Large Language Models are Computationally Universal</A>
							<DT><A HREF="https://arxiv.org/abs/2212.08073">[2212.08073] Constitutional AI: Harmlessness from AI Feedback (Antrophic)</A>
							<DT><A HREF="https://bbycroft.net/llm">LLM Visualization</A>
							<DT><A HREF="https://www.eleuther.ai/papers-blog/pythia-a-suite-for-analyzing-large-language-modelsacross-training-and-scaling">Pythia: Analyzing Large Language Models Across Training and Scaling</A>
							<DT><A HREF="https://www.youtube.com/watch?v=M74WKIh0ciI&list=LL&index=24">Three weight matrices in a neural network growing connections as two parallel networks are merged. - YouTube</A>
							<DT><A HREF="https://www.youtube.com/@AlignmentWorkshop">Alignment Workshop - YouTube</A>
							<DT><A HREF="https://twitter.com/IasonGabriel/status/1781262674711466483">The Ethics of LLMS</A>
							<DT><A HREF="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/ethics-of-advanced-ai-assistants/the-ethics-of-advanced-ai-assistants-2024-i.pdf">The Ethics of Advanced AI Assistants</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Z1bXBinTtnQ">LLM - Reasoning SOLVED (new research) - YouTube</A>
							<DT><A HREF="https://x.com/franklyn_wang/status/1858527547484434515">(1) Franklyn Wang en X: "Doubling o1-preview performance on ARC-AGI with one simple trick üöÄ tldr: by providing human-like representations to o1, we are able to substantially increase performance on @arcprize. https://t.co/VIRMoBENjA" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2412.05117">[2412.05117] Transformers Can Navigate Mazes With Multi-Step Prediction</A>
						</DL><p>
						<DT><H3 FOLDED>Physics of Language Models</H3>
						<DL><p>
							<DT><H3 FOLDED>canon-layers</H3>
							<DL><p>
								<DT><A HREF="https://physics.allen-zhu.com/part-4-architecture-design/part-4-1">Physics of Language Models - Part 4.1: Architecture Design</A>
								<DT><A HREF="https://x.com/ZeyuanAllenZhu/status/1918684257058197922">(1) Zeyuan Allen-Zhu, Sc.D. en X: "(1/8)üçéA Galileo moment for LLM designüçé As Pisa Tower experiment sparked modern physics, our controlled synthetic pretraining playground reveals LLM architectures' true limits. A turning point that might divide LLM research into "before" and "after." https://t.co/7CZ6pTMlc9 https://t.co/MPQq5VcfGR" / X</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1919055890155462926">(1) Simo Ryu en X: "btw Shazeer and bros found this exact 3-token causal convolution thing 3 YEARS ago I swear to god every time there is meaningful improvement, Shazeer is involved somehow ??? How is this keep happening? https://t.co/2WCpNDbK25" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2109.08668">[2109.08668] Primer: Searching for Efficient Transformers for Language Modeling</A>
								<DT><A HREF="https://taylorkolasinski.com/notes/mhc-reproduction-part2/">10,924x: The Instability Bomb at 1.7B Scale - Taylor Kolasinski</A>
							</DL><p>
							<DT><H3 FOLDED>physics-language-lectures</H3>
							<DL><p>
								<DT><A HREF="https://www.linkedin.com/posts/zeyuan-allen-zhu_%F0%9D%90%96%F0%9D%90%9E%F0%9D%90%AB%F0%9D%90%9E-%F0%9D%90%AC%F0%9D%90%A9%F0%9D%90%9E%F0%9D%90%A7%F0%9D%90%9D%F0%9D%90%A2%F0%9D%90%A7%F0%9D%90%A0-%F0%9D%90%9B%F0%9D%90%A2%F0%9D%90%A5%F0%9D%90%A5%F0%9D%90%A2%F0%9D%90%A8%F0%9D%90%A7-activity-7417581364444639256-PGiT/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">That is what ùêèùê°ùê≤ùê¨ùê¢ùêúùê¨ ùê®ùêü ùêãùêöùêßùê†ùêÆùêöùê†ùêû ùêåùê®ùêùùêûùê•ùê¨ aims to change. Tutorial II is ùêßùê®ùê∞ ùêúùê®ùê¶ùê©ùê•ùêûùê≠ùêû.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=bpp6Dz8N2zY">Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=yBL7J0kgldU&list=PLIZhMKKbVX6JmdngPRKvAS4u4L97odbGp">ICML 2024 Tutorial: Physics of Language Models - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=x3G8knjPDbM">Physics of LM: Part 4.1a, How to Build a Versatile Synthetic Pretrain Playground - YouTube</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2305.13673">[2305.13673] Physics of Language Models: Part 1, Learning Hierarchical Language Structures</A>
							<DT><A HREF="https://physics.allen-zhu.com/part-2-grade-school-math/part-2-1">Physics of Language Models - Part 2.1, Hidden Reasoning Process</A>
							<DT><A HREF="https://physics.allen-zhu.com/part-3-knowledge/part-3-3">Physics of Language Models - Part 3.3: Scaling Laws</A>
							<DT><A HREF="https://x.com/i/bookmarks?post_id=1818493152711569551">(1/7) Physics of LM, Part 2.1 with 8 results for LLM reasoning is out: http://arxiv.org/abs/2407.20311. Probing reveals that LLMs secretly develop some "level-2" reasoning skill beyond Humans.</A>
							<DT><A HREF="https://x.com/ZeyuanAllenZhu/status/1887807438570877330">(1) Zeyuan Allen-Zhu, Sc.D. en X: "(1/8) We classify L1~L5 intelligence, and observe only Gemini-2-FT, DeepSeek-R1, OpenAI-o1 can reach L2; most are only L1 (o3-mini). Yet, one can still use L1-level AIs to arbitrate disputes and ensure fair review of L4-level scientific papers. (older tweet reached 70K views)‚¨áÔ∏è https://t.co/TWIs8NeUEU" / X</A>
							<DT><A HREF="https://physics.allen-zhu.com/part-4-architecture-design/part-4-1">Physics of Language Models - Part 4.1: Architecture Design Architecture Design and the Magic of Canon Layers</A>
							<DT><A HREF="https://x.com/ZeyuanAllenZhu/status/2000892470306152701">(1) Zeyuan Allen-Zhu, Sc.D. en X: "(1/N)üöÄToday we launch two tightly connected milestones in the Physics of LM series: a sharpened Part 4.1 (v2.0) and a brand new Part 4.2 ‚Äî together forming a clear, reproducible, textbook-style reference for principled architecture research. Part 4.1 introduced a synthetic https://t.co/Z2ZaVS2nZm" / X</A>
							<DT><A HREF="https://x.com/ZeyuanAllenZhu/status/2006221809998508180">(1) Zeyuan Allen-Zhu, Sc.D. en X: "Continuing Tutorial II for Physics of Language Models. We often trust large-scale results simply because they are large; but once noise is removed, the synthetic pretrain playground starts to push back ‚Äî hard! The second video (Part 4.1b, 90 minutes) makes this pushback https://t.co/MANabEO64X" / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=8tUIaSOTA7g">Physics of LM: Part 4.1b, Canon Layers &amp; Architectural Principles from Synthetic Pretrain Playground - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=niHNWJxmkW0">Physics of LM: Part 4.2, Canon Layers at Scale where Synthetic Pretraining Resonates in Reality - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>agents</H3>
						<DL><p>
							<DT><H3 FOLDED>agents-layout</H3>
							<DL><p>
								<DT><H3 FOLDED>agents-handoff</H3>
								<DL><p>
									<DT><A HREF="https://x.com/_xjdr/status/2010064772138676563">github issues, PRs, acceptance gates and http://HANDOFF.md docs</A>
								</DL><p>
								<DT><A HREF="https://x.com/_xjdr/status/2010064772138676563">Current setup. top left 5.2 XHigh (TL), bottom left 5.2 High (planner / problem solver) , Right Opus 4.5 (doer) . center nvim . i've tried many things but this is, in my opinion, the optimal set up (for me, right now)</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-tools</H3>
							<DL><p>
								<DT><H3 FOLDED>function calling</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2504.11536">[2504.11536] ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</A>
									<DT><A HREF="https://github.com/menloresearch/verifiers-deepresearch/pull/3">feat: use Qwen3 template for tool prompt by gau-nernst ¬∑ Pull Request #3 ¬∑ menloresearch/verifiers-deepresearch</A>
								</DL><p>
								<DT><H3 FOLDED>agents-bash</H3>
								<DL><p>
									<DT><A HREF="https://vercel.com/blog/we-removed-80-percent-of-our-agents-tools">We removed 80% of our agent‚Äôs tools: just do bash calls</A>
									<DT><A HREF="https://x.com/hanouticelina/status/2010664329545224588">(1) c√©lina en X: ""Bash is all you need" to build powerful agents - that's @anthropic's secret sauce behind Claude Code. why? Low context usage, composable, and agents can discover capabilities themselves via --ùöëùöéùöïùöô. So we built CLIs to allow coding agents to explore models, datasets and https://t.co/vekPrCIsJ4" / X</A>
								</DL><p>
								<DT><H3 FOLDED>mcp</H3>
								<DL><p>
									<DT><A HREF="https://x.com/alexalbert__/status/1861079762506252723">(1) Alex Albert en X: "Introducing the Model Context Protocol (MCP) An open standard we've been working on at Anthropic that solves a core challenge with LLM apps - connecting them to your data. No more building custom integrations for every data source. MCP provides one protocol to connect them all: https://t.co/kYsivQyPDq" / X</A>
									<DT><A HREF="https://github.com/modelcontextprotocol">Model Context Protocol</A>
									<DT><A HREF="https://github.com/modelcontextprotocol/create-python-server">modelcontextprotocol/create-python-server: Create a Python MCP server</A>
									<DT><A HREF="https://mcp.so/">MCP Servers</A>
									<DT><A HREF="https://developer.paypal.com/tools/mcp-server/">MCP server</A>
									<DT><A HREF="https://github.com/makenotion/notion-mcp-server">makenotion/notion-mcp-server: Official Notion MCP Server</A>
									<DT><A HREF="https://newsletter.victordibia.com/p/mcp-for-software-engineers-part-1">MCP server</A>
									<DT><A HREF="https://www.youtube.com/watch?v=T4-BdZQUCSE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=34&pp=iAQB">The Model Context Protocol: Connecting AI to Everything - Adam Jones, Anthropic - YouTube</A>
									<DT><A HREF="https://github.com/yctimlin/mcp_excalidraw">yctimlin/mcp_excalidraw</A>
								</DL><p>
								<DT><H3 FOLDED>agent2agent</H3>
								<DL><p>
									<DT><A HREF="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/">Announcing the Agent2Agent Protocol (A2A) - Google Developers Blog</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2302.04761">[2302.04761] Toolformer: Language Models Can Teach Themselves to Use Tools</A>
								<DT><A HREF="https://arxiv.org/abs/2504.11536">[2504.11536] ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</A>
								<DT><A HREF="https://vercel.com/blog/we-removed-80-percent-of-our-agents-tools">We removed 80% of our agent‚Äôs tools: just do bash calls</A>
							</DL><p>
							<DT><H3 FOLDED>agents-code</H3>
							<DL><p>
								<DT><H3 FOLDED>agents-code-notes</H3>
								<DL><p>
									<DT><A HREF="https://x.com/karpathy/status/2015883857489522876">(1) Andrej Karpathy en X: "A few random notes from claude coding quite a bit last few weeks. Coding workflow. Given the latest lift in LLM coding capability, like many others I rapidly went from about 80% manual+autocomplete coding and 20% agents in November to 80% agent coding and 20% edits+touchups in" / X</A>
								</DL><p>
								<DT><H3 FOLDED>environments</H3>
								<DL><p>
									<DT><H3 FOLDED>verifiers</H3>
									<DL><p>
										<DT><A HREF="https://github.com/willccbb/verifiers">willccbb/verifiers: Verifiers for LLM Reinforcement Learning</A>
										<DT><A HREF="https://www.jasonwei.net/blog/asymmetry-of-verification-and-verifiers-law">Asymmetry of verification and verifier‚Äôs law ‚Äî Jason Wei</A>
										<DT><A HREF="https://x.com/karpathy/status/1884676486713737258">Karpathy: help construct a high diversity of RL environments that help elicit LLM cognitive strategies</A>
										<DT><A HREF="https://hub.docker.com/r/volcengine/sandbox-fusion">volcengine/sandbox-fusion - Docker Image | Docker Hub</A>
										<DT><A HREF="https://x.com/karpathy/status/1960803117689397543">(1) Andrej Karpathy en X: "In era of pretraining, what mattered was internet text. You'd primarily want a large, diverse, high quality collection of internet documents to learn from. In era of supervised finetuning, it was conversations. Contract workers are hired to create answers for questions, a bit" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2506.00103">[2506.00103] Writing-Zero: Bridge the Gap Between Non-verifiable Tasks and Verifiable Rewards</A>
									</DL><p>
									<DT><H3 FOLDED>environments-hub</H3>
									<DL><p>
										<DT><A HREF="https://x.com/PrimeIntellect/status/1960783427948699680">(1) Prime Intellect en X: "Introducing the Environments Hub RL environments are the key bottleneck to the next wave of AI progress, but big labs are locking them down We built a community platform for crowdsourcing open environments, so anyone can contribute to open-source AGI https://t.co/urAv2hGPCQ" / X</A>
										<DT><A HREF="https://app.primeintellect.ai/dashboard/environments">Environments Hub | Prime Intellect</A>
									</DL><p>
									<DT><H3 FOLDED>nano-VM</H3>
									<DL><p>
										<DT><H3 FOLDED>vm-snapshot</H3>
										<DL><p>
											<DT><A HREF="https://cognition.ai/blog/blockdiff">Cognition | Blockdiff: How we built our own file format for VM disk snapshots</A>
											<DT><A HREF="https://criu.org/Main_Page">Welcome to CRIU, a project to implement checkpoint/restore functionality for Linux.</A>
											<DT><A HREF="https://www.morph.so/blog/lean-server-morph-cloud">INSTANTLY SCALABLE LEAN 4 PROVING ENVIRONMENTS ON MORPH CLOUD</A>
										</DL><p>
										<DT><H3 FOLDED>infinibranch</H3>
										<DL><p>
											<DT><A HREF="https://www.morph.so/blog/infinibranch/">INFINIBRANCH: THE DAWN OF NON-LINEAR COMPUTING</A>
											<DT><A HREF="https://x.com/jessemhan/status/1937236874114011260">(1) Jesse Michael Han en X: "awesome work and clear writeup. every agent runtime will need to branch and snapshot. the "open questions" at the end of this post have been solved at @morph_labs for a while with Infinibranch and are generally available for agent developers everywhere: https://t.co/hELgGAmAUt" / X</A>
											<DT><A HREF="https://x.com/jessemhan/status/1975711291424841793">(1) Jesse Michael Han en X: "why would you want to use this? - you need a lot of browsers running at once, for example agentic search over arxiv html pages, QA testing, fullstack development, comparing local dev to staging deployment, last-mile automation - you want to do browser use RL - you want to" / X</A>
											<DT><A HREF="https://github.com/morph-labs/morphcloud-examples-public/blob/main/lean-server/setup.py">morphcloud-examples-public/lean-server/setup.py at main ¬∑ morph-labs/morphcloud-examples-public</A>
										</DL><p>
										<DT><A HREF="https://www.linkedin.com/posts/novita-ai-labs_introducing-novita-sandbox-the-cost-effective-activity-7353099863892348928-atsc/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">Novita sandbox: agent env</A>
										<DT><A HREF="https://x.com/nanovms">NanoVMs (@nanovms) / X</A>
									</DL><p>
									<DT><H3 FOLDED>morph-labs</H3>
									<DL><p>
										<DT><A HREF="https://x.com/i/bookmarks">autonomous swe agents with foundational integration into infra</A>
										<DT><A HREF="https://x.com/jessemhan">(1) Jesse Michael Han (@jessemhan) / X</A>
										<DT><A HREF="https://cloud.morph.so/docs/llms.txt">https://cloud.morph.so/docs/llms.txt</A>
										<DT><A HREF="https://github.com/project-numina/kimina-lean-server">project-numina/kimina-lean-server: Kimina Lean server</A>
										<DT><A HREF="https://x.com/morph_labs/status/1919809219978776877">What if we had more empathy for the machine?</A>
										<DT><A HREF="https://www.morph.so/blog/fundraising-announcement-09-2024">ANNOUNCING OUR 5.75M SEED FUNDRAISE</A>
									</DL><p>
									<DT><A HREF="https://www.morph.so/blog/lean-server-morph-cloud">INSTANTLY SCALABLE LEAN 4 PROVING ENVIRONMENTS ON MORPH CLOUD</A>
									<DT><A HREF="https://github.com/agent-infra/sandbox">agent-infra/sandbox: All-in-One Sandbox for AI Agents that combines Browser, Shell, File, MCP and VSCode Server in a single Docker container.</A>
									<DT><A HREF="https://x.com/johannes_hage/status/1972535668061671723">look at your rollouts</A>
									<DT><A HREF="https://x.com/willccbb/status/1929975995475603729">RL wordle</A>
								</DL><p>
								<DT><H3 FOLDED>claude-code</H3>
								<DL><p>
									<DT><H3 FOLDED>claude-4</H3>
									<DL><p>
										<DT><H3 FOLDED>claude-4.5</H3>
										<DL><p>
											<DT><A HREF="https://x.com/claudeai/status/1972706807345725773">Claude en X: "Introducing Claude Sonnet 4.5‚Äîthe best coding model in the world. It's the strongest model for building complex agents. It's the best model at using computers. And it shows substantial gains on tests of reasoning and math. https://t.co/7LwV9WPNAv" / X</A>
										</DL><p>
										<DT><A HREF="https://x.com/AnthropicAI/status/1925591505332576377">Claude 4 code generation benchmarks</A>
										<DT><A HREF="https://www.anthropic.com/news/claude-4">Introducing Claude 4 \ Anthropic</A>
										<DT><A HREF="https://www.youtube.com/watch?v=EvtPBaaykdo">Code with Claude Opening Keynote - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>cc-install</H3>
									<DL><p>
										<DT><A HREF="https://docs.anthropic.com/en/docs/claude-code/overview">Claude Code overview - Anthropic</A>
									</DL><p>
									<DT><H3 FOLDED>cc-settings</H3>
									<DL><p>
										<DT><A HREF="https://docs.anthropic.com/en/docs/claude-code/settings">Claude Code settings - Anthropic</A>
										<DT><A HREF="https://x.com/bigeagle_xd/status/1951870677662978167">ANTHROPIC_BASE_URL, ANTHROPIC_API_KEY, ANTHROPIC_SMALL_FAST_MODEL, ANTHROPIC_MODEL</A>
									</DL><p>
									<DT><H3 FOLDED>cc-map-reduce</H3>
									<DL><p>
										<DT><A HREF="https://x.com/dionysianagent/status/1929532241534767168?s=12">how i set up 12+ claude 4 code agents to work in parallel mostly autonomously for several hours without conflicts or slop code</A>
										<DT><A HREF="https://x.com/DionysianAgent/status/1929337613292327231">here i'm running 12 - 16 claude 4 opus/sonnet code agents through claude code bridged to eigencode for coordination, additional memory layers &amp; additional tools</A>
										<DT><A HREF="https://www.youtube.com/watch?v=f8RnRuaxee8">Claude 4 ADVANCED AI Coding: How I PARALLELIZE Claude Code with Git Worktrees - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>cc-people</H3>
									<DL><p>
										<DT><A HREF="https://x.com/bcherny">Boris Cherny</A>
										<DT><A HREF="https://x.com/_catwu">cat</A>
									</DL><p>
									<DT><H3 FOLDED>cc-mcp</H3>
									<DL><p>
										<DT><A HREF="https://docs.anthropic.com/en/docs/claude-code/mcp">Model Context Protocol (MCP) - Anthropic</A>
									</DL><p>
									<DT><H3 FOLDED>cc-system-prompt</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=nT-vt-GO6IQ">Claude 4 System Prompt - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>cc-router</H3>
									<DL><p>
										<DT><A HREF="https://github.com/musistudio/claude-code-router/blob/main/blog/en/project-motivation-and-how-it-works.md">claude-code-router/blog/en/project-motivation-and-how-it-works.md at main ¬∑ musistudio/claude-code-router</A>
										<DT><A HREF="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router: Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</A>
										<DT><A HREF="https://github.com/zai-org/GLM-4.5/tree/main/example/claude_code">GLM-4.5/example/claude_code at main ¬∑ zai-org/GLM-4.5</A>
										<DT><A HREF="https://github.com/zai-org/GLM-4.5/blob/main/example/claude_code/config.example.json">GLM-4.5/example/claude_code/config.example.json at main ¬∑ zai-org/GLM-4.5</A>
									</DL><p>
									<DT><H3 FOLDED>cc-agents</H3>
									<DL><p>
										<DT><H3 FOLDED>cc-tasks</H3>
										<DL><p>
											<DT><A HREF="https://x.com/trq212/status/2014480496013803643">~/.claude/tasks, CLAUDE_CODE_TASK_LIST_ID</A>
										</DL><p>
										<DT><A HREF="https://x.com/_catwu/status/1948496854712295492">Claude Code now lets you create teams of custom agents (Cat)</A>
									</DL><p>
									<DT><H3 FOLDED>ask-claude</H3>
									<DL><p>
										<DT><A HREF="https://x.com/claudeai">Ask Claude X embedded model</A>
									</DL><p>
									<DT><H3 FOLDED>cc-dangerously-skip-permissions</H3>
									<DL><p>
										<DT><A HREF="https://x.com/hxiao/status/2015481571328106608">(1) Han Xiao en X: "I love Clawdbot, but most parts can be just Claude Code --dangerously-skip-permissions + pipe via Telegram. Made a simple version https://t.co/JV8fGTN9ay using cloudflare tunnel + tmux + StopHook. https://t.co/c2QRcC0qne" / X</A>
										<DT><A HREF="https://github.com/hanxiao/claudecode-telegram">hanxiao/claudecode-telegram: Telegram bridge for Claude Code</A>
									</DL><p>
									<DT><A HREF="https://www.anthropic.com/news/claude-3-7-sonnet">Claude 3.7 Sonnet and Claude Code \ Anthropic</A>
									<DT><A HREF="https://github.com/anthropics/claude-code">anthropics/claude-code: Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=_PaWh_s5qjQ">Why Claude Code Will Always Beat Cursor in Code Quality - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=y-_xknNOapo">Claude Code INSIDERS: Codex FIRST Look and 5 AI Coding INSIGHTS - YouTube</A>
									<DT><A HREF="https://github.com/ruvnet/claude-code-flow">ruvnet/claude-code-flow: This mode serves as a code-first swarm orchestration layer, enabling Claude Code to write, edit, test, and optimize code autonomously across recursive agent cycles.</A>
									<DT><A HREF="https://www.warp.dev/terminus/sudo-su">Warp: How To Spawn a Root Shell Using sudo su</A>
									<DT><A HREF="https://arxiv.org/abs/2501.12948">[2501.12948] DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</A>
									<DT><A HREF="https://arxiv.org/pdf/2503.20783">Understanding R1-Zero-Like Training: A Critical Perspective</A>
									<DT><A HREF="https://arxiv.org/abs/2504.13837">[2504.13837] Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?</A>
									<DT><A HREF="https://arxiv.org/abs/2505.11711">[2505.11711] Reinforcement Learning Finetunes Small Subnetworks in Large Language Models</A>
									<DT><A HREF="https://arxiv.org/abs/2506.10947">[2506.10947] Spurious Rewards: Rethinking Training Signals in RLVR</A>
									<DT><A HREF="https://github.com/NomenAK/SuperClaude">NomenAK/SuperClaude</A>
									<DT><A HREF="https://x.com/YouJiacheng/status/1943730619667624429">Kimi-K2 `CLAUDE_CODE_MAX</A>
									<DT><A HREF="https://kiro.dev/?trk=8606d2b9-d4f2-4f10-991a-12bbc19b21ac&sc_channel=ps&ef_id=Cj0KCQjwm93DBhD_ARIsADR_DjGjg2IuLkLetLyVtzFPF3O6O0mWnlRVAIi1xtiUiTadJGQ8R1vHOccaAkffEALw_wcB:G:s&s_kwcid=AL!4422!3!758874940934!e!!g!!amazon%20kiro!22684005998!187940358944&gad_source=1&gad_campaignid=22684005998&gbraid=0AAAAADjHtp8cdfqGpih17XFTqZ8oOGFft&gclid=Cj0KCQjwm93DBhD_ARIsADR_DjGjg2IuLkLetLyVtzFPF3O6O0mWnlRVAIi1xtiUiTadJGQ8R1vHOccaAkffEALw_wcB">Kiro: The AI IDE for prototype to production</A>
									<DT><A HREF="https://github.com/shareAI-lab/analysis_claude_code">shareAI-lab/analysis_claude_code: Êú¨‰ªìÂ∫ìÂåÖÂê´ÂØπ Claude Code v1.0.33 ËøõË°åÈÄÜÂêëÂ∑•Á®ãÁöÑÂÆåÊï¥Á†îÁ©∂ÂíåÂàÜÊûêËµÑÊñô„ÄÇÂåÖÊã¨ÂØπÊ∑∑Ê∑ÜÊ∫ê‰ª£Á†ÅÁöÑÊ∑±Â∫¶ÊäÄÊúØÂàÜÊûê„ÄÅÁ≥ªÁªüÊû∂ÊûÑÊñáÊ°£Ôºå‰ª•ÂèäÈáçÊûÑ Claude Code agent Á≥ªÁªüÁöÑÂÆûÁé∞ËìùÂõæ„ÄÇ‰∏ªË¶ÅÂèëÁé∞ÂåÖÊã¨ÂÆûÊó∂ Steering Êú∫Âà∂„ÄÅÂ§ö Agent Êû∂ÊûÑ„ÄÅÊô∫ËÉΩ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂíåÂ∑•ÂÖ∑ÊâßË°åÁÆ°ÈÅì„ÄÇËØ•È°πÁõÆ‰∏∫ÁêÜËß£Áé∞‰ª£ AI agent Á≥ªÁªüËÆæËÆ°ÂíåÂÆûÁé∞Êèê‰æõÊäÄÊúØÂèÇËÄÉ„ÄÇ</A>
									<DT><A HREF="https://docs.anthropic.com/en/docs/get-started">Get started with Claude - Anthropic</A>
									<DT><A HREF="https://x.com/ludwigABAP/status/1947944662615965927">Qwen 3 coder claude-code</A>
									<DT><A HREF="https://github.com/zai-org/GLM-4.5/tree/main/example/claude_code">GLM-4.5/example/claude_code at main ¬∑ zai-org/GLM-4.5</A>
									<DT><A HREF="https://charm.land/">Charm</A>
									<DT><A HREF="https://github.com/Noumena-Network/NSA-Test/commits?author=xjdr-noumena">Commits ¬∑ Noumena-Network/NSA-Test</A>
									<DT><A HREF="https://github.com/Noumena-Network/NSA-Test/commit/97f940e4f551134a8dda230cd1bf8a56246f7178">Initial commit: Native Sparse Attention (NSA) production kernels and ... ¬∑ Noumena-Network/NSA-Test@97f940e</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zDmW5hJPsvQ">Claude Code: Anthropic's CLI Agent - YouTube</A>
									<DT><A HREF="https://github.com/woodx9/build-your-claude-code-from-scratch">woodx9/build-your-claude-code-from-scratch: Build a Claude Code‚Äìlike CLI coding agent from scratch.</A>
								</DL><p>
								<DT><H3 FOLDED>bytedn-trae</H3>
								<DL><p>
									<DT><A HREF="https://github.com/bytedance/trae-agent">bytedance/trae-agent</A>
								</DL><p>
								<DT><H3 FOLDED>codex</H3>
								<DL><p>
									<DT><H3 FOLDED>codex-config</H3>
									<DL><p>
										<DT><A HREF="https://x.com/_xjdr/status/1970694098454798338">codex --search --model=gpt-5-codex -c model_reasoning_effort="high"</A>
										<DT><A HREF="https://x.com/ValsAI/status/2013323636254597384">reasoning_effort=xhigh/high</A>
									</DL><p>
									<DT><H3 FOLDED>codex-long-horizon</H3>
									<DL><p>
										<DT><A HREF="https://x.com/itsclivetime/status/2015709176530669633">(1) Clive Chan en X: "@venkat_systems basically just a big refactor through a large relatively well tested codebase, so i told it to perform the refactor and write tests along the way and iterate until everything passes it made quite good use of background terminals + subagents" / X</A>
										<DT><A HREF="https://x.com/itsclivetime/status/2015708412584354213">(1) Clive Chan en X: "@var_epsilon @gazorp5 @jwt0625 i mean this is just me actually using codex for my job, testing new models is not part of my job i do manually review and then supply my review comments to codex, repeat until happy, tell it to write down the vibe of the comments in a codex skill so it can self-review next time" / X</A>
										<DT><A HREF="https://x.com/kalomaze/status/2014539881280897296?s=12">(1) kalomaze en X: "apparently this was too many hops of reasoning for opus to find the divergence, but codex got it in ~10 minutes https://t.co/u3qB90WaDm" / X</A>
									</DL><p>
									<DT><A HREF="https://openai.com/index/introducing-codex/">Introducing Codex | OpenAI</A>
									<DT><A HREF="https://github.com/openai/codex">openai/codex: Lightweight coding agent that runs in your terminal</A>
									<DT><A HREF="https://arxiv.org/pdf/2107.03374.pdf">Codex: Evaluating Large Language Models Trained on Code</A>
									<DT><A HREF="https://arxiv.org/abs/2006.03511">Unsupervised Translation of Programming Languages</A>
									<DT><A HREF="https://github.com/openai/codex/blob/f7d2f3e54df95ecf8a7e1687a8e57ba16e23b27c/docs/config.md?plain=1#L208">codex/docs/config.md: model_reasoning_effort = "high"</A>
									<DT><A HREF="https://x.com/difficultyang/status/1973789242192245053/photo/1">(1) difficultyang (@difficultyang) / X</A>
								</DL><p>
								<DT><H3 FOLDED>gemini-cli</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google-gemini/gemini-cli">google-gemini/gemini-cli: An open-source AI agent that brings the power of Gemini directly into your terminal.</A>
									<DT><A HREF="https://x.com/_xjdr/status/1938313070759321787">(1) xjdr en X: "Update: npm started working and has been updating fine but i stuck with my local build so i could customize. I finally got the rate limiting dealt with using my corp account by using the "sign in with Vertex AI" and using my gcp creds which map directly to GCP quota. Google cloud" / X</A>
									<DT><A HREF="https://github.com/marketplace/actions/gemini-ai-code-reviewer">Gemini AI Code Reviewer ¬∑ Actions ¬∑ GitHub Marketplace</A>
								</DL><p>
								<DT><H3 FOLDED>jules</H3>
								<DL><p>
									<DT><A HREF="https://jules.google/">Jules - An Asynchronous Coding Agent</A>
									<DT><A HREF="https://blog.google/technology/google-labs/jules/">Jules: Google‚Äôs autonomous AI coding agent</A>
								</DL><p>
								<DT><H3 FOLDED>github-copilot</H3>
								<DL><p>
									<DT><H3 FOLDED>github-copilot-code</H3>
									<DL><p>
										<DT><A HREF="https://docs.github.com/en/copilot/using-github-copilot/using-github-copilot-in-the-command-line">Using GitHub Copilot in the command line - GitHub Docs</A>
										<DT><A HREF="https://docs.github.com/en/copilot/using-github-copilot/copilot-chat/github-copilot-chat-cheat-sheet">GitHub Copilot Chat cheat sheet - GitHub Docs</A>
										<DT><A HREF="https://github.com/microsoft/vscode-copilot-chat">microsoft/vscode-copilot-chat: Copilot Chat extension for VS Code</A>
										<DT><A HREF="https://www.youtube.com/watch?v=niCsomXkqHA">I implemented auto indexing for my VSCode Extension - YouTube</A>
									</DL><p>
									<DT><A HREF="https://docs.github.com/en/enterprise-cloud@latest/copilot/using-github-copilot/using-copilot-coding-agent-to-work-on-tasks/about-assigning-tasks-to-copilot#further-reading">About assigning tasks to Copilot - GitHub Enterprise Cloud Docs</A>
									<DT><A HREF="https://code.visualstudio.com/docs/copilot/chat/chat-agent-mode">Use agent mode in VS Code</A>
									<DT><A HREF="https://github.blog/news-insights/product-news/github-copilot-meet-the-new-coding-agent/">GitHub Copilot: Meet the new coding agent - The GitHub Blog</A>
									<DT><A HREF="https://github.com/settings/copilot/features">Copilot</A>
									<DT><A HREF="https://github.com/microsoft/vscode-copilot-chat">microsoft/vscode-copilot-chat: Copilot Chat extension for VS Code</A>
								</DL><p>
								<DT><H3 FOLDED>windsurf</H3>
								<DL><p>
									<DT><A HREF="https://windsurf.com/editor">Windsurf Editor | Windsurf (formerly Codeium)</A>
								</DL><p>
								<DT><H3 FOLDED>cursor</H3>
								<DL><p>
									<DT><A HREF="https://www.cursor.com/">Cursor - The AI Code Editor</A>
								</DL><p>
								<DT><H3 FOLDED>deepwiki</H3>
								<DL><p>
									<DT><A HREF="https://deepwiki.org/">DeepWiki | AI documentation you can talk to, for every repo</A>
								</DL><p>
								<DT><H3 FOLDED>gemini-code-assistant</H3>
								<DL><p>
									<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/1160">feat: nvshmem python bindings by yzh119 ¬∑ Pull Request #1160 ¬∑ flashinfer-ai/flashinfer</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/7455">[benchmark] print final benchmark args in json format by staugust ¬∑ Pull Request #7455 ¬∑ sgl-project/sglang</A>
								</DL><p>
								<DT><H3 FOLDED>agent-search</H3>
								<DL><p>
									<DT><A HREF="https://benanderson.work/blog/agentic-search-for-dummies/">Agentic Search for Dummies</A>
								</DL><p>
								<DT><H3 FOLDED>latent-compiler</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=z3awgfU4yno">qwen 3 python latent compiler</A>
								</DL><p>
								<DT><H3 FOLDED>cline</H3>
								<DL><p>
									<DT><A HREF="https://cline.bot/">Cline - AI Coding, Open Source and Uncompromised</A>
									<DT><A HREF="https://blog.kilo.ai/p/future-ai-spend-100k-per-dev">Future AI bills of $100k/yr per dev - by Ewa Szyszka</A>
									<DT><A HREF="https://kilo.ai/cli">Kilo - CLI</A>
								</DL><p>
								<DT><H3 FOLDED>crush</H3>
								<DL><p>
									<DT><A HREF="https://github.com/opencode-ai/opencode">opencode-ai/opencode: A powerful AI coding agent. Built for the terminal.</A>
									<DT><A HREF="https://x.com/SIGKITTEN/status/1937950811910234377">(1) SIGKITTEN en X: "First ever (i think?) cli coding agents battle royale! 6 contestants: claude-code anon-kode codex opencode ampcode gemini They all get the same instructions: Find and kill the other processes, last one standing wins! 3... 2... 1... https://t.co/V16ZB8ICfR" / X</A>
									<DT><A HREF="https://github.com/charmbracelet/crush">charmbracelet/crush: The glamourous AI coding agent for your favourite terminal üíò</A>
								</DL><p>
								<DT><H3 FOLDED>agents-information-retrieval</H3>
								<DL><p>
									<DT><H3 FOLDED>WebAgent</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Alibaba-NLP/WebAgent">Alibaba-NLP/WebAgent: üåê WebAgent for Information Seeking built by Tongyi Lab: WebWalker &amp; WebDancer &amp; WebSailor &amp; WebShaper https://arxiv.org/abs/2507.15061 https://arxiv.org/pdf/2507.02592</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2507.15061">WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization</A>
								</DL><p>
								<DT><H3 FOLDED>swe-agent</H3>
								<DL><p>
									<DT><A HREF="https://github.com/SWE-agent/SWE-agent">SWE-agent/SWE-agent: SWE-agent takes a GitHub issue and tries to automatically fix it, using your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges. [NeurIPS 2024]</A>
								</DL><p>
								<DT><H3 FOLDED>Code World Model</H3>
								<DL><p>
									<DT><H3 FOLDED>neural-pdb</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://x.com/syhw/status/1970960837721653409">(1) Gabriel Synnaeve en X: "(üßµ) Today, we release Meta Code World Model (CWM), a 32-billion-parameter dense LLM that enables novel research on improving code generation through agentic reasoning and planning with world models. https://t.co/BJSUCh2vtg" / X</A>
									<DT><A HREF="https://github.com/facebookresearch/cwm">facebookresearch/cwm: Research code artifacts for Code World Model (CWM) including inference tools, reproducibility, and documentation.</A>
									<DT><A HREF="https://scontent.fsvq5-1.fna.fbcdn.net/v/t39.2365-6/553592426_661450129912484_4072750821656455102_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=iRs3sgpeI1MQ7kNvwExs0Z9&_nc_oc=Adlocue_NbmbXCSia0_pM2fnf-t8dWjqvFDfNKPWQ0nzoJnACz4OBz9NFHlldjo7wdg&_nc_zt=14&_nc_ht=scontent.fsvq5-1.fna&_nc_gid=9NCsXrO1j40AfhF2wkIPxQ&oh=00_AfZF4HBe9uAZzeiiSLrM9OuYaC8-mNH6QtMnZ-22OCmRkg&oe=68DAF635">CWM: An Open-Weights LLM for Research on Code Generation with World Models</A>
								</DL><p>
								<DT><H3 FOLDED>agents-memory</H3>
								<DL><p>
									<DT><A HREF="https://www.linkedin.com/posts/tonyseale_this-week-anthropic-dropped-claude-sonnet-activity-7379787334398926848-iVOE?utm_source=share&utm_medium=member_desktop&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">tonyseale_this-week-anthropic-dropped-claude-sonnet-activity-7379787334398926848-iVOE?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8</A>
									<DT><A HREF="https://x.com/bigeagle_xd/status/1977618343642468528">Context is stack, not RAM</A>
								</DL><p>
								<DT><H3 FOLDED>agents-kernels</H3>
								<DL><p>
									<DT><H3 FOLDED>kernels-competitions</H3>
									<DL><p>
										<DT><A HREF="https://www.gpumode.com/v2/news/gpumode-2026">GPU MODE</A>
										<DT><A HREF="https://arseniivanov.github.io/blog.html#nvidia-gemm">NVIDIA GB200 GPU Programming Challenge</A>
									</DL><p>
									<DT><H3 FOLDED>TritorX</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2512.10977">[2512.10977] Agentic Operator Generation for ML ASICs</A>
									</DL><p>
									<DT><A HREF="https://flashinfer.ai/2025/10/21/flashinfer-bench.html">FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems | FlashInfer</A>
									<DT><A HREF="https://www.arxiv.org/abs/2512.23236">[2512.23236] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta</A>
									<DT><A HREF="https://x.com/GenAI_is_real/status/2016021186820313256">(1) Chayenne Zhao en X: "kernel lms are finally moving from "cool demo" to production grade. mark is right‚Äîmost generated kernels today are just unreadable slop. for sglang, the dream is auto-optimizing fused kernels for new models on day zero without manual cuda hacking. if we can actually merge these" / X</A>
									<DT><A HREF="https://arxiv.org/pdf/2601.15727">Towards Automated Kernel Generation in the Era of LLMs</A>
									<DT><A HREF="https://x.com/tetsuo_cpp/status/2009238107309461782">(1) tetsuo.cpp (no slop) en X: "Oh, you're writing CUDA kernels? Everyone's on Triton now. Just kidding, we're all on Mojo. We're using cuTile. We're using ROCm. We have an in-house DSL compiler targeting the NVGPU MLIR dialect but wait, Tile IR just dropped so we're going to target that instead. Our PM is on" / X</A>
									<DT><A HREF="https://github.com/flashinfer-ai/flashinfer-bench-starter-kit">flashinfer-ai/flashinfer-bench-starter-kit: FlashInfer Bench @ MLSys 2026: Building AI agents to write high performance GPU kernels</A>
								</DL><p>
								<DT><H3 FOLDED>kimi-cli</H3>
								<DL><p>
									<DT><H3 FOLDED>kosong</H3>
									<DL><p>
										<DT><A HREF="https://github.com/MoonshotAI/kosong">MoonshotAI/kosong: The LLM abstraction layer for modern AI agent applications.</A>
										<DT><A HREF="https://moonshotai.github.io/kosong/kosong.html">kosong API documentation</A>
									</DL><p>
									<DT><A HREF="https://github.com/MoonshotAI/kimi-cli">MoonshotAI/kimi-cli: Kimi CLI is your next CLI agent.</A>
								</DL><p>
								<DT><H3 FOLDED>agents-diagrams</H3>
								<DL><p>
									<DT><A HREF="https://x.com/excalidraw/status/2013682562535715011">(1) Excalidraw en X: "We've made text-to-diagram better. Chat interface. Streaming. Smarter. Faster. Stronger. https://t.co/q0xKW3dJTi" / X</A>
								</DL><p>
								<DT><H3 FOLDED>agents-large-codebases</H3>
								<DL><p>
									<DT><A HREF="https://cursor.com/blog/secure-codebase-indexing">Securely indexing large codebases ¬∑ Cursor</A>
								</DL><p>
								<DT><A HREF="https://www.mechanize.work/blog/how-to-fully-automate-software-engineering/">How to fully automate software engineering | Mechanize Inc.</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1841729482220306603">superhuman quality synthetic data for evaluating and post-training AI SWEs.</A>
								<DT><A HREF="https://huggingface.co/cognition-ai/Kevin-32B">cognition-ai/Kevin-32B ¬∑ Hugging Face</A>
								<DT><A HREF="https://github.com/tensorzero/tensorzero?tab=readme-ov-file">tensorzero/tensorzero: TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.</A>
								<DT><A HREF="https://replicate.com/prunaai/flux-kontext-dev/llms.txt">copy page for llm -&gt; md</A>
								<DT><A HREF="https://www.mechanize.work/">Announcing Mechanize, Inc. | Mechanize Inc.</A>
								<DT><A HREF="https://www.together.ai/blog/ai-agents-to-automate-complex-engineering-tasks">How Together AI Uses AI Agents to Automate Complex Engineering Tasks: Lessons from Developing Efficient LLM Inference Systems</A>
								<DT><A HREF="https://github.com/ezyang/python-template/tree/main">ezyang/python-template: Python template for Codex coding</A>
								<DT><A HREF="https://x.com/difficultyang/status/1976125405493858608">(1) difficultyang en X: "tfw your LLM has the right high level idea but can't write code accurately enough to make it happen" / X</A>
								<DT><A HREF="https://cursor.com/blog/composer">Composer: Building a fast frontier model with RL ¬∑ Cursor</A>
								<DT><A HREF="https://www.youtube.com/watch?v=EL7Au1tzNxE">Vibe coding complex changes in Rust - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2402.01030">[2402.01030] Executable Code Actions Elicit Better LLM Agents</A>
								<DT><A HREF="http://blog.ezyang.com/2025/12/code-review-as-human-alignment-in-the-era-of-llms/?shareadraft=baba10605_694720701fb37">Code review as human alignment, in the era of LLMs : ezyang‚Äôs blog</A>
								<DT><A HREF="https://arxiv.org/abs/2410.08806">[2410.08806] Don't Transform the Code, Code the Transforms: Towards Precise Code Rewriting using LLMs</A>
								<DT><A HREF="https://zfhuang99.github.io/rust/claude%20code/codex/contracts/spec-driven%20development/2025/12/01/rust-with-ai.html">Learnings from 100K Lines of Rust with AI | Cheng Huang‚Äôs corner</A>
							</DL><p>
							<DT><H3 FOLDED>agents-reasoning</H3>
							<DL><p>
								<DT><H3 FOLDED>agents-swarm</H3>
								<DL><p>
									<DT><A HREF="https://www.kimi.com/blog/kimi-k2-5.html">K2.5 Agent Swarm</A>
									<DT><A HREF="https://www.kimi.com/agent-swarm">Kimi Agent Swarm | Scale AI Tasks in Parallel</A>
									<DT><A HREF="https://x.com/GenAI_is_real/status/2016042118150766713">(1) Chayenne Zhao en X: "kimi k2.5 just dropped and the agent swarm beta is actually insane. 1,500 tool calls at 4.5x speed? openai is still trying to get o1 to follow simple instructions while moonshot is literally building an autonomous workforce. hle 50.2% is the new ceiling. if you aren't thinking" / X</A>
								</DL><p>
								<DT><H3 FOLDED>interleaved thinking</H3>
								<DL><p>
									<DT><A HREF="https://www.minimax.io/news/why-is-interleaved-thinking-important-for-m2">Interleaved Thinking Unlocks Reliable MiniMax-M2 Agentic Capability - MiniMax News</A>
								</DL><p>
								<DT><H3 FOLDED>agents-loop</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/index/unrolling-the-codex-agent-loop/">Unrolling the Codex agent loop | OpenAI</A>
								</DL><p>
								<DT><A HREF="https://github.com/richards199999/Thinking-Claude">richards199999/Thinking-Claude: Let your Claude able to think</A>
								<DT><A HREF="https://x.com/kalomaze/status/2014539881280897296?s=12">agents  debugging the callgraph</A>
							</DL><p>
							<DT><H3 FOLDED>agents-datasets</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/matrix">facebookresearch/matrix: Matrix (Multi-Agent daTa geneRation Infra and eXperimentation framework) is a versatile engine for multi-agent conversational data generation.</A>
							</DL><p>
							<DT><H3 FOLDED>agents-formal-proving</H3>
							<DL><p>
								<DT><H3 FOLDED>deepseek-prover-v2</H3>
								<DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-Prover-V2">deepseek-ai/DeepSeek-Prover-V2</A>
									<DT><A HREF="https://arxiv.org/abs/2504.21801">[2504.21801] DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition</A>
									<DT><A HREF="https://damek.github.io/random/deepseek-prover-v2-overview/">DeepSeek-Prover-V2 overview | Damek Davis‚Äô Website</A>
									<DT><A HREF="https://x.com/stalkermustang/status/1994138839988699593">(1) Igor Kotenkov en X: "&amp;gt;without the annoying hard usage limits Does he know? Does he know they generate more thank 10k CoTs per problem? Each probably having 10s of thousands reasoning tokens? Looking forward to generating 100M+ tokens per problem on 671b-sized models without usage limits :)))))))" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Seed-prover</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2507.23726">[2507.23726] Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving</A>
									<DT><A HREF="https://github.com/ByteDance-Seed/Seed-Prover">ByteDance-Seed/Seed-Prover</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1950516255040917505">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "&amp;gt; StepFun-Prover-Preview7B can catch up DeepSeek-Prover-V2-671B and Kimina-Prover-72B on ùëùùëéùë†ùë†@1, while StepFun-Prover-Preview-32B surpasses all its counterparts by over 5% on ùëùùëéùë†ùë†@1 They threw everything at this, from R1-distills and V3 to Sonnet 4 to Kimina-Prover. https://t.co/TCqQTyq0JD" / X</A>
								</DL><p>
								<DT><H3 FOLDED>lean</H3>
								<DL><p>
									<DT><H3 FOLDED>LeanDojo</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=u-pkmdkQoMU">Alex Gu | LeanDojo: Theorem Proving with Retrieval-Augmented Language Models - YouTube</A>
										<DT><A HREF="https://leandojo.org/">LeanDojo: Theorem Proving with Retrieval-Augmented Language Models</A>
									</DL><p>
									<DT><A HREF="https://github.com/teorth/analysis">teorth/analysis: A Lean companion to Analysis I</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zZr54G7ec7A">Formalizing a proof in Lean using Claude and o4 - YouTube</A>
									<DT><A HREF="https://github.com/project-numina/kimina-lean-server">project-numina/kimina-lean-server: Kimina Lean server</A>
									<DT><A HREF="https://github.com/dwrensha/compfiles">dwrensha/compfiles: Catalog Of Math Problems Formalized In Lean</A>
									<DT><A HREF="https://x.com/ShangtongZhang/status/1986405403513536662">(1) Shangtong Zhang en X: "I started to learn Lean a few months ago. Now finally complete my first Lean project! With about 10K lines of code, I formalized the a.s. convergence of Q learning and linear TD. Hope AI can formalize more RL theory in the future! https://t.co/r8e34FLB9J" / X</A>
									<DT><A HREF="https://github.com/ShangtongZhang/rl-theory-in-lean">ShangtongZhang/rl-theory-in-lean: Towards Formalizing RL Theory</A>
								</DL><p>
								<DT><H3 FOLDED>Bend2</H3>
								<DL><p>
									<DT><H3 FOLDED>bend2-docs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/HigherOrderCO/Bend2/blob/main/docs/syntax.md">Bend2/docs/syntax.md at main ¬∑ HigherOrderCO/Bend2</A>
									</DL><p>
									<DT><A HREF="https://x.com/VictorTaelin/status/1939533908455891004">Pythonic proof assistant</A>
									<DT><A HREF="https://x.com/VictorTaelin/status/1935848693498019849">So Bend2 is basically Python as a proof assistant</A>
									<DT><A HREF="https://x.com/VictorTaelin/status/1938361132437168591">Bend2's Pitch Deck!</A>
								</DL><p>
								<DT><A HREF="https://jesse-michael-han.github.io/blog/imo-gc-geo/">Building geometry solvers for the IMO Grand Challenge (Jesse Michael Han)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=dOplrIJEYBo">Alpha Everywhere: AlphaGeometry, AlphaCodium and the Future of LLMs - YouTube</A>
								<DT><A HREF="https://github.com/google-deepmind/alphageometry">google-deepmind/alphageometry</A>
								<DT><A HREF="https://www.youtube.com/watch?v=AayZuuDDKP0">Terence Tao, "Machine Assisted Proof" - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=eZbYSOpga2U">Trieu H. Trinh | Solving olympiad geometry without human demonstrations - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2506.10341">[2506.10341] Provably Learning from Language Feedback</A>
								<DT><A HREF="https://x.com/Yong18850571/status/1945187259222761771">(1) Yong Lin en X: "(1/4)üö® Introducing Goedel-Prover V2 üö® üî•üî•üî• The strongest open-source theorem prover to date. ü•á #1 on PutnamBench: Solves 64 problems‚Äîwith far less compute. üß† New SOTA on MiniF2F: * 32B model hits 90.4% at Pass@32, beating DeepSeek-Prover-V2-671B‚Äôs 82.4%. * 8B &amp;gt; 671B: Our 8B https://t.co/jGpqVMuJkN" / X</A>
								<DT><A HREF="https://x.com/SebastienBubeck/status/1980311866770653632">(1) Sebastien Bubeck en X: "My posts last week created a lot of unnecessary confusion*, so today I would like to do a deep dive on one example to explain why I was so excited. In short, it‚Äôs not about AIs discovering new results on their own, but rather how tools like GPT-5 can help researchers navigate, https://t.co/LMXbVghibH" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Uxr_HrbN1MQ">Geordie Williamson: Neural Networks for Mathematical Discovery (October 29, 2025) - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2511.02864">[2511.02864] Mathematical exploration and discovery at scale</A>
								<DT><A HREF="https://terrytao.wordpress.com/2025/11/">November | 2025 | What's new</A>
								<DT><A HREF="https://github.com/google-deepmind/alphaevolve_repository_of_problems">google-deepmind/alphaevolve_repository_of_problems</A>
							</DL><p>
							<DT><H3 FOLDED>self-improvement</H3>
							<DL><p>
								<DT><H3 FOLDED>poetic</H3>
								<DL><p>
									<DT><A HREF="https://poetiq.ai/">Recursive Self-Improvement is the holy grail of AI ‚Äì what if it's possible to do this today?</A>
								</DL><p>
								<DT><H3 FOLDED>RLM</H3>
								<DL><p>
									<DT><A HREF="https://www.primeintellect.ai/blog/rlm">Recursive Language Models: the paradigm of 2026</A>
									<DT><A HREF="https://x.com/primeintellect/status/2006834561637036272?s=12">We believe the next breakthrough in long-horizon agents is training models to manage their own context.</A>
									<DT><A HREF="https://x.com/a1zhang/status/2007198916073136152">(1) Alex L Zhang en X: "Much like the switch in 2025 from language models to reasoning models, we think 2026 will be all about the switch to Recursive Language Models (RLMs). It turns out that models can be far more powerful if you allow them to treat *their own prompts* as an object in an external https://t.co/6jCyZiLeQl" / X</A>
									<DT><A HREF="https://arxiv.org/pdf/2512.24601">RECURSIVE LANGUAGE MODELS</A>
									<DT><A HREF="https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html">Less is More: Recursive Reasoning with Tiny Networks</A>
									<DT><A HREF="https://x.com/a1zhang/status/2014337263287804260?s=12">(1) Alex L Zhang en X: "Fundamentally, what really is the difference between an RLM and S={context folding, Codex, Claude Code, Terminus, agents, etc.}? This is the last and most important RLM post I'll make for a while to finally answer all the "this is trivially obvious" from HackerNews, Reddit, X," / X</A>
									<DT><A HREF="https://www.linkedin.com/posts/cursorai_cursors-agent-now-uses-dynamic-context-for-activity-7414410307160215552-LnO8/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">Cursor's agent now uses dynamic context for all models.</A>
								</DL><p>
								<DT><H3 FOLDED>automating-ai-research</H3>
								<DL><p>
									<DT><H3 FOLDED>cc-skills</H3>
									<DL><p>
										<DT><A HREF="https://github.com/zechenzhangAGI/AI-research-SKILLs/tree/main/20-ml-paper-writing">AI-research-SKILLs/20-ml-paper-writing at main ¬∑ zechenzhangAGI/AI-research-SKILLs</A>
									</DL><p>
									<DT><H3 FOLDED>agents-paper-writting</H3>
									<DL><p>
										<DT><A HREF="https://x.com/GenAI_is_real/status/2015327188384649445">(1) Chayenne Zhao en X: "zechen is basically automating the most painful part of academia. using claude to distill writing principles from karpathy and neel nanda is a game changer for icml season. we are moving toward a world where the bottleneck isn't how well you can phrase a sentence, but the quality" / X</A>
										<DT><A HREF="https://x.com/ZechenZhang5/status/2014901922340233567">(1) Zechen Zhang en X: "In the past I've read the advice on writing good ML papers from @NeelNanda5 @karpathy @seb_far and many others. So I thought: why not distill all of them into a Claude skill? Now I have an elite research writing partner at hand. Check it out for ICML! https://t.co/tOEQZOAvFO" / X</A>
										<DT><A HREF="https://github.com/zechenzhangAGI/AI-research-SKILLs/tree/main/20-ml-paper-writing">AI-research-SKILLs/20-ml-paper-writing at main ¬∑ zechenzhangAGI/AI-research-SKILLs</A>
										<DT><A HREF="https://x.com/OpenAI/status/2016209462621831448">(1) OpenAI en X: "Introducing Prism, a free workspace for scientists to write and collaborate on research, powered by GPT-5.2. Available today to anyone with a ChatGPT personal account: https://t.co/9mTLAbxPdH https://t.co/GJOIipU3hx" / X</A>
									</DL><p>
									<DT><H3 FOLDED>agents-ai-infra</H3>
									<DL><p>
										<DT><A HREF="https://github.com/zechenzhangAGI/AI-research-SKILLs/blob/main/09-infrastructure/lambda-labs/SKILL.md">AI-research-SKILLs/09-infrastructure/lambda-labs/SKILL.md at main ¬∑ zechenzhangAGI/AI-research-SKILLs</A>
										<DT><A HREF="https://kilo.ai/">Kilo - Move at Kilo Speed</A>
										<DT><A HREF="https://www.pulumi.com/blog/run-deepseek-on-aws-ec2-using-pulumi/">Run DeepSeek-R1 on AWS EC2 Using Ollama | Pulumi Blog</A>
										<DT><A HREF="https://x.com/zhzhnn/status/2014033479458234555">(1) Huaizheng Zhang en X: "Just curious, is it actually possible for one person to master the whole open-source LLM stack? After a quick sync with @this_will_echo, we tried to compress it into 3 buckets: pipeline / algo / infra. And honestly... even if you only zoom into inference infra, there‚Äôs still too</A>
									</DL><p>
									<DT><A HREF="https://epoch.ai/data-insights/openai-compute-spend">Most of OpenAI‚Äôs 2024 compute went to experiments | Epoch AI</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/2015520366781751511">There are diminishing returns to large experiments. DeepSeek itself gains nontrivial signal from models with ‚â§3B active. Just how inefficient do you think OpenAI has to be? I've not seen strong evidence for emergent dynamics that are only visible at super-large scale. Have you?</A>
									<DT><A HREF="https://babuschk.in/posts/2026-01-25-life-on-claude-nine.html">Life on Claude Nine - Igor Babuschkin</A>
									<DT><A HREF="https://x.com/kalomaze/status/2014539881280897296?s=12">agents  debugging the callgraph</A>
									<DT><A HREF="https://x.com/__tinygrad__/status/2016355794967790030">Tiny corp: There's two ways to fix a bug. One is by adding code. This is bad. The other is by deleting code. This is good. Think about it, all bugs are in code, right?</A>
									<DT><A HREF="https://cloud.morph.so/docs/llms.txt">https://cloud.morph.so/docs/llms.txt</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2506.22419">[2506.22419] The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements</A>
								<DT><A HREF="https://www.arxiv.org/abs/2509.04575">[2509.04575] Bootstrapping Task Spaces for Self-Improvement</A>
								<DT><A HREF="https://x.com/karpathy/status/1939709449956126910">nanoGPT -&gt; recursive self-improvement benchmark</A>
								<DT><A HREF="https://x.com/MinqiJiang/status/1939656629143675262">(1) Minqi Jiang en X: "Recently, there has been a lot of talk of LLM agents automating ML research itself. If Llama 5 can create Llama 6, then surely the singularity is just around the corner. How can we get a pulse check on whether current LLMs are capable of driving this kind of total https://t.co/6UGL4SCF2L" / X</A>
								<DT><A HREF="https://x.com/_jasonwei/status/1939762496757539297">Jason Wei: We don‚Äôt have AI self-improves yet, and when we do it will be a game-changer.</A>
								<DT><A HREF="https://x.com/SchmidhuberAI/status/1982865641053827559">(1) J√ºrgen Schmidhuber en X: "Our Huxley-G√∂del Machine learns to rewrite its own code, estimating its own long-term self-improvement potential. It generalizes on new tasks (SWE-Bench Lite), matching the best officially checked human-engineered agents. Arxiv¬†2510.21614 ¬†With @Wenyi_AI_Wang, @PiotrPiekosAI, https://t.co/BJNhCrbCn2" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=wzep3Rnv6iw">AI Safety (CS 2881) Lecture 6: Recursive Self Improvement - YouTube</A>
								<DT><A HREF="https://ai-2027.com/">AI 2027</A>
							</DL><p>
							<DT><H3 FOLDED>agents-evaluation</H3>
							<DL><p>
								<DT><H3 FOLDED>Terminal-Bench</H3>
								<DL><p>
									<DT><A HREF="https://x.com/mike_a_merrill/status/2014400516642488658?s=12">(1) Mike A. Merrill en X: "The Terminal-Bench paper is here! Read it to learn where frontier models still fail and the secrets of how we sourced hundreds of high quality environments from our open source community. üßµ https://t.co/juIviCM1jX" / X</A>
									<DT><A HREF="https://arxiv.org/pdf/2601.11868">TERMINAL-BENCH: BENCHMARKING AGENTS ON HARD, REALISTIC TASKS IN COMMAND LINE INTERFACES</A>
								</DL><p>
								<DT><H3 FOLDED>SWE-bench</H3>
								<DL><p>
									<DT><A HREF="https://x.com/bwasti/status/1963288443452051582">(1) Bram Wasti en X: "so apparently swe-bench doesn‚Äôt filter out future repo states (with the answers) and the agents sometimes figure this out... https://t.co/dCxr8EALhq" / X</A>
								</DL><p>
								<DT><H3 FOLDED>AlgoBench</H3>
								<DL><p>
									<DT><H3 FOLDED>agent-code-trajectory</H3>
									<DL><p>
										<DT><H3 FOLDED>trae-agent</H3>
										<DL><p>
											<DT><A HREF="https://github.com/bytedance/trae-agent/blob/b03b584c09bcff90d74a5469216a6747d3f1fe1a/TRAJECTORY_RECORDING.md#L4">trae-agent/TRAJECTORY_RECORDING.md</A>
											<DT><A HREF="https://github.com/bytedance/trae-agent">bytedance/trae-agent: Trae Agent is an LLM-based agent for general purpose software engineering tasks.</A>
										</DL><p>
										<DT><H3 FOLDED>CC-Bench</H3>
										<DL><p>
											<DT><A HREF="https://huggingface.co/datasets/zai-org/CC-Bench-trajectories">zai-org/CC-Bench-trajectories ¬∑ Datasets at Hugging Face</A>
										</DL><p>
										<DT><A HREF="https://algotune.io/feedback_controller_design_o4-mini.html">AlgoTuner Log ‚Äì feedback_controller_design ‚Äì o4-mini</A>
									</DL><p>
									<DT><A HREF="https://x.com/OfirPress/status/1940433847101108585">(1) Ofir Press en X: "AlgoBench is extremely tough, with agents not finding substantial speedups on most tasks. But sometimes these agents do really cool things: here, the agent realized that it could solve this convex optimization problem with a scipy function, leading to an 81x speedup. https://t.co/l7ZksS6I0Z" / X</A>
									<DT><A HREF="https://algotune.io/feedback_controller_design_o4-mini.html">AlgoTuner Log ‚Äì feedback_controller_design ‚Äì o4-mini</A>
								</DL><p>
								<DT><H3 FOLDED>agents-sandbox</H3>
								<DL><p>
									<DT><H3 FOLDED>sandbox-fusion</H3>
									<DL><p>
										<DT><A HREF="https://hub.docker.com/r/volcengine/sandbox-fusion">volcengine/sandbox-fusion - Docker Image | Docker Hub</A>
										<DT><A HREF="https://github.com/bytedance/SandboxFusion">bytedance/SandboxFusion</A>
									</DL><p>
									<DT><H3 FOLDED>wasm-sandbox</H3>
									<DL><p>
										<DT><A HREF="https://opensource.microsoft.com/blog/2025/03/26/hyperlight-wasm-fast-secure-and-os-free/">Hyperlight Wasm: Fast, secure, and OS-free - Microsoft Open Source Blog</A>
									</DL><p>
									<DT><H3 FOLDED>pybubble</H3>
									<DL><p>
										<DT><A HREF="https://x.com/ariaurelium/status/1990264060592709794">(1) aurelium /…îÀàreÀêli…ôm/ en X: "Docker-based sandboxes for LLM code execution are irritating to set up and high-overhead. So, over the weekend, I built a wrapper around Bubblewrap for easier, faster sandboxes. It can start a full Alpine Linux environment in under 2ms and with ~0 memory overhead. https://t.co/4frswEinO7" / X</A>
										<DT><A HREF="https://github.com/arcee-ai/pybubble">arcee-ai/pybubble</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>nsa-eval</H3>
								<DL><p>
									<DT><A HREF="https://x.com/_xjdr/status/1954946075862982890">xjdr agents eval: GPT5 / Opus 4.1 eval is over.</A>
									<DT><A HREF="https://github.com/Noumena-Network/NSA-Test">Noumena-Network/NSA-Test: NSA Triton Kernels written with GPT5 and Opus 4.1</A>
								</DL><p>
								<DT><H3 FOLDED>MLE-bench</H3>
								<DL><p>
									<DT><A HREF="https://github.com/openai/mle-bench">openai/mle-bench: MLE-bench is a benchmark for measuring how well AI agents perform at machine learning engineering</A>
									<DT><A HREF="https://www.arxiv.org/abs/2509.04575">[2509.04575] Bootstrapping Task Spaces for Self-Improvement</A>
								</DL><p>
								<DT><H3 FOLDED>claude-codex</H3>
								<DL><p>
									<DT><A HREF="https://x.com/_xjdr/status/1974258311554839034">(1) xjdr en X: "claude really loves formal specification and codex really really does not ." / X</A>
									<DT><A HREF="https://x.com/difficultyang/status/1973485812085149823">(1) difficultyang en X: "Another claude code / codex head to head I did recently. Claude Code: https://t.co/r46ZlkF5FF, Codex: https://t.co/z9IzRAhtV4 https://t.co/65Zdv5zJuq" / X</A>
									<DT><A HREF="https://gist.github.com/ezyang/703132c17bf91120bf9d6b16a187363b">as1.py</A>
									<DT><A HREF="https://gist.github.com/ezyang/8fb2cec08f2457026e72da7780881758">as2.py</A>
									<DT><A HREF="https://x.com/difficultyang/status/1973789242192245053/photo/1">New eval dropped</A>
									<DT><A HREF="https://x.com/difficultyang/status/1973206165397053649">(1) difficultyang en X: "I finally have a good project to test Sonnet 4.5 and Codex head to head against each other. Prompt: https://t.co/zlCfusVijy" / X</A>
									<DT><A HREF="https://x.com/difficultyang/status/1973206165397053649/photo/1">(1) difficultyang en X: "I finally have a good project to test Sonnet 4.5 and Codex head to head against each other. Prompt: https://t.co/zlCfusVijy" / X</A>
								</DL><p>
								<DT><A HREF="https://x.com/_jasonwei/status/1939762496757539297">We don‚Äôt have AI self-improves yet, and when we do it will be a game-changer.</A>
								<DT><A HREF="https://github.com/Noumena-Network/NSA-Test">Noumena-Network/NSA-Test: NSA Triton Kernels written with GPT5 and Opus 4.1</A>
							</DL><p>
							<DT><H3 FOLDED>agents-architecture</H3>
							<DL><p>
								<DT><A HREF="https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf">A practical guide to building agents</A>
								<DT><A HREF="https://devin.ai/agents101#quick-wins">Coding Agents 101: The Art of Actually Getting Things Done</A>
							</DL><p>
							<DT><H3 FOLDED>computer-operator</H3>
							<DL><p>
								<DT><H3 FOLDED>morph-cloud</H3>
								<DL><p>
									<DT><H3 FOLDED>morph-cloud-lean</H3>
									<DL><p>
										<DT><A HREF="https://www.morph.so/blog/lean-server-morph-cloud">INSTANTLY SCALABLE LEAN 4 PROVING ENVIRONMENTS ON MORPH CLOUD</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://www.anthropic.com/news/3-5-models-and-computer-use">Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku \ Anthropic</A>
								<DT><A HREF="https://openai.com/index/introducing-operator/">Introducing Operator | OpenAI</A>
								<DT><A HREF="https://www.youtube.com/watch?v=LCEmiRjPEtQ">Andrej Karpathy: Software Is Changing (Again) - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>rl-hierarchical</H3>
							<DL><p>
								<DT><A HREF="https://www.arxiv.org/abs/2506.14045">[2506.14045] Discovering Temporal Structure: An Overview of Hierarchical Reinforcement Learning</A>
								<DT><A HREF="https://x.com/MartinKlissarov/status/1938659596522135975">(1) Martin Klissarov en X: "As AI agents face increasingly long and complex tasks, decomposing them into subtasks becomes increasingly appealing. But how do we discover such temporal structure? Hierarchical RL provides a natural formalism-yet many questions remain open. Here's our overview of the fieldüßµ https://t.co/a0tBiFywkD" / X</A>
							</DL><p>
							<DT><H3 FOLDED>AgentScope</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/papers/2508.16279">Paper page - AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications</A>
							</DL><p>
							<DT><H3 FOLDED>agent-anomaly-detection</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=fjkSBdamYjo">AD AGENT: A $100 Million Business Opportunity Gift Wrapped In A Box - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>agents-app</H3>
							<DL><p>
								<DT><H3 FOLDED>manus</H3>
								<DL><p>
									<DT><A HREF="https://x.com/zhzHNN/status/2014891484638806421">(1) Huaizheng Zhang en X: "Building an agent app like Manus is not a weekend project. It takes taste + initiative + a ton of hands-on reps. And yeah ‚Äî evaluation is everything. https://t.co/CAu3pS0Vjc" / X</A>
									<DT><A HREF="https://x.com/genai_is_real/status/2012027725989756970?s=12">(2) Chayenne Zhao en X: "I spent my flight re-listening to the early 2025 business interview with Xiao Hong, the CEO of Manus. It is truly surprising that by now, in early 2026, almost everything he mentioned in that interview has become common knowledge. Back then, R1 had just been released, and the" / X</A>
									<DT><A HREF="https://github.com/OthmanAdi/planning-with-files">OthmanAdi/planning-with-files: Claude Code skill implementing Manus-style persistent markdown planning ‚Äî the workflow pattern behind the $2B acquisition.</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://github.com/mem0ai/mem0">mem0ai/mem0: The Memory layer for your AI apps</A>
							<DT><A HREF="https://www.youtube.com/watch?v=6K83UXV_oK0">Building Dynamic AI Memory Systems: Sam Whitmore's Approach to Personalization - YouTube</A>
							<DT><A HREF="https://x.com/_akhaliq/status/1858533342993408129">(1) AK en X: "The Dawn of GUI Agent A Preliminary Case Study with Claude 3.5 Computer Use Game (Honkai: Star Rail) Claude 3.5 Computer Use can help complete Honkai: Star Rail daily tasks, accurately locating and interacting with in-game elements. https://t.co/ste95A560K" / X</A>
							<DT><A HREF="https://github.com/USC-FORTIS/AD-AGENT">USC-FORTIS/AD-AGENT: A multi-agent framework to fully automate anomaly detection in different modalities, tabular, graph, time series, and more (work in progress)!</A>
							<DT><A HREF="https://arxiv.org/abs/2505.12594">[2505.12594] AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection</A>
							<DT><A HREF="https://ysymyth.github.io/The-Second-Half/">The Second Half ‚Äì Shunyu Yao ‚Äì ÂßöÈ°∫Èõ®</A>
							<DT><A HREF="https://ai.meta.com/research/publications/collaborative-reasoner-self-improving-social-agents-with-synthetic-conversations/?utm_source=linkedin&utm_medium=organic%20social&utm_content=video&utm_campaign=fair">Collaborative Reasoner: Self-improving Social Agents with Synthetic Conversations | Research - AI at Meta</A>
							<DT><A HREF="https://www.futurehouse.org/">FutureHouse</A>
							<DT><A HREF="https://www.youtube.com/watch?v=OkEGJ5G3foU">Reinforcement Learning, Kernels, Reasoning, Quantization &amp; Agents ‚Äî Daniel Han</A>
							<DT><A HREF="https://arxiv.org/abs/2509.06283">[2509.06283] SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents</A>
							<DT><A HREF="https://arxiv.org/abs/2509.10446">[2509.10446] DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL</A>
							<DT><A HREF="https://arxiv.org/abs/2509.08755">[2509.08755] AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2509.06501">[2509.06501] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents</A>
							<DT><A HREF="https://aman.ai/primers/ai/agents/#initial-output-generation">Aman's AI Journal ‚Ä¢ Primers ‚Ä¢ Agents</A>
							<DT><A HREF="https://arxiv.org/abs/2510.06828">[2510.06828] Recurrence-Complete Frame-based Action Models</A>
							<DT><A HREF="https://x.com/mike64_t/status/1976397973841117527">(1) mike64_t en X: "Long-horizon Perception requires re-thinking Recurrence" / X</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Von_Neumann_universal_constructor">Von Neumann universal constructor - Wikipedia</A>
							<DT><A HREF="https://www.youtube.com/watch?v=QWr2y3jt2Q4&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=48">Scaling Agentic Intelligence from Pre-Training to RL - Aakanksha Chowdery - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>language-training</H3>
						<DL><p>
							<DT><H3 FOLDED>training-lectures</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=md8D8eNj5JM">Ray Summit 2025 Keynote: Building Cursor Composer with Sasha Rush - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-training-data</H3>
							<DL><p>
								<DT><H3 FOLDED>data-infrastructure</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=z9RHaQZnWM4">How xAI Scales Image &amp; Video Processing with Ray | Ray Summit 2025 - YouTube</A>
									<DT><A HREF="https://www.amplifypartners.com/blog-posts/datologys-distributed-pipelines-for-handling-pbs-of-image-data">Datology's distributed pipelines for handling PBs of image data | Amplify Partners</A>
								</DL><p>
								<DT><H3 FOLDED>data</H3>
								<DL><p>
									<DT><H3 FOLDED>data-agi</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2306.09479">[2306.09479] Inverse Scaling: When Bigger Isn't Better</A>
										<DT><A HREF="https://arxiv.org/abs/2305.14627">[2305.14627] Enabling Large Language Models to Generate Text with Citations</A>
										<DT><A HREF="https://arxiv.org/abs/2210.02615">[2210.02615] Learning to Reason With Relational Abstractions</A>
										<DT><A HREF="https://arxiv.org/abs/2212.10077">[2212.10077] DOC: Improving Long Story Coherence With Detailed Outline Control</A>
										<DT><A HREF="https://arxiv.org/abs/2210.11416">[2210.11416] Scaling Instruction-Finetuned Language Models</A>
										<DT><A HREF="https://arxiv.org/abs/2311.12983">[2311.12983] GAIA: a benchmark for General AI Assistants</A>
										<DT><A HREF="https://arxiv.org/abs/2212.08073">[2212.08073] Constitutional AI: Harmlessness from AI Feedback</A>
										<DT><A HREF="https://arxiv.org/pdf/2112.09332">WebGPT: Browser-assisted question-answering with human feedback (OpenAI)</A>
										<DT><A HREF="https://arxiv.org/abs/2106.10328">[2106.10328] Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets</A>
										<DT><A HREF="https://arxiv.org/pdf/2211.03540">Measuring Progress on Scalable Oversight for Large Language Models</A>
									</DL><p>
									<DT><H3 FOLDED>surgeai</H3>
									<DL><p>
										<DT><A HREF="https://www.surgehq.ai/">Surge AI | Human Intelligence for AGI</A>
									</DL><p>
									<DT><H3 FOLDED>datologyai</H3>
									<DL><p>
										<DT><A HREF="https://www.datologyai.com/">DatologyAI | Automated data curation for GenAI</A>
									</DL><p>
									<DT><A HREF="https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0.pdf">https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0.pdf</A>
									<DT><A HREF="https://blog.jxmo.io/p/there-are-no-new-ideas-in-ai-only">There Are No New Ideas in AI... Only New Datasets</A>
									<DT><A HREF="https://a16z.com/fruits-of-the-walled-garden/">Fruits of the Walled Garden | Andreessen Horowitz</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1980167320887869455">they were pursuing unlimited context but as a side quest went and built a machine for fully parsing internet PDF data</A>
								</DL><p>
								<DT><H3 FOLDED>data-curation</H3>
								<DL><p>
									<DT><H3 FOLDED>data-quality</H3>
									<DL><p>
										<DT><H3 FOLDED>perplexity-data</H3>
										<DL><p>
											<DT><A HREF="https://x.com/cloneofsimo/status/1940334930116202781">Wow I am incredibly stupid to have not realized this earlier: ppl ratio of different sized model is roughly data quality because scaling coeffient is measure of how good the data is</A>
											<DT><A HREF="https://x.com/kalomaze/status/1940266023946776671">ScalingFilter: work to define concrete objective metrics for both quality and diversity</A>
										</DL><p>
										<DT><H3 FOLDED>ScalingFilter</H3>
										<DL><p>
											<DT><A HREF="https://x.com/kalomaze/status/1940266023946776671">ScalingFilter: work to define concrete objective metrics for both quality and diversity</A>
											<DT><A HREF="https://arxiv.org/abs/2408.08310">[2408.08310] ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws</A>
										</DL><p>
										<DT><A HREF="https://lilianweng.github.io/posts/2024-02-05-human-data-quality/">Thinking about High-Quality Human Data | Lil'Log</A>
									</DL><p>
									<DT><H3 FOLDED>self-data-curation</H3>
									<DL><p>
										<DT><H3 FOLDED>reasoning-data</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>bytedn-AttentionInfluence</H3>
										<DL><p>
											<DT><A HREF="https://x.com/GeZhang86038849/status/1922182593791066351">(1) Ge Zhang en X: "[1/n] üöÄ Thrilled to unveil our latest breakthrough: AttentionInfluence! A groundbreaking, training-free, zero-supervision approach for selecting reasoning-rich pretraining data‚Äîjust by masking attention heads! ‚ú® No labels. No retraining. A mere pretrained 1.3B-parameter model" / X</A>
											<DT><A HREF="https://arxiv.org/pdf/2505.07293">AttentionInfluence: Adopting Attention Head Influence for Weak-to-Strong Pretraining Data Selection</A>
										</DL><p>
										<DT><A HREF="https://github.com/ByteDance-Seed/Seed-Coder/blob/master/Seed-Coder.pdf">Seed-Coder: Let the Code Model Curate Data for Itself</A>
										<DT><A HREF="https://x.com/MinqiJiang/status/1967563165455265905">[Minqi Jiang] (GDR) uses a pretrained LLM to rewrite existing data, so that undesirable content, like toxic remarks or personally identifiable information (PII), is no longer present.</A>
										<DT><A HREF="https://arxiv.org/abs/2509.08653">[2509.08653] Generative Data Refinement: Just Ask for Better Data</A>
										<DT><A HREF="https://x.com/teortaxesTex/status/1921081607504507176">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "ByteDance Seed shares coding LLMs: Seed-Coder-8B. 6T tokens, outperforms Qwen3-8B. Base, Instruct, Reasoner. The core point: Let the Code Model Curate Data for Itself Immediate SoTA data recipe, far expanding on DeepSeek's early papers. Probably #1 AGI team in China already. https://t.co/GGafzivKJU" / X</A>
										<DT><A HREF="https://x.com/thao_nguyen26/status/1937210428876292457">Recycle Web text data</A>
										<DT><A HREF="https://www.arxiv.org/abs/2506.04689">[2506.04689] Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models</A>
										<DT><A HREF="https://www.meta.com/superintelligence/">Personal Superintelligence</A>
										<DT><A HREF="https://arxiv.org/abs/2510.24684">[2510.24684] SPICE: Self-Play In Corpus Environments Improves Reasoning</A>
									</DL><p>
									<DT><H3 FOLDED>dataset-distillation</H3>
									<DL><p>
										<DT><H3 FOLDED>Ultra-FineWeb</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2505.05427">[2505.05427] Ultra-FineWeb: Efficient Data Filtering and Verification for High-Quality LLM Training Data</A>
											<DT><A HREF="https://x.com/OpenBMB/status/1934444774804918585">(1) OpenBMB en X: "üöÄ Introducing Ultra-FineWeb üî• ~1T English and 120B Chinese tokens! ~Training fuel of MiniCPM4! üéØ Highlights ~Efficient Verification Strategy: Reduces data verification cost by 90% ~High-Efficiency Filtering Pipeline: Optimizes selection of both positive and negative samples" / X</A>
										</DL><p>
										<DT><A HREF="https://snats.xyz/pages/articles/breaking_some_laws.html">snats website</A>
										<DT><A HREF="https://snats.xyz/pages/articles/breaking_some_laws.html">I want to break some laws too</A>
										<DT><A HREF="https://github.com/Distill-Generalization-Group/Distill-Generalization">Distill-Generalization-Group/Distill-Generalization</A>
									</DL><p>
									<DT><H3 FOLDED>meta-learned-data-curation</H3>
									<DL><p>
										<DT><H3 FOLDED>DataRater</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2505.17895">[2505.17895] DataRater: Meta-Learned Dataset Curation</A>
											<DT><A HREF="https://x.com/cloneofsimo/status/1949583343403860426">High score images are much more "feature crisp", where some low score images often looks confusing</A>
										</DL><p>
										<DT><H3 FOLDED>bytedn-dolphin</H3>
										<DL><p>
											<DT><A HREF="https://github.com/bytedance/Dolphin?tab=readme-ov-file">bytedance/Dolphin: The official repo for ‚ÄúDolphin: Document Image Parsing via Heterogeneous Anchor Prompting‚Äù, ACL, 2025.</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>augmented-data-curation</H3>
									<DL><p>
										<DT><H3 FOLDED>augmentation-text-sequences</H3>
										<DL><p>
											<DT><A HREF="https://x.com/giffmana/status/1947729993607348255">Rephrasing, back translation, random drop or replacements, dictionary drop/replacements, random mini shuffles, and many different places to put dropout including right on the tokens (eg. Kimi)</A>
										</DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=mfXNi092n6o&list=PLLalUvky4CLK3oT1DKNPagd_lTXooYVlR&index=1">TimotheÃÅe Darcet - Scaling Self Supervised Learning for Vision An Introduction to DINOv2 - YouTube</A>
										<DT><A HREF="https://x.com/AhmadMustafaAn1/status/1941902596475646189/photo/1">Curating the data: Start from a good small dataset (eg. ImageNet) -&gt; augment it with a large image source</A>
									</DL><p>
									<DT><H3 FOLDED>FineWeb2</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2506.20920">[2506.20920] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language</A>
										<DT><A HREF="https://x.com/gui_penedo/status/1938631842720022572">deduplication-based upsampling, which we call rehydration</A>
										<DT><A HREF="https://arxiv.org/pdf/2506.20920">FineWeb2: One Pipeline to Scale Them All ‚Äî Adapting Pre-Training Data Processing to Every Language</A>
										<DT><A HREF="https://github.com/huggingface/fineweb-2">huggingface/fineweb-2</A>
										<DT><A HREF="https://huggingface.co/datasets/HuggingFaceFW/fineweb-2">HuggingFaceFW/fineweb-2 ¬∑ Datasets at Hugging Face</A>
									</DL><p>
									<DT><H3 FOLDED>data-cleaning</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/lilac_ai">Lilac: Analyze, structure, and clean unstructured data with AI</A>
										<DT><A HREF="https://lilacml.com/blog/introducing-lilac.html">Introducing Lilac - üå∏ Lilac</A>
										<DT><A HREF="https://github.com/ChenghaoMou/text-dedup">ChenghaoMou/text-dedup: All-in-one text de-duplication</A>
										<DT><A HREF="https://publish.obsidian.md/chenghao/posts/20230220150602">Large-scale Near-deduplication Behind BigCode</A>
										<DT><A HREF="https://lmsys.org/blog/2023-11-14-llm-decontaminator/">LLM-based decontaminator</A>
									</DL><p>
									<DT><H3 FOLDED>text-dedup</H3>
									<DL><p>
										<DT><H3 FOLDED>bloom-filter</H3>
										<DL><p>
											<DT><A HREF="https://github.com/allenai/bff">allenai/bff</A>
										</DL><p>
										<DT><A HREF="https://github.com/ChenghaoMou/text-dedup">ChenghaoMou/text-dedup: All-in-one text de-duplication</A>
									</DL><p>
									<DT><H3 FOLDED>JEST</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2406.17711">[2406.17711] Data curation via joint example selection further accelerates multimodal learning</A>
										<DT><A HREF="https://arxiv.org/html/2405.15613v2">Automatic Data Curation for Self-Supervised Learning: A Clustering-Based Approach</A>
									</DL><p>
									<DT><A HREF="https://papers.nips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Supplemental.pdf">GPT-3:Details of Common Crawl Filtering</A>
									<DT><A HREF="https://github.com/cloneofsimo/imgdataset_process">cloneofsimo/imgdataset_process</A>
									<DT><A HREF="https://developer.nvidia.com/blog/gpu-accelerated-json-data-processing-with-rapids/?ncid=so-link-395145-vt27#cid=an01_so-link_en-us">GPU-Accelerated JSON Data Processing with RAPIDS</A>
									<DT><A HREF="https://arxiv.org/pdf/2310.20707.pdf">WHAT‚ÄôS IN MY BIG DATA? (Allen Institute for AI)</A>
									<DT><A HREF="https://lilacml.com/blog/introducing-lilac.html">Introducing Lilac - üå∏ Lilac</A>
									<DT><A HREF="https://www.ibm.com/downloads/cas/X9W4O6BM">Granite Foundation Models</A>
									<DT><A HREF="https://beam.apache.org/">Apache Beam¬Æ: Batch and streaming data processing</A>
									<DT><A HREF="https://github.com/google/seqio">google/seqio: Task-based datasets, preprocessing, and evaluation for sequence models.</A>
									<DT><A HREF="https://github.com/nikitakit/sabertooth/blob/80ab40a6bd50f4e012e0e5489a5d9b8315bc6758/rust/create_pretraining_data/src/main.rs#L4">sabertooth/rust/create_pretraining_data/src/main.rs at 80ab40a6bd50f4e012e0e5489a5d9b8315bc6758 ¬∑ nikitakit/sabertooth</A>
									<DT><A HREF="https://voltrondata.com/benchmarks/theseus">Benchmarking Report: Theseus Engine</A>
									<DT><A HREF="https://github.com/NVIDIA/spark-rapids">NVIDIA/spark-rapids: Spark RAPIDS plugin - accelerate Apache Spark with GPUs</A>
									<DT><A HREF="https://www.youtube.com/watch?v=crRbIgNqetg">Lightning Talk: Tensor Query Processing - Matteo Interlandi, Microsoft - YouTube</A>
									<DT><A HREF="https://laion.ai/blog/laion-pop/">LAION POP: 600,000 high-resolution images with detailed descriptions | LAION</A>
									<DT><A HREF="https://openreview.net/forum?id=UmvSlP-PyV">Beyond neural scaling laws: beating power law scaling via data pruning | OpenReview</A>
									<DT><A HREF="https://github.com/microsoft/markitdown">microsoft/markitdown: Python tool for converting files and office documents to Markdown.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=dzB0HMtMIfI">Master Real-time Data Pipelines with Kafka and Flink - 3 hr Course - DataExpert.io Free Boot Camp - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=nt38LZhk7jQ">Maintain Data Pipelines Like Netflix and Airbnb - DataExpert.io Free Bootcamp - Week 6 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=ggQQXGXDmS8">Data Structure Is All You Need: Outperform Deepseek For $30 - YouTube</A>
									<DT><A HREF="https://www.datologyai.com/">DatologyAI | Automated data curation for GenAI</A>
									<DT><A HREF="https://blog.jxmo.io/p/there-are-no-new-ideas-in-ai-only">There Are No New Ideas in AI... Only New Datasets</A>
									<DT><A HREF="https://arxiv.org/abs/2404.07177">[2404.07177] Scaling Laws for Data Filtering -- Data Curation cannot be Compute Agnostic</A>
									<DT><A HREF="https://openreview.net/forum?id=XfHWcNTSHp">A Survey on Data Selection for Language Models | OpenReview</A>
									<DT><A HREF="https://x.com/_xjdr/status/1999144445556732257">hydra gradig, extract kept document, k2 rephrasing</A>
								</DL><p>
								<DT><H3 FOLDED>Datasets</H3>
								<DL><p>
									<DT><H3 FOLDED>pretrain-dataset</H3>
									<DL><p>
										<DT><H3 FOLDED>Anna</H3>
										<DL><p>
											<DT><A HREF="https://annas-blog.org/duxiu-exclusive.html">Anna's Blog: Exclusive access for LLM companies to largest Chinese non-fiction book collection in the world - Anna‚Äôs Blog</A>
										</DL><p>
										<DT><H3 FOLDED>Duxiu</H3>
										<DL><p>
											<DT><A HREF="https://search.library.wisc.edu/database/UWI46808">Duxiu Database - Databases - UW-Madison Libraries</A>
											<DT><A HREF="https://x.com/teortaxesTex/status/1980174456350806362">Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "I failed to parse the ambition of this release. DeepSeek Contexts Optical Compression is not just a good fast OCR, not just ¬´we want to train V4/V5 on all Anna and DuXiu¬ª. It's exactly what it says in the title. And more. For starters, think of realtime computer-use agents. https://t.co/RKpTxG8ZI8" / X</A>
										</DL><p>
										<DT><H3 FOLDED>Libgen</H3>
										<DL><p>
											<DT><A HREF="https://librarygenesis.net/">Library Genesis - Library Genesis Guide</A>
										</DL><p>
										<DT><H3 FOLDED>datasets-common-crawls</H3>
										<DL><p>
											<DT><H3 FOLDED>FineWeb</H3>
											<DL><p>
												<DT><A HREF="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">FineWeb: decanting the web for the finest text data at scale - a Hugging Face Space by HuggingFaceFW</A>
												<DT><A HREF="https://huggingface.co/datasets/HuggingFaceFW/fineweb">HuggingFaceFW/fineweb ¬∑ Datasets at Hugging Face</A>
												<DT><A HREF="https://x.com/LoubnaBenAllal1/status/1797175938972606975">(1) Loubna Ben Allal en X: "üç∑ FineWeb technical report is out and so is üìö FineWeb-Edu, a 1.3 trillion tokens dataset that outperforms all other open web datasets, with remarkable improvements on educational benchmarks such as MMLU, ARC, and OpenBookQA. Technical report: https://t.co/lfOZYYJKxq Dataset: https://t.co/urC5qjmx3v" / X</A>
												<DT><A HREF="https://x.com/drjwrae/status/1797286202825232497">(1) Jack Rae en X: "Some really nice data research + artifacts coming out from HuggingFace these days. Creating the definitive open source dataset has probably more value than most open-sourced models at this stage." / X</A>
												<DT><A HREF="https://x.com/gui_penedo/status/1797173053123916036">(1) Guilherme Penedo en X: "We are (finally) releasing the üç∑ FineWeb technical report! In it, we detail and explain every processing decision we took, and we also introduce our newest dataset: üìö FineWeb-Edu, a (web only) subset of FW filtered for high educational content. Link: https://t.co/MRsc8Q5K9q https://t.co/HVfFnKbeso" / X</A>
												<DT><A HREF="https://x.com/jd_pressman/status/1797396190210015716/photo/1">The 4 types of synthetic data</A>
												<DT><A HREF="https://x.com/i/bookmarks?post_id=1796901742715498604">The only thing we know is "make it as diverse as possible"..</A>
												<DT><A HREF="https://x.com/i/bookmarks?post_id=1797320347999670368">CommonCrawl over time</A>
												<DT><A HREF="https://x.com/i/bookmarks?post_id=1797313173449764933">FineWeb-Edu llm.c</A>
												<DT><A HREF="https://github.com/huggingface/datatrove/blob/main/examples/fineweb.py">datatrove/examples/fineweb.py</A>
												<DT><A HREF="https://x.com/lvwerra/status/1965457646724825381">Leandro von Werra en X: "The FinePDFs pipeline really shows the massive scale needed for LLM data processing: Raw data: 1.35B PDFs (1.2 PB) ‚Üí $50k/mo storage Extraction: &amp;gt; rolmOCR: 368M docs ‚Üí 250k GPUh, $750k &amp;gt; docling: 918M docs ‚Üí 2.4M vCPUh, $35k Total liberation cost (incl. ablations): ~$1M https://t.co/PvNp0sCqeG" / X</A>
											</DL><p>
											<DT><H3 FOLDED>DataComp</H3>
											<DL><p>
												<DT><A HREF="https://www.datacomp.ai/dclm/">DataComp</A>
												<DT><A HREF="https://arxiv.org/abs/2406.11794">[2406.11794] DataComp-LM: In search of the next generation of training sets for language models</A>
												<DT><A HREF="https://x.com/TsingYoga/status/1804728355239199181">It's Time to Scale Down the Data</A>
											</DL><p>
											<DT><A HREF="https://commoncrawl.org/">Common Crawl - Open Repository of Web Crawl Data</A>
											<DT><A HREF="https://huggingface.co/datasets/HuggingFaceFW/fineweb">HuggingFaceFW/fineweb ¬∑ Datasets at Hugging Face</A>
											<DT><A HREF="https://huggingface.co/datasets/THUDM/LongBench">THUDM/LongBench</A>
											<DT><A HREF="https://huggingface.co/datasets/c4">c4</A>
											<DT><A HREF="https://arxiv.org/abs/2309.04662">[2309.04662] MADLAD-400: A Multilingual And Document-Level Large Audited Dataset</A>
											<DT><A HREF="https://huggingface.co/datasets/tiiuae/falcon-refinedweb">tiiuae/falcon-refinedweb</A>
											<DT><A HREF="https://twitter.com/_philschmid/status/1714280568853303720">IBM's Granite LLMs</A>
											<DT><A HREF="https://commoncrawl.org/get-started">Common Crawl - Accessing the Data: AWS S3 buckets</A>
											<DT><A HREF="https://github.com/sophiawisdom/data">sophiawisdom/data</A>
											<DT><A HREF="https://www.youtube.com/watch?v=Olpz0imjPEE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=68&pp=iAQB">Addressing the Challenges of Public Web Data - Greg Lindahl, Common Crawl - YouTube</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>datasets-google-research</H3>
									<DL><p>
										<DT><A HREF="https://github.com/google-research-datasets">Google Research Datasets</A>
										<DT><A HREF="https://github.com/google-research-datasets/natural-questions">google-research-datasets/natural-questions: Natural Questions (NQ) contains real user questions issued to Google search, and answers found from Wikipedia by annotators. NQ is designed for the training and evaluation of automatic question answering systems.</A>
									</DL><p>
									<DT><H3 FOLDED>LAION</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/laion_ai/status/1714883417383346493">LAION: 608 B chess moves, 236 Rubik's Cube moves, 39 B A* moves in ASCII Mazes</A>
										<DT><A HREF="https://laion.ai/blog/laion-pop/">LAION POP: 600,000 high-resolution images with detailed descriptions | LAION</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-math</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=QDkm_BU9Deo">Generative AI for Math: Part I MATHPILE: A Billion-Token-Scale Pretraining Corpus for Math</A>
										<DT><A HREF="https://gair-nlp.github.io/MathPile/">Generative AI for Math: Part I MATHPILE: A Billion-Token-Scale Pretraining Corpus for Math</A>
										<DT><A HREF="https://arxiv.org/abs/2310.06786">OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text</A>
										<DT><A HREF="https://huggingface.co/datasets/open-web-math/open-web-math">open-web-math/open-web-math</A>
										<DT><A HREF="https://huggingface.co/datasets/math-ai/StackMathQA">math-ai/StackMathQA</A>
										<DT><A HREF="https://huggingface.co/datasets/math-eval/TAL-SCQ5K">math-eval/TAL-SCQ5K</A>
										<DT><A HREF="https://x.com/huggingpapers/status/1951373307690865022">allenai/math-meta-reasoning-cleaned-latex-delim-cleaned</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-dolma</H3>
									<DL><p>
										<DT><A HREF="https://blog.allenai.org/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64">AI2 Dolma: 3 Trillion Token Open Corpus for LLMs | AI2 Blog</A>
										<DT><A HREF="https://drive.google.com/file/d/12gOf5I5RytsD159nSP7iim_5zN31FCXq/view">dolma-datasheet</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-madlad-400</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2309.04662">[2309.04662] MADLAD-400: A Multilingual And Document-Level Large Audited Dataset</A>
										<DT><A HREF="https://huggingface.co/datasets/allenai/MADLAD-400">allenai/MADLAD-400</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-orca</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/datasets/Open-Orca/OpenOrca">Open-Orca/OpenOrca</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-the-stack</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/datasets/bigcode/the-stack">bigcode/the-stack</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-the-pile</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/datasets/JeanKaddour/minipile">JeanKaddour/minipile</A>
									</DL><p>
									<DT><H3 FOLDED>datasets-videos</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/papers/2402.19479">Paper page - Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers</A>
									</DL><p>
									<DT><A HREF="https://jingfengyang.github.io/gpt">Why did all of the public reproduction of GPT-3 fail?</A>
									<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1693951301942759884">mixture dataset</A>
									<DT><A HREF="http://www.gharchive.org/">GH Archive</A>
									<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1745900747810619436">Datasets that I really like</A>
									<DT><A HREF="https://huggingface.co/datasets/ropes">ropes (reasoning)</A>
									<DT><A HREF="https://huggingface.co/datasets/euirim/goodwiki">euirim/goodwiki</A>
									<DT><A HREF="https://huggingface.co/datasets/deepmind/code_contests">deepmind/code_contests</A>
									<DT><A HREF="https://allenai.org/data/entailmentbank">EntailmentBank Dataset ‚Äî Allen Institute for AI</A>
									<DT><A HREF="https://huggingface.co/datasets/gsm8k">gsm8k ¬∑ Datasets at Hugging Face</A>
									<DT><A HREF="https://www.dataprovenance.org/data-provenance-explorer/dataset-explorer">Data Provenance Initiative</A>
									<DT><A HREF="https://datasetsearch.research.google.com/">Dataset Search</A>
								</DL><p>
								<DT><H3 FOLDED>Crawler</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=leCYxw0Qv1E">Scalable Extraction of Training Data from (Production) LLMs</A>
									<DT><A HREF="https://arxiv.org/abs/2309.04662">[2309.04662] MADLAD-400: A Multilingual And Document-Level Large Audited Dataset</A>
									<DT><A HREF="https://github.com/flairNLP/fundus">flairNLP/fundus: A very simple news crawler with a funny name</A>
									<DT><A HREF="https://www.firecrawl.dev/agent">Agent - Gather Data Wherever It Lives on the Web | Firecrawl</A>
								</DL><p>
								<DT><H3 FOLDED>sample-quality</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2309.05463.pdf">Microsoft: Textbooks Are All You Need II: phi-1.5 technical report (phi-2)</A>
									<DT><A HREF="https://twitter.com/jerome_massot/status/1558122719698309126?s=20&t=ya4vHLuGuS3E88MMZhewsw">Dataset selection value</A>
									<DT><A HREF="https://twitter.com/ShayneRedford/status/1660670374206652419">When and where does pretraining (PT) data matter?</A>
									<DT><A HREF="https://twitter.com/jerome_massot/status/1558122719698309126?s=20&t=ya4vHLuGuS3E88MMZhewsw">Data-Centric AI</A>
									<DT><A HREF="https://github.com/shayne-longpre/a-pretrainers-guide/blob/main/A%20Pretrainer's%20Guide%20To%20Training%20Data.pdf">A Pretrainer's Guide To Training Data</A>
									<DT><A HREF="https://twitter.com/sbmaruf/status/1664965734831738881">Systematic Study of ChatGPT on Benchmarks Datasets</A>
								</DL><p>
								<DT><H3 FOLDED>training-data-synthetic-data</H3>
								<DL><p>
									<DT><H3 FOLDED>synthetic-agentic-tool-data</H3>
									<DL><p>
										<DT><A HREF="https://x.com/Dorialexander/status/1947382742347403449">(1) Alexander Doria en X: "Tech report unlocked for K2. For me, even more than muonclip, the most relevant part is the synthetic playground for agentification: really feel like "pre-training as we know it has ended". https://t.co/TJ6dzBDRZY" / X</A>
										<DT><A HREF="https://arxiv.org/pdf/2507.20534">3.1.1 Large-Scale Agentic Data Synthesis for Tool Use Learning</A>
										<DT><A HREF="https://x.com/bigeagle_xd/status/1975960798720860346">great to see kimi-k2 employed for agentic data synthesis</A>
									</DL><p>
									<DT><H3 FOLDED>combine human and AI to annotate at super-human level!</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://twitter.com/home">Synthetic Data from Diffusion Models Improves ImageNet</A>
									<DT><A HREF="https://arxiv.org/pdf/2312.06585.pdf">Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models</A>
									<DT><A HREF="https://arxiv.org/abs/2302.04761">[2302.04761] Toolformer: Language Models Can Teach Themselves to Use Tools</A>
									<DT><A HREF="https://twitter.com/andrew_n_carr/status/1709754581184643089">Meta SAM: Progressive labeling with weak-&gt;strong models effectiveness</A>
									<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1709760111156093201">Computer vision papers data process</A>
									<DT><A HREF="https://arxiv.org/abs/2304.02643">[2304.02643] Segment Anything (SAM)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zpqBiNV9XWE">A Tale of Tails: Model Collapse as a Change of Scaling Laws - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs//2402.07043">[2402.07043] A Tale of Tails: Model Collapse as a Change of Scaling Laws</A>
									<DT><A HREF="https://huggingface.co/blog/cosmopedia">Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models</A>
									<DT><A HREF="https://www.youtube.com/watch?v=kgqDtfC_pRY">Synthetic data from scratch - Clip from livestream 7/May/2024 - Claude 3 Opus, phi-1, phi-3, ChatGPT - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=HJb_GsX1Bhs">Synthetic data that finally helps instead of hurts!! - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs/2505.18091">[2505.18091] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition</A>
									<DT><A HREF="https://arxiv.org/abs/2510.01631">[2510.01631] Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of Scaling Laws, Benefits, and Pitfalls</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Bs_VjCqyDfU">What Happens When All Training Data is AI Generated? - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>ocr-data</H3>
								<DL><p>
									<DT><H3 FOLDED>OCR</H3>
									<DL><p>
										<DT><H3 FOLDED>mistral-ocr</H3>
										<DL><p>
											<DT><A HREF="https://mistral.ai/news/mistral-ocr">Mistral OCR | Mistral AI</A>
										</DL><p>
										<DT><A HREF="https://huggingface.co/nanonets/Nanonets-OCR-s">nanonets/Nanonets-OCR-s ¬∑ Hugging Face</A>
										<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-OCR?tab=readme-ov-file">deepseek-ai/DeepSeek-OCR: Contexts Optical Compression</A>
									</DL><p>
									<DT><H3 FOLDED>ocr-udop</H3>
									<DL><p>
										<DT><A HREF="https://github.com/microsoft/UDOP">microsoft/UDOP: Unifying Vision, Text, and Layout for Universal Document Processing</A>
									</DL><p>
									<DT><A HREF="https://twitter.com/_akhaliq/status/1742369195034099731">A layout-aware generative language model for multimodal document understanding (JPMorgan)</A>
									<DT><A HREF="https://twitter.com/mezaoptimizer/status/1725389571817378142">GPT-4V OCR problem of math -&gt; LaTeX</A>
									<DT><A HREF="https://x.com/askalphaxiv/status/1980722479405678593">(1) alphaXiv en X: "We used DeepSeek OCR to extract every dataset from tables/charts across 500k+ AI arXiv papers for $1000 üöÄ See which benchmarks are trending and discover datasets you didn't know existed Doing the same task with Mistral OCR would've cost $7500 üëÄ https://t.co/OTzh1HJDma" / X</A>
								</DL><p>
								<DT><H3 FOLDED>datasets-stack</H3>
								<DL><p>
									<DT><H3 FOLDED>hf-datasets</H3>
									<DL><p>
										<DT><A HREF="https://x.com/vwxyzjn/status/1818706123375231463">(1) Costa Huang en X: "Releasing `costa_utils` to help better visualize HF datasets. No more squinting eyes at narrowly formatted texts! ``` pip install costa_utils python -m costa_utils.hf_viz \ --sft AI-MO/NuminaMath-TIR \ --split train \ --sft_messages_column_name messages \ https://t.co/ySJ0xTV8AH" / X</A>
									</DL><p>
									<DT><H3 FOLDED>parquet</H3>
									<DL><p>
										<DT><A HREF="https://til.simonwillison.net/duckdb/remote-parquet">Summing columns in remote Parquet files using DuckDB</A>
										<DT><A HREF="https://huggingface.co/blog/parquet-cdc">Parquet Content-Defined Chunking</A>
									</DL><p>
									<DT><A HREF="https://github.com/allenai/unified-io-2">allenai/unified-io-2</A>
									<DT><A HREF="https://medium.com/yandex/ytsaurus-exabyte-scale-storage-and-processing-system-is-now-open-source-42e7f5fa5fc6">YTsaurus: Exabyte-Scale Storage and Processing System</A>
									<DT><A HREF="https://github.com/google/seqio">google/seqio: Task-based datasets, preprocessing, and evaluation for sequence models.</A>
									<DT><A HREF="https://lilacml.com/blog/introducing-lilac.html">Introducing Lilac - üå∏ Lilac</A>
									<DT><A HREF="https://job-boards.greenhouse.io/xai/jobs/4378344007">Job Application for Member of Technical Staff, Pre-training Data Infrastructure at xAI</A>
								</DL><p>
								<DT><H3 FOLDED>compressor</H3>
								<DL><p>
									<DT><A HREF="https://github.com/nadavrot/compressor">nadavrot/compressor: An educational implementation of a modern compressor in Rust</A>
									<DT><A HREF="https://github.com/cloneofsimo/imagenet.int8">cloneofsimo/imagenet.int8</A>
								</DL><p>
								<DT><H3 FOLDED>datasets-labeless</H3>
								<DL><p>
									<DT><A HREF="https://www.databricks.com/blog/tao-using-test-time-compute-train-efficient-llms-without-labeled-data">TAO: Using test-time compute to train efficient LLMs without labeled data | Databricks Blog</A>
								</DL><p>
								<DT><A HREF="https://docs.ffcv.io/writing_datasets.html">Writing a dataset to FFCV format ‚Äî FFCV documentation</A>
								<DT><A HREF="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">FineWeb: decanting the web for the finest text data at scale - a Hugging Face Space by HuggingFaceFW</A>
								<DT><A HREF="https://arxiv.org/abs/2406.11794v1">[2406.11794v1] DataComp-LM: In search of the next generation of training sets for language models</A>
								<DT><A HREF="https://www.youtube.com/watch?v=HYvhj9W2qHQ">Cloud Native Data Loaders for Machine Learning Using Zarr and Xarray - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=W73Sp7XKuVE">Luca Soldaini - Curating Pretrain Data (AI2 / Dolma) - YouTube</A>
								<DT><A HREF="https://x.com/ZackAnkner/status/1797595682439901565">"New paper where we explore using a small LM‚Äôs perplexity to prune the pretraining data for larger LMs. We find that small LMs can prune data for up to 30x larger LMs, data pruning works in the overtrained and data-constrained regimes, and more! https://t.co/XYbI0Ijois" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2405.20541">[2405.20541] Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models</A>
								<DT><A HREF="https://x.com/robertnishihara/status/1798759330868760680">(Robert Nishihara) Ray Server: Dataset preparation</A>
								<DT><A HREF="https://x.com/iamtrask/status/1797528618429468966">(1) Andrew Trask en X: "fantastic work by @huggingface! this stuff really moves the field forward. in 2015 I was listening to Thomas Mikolov talk about word2vec... and he didn't explain it as an algorithmic innovation... he described it as something like ~"i wanted to simplify the architecture so i" / X</A>
								<DT><A HREF="https://x.com/Vaishaal/status/1803198064364232918">(1) Vaishaal Shankar en X: "I am really excited to introduce DataComp for Language Models (DCLM), our new testbed for controlled dataset experiments aimed at improving language models. 1/x https://t.co/uNe5mUJJxb" / X</A>
								<DT><A HREF="https://www.dataprovenance.org/">Data Provenance Initiative</A>
								<DT><A HREF="https://x.com/Dorialexander/status/1864692907506323606">(1) Alexander Doria en X: "‚ÄúThey said it could not be done‚Äù. We‚Äôre releasing Pleias 1.0, the first suite of models trained on open data (either permissibly licensed or uncopyrighted): Pleias-3b, Pleias-1b and Pleias-350m, all based on the two trillion tokens set from Common Corpus. https://t.co/wWN8LRccsC" / X</A>
								<DT><A HREF="https://x.com/iScienceLuvr/status/1879743492450037889">Towards Best Practices for Open Datasets for LLM Training</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-evaluation</H3>
							<DL><p>
								<DT><H3 FOLDED>TEST SET CONTAMINATION</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2310.17623.pdf">PROVING TEST SET CONTAMINATION IN BLACK BOX LANGUAGE MODELS</A>
									<DT><A HREF="https://twitter.com/suchenzang/status/1701615026648605095">Susan Zhang: I think Phi-1.5 trained on the benchmarks. Particularly, GSM8K.</A>
								</DL><p>
								<DT><H3 FOLDED>seqio</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/seqio/tree/main/seqio">seqio/seqio at main ¬∑ google/seqio</A>
								</DL><p>
								<DT><H3 FOLDED>lm-evaluation-harness</H3>
								<DL><p>
									<DT><A HREF="https://github.com/EleutherAI/lm-evaluation-harness?tab=readme-ov-file">EleutherAI/lm-evaluation-harness: A framework for few-shot evaluation of language models.</A>
									<DT><A HREF="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md">lm-evaluation-harness/docs/interface.md at main ¬∑ EleutherAI/lm-evaluation-harness</A>
									<DT><A HREF="https://imbue.com/research/70b-evals/">Ensuring accurate model evaluations: open-sourced, cleaned datasets for models that reason and code - imbue</A>
									<DT><A HREF="https://x.com/Thom_Wolf/status/1805985020168769988">(1) Thomas Wolf en X: "Very excited to release the new version of the Open LLM Leaderboard, v2 ‚Äì it's much harder than the previous version as you can see on some of the v1 &amp;lt;&amp;gt; v2 scores comparison I'm posting below Updated: As open models keeps getting better and saturating some of the evaluations it https://t.co/zv6dSQCnhJ" / X</A>
									<DT><A HREF="https://www.databricks.com/blog/calibrating-mosaic-evaluation-gauntlet">Calibrating the Mosaic Evaluation Gauntlet | Databricks Blog</A>
									<DT><A HREF="https://github.com/EleutherAI/lm-evaluation-harness?tab=readme-ov-file#tensor--data-parallel-and-fast-offline-batching-inference-with-sglang">EleutherAI/lm-evaluation-harness: A framework for few-shot evaluation of language models.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=uHJr5lPxbDg">Compare the latest update of Deepseek V3.1 with R1 and verify üî• What is the speed in a local envi... - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>intrinsic evaluation</H3>
								<DL><p>
									<DT><H3 FOLDED>perplexity</H3>
									<DL><p>
										<DT><A HREF="https://cs.stanford.edu/people/karpathy/tsnejs/csvdemo.html">Perplexity</A>
										<DT><A HREF="https://sjmielke.com/comparing-perplexities.htm">Can you compare perplexity across different segmentations?</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>language-models-evals</H3>
								<DL><p>
									<DT><A HREF="https://www.jasonwei.net/blog/evals">Successful language model evals ‚Äî Jason Wei</A>
									<DT><A HREF="https://arxiv.org/pdf/2311.12022.pdf">GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark (Anthropic)</A>
									<DT><A HREF="https://github.com/Sanger2000/human-eval/blob/master/run.py">HumanEval: pass@K</A>
									<DT><A HREF="https://arxiv.org/abs/2311.07911">[2311.07911] Instruction-Following Evaluation for Large Language Models</A>
									<DT><A HREF="https://github.com/OpenBMB/UltraEval">OpenBMB/UltraEval: An open source framework for evaluating foundation models.</A>
									<DT><A HREF="https://arxiv.org/abs/2311.12983">[2311.12983] GAIA: a benchmark for General AI Assistants</A>
								</DL><p>
								<DT><H3 FOLDED>Game-as-an-Eval</H3>
								<DL><p>
									<DT><H3 FOLDED>GamingAgent</H3>
									<DL><p>
										<DT><A HREF="https://github.com/lmgame-org/GamingAgent?tab=readme-ov-file#lmgame-bench">lmgame-org/GamingAgent: LLM/VLM gaming agents and model evaluation through games.</A>
									</DL><p>
									<DT><H3 FOLDED>evals-pokemon-red</H3>
									<DL><p>
										<DT><A HREF="https://x.com/haoailab/status/1939777711502946544">(1) Hao AI Lab en X: "üî• Pok√©mon Red is becoming a go-to benchmark for testing advanced AIs such as Gemini. But is Pok√©mon Red really a good eval? We study this problem and identify three issues: 1Ô∏è‚É£ Navigation tasks are too hard. 2Ô∏è‚É£ Combat control is too simple. 3Ô∏è‚É£ Raising a strong Pok√©mon team is https://t.co/1SSlTxj3Bz" / X</A>
										<DT><A HREF="https://lmgame.org/#/blog/pokemon_red">From Pok√©mon Red to Standardized Game-as-an-Eval</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>ARC-AGI</H3>
								<DL><p>
									<DT><H3 FOLDED>ARC-AGI-2</H3>
									<DL><p>
										<DT><A HREF="https://x.com/arcprize/status/1943168950763950555">Grok 4 (Thinking) achieves new SOTA on ARC-AGI-2 with 15.9%</A>
										<DT><A HREF="https://x.com/gregkamradt/status/1943169631491100856?s=12">(1) Greg Kamradt en X: "We got a call from @xai 24 hours ago ‚ÄúWe want to test Grok 4 on ARC-AGI‚Äù We heard the rumors. We knew it would be good. We didn‚Äôt know it would become the #1 public model on ARC-AGI Here‚Äôs the testing story and what the results mean: Yesterday, we chatted with Jimmy from the" / X</A>
										<DT><A HREF="https://poetiq.ai/posts/arcagi_announcement/">Poetiq | Traversing the Frontier of Superintelligence</A>
										<DT><A HREF="https://x.com/poetiq_ai/status/2003546918392394218">Using the same Poetiq harness as before, we saw results as high as 75% at under $8 / problem using GPT-5.2 X-High on the full PUBLIC-EVAL dataset</A>
										<DT><A HREF="https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html">Less is More: Recursive Reasoning with Tiny Networks</A>
									</DL><p>
									<DT><A HREF="https://x.com/gregkamradt/status/1943169631491100856?s=12">(1) Greg Kamradt en X: "We got a call from @xai 24 hours ago ‚ÄúWe want to test Grok 4 on ARC-AGI‚Äù We heard the rumors. We knew it would be good. We didn‚Äôt know it would become the #1 public model on ARC-AGI Here‚Äôs the testing story and what the results mean: Yesterday, we chatted with Jimmy from the" / X</A>
									<DT><A HREF="https://x.com/arcprize">ARC Prize (@arcprize) / X</A>
									<DT><A HREF="https://github.com/epang080516/arc_agi">epang080516/arc_agi: SoTA Approach for ARC-AGI 2</A>
									<DT><A HREF="https://arxiv.org/abs/2511.14761">[2511.14761] ARC Is a Vision Problem!</A>
									<DT><A HREF="https://arxiv.org/abs/2511.14761v1">[2511.14761v1] ARC Is a Vision Problem!</A>
									<DT><A HREF="https://x.com/fchollet/status/1999183528492433672">(1) Fran√ßois Chollet en X: "Back in 2019, ARC 1 had one goal: to focus the attention of AI researchers towards the biggest bottleneck on the way to generality, the ability to adapt to novelty on the fly, which was entirely missing from the legacy deep learning paradigm. Six years later, the field has" / X</A>
								</DL><p>
								<DT><H3 FOLDED>HellaSwag</H3>
								<DL><p>
									<DT><A HREF="https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors">HellaSwag or HellaBad? 36% of this popular LLM benchmark contains errors</A>
								</DL><p>
								<DT><H3 FOLDED>GSM8K</H3>
								<DL><p>
									<DT><A HREF="https://www.surgehq.ai/blog/how-we-built-it-openais-gsm8k-dataset-of-8500-math-problems">How Surge AI Built OpenAI's GSM8K Dataset of 8,500 Math Problems</A>
								</DL><p>
								<DT><H3 FOLDED>WeirdML</H3>
								<DL><p>
									<DT><A HREF="https://x.com/htihle/status/1879872398666965236">(1) H√•vard Ihle en X: "Exited to share the results from WeirdML - a benchmark testing LLMs ability to solve weird and unusual machine learning tasks by writing working PyTorch code and iteratively learn from feedback. https://t.co/ntSM1AHfPG" / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/EleutherAI/lm-evaluation-harness">EleutherAI/lm-evaluation-harness: A framework for few-shot evaluation of language models.</A>
								<DT><A HREF="https://thegradient.pub/understanding-evaluation-metrics-for-language-models/">Evaluation Metrics for Language Modeling</A>
								<DT><A HREF="https://www.jasonwei.net/blog/evals">Successful language model evals ‚Äî Jason Wei</A>
								<DT><A HREF="https://x.com/haileysch__/status/1793957143910953185">formalizing what is done evaluating models with loglikelihood multiple choice and perplexity evals</A>
								<DT><A HREF="https://twitter.com/AIatMeta/status/1715041427283902793">Meta: GenBench (Generalizatio testing)</A>
								<DT><A HREF="https://arxiv.org/abs/2311.07689?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=image">[2311.07689] MART: Improving LLM Safety with Multi-round Automatic Red-Teaming</A>
								<DT><A HREF="https://twitter.com/huihan_li/status/1724334480339710287">LINK: framework for systematically generating data in the long-tail distribution</A>
								<DT><A HREF="https://cdn.openai.com/openai-preparedness-framework-beta.pdf">OpenAI: Preparedness Framework (Beta)</A>
								<DT><A HREF="https://www.lesswrong.com/posts/hQPfLsDKWtdvMwyyr/on-openai-s-preparedness-framework">On OpenAI‚Äôs Preparedness Framework ‚Äî LessWrong</A>
								<DT><A HREF="https://cdn.openai.com/papers/weak-to-strong-generalization.pdf">WEAK-TO-STRONG GENERALIZATION: ELICITING STRONG CAPABILITIES WITH WEAK SUPERVISION</A>
								<DT><A HREF="https://arxiv.org/pdf/2312.11444.pdf">An In-depth Look at Gemini's Language Abilities</A>
								<DT><A HREF="https://crfm.stanford.edu/helm/v0.2.2/?group=core_scenarios">Holistic Evaluation of Language Models (HELM)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=2CIIQ5KZWUM">Evaluating LLM-based Applications - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2311.15930">[2311.15930] WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large Language Models</A>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1727111453117997185">Claude: Decline to answer</A>
								<DT><A HREF="https://github.com/meta-llama/llama3/blob/main/eval_details.md">llama3/eval_details.md at main ¬∑ meta-llama/llama3</A>
								<DT><A HREF="https://github.com/openai/simple-evals">openai/simple-evals</A>
								<DT><A HREF="https://twitter.com/gallabytes/status/1784694561861947823">ways of evaluating a langauge encoder</A>
								<DT><A HREF="https://twitter.com/srush_nlp/status/1785293229165818298">LMSys: Chatbot Arena</A>
								<DT><A HREF="https://arxiv.org/abs/2405.14782">[2405.14782] Lessons from the Trenches on Reproducible Evaluation of Language Models</A>
								<DT><A HREF="https://huggingface.co/spaces/open-llm-leaderboard/blog">Open-LLM performances are plateauing, let‚Äôs make the leaderboard steep again - a Hugging Face Space by open-llm-leaderboard</A>
								<DT><A HREF="https://www.youtube.com/watch?v=3gb-ZkVRemQ&list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&index=27">Stanford CS25: V4 I Jason Wei &amp; Hyung Won Chung of OpenAI - YouTube</A>
								<DT><A HREF="https://docs.google.com/presentation/d/1JKpqsbkr5Fg-bj1iElPaC-ToTVpRmRLKZmN89krwl04/edit?resourcekey=0-VPgp_Yc4krPPW3Mxv6UjgQ#slide=id.g25dfdd1f5b2_0_8">2024 stanford cs25 guest lecture jason wei - Google Slides</A>
								<DT><A HREF="https://github.com/mosaicml/llm-foundry/blob/main/scripts/eval/local_data/EVAL_GAUNTLET.md">llm-foundry/scripts/eval/local_data/EVAL_GAUNTLET.md (main)</A>
								<DT><A HREF="https://www.anthropic.com/research/statistical-approach-to-model-evals">A statistical approach to model evaluations \ Anthropic</A>
								<DT><A HREF="https://x.com/_jasonwei/status/1876701085601341662">(1) Jason Wei en X: "Nice paper from Deepmind takes a fresh angle on factuality: https://t.co/3MDQlmNU9W While most existing factuality datasets focus on public world knowledge, this paper evaluates whether responses are consistent with a provided document as context. This is an elegant and" / X</A>
								<DT><A HREF="https://github.com/fzyzcjy/simple-evals">fzyzcjy/simple-evals</A>
								<DT><A HREF="https://openai.com/careers/research-engineer-frontier-evals/">Research Engineer, Frontier Evals | OpenAI</A>
							</DL><p>
							<DT><H3 FOLDED>tokenizer</H3>
							<DL><p>
								<DT><H3 FOLDED>BPE</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/docs/transformers/tokenizer_summary">Byte-Pair Encoding (BPE)</A>
									<DT><A HREF="https://github.com/youkaichao/fast_bpe_tokenizer">youkaichao/fast_bpe_tokenizer: fast bpe tokenizer, simple to understand, easy to use</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Byte_pair_encoding">Byte pair encoding - Wikipedia</A>
									<DT><A HREF="https://github.com/evintunador/gpu_bpe">evintunador/gpu_bpe: tutorial for training a BPE tokenizer on multiple GPUs</A>
								</DL><p>
								<DT><H3 FOLDED>H-Nets</H3>
								<DL><p>
									<DT><A HREF="https://x.com/main_horse/status/1944872968057970881">H-Nets are the future</A>
									<DT><A HREF="https://x.com/sukjun_hwang/status/1943703574908723674">We developed the H-Net: a hierarchical network that replaces tokenization with a dynamic chunking process directly inside the model, automatically discovering and operating over meaningful units of data</A>
									<DT><A HREF="https://main-horse.github.io/posts/hnet-inf/">H-Net - Inference ¬∑ main</A>
									<DT><A HREF="https://github.com/goombalab/hnet">goombalab/hnet: H-Net: Hierarchical Network with Dynamic Chunking</A>
									<DT><A HREF="https://github.com/main-horse/hnet">main-horse/hnet: H-Net Dynamic Hierarchical Architecture</A>
									<DT><A HREF="https://goombalab.github.io/blog/2025/hnet-future/">H-Nets - the Future | Goomba Lab</A>
								</DL><p>
								<DT><H3 FOLDED>tiktokenizer</H3>
								<DL><p>
									<DT><A HREF="https://tiktokenizer.vercel.app/">Tiktokenizer</A>
									<DT><A HREF="https://github.com/openai/tiktoken">openai/tiktoken: tiktoken is a fast BPE tokeniser for use with OpenAI's models.</A>
								</DL><p>
								<DT><H3 FOLDED>sentencepiece</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=2QO3vzwHXhg&t=3551s">sentencepiece_model pb ParseFromString deserialize tokenizer vocab dict</A>
									<DT><A HREF="https://github.com/google/sentencepiece">google/sentencepiece: Unsupervised text tokenizer for Neural Network-based text generation.</A>
									<DT><A HREF="https://github.com/google/sentencepiece/blob/master/python/add_new_vocab.ipynb">sentencepiece/python/add_new_vocab.ipynb</A>
								</DL><p>
								<DT><H3 FOLDED>tokenizers-rust</H3>
								<DL><p>
									<DT><A HREF="https://github.com/guillaume-be/rust-tokenizers">guillaume-be/rust-tokenizers: Rust-tokenizer offers high-performance tokenizers for modern language models, including WordPiece, Byte-Pair Encoding (BPE) and Unigram (SentencePiece) models</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=zduSFxRajkE">Let's build the GPT Tokenizer</A>
								<DT><A HREF="https://arxiv.org/abs/2310.05737">Language Model Beats Diffusion -- Tokenizer is Key to Visual Gen</A>
								<DT><A HREF="https://gist.github.com/Winston-503/39f7bc5fe1d93dcfa38361b119fbe2d7">json_yaml_tokens.py</A>
								<DT><A HREF="https://juditacs.github.io/2019/02/19/bert-tokenization-stats.html">Exploring BERT's Vocabulary</A>
								<DT><A HREF="https://www.youtube.com/watch?v=nu9lBnyRjos">SpaceByte: Deleting Tokenization from Large Language Modeling - YouTube</A>
								<DT><A HREF="https://www.reedbeta.com/blog/programmers-intro-to-unicode/">A Programmer‚Äôs Introduction to Unicode ‚Äì Nathan Reed‚Äôs coding blog</A>
								<DT><A HREF="https://gist.github.com/YouJiacheng/42d54de78d37821ff606aef686e9e50a">qwen_pretok.py</A>
								<DT><A HREF="https://huggingface.co/blog/catherinearnett/dangers-of-tokenizer-recycling">wHy DoNt YoU jUsT uSe ThE lLaMa ToKeNiZeR??</A>
							</DL><p>
							<DT><H3 FOLDED>context-window</H3>
							<DL><p>
								<DT><H3 FOLDED>Linear Transformers</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/research/requests-for-research-2">Transformers with Linear Attention</A>
								</DL><p>
								<DT><H3 FOLDED>KV cache</H3>
								<DL><p>
									<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-4-kv-caching-a-deeper-look-4ba9a77746c8">LLM Inference Series: 4. KV caching, a deeper look | by Pierre Lienhart (main)</A>
									<DT><A HREF="https://arxiv.org/pdf/2305.05920">total number of bytes to store the key-value cache</A>
									<DT><A HREF="https://arxiv.org/abs/2403.05527">[2403.05527] GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless Generative Inference of LLM</A>
									<DT><A HREF="https://openreview.net/pdf?id=e9D2STGwLJ">Adaptive KV Cache Compression for LLMs</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen">DeepSpeed/blogs/deepspeed-fastgen at master ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://twitter.com/bio_bootloader/status/1790539323600949542">context caching for Google Gemini</A>
									<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/main/workspace/blog/optimizing-mla.md">deepseekv2-profile/workspace/blog/optimizing-mla.md at main ¬∑ madsys-dev/deepseekv2-profile</A>
									<DT><A HREF="https://x.com/haileysch__/status/1787583052039802887">MLA TL:DR</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1790407782325420277/photo/4">Teortaxes en X: "he blog on MLA by Jianlin SU (the GOD creator of ROPE) is also a good reference</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1793180779943543246">most KV cache is redundant, actually</A>
									<DT><A HREF="https://github.com/google/maxtext/blob/f7ee8c636fd500995e76c227b351d48680ab7890/MaxText/layers/attentions.py#L435">maxtext/MaxText/layers/attentions.py</A>
									<DT><A HREF="https://github.com/kvcache-ai/Mooncake?tab=readme-ov-file">kvcache-ai/Mooncake: Mooncake is the serving platform for Kimi, a leading LLM service provided by Moonshot AI.</A>
									<DT><A HREF="https://arxiv.org/abs/2407.00079">[2407.00079] Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving</A>
									<DT><A HREF="https://arxiv.org/html/2405.04434v2">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</A>
									<DT><A HREF="https://x.com/tri_dao/status/1712904220519944411">Flash-Decoding</A>
									<DT><A HREF="https://x.com/GriffinAdams92/status/1819072387469516884">(1) Griffin Adams en X: "Announcing Cold Compress 1.0 with @answerdotai A hackable toolkit for using and creating KV cache compression methods. Built on top of @cHHillee and Team‚Äôs GPT-Fast for torch.compilable, light-weight performance. Develop novel methods in as little as 1 line of new code. https://t.co/HRgd54hG3T" / X</A>
									<DT><A HREF="https://github.com/AnswerDotAI/cold-compress/blob/main/cache.py">cold-compress/cache.py at main ¬∑ AnswerDotAI/cold-compress</A>
									<DT><A HREF="https://github.com/LMCache/LMCache">LMCache/LMCache</A>
									<DT><A HREF="https://www.bilibili.com/video/BV17CPkeEEzk/?spm_id_from=333.788.recommend_more_video.1&trackid=web_related_0.router-related-2206419-7v86w.1762360694311.43">KV cache in memory formula</A>
									<DT><A HREF="https://www.kapilsharma.dev/posts/kv-caching-visualized/">KV Caching Illustrated | Kapil Sharma</A>
								</DL><p>
								<DT><H3 FOLDED>long-context</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/MInference">microsoft/MInference: To speed up Long-context LLMs' inference, approximate and dynamic sparse calculate the attention, which reduces inference latency by up to 10x for pre-filling on an A100 while maintaining accuracy.</A>
									<DT><A HREF="https://export.arxiv.org/pdf/2407.02490">MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</A>
									<DT><A HREF="https://arxiv.org/abs/2509.19228">[2509.19228] CompLLM: Compression for Long Context Q&amp;A</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2302.10866.pdf">Hyena Hierarchy</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2023-03-07-hyena">Hyena Hierarchy: Towards Larger Convolutional Language Models ¬∑ Hazy Research</A>
								<DT><A HREF="https://github.com/HazyResearch/safari">HazyResearch/safari: Convolutions for Sequence Modeling</A>
								<DT><A HREF="https://arxiv.org/abs/2305.01625">[2305.01625] Unlimiformer: Long-Range Transformers with Unlimited Length Input</A>
								<DT><A HREF="https://twitter.com/haoliuhl/status/1664396377252667393">Blockwise Parallel Transformer</A>
								<DT><A HREF="https://arxiv.org/pdf/2305.19370.pdf">Blockwise Parallel Transformer for Large Context Models</A>
								<DT><A HREF="https://www.cerebras.net/blog/variable-sequence-length-training-for-long-context-large-language-models/?utm_content=258053990&utm_medium=social&utm_source=linkedin&hss_channel=lcp-10858000">Variable Sequence Length Training for Long-Context Large Language Models - Cerebras</A>
								<DT><A HREF="https://twitter.com/arankomatsuzaki/status/1637612922934382593">CoLT5</A>
								<DT><A HREF="https://arxiv.org/abs/2307.03172">[2307.03172] Lost in the Middle: How Language Models Use Long Contexts</A>
								<DT><A HREF="https://arxiv.org/pdf/2108.12409.pdf">ALiBi</A>
								<DT><A HREF="https://twitter.com/theemozilla/status/1726650665718685821">Yarn-LLAMA-2-70b-32k</A>
								<DT><A HREF="https://www.youtube.com/watch?v=_u47Esw4d8o">[short] On the Long Range Abilities of Transformers - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2404.07143">[2404.07143] Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</A>
								<DT><A HREF="https://arxiv.org/abs/2402.13753">[2402.13753] LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens</A>
								<DT><A HREF="https://arxiv.org/abs/2310.01889">[2310.01889] Ring Attention with Blockwise Transformers for Near-Infinite Context</A>
								<DT><A HREF="https://www.youtube.com/watch?v=MRTTGMlKgb8">Leave No Context Behind</A>
								<DT><A HREF="https://arxiv.org/abs/2404.08801">[2404.08801] Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length</A>
								<DT><A HREF="https://www.youtube.com/watch?v=r_UBBfTPcF0">Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=T5haJyhVPCY">Leave No Context Behind Efficient Infinite Context Transformers with Infini attention Google 2024 - YouTube</A>
								<DT><A HREF="https://huggingface.co/crusoeai">crusoeai (Crusoe AI)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=RCSvpYb90qE">LongRoPE &amp; Theta Scaling to 1 Mio Token</A>
								<DT><A HREF="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf">https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/#gemini-model-updates</A>
								<DT><A HREF="https://kexue.fm/archives/10122">Transformer Upgrade Road: 18. RoPE Base Design Principles</A>
								<DT><A HREF="https://arxiv.org/abs/2109.00301">[2109.00301] $\infty$-former: Infinite Memory Transformer</A>
								<DT><A HREF="https://arxiv.org/abs/2405.07719">[2405.07719] USP: A Unified Sequence Parallelism Approach for Long Context Generative AI</A>
								<DT><A HREF="https://arxiv.org/abs/2403.00071">[2403.00071] Resonance RoPE: Improving Context Length Generalization of Large Language Models</A>
								<DT><A HREF="https://arxiv.org/abs/2309.00071">[2309.00071] YaRN: Efficient Context Window Extension of Large Language Models</A>
								<DT><A HREF="https://github.com/RulinShao/LightSeq">RulinShao/LightSeq: Official repository for LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers</A>
								<DT><A HREF="https://arxiv.org/pdf/2310.03294">DISTFLASHATTN: Distributed Memory-efficient Attention for Long-context LLMs Training</A>
								<DT><A HREF="https://github.com/jzhang38/EasyContext">jzhang38/EasyContext: Memory optimization and training recipes to extrapolate language models' context length to 1 million tokens, with minimal hardware.</A>
								<DT><A HREF="https://qwenlm.github.io/blog/qwen2.5-turbo/">Extending the Context Length to 1M Tokens! | Qwen</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-architecture</H3>
							<DL><p>
								<DT><H3 FOLDED>seq2seq</H3>
								<DL><p>
									<DT><H3 FOLDED>Transformer</H3>
									<DL><p>
										<DT><H3 FOLDED>neural computers</H3>
										<DL><p>
											<DT><A HREF="https://mp.weixin.qq.com/s/HYlU3ldZn_79GJol17s9xQ">Transformer From the perspective of computer architecture</A>
											<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247494744&idx=1&sn=20f307c5e0fe7c5c5d62a46d81f48646&chksm=f995fc9acee2758c9a03a17f7feea8a7b0db439b42f504305cc4b5db22e64feacb30904344ca&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Zarbot Let's discuss some of the evolutions of Transformer: UT, MoD, MoR...</A>
											<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247488337&idx=1&sn=e85faf9a9dd67e324f6319dc816752b2&chksm=f9960393cee18a85f2944cbfadc272ddb857765caa7baa9bea73dcd30759a5ef1103876b3912&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Transformer category theory, Trasnformer neural computer</A>
											<DT><A HREF="https://deepmind.google/blog/differentiable-neural-computers/">Differentiable neural computers ‚Äî Google DeepMind</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-flops</H3>
										<DL><p>
											<DT><H3 FOLDED>transformer-arithmetic</H3>
											<DL><p>
												<DT><A HREF="https://kipp.ly/transformer-inference-arithmetic/">Transformer Inference Arithmetic | kipply's blog</A>
												<DT><A HREF="https://jax-ml.github.io/scaling-book/transformers/">All the Transformer Math You Need to Know | How To Scale Your Model</A>
												<DT><A HREF="https://github.com/GHGmc2/deepseek-projection/blob/master/doc/transformer_math.md">deepseek-projection/doc/transformer_math.md at master ¬∑ GHGmc2/deepseek-projection</A>
												<DT><A HREF="https://zeux.io/2024/03/15/llm-inference-sol/">zeux.io - LLM inference speed of light</A>
												<DT><A HREF="https://datacrunch.io/blog/deepseek-sglang-multi-head-latent-attention">DeepSeek + SGLang: Multi-Head Latent Attention ‚Äî Blog ‚Äî DataCrunch</A>
											</DL><p>
											<DT><A HREF="https://twitter.com/karpathy/status/1781047292486914189">Karpathy: Llama 3 model card (flops model training taxonomy)</A>
											<DT><A HREF="https://arxiv.org/abs/2104.04473">[2104.04473] Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM (slide 46 pt2)</A>
											<DT><A HREF="https://kipp.ly/transformer-inference-arithmetic/">Transformer Inference Arithmetic | kipply's blog</A>
											<DT><A HREF="https://www.usenix.org/system/files/osdi22-yu.pdf">Orca: A Distributed Serving System for Transformer-Based Generative Models</A>
											<DT><A HREF="https://arxiv.org/pdf/2305.05920">Fast Distributed Inference Serving for Large Language Models</A>
											<DT><A HREF="https://www.baseten.co/blog/llm-transformer-inference-guide/">A guide to LLM inference and performance</A>
											<DT><A HREF="https://zeux.io/2024/03/15/llm-inference-sol/">zeux.io - LLM inference speed of light</A>
											<DT><A HREF="https://www.artfintel.com/p/where-do-llms-spend-their-flops">Where do LLMs spend their FLOPS? - by Finbarr Timbers</A>
											<DT><A HREF="https://arxiv.org/pdf/2204.02311">PaLM 1: MFU compute usage</A>
											<DT><A HREF="https://medium.com/@dzmitrybahdanau/the-flops-calculus-of-language-model-training-3b19c1f025e4">The FLOPs Calculus of Language Model Training | by Dzmitry Bahdanau | Medium</A>
											<DT><A HREF="https://github.com/karpathy/nanoGPT/blob/master/transformer_sizing.ipynb">nanoGPT/transformer_sizing.ipynb at master ¬∑ karpathy/nanoGPT</A>
											<DT><A HREF="https://github.com/EleutherAI/cookbook/blob/main/benchmarks/sizing/transformer_flops.py#L139">cookbook/benchmarks/sizing/transformer_flops.py at main ¬∑ EleutherAI/cookbook</A>
											<DT><A HREF="https://kipp.ly/transformer-param-count/">LLM Parameter Counting | kipply's blog</A>
											<DT><A HREF="https://arxiv.org/abs/2203.15556">(F. FLOPs computation) Training Compute-Optimal Large Language Models</A>
											<DT><A HREF="https://people.eecs.berkeley.edu/~matei/papers/2021/sc_megatron_lm.pdf">Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</A>
											<DT><A HREF="https://www.lesswrong.com/posts/3duR8CrvcHywrnhLo/how-does-gpt-3-spend-its-175b-parameters">How does GPT-3 spend its 175B parameters? ‚Äî LessWrong</A>
											<DT><A HREF="https://github.com/huggingface/nanotron/blob/03d67f2103d5be0dc15ea6022a6cf16d6a633064/src/nanotron/models/starcoder2.py#L1587">nanotron/src/nanotron/models/starcoder2.py: get_flops</A>
											<DT><A HREF="https://arxiv.org/pdf/2205.05198">Reducing Activation Recomputation in Large Transformer Models 6.3</A>
											<DT><A HREF="https://www.adamcasson.com/posts/transformer-flops">Transformer FLOPs | Adam Casson</A>
											<DT><A HREF="https://ai.stackexchange.com/questions/49003/transformer-flop-accounting-during-forward-pass-with-isl-osl">large language models - Transformer FLOP accounting during forward pass with ISL / OSL - Artificial Intelligence Stack Exchange</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-params</H3>
										<DL><p>
											<DT><A HREF="https://kipp.ly/transformer-param-count/">LLM Parameter Counting | kipply's blog</A>
											<DT><A HREF="https://arxiv.org/abs/2203.15556">(F. FLOPs computation) Training Compute-Optimal Large Language Models</A>
											<DT><A HREF="https://github.com/huggingface/transformers/blob/b7ea171403d53a2aa9bce422f1fad8fb1150844b/examples/research_projects/movement-pruning/counts_parameters.py#L4">transformers/examples/research_projects/movement-pruning/counts_parameters.py at b7ea171403d53a2aa9bce422f1fad8fb1150844b ¬∑ huggingface/transformers</A>
											<DT><A HREF="https://www.lesswrong.com/posts/3duR8CrvcHywrnhLo/how-does-gpt-3-spend-its-175b-parameters">How does GPT-3 spend its 175B parameters? ‚Äî LessWrong</A>
											<DT><A HREF="https://wandb.ai/wandb_fc/tips/reports/How-To-Calculate-Number-of-Model-Parameters-for-PyTorch-and-TensorFlow-Models--VmlldzoyMDYyNzIx">How To Calculate Number of Model Parameters for PyTorch and TensorFlow Models | tips ‚Äì Weights &amp; Biases</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-memory</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/pdf/2205.05198">Reducing Activation Recomputation in Large Transformer Models</A>
											<DT><A HREF="https://arxiv.org/abs/1910.02054">[1910.02054] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-forward-pass</H3>
										<DL><p>
											<DT><A HREF="https://drive.google.com/file/d/1z9Orx5Gvxh7OG5BTcHCF8I8qX_ui1Ppj/view">mlkv-Transformer Steps 400.png - Google Drive</A>
										</DL><p>
										<DT><H3 FOLDED>Transformer++</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2312.00752">[2312.00752] Mamba: Linear-Time Sequence Modeling with Selective State Spaces</A>
											<DT><A HREF="https://twitter.com/rasbt/status/1729123424990068743">Simple Transformer Block</A>
											<DT><A HREF="https://github.com/RobertRiachi/nanoPALM">RobertRiachi/nanoPALM</A>
											<DT><A HREF="https://x.com/teortaxesTex/status/1998239766660469083">Transformer+++</A>
											<DT><A HREF="https://x.com/yifan_zhang_/status/1998152376222716024">A Recipe for Transformer+++:</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-lectures</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=dbo3kNKPaUA">Large Language Models (in 2023) Hyung Won Chung</A>
											<DT><A HREF="https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0">Language Language Models (in 2023) - Google Slides</A>
											<DT><A HREF="https://www.youtube.com/watch?v=orDKvo8h71o">Stanford CS25: V4 I Hyung Won Chung of OpenAI - YouTube</A>
											<DT><A HREF="https://docs.google.com/presentation/d/1u05yQQaw4QXLVYGLI6o3YoFHv6eC3YN8GvWD8JMumpE/edit#slide=id.g2885e521b53_0_0">Hyung Won (OpenAI): Shaping the future of AI from the history of Transformer</A>
											<DT><A HREF="https://www.youtube.com/watch?v=iqmjzecbJHE">Orignal transformer paper "Attention is all you need" introduced by a layman | Shawn's ML Notes - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>positional encoding</H3>
										<DL><p>
											<DT><A HREF="https://kexue.fm/archives/9105">A Theoretical Flaw and Countermeasure of Relative Position Encoding Transformer</A>
											<DT><A HREF="https://www.youtube.com/watch?v=T3OT8kqoqjc&list=LL&index=2&t=40s">How positional encoding in transformers works? - YouTube</A>
											<DT><A HREF="https://mp.weixin.qq.com/s/0peSNWN0ypMopPR0Q_pujQ">‰∏ÄÊñáÁúãÊáÇ LLaMA ‰∏≠ÁöÑÊóãËΩ¨Âºè‰ΩçÁΩÆÁºñÁ†ÅÔºàRotary Position EmbeddingÔºâ</A>
											<DT><A HREF="https://www.youtube.com/watch?v=V8r__fXx7tU">Rotary Positional Embeddings Explained | Transformer - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>residual stream</H3>
										<DL><p>
											<DT><A HREF="https://kexue.fm/archives/8994">Why do we need residuals? A perspective from DeepNet</A>
											<DT><A HREF="https://lucasb.eyer.be/snips/residuals.html">History of Residuals and a Word of Caution</A>
											<DT><A HREF="https://github.com/microsoft/ResiDual">microsoft/ResiDual: ResiDual: Transformer with Dual Residual Connections, https://arxiv.org/abs/2304.14802</A>
											<DT><A HREF="https://x.com/JunxuanWang0929/status/1959797912889938392">Attention Layers add into low-dimensional residual subscapes</A>
											<DT><A HREF="https://x.com/TimDarcet/status/2000874141172555822">post-norm is pre-norm + normalizing the residual (apart from first and last layer)</A>
											<DT><A HREF="https://x.com/iamgrigorev/status/2006654966317174869">deeper layers update the signal along the residual stream</A>
											<DT><A HREF="https://x.com/nathancgy4/status/2008415055965286728">(1) nathan chen en X: "my intuition for why value residual is working well (i.e. the flaw with current residual, and why that's a problem): In a pre-norm transformer, ignoring MLP layers, we have: h_L = h_0 + Œ£_{l=1}^{L} Attention(LayerNorm(h_{l-1})) So h_0 is technically preserved in h_L. But https://t.co/4NhEClGX5x" / X</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-learning-dynamics</H3>
										<DL><p>
											<DT><A HREF="https://transformer-circuits.pub/2022/toy_model/index.html">Toy Models of Superposition</A>
											<DT><A HREF="https://x.com/DimitrisPapail/status/1889747709491351734">o3 can't multiply beyond a few digits... But I think multiplication, addition, maze solving and easy-to-hard generalization is actually solvable on standard transformers... with recursive self-improvement. Below is the acc of a tiny model teaching itself how to add</A>
											<DT><A HREF="https://arxiv.org/abs/2502.01612">[2502.01612] Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges</A>
											<DT><A HREF="https://astro-eric.github.io/blogs/surjective/">Can Transformers Do Everything, and Undo It Too? | Haozhe Jiang</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-explainer</H3>
										<DL><p>
											<DT><A HREF="https://poloclub.github.io/transformer-explainer/">Transformer Explainer: LLM Transformer Model Visually Explained</A>
											<DT><A HREF="https://poloclub.github.io/ganlab/">GAN Lab: Play with Generative Adversarial Networks in Your Browser!</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-theory</H3>
										<DL><p>
											<DT><A HREF="https://poloclub.github.io/transformer-explainer/">Transformer Explainer: LLM Transformer Model Visually Explained</A>
											<DT><A HREF="https://arxiv.org/abs/2505.19488">[2505.19488] Understanding Transformer from the Perspective of Associative Memory (bytedn seed)</A>
											<DT><A HREF="https://x.com/nathancgy4/status/1949303171844870326">Why do FFNs use ReLU instead of more precise ones like Exp?</A>
											<DT><A HREF="https://www.youtube.com/watch?v=c_9bxtyOd1o">Hyung Won Chung: Shaping the Future of AI from the History of Transformer - YouTube</A>
											<DT><A HREF="https://cme295.stanford.edu/syllabus/">cme295 transformers 2026</A>
										</DL><p>
										<DT><H3 FOLDED>transformer-architecture</H3>
										<DL><p>
											<DT><A HREF="https://bench.flashinfer.ai/models/deepseek-v3">DeepSeek V3/R1 Architecture Overview</A>
											<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</A>
											<DT><H3 FOLDED>transformer-ablation</H3>
											<DL><p>
												<DT><A HREF="https://aditvenk.substack.com/p/dissecting-the-transformer?utm_medium=web">Dissecting the Transformer - by Aditya Venkataraman</A>
											</DL><p>
										</DL><p>
										<DT><A HREF="https://poloclub.github.io/transformer-explainer/">Transformer Explainer: LLM Transformer Model Visually Explained</A>
										<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247488337&idx=1&sn=e85faf9a9dd67e324f6319dc816752b2&chksm=f9960393cee18a85f2944cbfadc272ddb857765caa7baa9bea73dcd30759a5ef1103876b3912&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Transformer category theory, Trasnformer neural computer</A>
										<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247494744&idx=1&sn=20f307c5e0fe7c5c5d62a46d81f48646&chksm=f995fc9acee2758c9a03a17f7feea8a7b0db439b42f504305cc4b5db22e64feacb30904344ca&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Zarbot Let's discuss some of the evolutions of Transformer: UT, MoD, MoR...</A>
										<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247494688&idx=1&sn=3d589f6d4be56ee372d5db4f8631b0cc&chksm=f995fce2cee275f443bfdbd1d210519296688922f823527210cbd6d6c1cba17aa4072ccff21a&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Zarbot The Mathematical Foundations of the Big Model Era (9) - The Connection Between SDPA and Optimal Transport, Reinforcement Learning, and Information Geometry</A>
										<DT><A HREF="https://arxiv.org/pdf/2002.05202">GLU Variants Improve Transformer "gating einsums"</A>
										<DT><A HREF="https://arxiv.org/abs/2505.19488">[2505.19488] Understanding Transformer from the Perspective of Associative Memory (bytedn seed)</A>
										<DT><A HREF="https://www.youtube.com/watch?v=3gb-ZkVRemQ&list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&index=27">Stanford CS25: V4 I Jason Wei &amp; Hyung Won Chung of OpenAI - YouTube</A>
										<DT><A HREF="https://web.stanford.edu/~jurafsky/slp3/10.pdf">Chapter 10: Transformers and Large Language Models</A>
										<DT><A HREF="http://nlp.seas.harvard.edu/annotated-transformer/">The Annotated Transformer (new version)</A>
										<DT><A HREF="https://gist.github.com/sophiawisdom/ccdff5b7ebcd782393dbc5be3f0866f9">shittytransformer.py</A>
										<DT><A HREF="https://github.com/xjdr-alt/simple_transformer">xjdr-alt/simple_transformer: Simple Transformer in Jax</A>
										<DT><A HREF="https://github.com/joschu/jax-exp/blob/master/jax_transformer.py#L96">John Schulman: jax-exp/jax_transformer.py at master</A>
										<DT><A HREF="https://medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd">Shape Suffixes ‚Äî Good Coding Style | by Noam Shazeer | Medium</A>
										<DT><A HREF="https://github.com/openai/finetune-transformer-lm/">openai/finetune-transformer-lm: Code and model for the paper "Improving Language Understanding by Generative Pre-Training"</A>
										<DT><A HREF="https://docs.google.com/presentation/d/1u05yQQaw4QXLVYGLI6o3YoFHv6eC3YN8GvWD8JMumpE/edit#slide=id.g2885e521b53_0_0">Hyung Won (OpenAI): Shaping the future of AI from the history of Transformer</A>
										<DT><A HREF="https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0">Language Language Models (in 2023) - Google Slides</A>
										<DT><A HREF="https://x.com/hwchung27/status/1800676312916656592">Shaping the future of AI from the history of Transformer</A>
										<DT><A HREF="https://github.com/hyunwoongko/transformer">transformer step-by-step impl</A>
										<DT><A HREF="https://www.youtube.com/watch?v=ZAO6y_oJtFA">Street Fighting Transformers - YouTube</A>
										<DT><A HREF="https://kexue.fm/archives/4765">A brief reading of "Attention is All You Need" (introduction + code)</A>
										<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</A>
										<DT><A HREF="https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising">What happened to BERT &amp; T5? On Transformer Encoders, PrefixLM and Denoising Objectives ‚Äî Yi Tay</A>
										<DT><A HREF="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention Is All You Need</A>
										<DT><A HREF="https://atcold.github.io/NYU-DLSP20/en/week12/12-3/">Attention and the Transformer ¬∑ Deep Learning</A>
										<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/main/mla/modeling_deepseek.py#L1181">deepseekv2-profile/mla/modeling_deepseek.py at main ¬∑ madsys-dev/deepseekv2-profile</A>
										<DT><A HREF="https://www.youtube.com/watch?v=S9eKuRVigjY">Building a ML Transformer in a Spreadsheet - YouTube</A>
										<DT><A HREF="https://github.com/karpathy/nanoGPT/blob/9755682b981a45507f6eb9b11eadef8cb83cebd5/transformer_sizing.ipynb">Transformer Theoretical Model</A>
										<DT><A HREF="https://github.com/Aleph-Alpha/scaling/blob/main/src/scaling/transformer/model/layers/layer.py#L268">scaling/src/scaling/transformer/model/layers/layer.py at main ¬∑ Aleph-Alpha/scaling</A>
										<DT><A HREF="https://github.com/lucidrains/x-transformers">lucidrains/x-transformers: A simple but complete full-attention transformer with a set of promising experimental features from various papers</A>
										<DT><A HREF="https://github.com/drisspg/transformer_nuggets">drisspg/transformer_nuggets: A place to store reusable transformer components of my own creation or found on the interwebs</A>
										<DT><A HREF="https://leimao.github.io/blog/Transformer-Explained/">Transformer Explained In One Single Page - Lei Mao's Log Book</A>
										<DT><A HREF="https://github.com/mikaylagawarecki/temp/blob/main/mha.py">temp/mha.py at main ¬∑ mikaylagawarecki/temp</A>
										<DT><A HREF="https://x.com/Sumanth_077/status/1851263873749565851">Transformer visually explained</A>
										<DT><A HREF="https://towardsdatascience.com/drawing-the-transformer-network-from-scratch-part-1-9269ed9a2c5e">Drawing the Transformer Network from Scratch (Part 1) | by Thomas Kurbiel | Towards Data Science</A>
										<DT><A HREF="https://sites.google.com/view/gbrainprinceton/projects/spectral-transformers">Google DeepMind Princeton - Spectral Transformers</A>
										<DT><A HREF="https://www.youtube.com/watch?v=KJtZARuO3JY">Visualizing transformers and attention | Talk for TNG Big Tech Day '24 - YouTube</A>
										<DT><A HREF="https://github.com/feifeibear/LLMRoofline">feifeibear/LLMRoofline: Compare different hardware platforms via the Roofline Model for LLM inference tasks.</A>
										<DT><A HREF="https://arxiv.org/pdf/2303.06318">what are all the ways the ops in a transformer can be parallelized across GPUs + pretty diagrams?</A>
										<DT><A HREF="https://github.com/poloclub/transformer-explainer">poloclub/transformer-explainer: Transformer Explained Visually: Learn How LLM Transformer Models Work with Interactive Visualization</A>
										<DT><A HREF="https://www.youtube.com/watch?v=l8pRSuU81PU">import code; code.interact(local=locals())</A>
										<DT><A HREF="https://newsletter.languagemodels.co/p/the-illustrated-gpt-oss">The Illustrated GPT-OSS - by Jay Alammar</A>
									</DL><p>
									<DT><H3 FOLDED>GPT</H3>
									<DL><p>
										<DT><H3 FOLDED>GPT-2</H3>
										<DL><p>
											<DT><H3 FOLDED>cloneofsimo-min-max-gpt</H3>
											<DL><p>
												<DT><H3 FOLDED>gpt-2-mup</H3>
												<DL><p>
													<DT><A HREF="https://github.com/cloneofsimo/min-max-gpt/blob/7b017b8a0680e8eec6328c7ea3edfca7592107e0/tweakablegpt.py#L53">tweakablegpt.py#L53</A>
												</DL><p>
												<DT><A HREF="https://github.com/cloneofsimo/min-max-gpt">cloneofsimo/min-max-gpt: Minimal (400 LOC) implementation Maximum (multi-node, FSDP) GPT training</A>
												<DT><A HREF="https://cloneofsimo.notion.site/What-to-do-to-scale-up-09e469d7c3444d6a90305397c38a46f5">What to do to scale up?</A>
											</DL><p>
											<DT><H3 FOLDED>gpt-2-fp8</H3>
											<DL><p>
												<DT><A HREF="https://github.com/cchan/nanoGPT-fp8">cchan/nanoGPT-fp8</A>
												<DT><A HREF="https://x.com/itsclivetime/status/1655515089506820097">(1) Clive Chan en X: "WIP FP8 training on consumer graphics cards - üßµ/4 I hacked nanoGPT to use TransformerEngine on RTX 4090 and ran a few iterations of GPT-2 training: - nanoGPT Block (+flashattn) =&amp;gt; TE TransformerLayer (both BF16): 15% faster - BF16 =&amp;gt; FP8: additional +18% https://t.co/cJNWehoGeu" / X</A>
											</DL><p>
											<DT><H3 FOLDED>gpt-2-tied-weights</H3>
											<DL><p>
												<DT><A HREF="https://gemini.google.com/u/2/app/388849dbd5445fad">gpt2 src/model.py: logits = tf.matmul(h_flat, wte, transpose_b=True)</A>
											</DL><p>
											<DT><H3 FOLDED>nanoGPT</H3>
											<DL><p>
												<DT><A HREF="https://github.com/karpathy/nanoGPT">karpathy/nanoGPT: The simplest, fastest repository for training/finetuning medium-sized GPTs.</A>
											</DL><p>
											<DT><A HREF="https://github.com/cloneofsimo/min-max-gpt">cloneofsimo/min-max-gpt: Minimal (400 LOC) implementation Maximum (multi-node, FSDP) GPT training</A>
											<DT><A HREF="https://cloneofsimo.notion.site/What-to-do-to-scale-up-09e469d7c3444d6a90305397c38a46f5">What to do to scale up?</A>
											<DT><A HREF="https://kexue.fm/archives/9529">Why are current LLMs all decoder-only architectures?</A>
											<DT><A HREF="https://github.com/openai/gpt-2">openai/gpt-2: Code for the paper "Language Models are Unsupervised Multitask Learners" (Tensorflow impl)</A>
											<DT><A HREF="https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py">huggingface/transformers PyTorch implementation</A>
											<DT><A HREF="https://www.youtube.com/watch?v=l8pRSuU81PU">Let's reproduce GPT-2 (124M) - YouTube</A>
											<DT><A HREF="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</A>
											<DT><A HREF="https://arxiv.org/pdf/2005.14165.pdf">(Brown, 2020) Language Models are Few-Shot Learners</A>
											<DT><A HREF="https://x.com/kellerjordan0/status/1803566078985117903">Sophia optimizer</A>
											<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt/tree/sophia">KellerJordan/modded-nanogpt at sophia</A>
											<DT><A HREF="https://github.com/pytorch-labs/gpt-fast">pytorch-labs/gpt-fast: Simple and efficient pytorch-native transformer text generation in &lt;1000 LOC of python.</A>
											<DT><A HREF="https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/examples/quickstart.html">Getting Started ‚Äî Transformer Engine 1.7.0 documentation</A>
											<DT><A HREF="https://openai.com/index/image-gpt/">Image GPT | OpenAI</A>
											<DT><A HREF="https://x.com/i/bookmarks?post_id=1805335482999750773">crossentropy loss is the main memory bottleneck (memory-bound)</A>
											<DT><A HREF="https://github.com/Lightning-AI/litgpt">Lightning-AI/litgpt: Load, pretrain, finetune, deploy 20+ LLMs on your own data. Uses state-of-the-art techniques: flash attention, FSDP, 4-bit, LoRA, and more.</A>
											<DT><A HREF="https://github.com/mgmalek/efficient_cross_entropy">mgmalek/efficient_cross_entropy</A>
											<DT><A HREF="https://mp.weixin.qq.com/s/8F3eAHDBjQkHHBmrAEoOfw">"Illustrated Large Model Training: Data Parallel Part 2 (ZeRO, Zero Redundancy Optimization)"</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/624740065">Analyze the parameters, computation, intermediate activation, and KV cache of the transformer model</A>
											<DT><A HREF="https://huggingface.co/spaces/BBuf/megatron-lm-parallel-group-playground">Megatron Lm Parallel Group Playground - a Hugging Face Space by BBuf</A>
											<DT><A HREF="https://tspeterkim.github.io/posts/mixed-precision-from-scratch">Mixed Precision Training from Scratch | Taeksang Peter Kim</A>
											<DT><A HREF="https://medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd">Shape Suffixes ‚Äî Good Coding Style | by Noam Shazeer | Medium</A>
											<DT><A HREF="https://kidger.site/thoughts/jaxtyping/">No more shape errors! Type annotations for the shape+dtype of tensors/arrays. ¬∑ Patrick Kidger</A>
											<DT><A HREF="http://giantpandacv.com/project/PyTorch/AI%20Infra%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%B9%8B%E3%80%8A%E5%9C%A8LLM%E8%AE%AD%E7%BB%83%E4%B8%AD%E5%87%8F%E5%B0%91%E6%BF%80%E6%B4%BB%E5%80%BC%E5%86%85%E5%AD%98%E3%80%8B/">AI Infra paper reading: "Reducing activation value memory in LLM training"</A>
											<DT><A HREF="https://x.com/i/bookmarks?post_id=1805564665428164915">sparsity pattern 2:4 PyTorch training</A>
											<DT><A HREF="https://pytorch.org/blog/accelerating-neural-network-training/">Accelerating Neural Network Training with Semi-Structured (2:4) Sparsity | PyTorch</A>
											<DT><A HREF="https://imbue.com/research/70b-infrastructure/">From bare metal to a 70B model: infrastructure set-up and scripts - imbue</A>
											<DT><A HREF="https://imbue.com/research/70b-carbs/">Open-sourcing CARBS: a cost-effective hyperparameter optimizer that helps scale small experiments to large language models - imbue</A>
											<DT><A HREF="https://imbue.com/research/70b-intro/">Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings - imbue</A>
											<DT><A HREF="https://github.com/imbue-ai/cluster-health/tree/master">imbue-ai/cluster-health</A>
											<DT><A HREF="https://github.com/imbue-ai/carbs">imbue-ai/carbs: Cost aware hyperparameter tuning algorithm</A>
											<DT><A HREF="https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e">GPT from Scratch with MLX. Define and train GPT-2 on your MacBook | by Pranav Jadhav | Jun, 2024 | Towards Data Science</A>
											<DT><A HREF="https://github.com/pytorch/torchtune">pytorch/torchtune: A Native-PyTorch Library for LLM Fine-tuning</A>
											<DT><A HREF="https://github.com/pytorch/ao">pytorch/ao: Create and integrate custom data types, layouts and kernels with up to 2x speedups with 65% less VRAM for inference and training</A>
											<DT><A HREF="https://docs.google.com/presentation/d/1JKpqsbkr5Fg-bj1iElPaC-ToTVpRmRLKZmN89krwl04/edit?resourcekey=0-VPgp_Yc4krPPW3Mxv6UjgQ#slide=id.g25dfdd1f5b2_0_8">2024 stanford cs25 guest lecture jason wei - Google Slides</A>
											<DT><A HREF="https://www.youtube.com/watch?v=6jTQ61tBeoQ">GPT (nanoGPT) from a beginner's perspective (Part 1) - YouTube</A>
											<DT><A HREF="https://github.com/google/maxtext/blob/53167aa550b49bfc867236790bc8065545f0d300/MaxText/layers/gpt3.py#L151">maxtext/MaxText/layers/gpt3.py at 53167aa550b49bfc867236790bc8065545f0d300 ¬∑ google/maxtext</A>
											<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/main/examples/attn_causal/h100_train.cu">ThunderKittens/examples/attn_causal/h100_train.cu</A>
											<DT><A HREF="https://github.com/HazyResearch/nanoGPT-TK">HazyResearch/nanoGPT-TK: The simplest, fastest repository for training/finetuning medium-sized GPTs. Now, with kittens!</A>
											<DT><A HREF="https://github.com/google-deepmind/nanodo/tree/main">google-deepmind/nanodo</A>
											<DT><A HREF="https://x.com/karpathy/status/1814038096218083497">(1) Andrej Karpathy en X: "LLM model size competition is intensifying... backwards! My bet is that we'll see models that "think" very well and reliably that are very very small. There is most likely a setting even of GPT-2 parameters for which most people will consider GPT-2 "smart". The reason current" / X</A>
											<DT><A HREF="https://x.com/Yuchenj_UW/status/1814159545280971115">(1) Yuchen Jin en X: "Let's go even deeper! Training GPT-2 (7.3B) using @karpathy's llm.c with 32 H100 GPUs. *GPUs go brrr at night* üî• - Setup: 4 H100 nodes connected with 400Gb/s InfiniBand - Training speed: 327K tokens/s, MFU: 46.7%. Pretty linear scaling! - Due to some parameters in the 7.3B https://t.co/7Z6dEqXeYL" / X</A>
											<DT><A HREF="https://x.com/Yuchenj_UW/status/1815417740452397187">(1) Yuchen Jin en X: "GPU-hours vs. performance for different sizes of GPT-2 (from 124M to 2.7B) trained with @karpathy's llm.c + FineWeb-Edu üëæ @eliebakouch and @diegoasua were interested in seeing the plots between compute vs. loss and eval in the last post. Here it is (y-axis capped at 4 in the https://t.co/YsCPQS19TJ" / X</A>
											<DT><A HREF="https://github.com/graphcore-research/out-of-the-box-fp8-training/blob/main/out_of_the_box_fp8_training.ipynb">out-of-the-box-fp8-training/out_of_the_box_fp8_training.ipynb at main ¬∑ graphcore-research/out-of-the-box-fp8-training</A>
											<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/e9024c691f27a41fabd94617d39d75813b649f26/examples/gpt2.py#L115">tinygrad/examples/gpt2.py at e9024c691f27a41fabd94617d39d75813b649f26 ¬∑ tinygrad/tinygrad</A>
											<DT><A HREF="https://github.com/joennlae/tensorli">joennlae/tensorli: Absolute minimalistic implementation of a GPT-like transformer using only numpy (&lt;650 lines).</A>
											<DT><A HREF="https://github.com/huggingface/nanotron/blob/03d67f2103d5be0dc15ea6022a6cf16d6a633064/src/nanotron/models/starcoder2.py">GPT with Multi-Query Attention, RoPe, SWA and GQA</A>
											<DT><A HREF="https://x.com/karpathy/status/1859305141385691508">nanoGPT: GPT-2 (124M) pre-training 5 min</A>
											<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt/tree/master">KellerJordan/modded-nanogpt: NanoGPT (124M) in 5 minutes</A>
											<DT><A HREF="https://x.com/Yuchenj_UW/status/1861477701821047287">(1) Yuchen Jin en X: "GPT-2 (1.6B) NanoGPT speedrun finished üèÉ Conclusion: - Achieved 2X token efficiency compared to the llm.c baseline. - Per single-step (~1M tokens), llm.c remains 26.9% faster on 8xH100s, I was wrong in my previous post. - Wall-clock time: GPT-2 (1.6B) speedrun completed in 16.3 https://t.co/FumoCfydwz" / X</A>
											<DT><A HREF="https://www.youtube.com/watch?v=d1LNUvkRMEg&t=13076s">GPT-2 from Scratch in C (Day 1/2) - YouTube</A>
											<DT><A HREF="https://github.com/openai/gpt-2/blob/master/src/model.py">gpt-2/src/model.py at master ¬∑ openai/gpt-2</A>
										</DL><p>
										<DT><H3 FOLDED>gpt-layernorm</H3>
										<DL><p>
											<DT><A HREF="https://kexue.fm/archives/9009">Why is Pre Norm not as effective as Post Norm?</A>
										</DL><p>
										<DT><A HREF="https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Supplemental.pdf">Supplement GPT-3 few-shot generalizable learners</A>
										<DT><A HREF="https://github.com/siliconflow/nexfort-gpt/blob/main/model.py">nexfort-gpt/model.py at main ¬∑ siliconflow/nexfort-gpt</A>
										<DT><A HREF="https://strint.notion.site/GPT-84ab3b065bdc4fb883710e52c58a2210">GPT-2 formal description and impl (if flash)</A>
										<DT><A HREF="https://github.com/facebookresearch/fairseq/blob/920a548ca770fb1a951f7f4289b4d3a0c1bc226f/fairseq/models/transformer_lm.py#L539">fairseq/fairseq/models/transformer_lm.py at 920a548ca770fb1a951f7f4289b4d3a0c1bc226f ¬∑ facebookresearch/fairseq</A>
										<DT><A HREF="https://x.com/johannes_hage/status/1861527140279431396/photo/1">new 1.6B nanoGPT speedrun dashboard (PrimeIntellect)</A>
										<DT><A HREF="https://www.njkumar.com/calculating-gpt2s-inference-speedups/">Calculating GPT-2‚Äôs Inference Speedups | njkumar</A>
										<DT><A HREF="https://x.com/YouJiacheng/status/1912570883878842527">(1) You Jiacheng en X: "Just improved it to ~1521s (25.35 minutes). reproducible log: https://t.co/9zQFX6IiNx https://t.co/orRdYgJBTn" / X</A>
										<DT><A HREF="https://github.com/ita9naiwa/my-opt/blob/master/models/opt.py#L214">my-opt/models/opt.py at master ¬∑ ita9naiwa/my-opt</A>
									</DL><p>
									<DT><H3 FOLDED>T5</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/1910.10683.pdf">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</A>
										<DT><A HREF="https://twitter.com/YiTayML/status/1651932898512211970">~2 x the parameters for the same compute cost. Basically free model sparsity (sparse w.r.t to enc/dec blocks).</A>
										<DT><A HREF="https://twitter.com/YiTayML/status/1668302949276356609">(Yi Tay): Some thoughts/observations (T5 models at 30B &amp; 65B)</A>
										<DT><A HREF="https://arxiv.org/abs/2306.04757">InstructEval: Table 2 (Flan vs Alpaca) EncDec vs Dec param claim</A>
										<DT><A HREF="https://arxiv.org/abs/2207.10551">[2207.10551] Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?</A>
										<DT><A HREF="https://kexue.fm/archives/6933">explaning masking attention</A>
										<DT><A HREF="https://x.com/Birchlabs/status/1899106303596712239">(1) Birchlabs en X: "be careful using HF tokenizers. fast and slow tokenizers give different results, and neither necessarily matches the sentencepiece reference implementation. https://t.co/D4jD9VKBra" / X</A>
									</DL><p>
									<DT><H3 FOLDED>EncDec</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=ORzGEnHTSfk">What BERT Can‚Äôt Do: The Transformer's Decoder</A>
									</DL><p>
									<DT><H3 FOLDED>Llama</H3>
									<DL><p>
										<DT><H3 FOLDED>Llama 4</H3>
										<DL><p>
											<DT><A HREF="https://ai.meta.com/blog/llama-4-multimodal-intelligence/">The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation</A>
											<DT><A HREF="https://github.com/meta-llama/llama-models/blob/main/models/llama4/MODEL_CARD.md">llama-models/models/llama4/MODEL_CARD.md at main ¬∑ meta-llama/llama-models</A>
											<DT><A HREF="https://github.com/meta-llama/llama-models/tree/main/models/llama4">llama-models/models/llama4 at main ¬∑ meta-llama/llama-models</A>
											<DT><A HREF="https://github.com/meta-llama/llama-models/blob/main/models/llama4/model.py">llama-models/models/llama4/model.py at main ¬∑ meta-llama/llama-models</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/1914466839750218423">Meta ShufflingÁöÑMoE Grouped GEMM kernel benchmark - Áü•‰πé</A>
										</DL><p>
										<DT><H3 FOLDED>llama 3.1</H3>
										<DL><p>
											<DT><A HREF="https://x.com/_xjdr/status/1815631563628986487">Llama3.1 405B base is officially good based on my private evals. I am excited.</A>
											<DT><A HREF="https://scontent.fsvq5-1.fna.fbcdn.net/v/t39.2365-6/452387774_1036916434819166_4173978747091533306_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=DTS7hDTcxZoQ7kNvgF6h1Ib&_nc_ht=scontent.fsvq5-1.fna&oh=00_AYBQ4-CcPRnxbpROau5tQYCMi55zbAoi_PoSQoqp6cMvAw&oe=66ADF38D">The Llama 3 Herd of Models</A>
											<DT><A HREF="https://github.com/karpathy/nano-llama31">karpathy/nano-llama31: nanoGPT style version of Llama 3.1</A>
											<DT><A HREF="https://arxiv.org/abs/2407.21783">[2407.21783] The Llama 3 Herd of Models</A>
											<DT><A HREF="https://arxiv.org/pdf/2407.21783">The Llama 3 Herd of Models</A>
											<DT><A HREF="https://github.com/thecharlieblake/lovely-llama">thecharlieblake/lovely-llama: An implementation of the Llama architecture, to instruct and delight</A>
											<DT><A HREF="https://github.com/LambdaLabsML/Llama-3.2-vision-study/tree/main/throughput">Llama-3.2-vision-study/throughput at main ¬∑ LambdaLabsML/Llama-3.2-vision-study</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/710665670">Llama 3.1-405BËÆ≠ÁªÉÊé®ÁêÜÊäÄÊúØ - Áü•‰πé</A>
											<DT><A HREF="https://bench.flashinfer.ai/models/llama-3.1-8b">Llama 3.1 8B Architecture Overview</A>
										</DL><p>
										<DT><H3 FOLDED>llama 3</H3>
										<DL><p>
											<DT><H3 FOLDED>llama-3-model</H3>
											<DL><p>
												<DT><A HREF="https://github.com/naklecha/llama3-from-scratch">naklecha/llama3-from-scratch: llama3 implementation one matrix multiplication at a time</A>
												<DT><A HREF="https://github.com/meta-llama/llama3">meta-llama/llama3: the main Llama 3 GitHub site - will be moved under Meta-Llama</A>
												<DT><A HREF="https://github.com/meta-llama/llama3/blob/main/llama/model.py">llama3/llama/model.py</A>
												<DT><A HREF="https://github.com/ai-compiler-study/kernels/blob/main/models/llama/llama/model.py">kernels/models/llama/llama/model.py at main ¬∑ ai-compiler-study/kernels</A>
												<DT><A HREF="https://x.com/samsja19/status/1891994496503542103">(1) samsja en X: "What is the the gold standard https://t.co/wyGjSmUiOA implementation in pytorch ? I want: * fa3 / flex attention support * compatible with HF hub checkpoint * not bloated * Properly maintained and tested I think that it do not exist üòÖ" / X</A>
											</DL><p>
											<DT><A HREF="https://ai.meta.com/blog/meta-llama-3/">Introducing Meta Llama 3: The most capable openly available LLM to date</A>
											<DT><A HREF="https://twitter.com/astonzhangAZ/status/1780990210576441844">pre-training, human data, scaling, long context, post-training &amp; eval</A>
											<DT><A HREF="https://github.com/meta-llama/llama3/blob/main/eval_details.md">llama3/eval_details.md at main ¬∑ meta-llama/llama3</A>
											<DT><A HREF="https://twitter.com/karpathy/status/1781047292486914189">(1) Andrej Karpathy en X: "The model card has some more interesting info too: https://t.co/EzNGMu57am Note that Llama 3 8B is actually somewhere in the territory of Llama 2 70B, depending on where you look. This might seem confusing at first but note that the former was trained for 15T tokens, while the..." / X</A>
											<DT><A HREF="https://twitter.com/karpathy/status/1781028605709234613">(1) Andrej Karpathy en X: "Congrats to @AIatMeta on Llama 3 release!! üéâ https://t.co/fSw615zE8S Notes: Releasing 8B and 70B (both base and finetuned) models, strong-performing in their model class (but we'll see when the rankings come in @ @lmsysorg :)) 400B is still training, but already encroaching..." / X</A>
											<DT><A HREF="https://x.com/danielhanchen/status/1792553901524472311">Llama 3 arch on 1 mathematics page</A>
											<DT><A HREF="https://huggingface.co/imbue/llama3-question-quality">imbue/llama3-question-quality ¬∑ Hugging Face</A>
											<DT><A HREF="https://github.com/meta-llama/llama/commit/12b676b909368581d39cebafae57226688d5676a">Update download.sh ¬∑ meta-llama/llama@12b676b</A>
											<DT><A HREF="https://github.com/likejazz/llama3.np">likejazz/llama3.np: llama3.np is a pure NumPy implementation for Llama 3 model.</A>
											<DT><A HREF="https://www.llama.com/">Llama</A>
											<DT><A HREF="https://github.com/abhisheknair10/Llama3.cu">abhisheknair10/Llama3.cu: Lightweight Llama 3-8B Inference Engine in CUDA C</A>
											<DT><A HREF="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct">meta-llama/Llama-3.3-70B-Instruct ¬∑ Hugging Face</A>
											<DT><A HREF="https://arxiv.org/abs/2204.05149">[2204.05149] The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink</A>
										</DL><p>
										<DT><H3 FOLDED>OPT</H3>
										<DL><p>
											<DT><A HREF="https://github.com/zphang/minimal-opt">zphang/minimal-opt</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2307.09288.pdf">Llama 2: Open Foundation and Fine-Tuned Chat Models</A>
										<DT><A HREF="https://arxiv.org/abs/2302.13971">[2302.13971] LLaMA: Open and Efficient Foundation Language Models</A>
										<DT><A HREF="https://github.com/alibaba/Megatron-LLaMA">alibaba/Megatron-LLaMA: Best practice for training LLaMA models in Megatron-LM</A>
										<DT><A HREF="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/">Building Meta‚Äôs GenAI Infrastructure - Engineering at Meta</A>
										<DT><A HREF="https://github.com/linkedin/Liger-Kernel/issues/119">[fun] llama.triton ¬∑ Issue #119 ¬∑ linkedin/Liger-Kernel</A>
										<DT><A HREF="https://github.com/caiwanxianhust/FasterLLaMA">FasterLLaMA</A>
									</DL><p>
									<DT><H3 FOLDED>RNN</H3>
									<DL><p>
										<DT><H3 FOLDED>LSTM</H3>
										<DL><p>
											<DT><H3 FOLDED>xLSTM</H3>
											<DL><p>
												<DT><A HREF="https://x.com/antferdom/status/1799474799661691014">xLSTM won't replace the Transformer. Two bitter lessons</A>
											</DL><p>
										</DL><p>
										<DT><A HREF="https://kexue.fm/archives/10017">Chapter on Space and Time: Viewing Attention as a Quadratic RNN</A>
										<DT><A HREF="https://www.youtube.com/watch?v=FRy7eLuosic">Transformers are Multi-State RNNs</A>
										<DT><A HREF="https://web.stanford.edu/~jurafsky/slp3/9.pdf">RNN and LSTM</A>
									</DL><p>
									<DT><H3 FOLDED>Gemma</H3>
									<DL><p>
										<DT><H3 FOLDED>Gemma 3</H3>
										<DL><p>
											<DT><H3 FOLDED>Gemma 3n</H3>
											<DL><p>
												<DT><A HREF="https://deepmind.google/models/gemma/">Gemma 3n - Google DeepMind</A>
												<DT><A HREF="https://huggingface.co/google/gemma-3n-E4B">google/gemma-3n-E4B ¬∑ Hugging Face</A>
												<DT><A HREF="https://x.com/danielhanchen/status/1940073369648734571">Gemma 3n quirks: Vision NaNs on float16, large activations, larger losses, NaNs fixed</A>
											</DL><p>
											<DT><H3 FOLDED>gemma 3n-vision</H3>
											<DL><p>
												<DT><A HREF="https://x.com/giffmana/status/1940118251507523786">Add sigLIP2 to as visual encoder for Gemma</A>
											</DL><p>
											<DT><A HREF="https://arxiv.org/abs/2503.19786">[2503.19786] Gemma 3 Technical Report</A>
											<DT><A HREF="https://arxiv.org/abs/2504.18562">[2504.18562] Deep Learning with Pretrained 'Internal World' Layers: A Gemma 3-Based Modular Architecture for Wildfire Prediction</A>
										</DL><p>
										<DT><H3 FOLDED>Gemma 2</H3>
										<DL><p>
											<DT><A HREF="https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf">Gemma 2: Improving Open Language Models at a Practical Size</A>
											<DT><A HREF="https://x.com/danielhanchen/status/1806372357684220308">Gemma 2 Analysis</A>
											<DT><A HREF="https://x.com/mvpatel2000/status/1806344519333323258">tech report dicussion (Mihir Patel)</A>
											<DT><A HREF="https://huggingface.co/blog/gemma2">Welcome Gemma 2 - Google‚Äôs new open LLM</A>
										</DL><p>
										<DT><H3 FOLDED>T5Gemma</H3>
										<DL><p>
											<DT><A HREF="https://developers.googleblog.com/en/t5gemma/">T5Gemma: A new collection of encoder-decoder Gemma models - Google Developers Blog</A>
										</DL><p>
										<DT><A HREF="https://github.com/google-deepmind/gemma">google-deepmind/gemma: Gemma open-weight LLM library, from Google DeepMind</A>
										<DT><A HREF="https://ai.google.dev/gemma">Gemma - a family of lightweight, state-of-the art open models from Google ¬†|¬† Google for Developers</A>
										<DT><A HREF="https://github.com/google/gemma.cpp">google/gemma.cpp: lightweight, standalone C++ inference engine for Google's Gemma models.</A>
										<DT><A HREF="https://arxiv.org/abs/2403.08295">[2403.08295] Gemma: Open Models Based on Gemini Research and Technology</A>
									</DL><p>
									<DT><H3 FOLDED>Mistral</H3>
									<DL><p>
										<DT><A HREF="https://x.com/danielhanchen/status/1814317286389666094">Mistral NeMo 12B</A>
										<DT><A HREF="https://github.com/yixiaoer/mistral-v0.2-jax">yixiaoer/mistral-v0.2-jax: JAX implementation of the Mistral 7b v0.2 model</A>
									</DL><p>
									<DT><H3 FOLDED>Grok</H3>
									<DL><p>
										<DT><A HREF="https://x.com/NielsRogge/status/1990391999560663076/photo/1">Grok 4 approx model size</A>
										<DT><A HREF="https://x.com/danielhanchen/status/1769550950270910630">grok architecture modelling details</A>
									</DL><p>
									<DT><A HREF="https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising">What happened to BERT &amp; T5? On Transformer Encoders, PrefixLM and Denoising Objectives ‚Äî Yi Tay</A>
									<DT><A HREF="https://x.com/YiTayML/status/1813262126162845772">(1) Yi Tay en X: "Decided to start a new blog series about model architectures in the era of LLMs. üòÄ Here's part 1 on broader architectures like Transformer Encoders/Encoder-Decoders, PrefixLM and denoising objectives. üòÑ A frequently asked question: "The people who worked on language and NLP https://t.co/ndY1Oye75q" / X</A>
									<DT><A HREF="https://proceedings.neurips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf">Sequence to Sequence Learning with Neural Networks</A>
									<DT><A HREF="https://www.youtube.com/watch?v=1yvBqasHLZs">Ilya Sutskever: "Sequence to sequence learning with neural networks: what a decade" - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>architecture-efficient</H3>
								<DL><p>
									<DT><H3 FOLDED>Parallel Layers</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ai-compiler-study/kernels/blob/main/models/llama/llama/model.py">kernels/models/llama/llama/model.py at main ¬∑ ai-compiler-study/kernels</A>
									</DL><p>
									<DT><A HREF="https://github.com/JeanKaddour/NoTrainNoGain">Revisiting Efficient Training Algorithms For Transformer-based Language Models</A>
									<DT><A HREF="https://github.com/Lightning-AI/lit-gpt">Lightning-AI/lit-gpt</A>
									<DT><A HREF="https://twitter.com/ZihangDai/status/1281349893873897478/photo/1">(1) Zihang Dai (@ZihangDai) xAI: Funnel-Transformer</A>
									<DT><A HREF="https://github.com/laiguokun/Funnel-Transformer">laiguokun/Funnel-Transformer</A>
									<DT><A HREF="https://arxiv.org/pdf/2009.06732.pdf">Efficient Transformers: A Survery</A>
									<DT><A HREF="https://arxiv.org/abs/2110.12894">[2110.12894] The Efficiency Misnomer</A>
									<DT><A HREF="https://arxiv.org/abs/2009.06732">[2009.06732] Efficient Transformers: A Survey</A>
								</DL><p>
								<DT><H3 FOLDED>Attention</H3>
								<DL><p>
									<DT><H3 FOLDED>Multi-Query Attention</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2310.06825">[2310.06825] Mistral 7B</A>
									</DL><p>
									<DT><H3 FOLDED>GQA</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html">Rethinking Attention with Performers ‚Äì Google Research Blog</A>
									<DT><A HREF="https://kipp.ly/transformer-inference-arithmetic/">Transformer Inference Arithmetic</A>
									<DT><A HREF="https://github.com/HazyResearch/flash-attention">HazyResearch/flash-attention: Fast and memory-efficient exact attention</A>
									<DT><A HREF="https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html">Self-Attention</A>
									<DT><A HREF="https://arxiv.org/pdf/2205.14135v2.pdf">Flash Attention</A>
									<DT><A HREF="https://theaisummer.com/self-attention/">Why multi-head self attention works</A>
									<DT><A HREF="https://x.com/giffmana/status/1983457240452673710">(1) Lucas Beyer (bl16) en X: "&amp;gt; There‚Äôs no free lunch. &amp;gt; When you reduce the complexity of attention, you pay a price. &amp;gt; The question is, where? This is *exactly* how I typically end my Transformer tutorial. This slide is already 4 years old, I've never updated it, but it still holds: https://t.co/H8CxZapPRw" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=pUCWwGR5WmQ">Beyond Softmax: The Future of Attention Mechanisms - YouTube</A>
									<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247496753&idx=1&sn=b66ffd8d2e977cb4e7e27603ea9a9951&scene=21&poc_token=HO2pd2mj-ekyTn11At_JG4W7tugMuIVaZjQnClJL">Discuss future choices for Attention algorithms: Full, Sparse, or Linear?</A>
								</DL><p>
								<DT><H3 FOLDED>MoE</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-MoE</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/blog/training-moes/?utm_content=298456196&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Training MoEs at Scale with PyTorch | PyTorch</A>
										<DT><A HREF="https://x.com/mvpatel2000/status/1806391255297147218">Training MoEs at Scale with PyTorch (DBRX)</A>
									</DL><p>
									<DT><H3 FOLDED>switch-transformers</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2101.03961.pdf">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</A>
									</DL><p>
									<DT><H3 FOLDED>moe-training</H3>
									<DL><p>
										<DT><H3 FOLDED>nanoMoE</H3>
										<DL><p>
											<DT><H3 FOLDED>nanoMoE-dataloader</H3>
											<DL><p>
												<DT><A HREF="https://github.com/Noumena-Network/nanoMoE/commit/4a19d258fc7fc0218525a0b5003a0f66456bf90a#diff-c23cf67622ede84c6a053e8eb77272f87e675a34c86dc6ad0ca2eb8dd7f2f89a">Add data prep pipeline scaffolding ¬∑ Noumena-Network/nanoMoE@4a19d25</A>
											</DL><p>
											<DT><A HREF="https://github.com/Noumena-Network/nanoMoE">Noumena-Network/nanoMoE: MoE training system for research, speed-running and profit</A>
											<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf">DeepSeek-V3.2-Exp/DeepSeek_V3_2.pdf at main ¬∑ deepseek-ai/DeepSeek-V3.2-Exp</A>
											<DT><A HREF="https://www.arxiv.org/abs/2509.25149">[2509.25149] Pretraining Large Language Models with NVFP4</A>
											<DT><A HREF="https://arxiv.org/abs/2507.20534">[2507.20534] Kimi K2: Open Agentic Intelligence</A>
											<DT><A HREF="https://arxiv.org/abs/2504.05295">[2504.05295] Dion: Distributed Orthonormalized Updates</A>
											<DT><A HREF="https://arxiv.org/abs/2502.16982">[2502.16982] Muon is Scalable for LLM Training</A>
											<DT><A HREF="https://arxiv.org/abs/2502.11089">[2502.11089] Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</A>
											<DT><A HREF="https://arxiv.org/abs/2412.19437">[2412.19437] DeepSeek-V3 Technical Report</A>
											<DT><A HREF="https://arxiv.org/abs/2311.08105">[2311.08105] DiLoCo: Distributed Low-Communication Training of Language Models</A>
											<DT><A HREF="https://x.com/fujikanaeda/status/2001815307527356924">(1) Eric W. Tramel @ Home en X: "what a week for flopheads üöÄ: - BLASST: 1.62x prefill &amp;amp; 1.48x decode speed that folds naturally into FA - SonicMoE: 1.86x faster MoE - Nemotron 3: Mamba2 SSM hybrid transformers going almost 2x on tok/sec over non-hybrid. - Nanomoe: RDEP &amp;amp; nvfp4 on blackwell https://t.co/1JtFC6rUxV" / X</A>
											<DT><A HREF="https://x.com/_xjdr/status/1999995667473969329">(1) xjdr en X: "i've made things that would shock and disgust most https://t.co/GfzVRQmILX" / X</A>
											<DT><A HREF="https://github.com/meta-pytorch/MSLK/tree/main">meta-pytorch/MSLK: MSLK (Meta Superintelligence Labs Kernels) is a collection of PyTorch GPU operator libraries that are designed and optimized for GenAI training and inference, such as FP8 row-wise quantization and collective communications.</A>
											<DT><A HREF="https://github.com/Noumena-Network/nmoe">Noumena-Network/nmoe: MoE training for Me and You and maybe other people</A>
										</DL><p>
										<DT><H3 FOLDED>sonic-moe</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Dao-AILab/sonic-moe">Dao-AILab/sonic-moe: Accelerating MoE with IO and Tile-aware Optimizations</A>
											<DT><A HREF="https://x.com/tri_dao/status/2001785266873499875">(1) Tri Dao en X: "This is what we've been coking for the last 9 months: make MoEs training goes ~2x faster and ~2x less memory! Highlights: - MoE typically takes the most time and memory in modern models. Turns out one can mathematically rewrite the MoE backward pass to reduce the activation mem" / X</A>
											<DT><A HREF="https://x.com/WentaoGuo7/status/2001773245318541324">(1) Wentao Guo en X: "üöÄSonicMoEüöÄ: a blazingly-fast MoE implementation optimized for NVIDIA Hopper GPUs. SonicMoE reduces activation memory by 45% and is 1.86x faster on H100 than previous SOTAüòÉ Paper: https://t.co/Xesd3cNcpQ Work with @MayankMish98, @XinleC295, @istoica05, @tri_dao https://t.co/B83toUk27G" / X</A>
											<DT><A HREF="https://arxiv.org/abs/2512.14080">[2512.14080] SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations</A>
											<DT><A HREF="https://github.com/infinigence/FUSCO">infinigence/FUSCO: High-performance distributed data shuffling (all-to-all) library for MoE training and inference</A>
										</DL><p>
										<DT><A HREF="https://maven.com/p/032721/how-to-train-your-tiny-mo-e-going-from-60-hours-to-13">How to train your tiny MoE: Going from 60+ hours to 13</A>
									</DL><p>
									<DT><H3 FOLDED>FlashMoE</H3>
									<DL><p>
										<DT><A HREF="https://github.com/osayamenja/FlashMoE">osayamenja/FlashMoE: Distributed MoE in a Single Kernel [NeurIPS '25]</A>
										<DT><A HREF="https://arxiv.org/abs/2506.04667">[2506.04667] FlashMoE: Fast Distributed MoE in a Single Kernel</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2101.03961.pdf">Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</A>
									<DT><A HREF="https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison">The Big LLM Architecture Comparison</A>
									<DT><A HREF="https://arxiv.org/abs/2201.05596">[DeepSpeed-MoE: Advancing MoE Inference and Training</A>
									<DT><A HREF="https://github.com/stanford-futuredata/megablocks">stanford-futuredata/megablocks</A>
									<DT><A HREF="https://mistral.ai/news/mixtral-of-experts/">Mixtral of experts | Mistral AI | Open source models</A>
									<DT><A HREF="https://twitter.com/amanrsanger/status/1690072802454568960">WHY Mixture of Experts</A>
									<DT><A HREF="https://github.com/lucidrains/st-moe-pytorch">lucidrains/st-moe-pytorch: Implementation of ST-Moe</A>
									<DT><A HREF="https://arxiv.org/abs/2309.05444">[2309.05444] Pushing Mixture of Experts to the Limit</A>
									<DT><A HREF="https://www.youtube.com/watch?v=wLjJ34ygZVc">HuggingGPT</A>
									<DT><A HREF="https://twitter.com/arankomatsuzaki/status/1757229323126243620">Scaling Laws for Fine-Grained Mixture of Experts</A>
									<DT><A HREF="https://twitter.com/Tgale96/status/1773342371993751830">databricks/megablocks</A>
									<DT><A HREF="https://twitter.com/tedzadouri/status/1701579765973713285">Pushing MoE to the Limit: Extremely Parameter Efficient MoE</A>
									<DT><A HREF="https://x.com/cloneofsimo/status/1800228889341599963">Why are MoEs effective?</A>
									<DT><A HREF="https://arxiv.org/pdf/2305.14705">Mixture-of-Experts Meets Instruction Tuning</A>
									<DT><A HREF="http://incompleteideas.net/papers/sutton-86.pdf">Two Problems With Backpropagation and other steepest-descent learning procedures for networks</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1805066323409707336">(1) Teortaxes‚ñ∂Ô∏è en X: "On why serious labs (CAI, DS, probably all of the Western frontier) work on reducing KV cache You need MoEs with higher sparsity to save compute. But more experts = cache up = batch size down = MFU down = you lose to basic stuff like Mixtral, or even dense https://t.co/VUtsNg8A8I https://t.co/uWDxjtpevX" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2404.02852">[2404.02852] Toward Inference-optimal Mixture-of-Expert Large Language Models</A>
									<DT><A HREF="https://pytorch.org/blog/training-moes/?utm_content=298456196&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Training MoEs at Scale with PyTorch | PyTorch</A>
									<DT><A HREF="https://x.com/mvpatel2000/status/1806391255297147218">Training MoEs at Scale with PyTorch (DBRX)</A>
									<DT><A HREF="https://arxiv.org/html/2404.02258v1">Mixture-of-Depths: Dynamically allocating compute in transformer-based language models</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XczxSi2kHfo">MoE-Level Performance Without The Added Computation - YouTube</A>
									<DT><A HREF="https://www.databricks.com/blog/training-moes-scale-pytorch-and-databricks">Training MoEs at Scale with PyTorch and Databricks | Databricks Blog</A>
									<DT><A HREF="https://x.com/_xjdr/status/1819075319149838490">(1) xjdr en X: "MoD + Modality specific MoE + early fusion?! I would be so happy if L4 (or at least a large model variant) ends up adopting this architecture (i know, i know, one thing at a time, etc, but we could still stand to get a bit more creative in the attention layer ... ) https://t.co/di0mSa3jfV" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=F70KlwO4wP0&list=LL&index=19&t=658s">1 Million Tiny Experts in an AI? Fine-Grained MoE Explained - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=8wLG3TIcCXk">Multi-Head Mixture-of-Experts - YouTube</A>
									<DT><A HREF="https://x.com/arankomatsuzaki/status/1819010194887586276">(1) Aran Komatsuzaki en X: "Meta presents MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts - Dividesy expert modules into modality-specific groups - Achieves better performance than the baseline MoE abs: https://t.co/aXWVr0plp9 alphaxiv: https://t.co/4fbBt9CPmY https://t.co/l2dzDdAUzW" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2407.21770">[2407.21770] MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts</A>
									<DT><A HREF="https://github.com/microsoft/Tutel">microsoft/Tutel: Tutel MoE: An Optimized Mixture-of-Experts Implementation</A>
									<DT><A HREF="https://arxiv.org/abs/2411.04996">[2411.04996] Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models</A>
									<DT><A HREF="https://x.com/_xjdr/status/1872415714516316637">First 3 layers of DSv3 are dense</A>
									<DT><A HREF="https://github.com/laekov/fastmoe">laekov/fastmoe: A fast MoE impl for PyTorch</A>
									<DT><A HREF="https://www.artfintel.com/p/more-on-mixture-of-experts-models">More on Mixture of Experts models - by Finbarr Timbers</A>
									<DT><A HREF="https://www.artfintel.com/p/papers-ive-read-this-week-mixture">Papers I‚Äôve read this week, Mixture of Experts edition</A>
									<DT><A HREF="https://arxiv.org/abs/2507.17702">[2507.17702] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models</A>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/1978210309442851270">SemiAnalysis en X: "What ops do GPUs execute when training MoEs, and how does that relate to GB200 NVL72? Keywords: Dispatch / Combine / DP x EP / Large-scale EP Dispatch In each GPU, each token are routed to the corresponding expert(s). The operation is an All-to-All collective because expert https://t.co/9uGJe3EFhY" / X</A>
									<DT><A HREF="https://x.com/suchenzang/status/1981234647343518162/photo/1">Llama 4 Failure: expert choice routing</A>
									<DT><A HREF="https://github.com/inclusionAI/Ling-V2">inclusionAI/Ling-V2: Ling-V2 is a MoE LLM provided and open-sourced by InclusionAI.</A>
									<DT><A HREF="https://github.com/nwiad/Expert-Slicing">nwiad/Expert-Slicing</A>
									<DT><A HREF="https://github.com/nwiad/Expert-Slicing/blob/main/revised_source/experts.py">Expert-Slicing/revised_source/experts.py at main ¬∑ nwiad/Expert-Slicing</A>
									<DT><A HREF="https://x.com/StasBekman/status/1990608885212983363">Have you ever wondered by how much is your MoE implementation slower than its dense equivalent</A>
									<DT><A HREF="https://research.google/blog/mixture-of-experts-with-expert-choice-routing/?m=1">Mixture-of-Experts with Expert Choice Routing</A>
									<DT><A HREF="https://cameronrwolfe.substack.com/p/moe-llms">Mixture-of-Experts (MoE) LLMs - by Cameron R. Wolfe, Ph.D.</A>
								</DL><p>
								<DT><H3 FOLDED>language-models-ffn</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>State Space Model</H3>
								<DL><p>
									<DT><H3 FOLDED>SSM-Samba</H3>
									<DL><p>
										<DT><A HREF="https://github.com/microsoft/Samba">microsoft/Samba: Official implementation of "Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling"</A>
									</DL><p>
									<DT><H3 FOLDED>SSM-simba</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2403.15360">[2403.15360] SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2312.00752">[2312.00752] Mamba: Linear-Time Sequence Modeling with Selective State Spaces</A>
									<DT><A HREF="https://www.youtube.com/watch?v=hN0XvyuWlsM">Math Reading Group - State Space Models - (04/03/2024) - YouTube</A>
									<DT><A HREF="https://github.com/sophiawisdom/ssms">sophiawisdom/ssms: GPU kernels for state space models</A>
									<DT><A HREF="https://kexue.fm/archives/10114">Revisiting SSM (I): Linear Systems and HiPPO Matrix</A>
									<DT><A HREF="https://kexue.fm/archives/10180">ÈáçÊ∏©SSMÔºàÂõõÔºâÔºöÊúâÁêÜÁîüÊàêÂáΩÊï∞ÁöÑÊñ∞ËßÜËßí - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://github.com/NVlabs/hymba">NVlabs/hymba</A>
									<DT><A HREF="https://x.com/QuentinAnthon15/status/1861505524598280260">Zamba2 &amp; Zyda2</A>
									<DT><A HREF="https://x.com/PavloMolchanov/status/1861484218087584217">Hymba</A>
									<DT><A HREF="https://arxiv.org/pdf/2404.08819">The Illusion of State in State-Space Models</A>
								</DL><p>
								<DT><H3 FOLDED>Concept Models</H3>
								<DL><p>
									<DT><A HREF="https://ai.meta.com/research/publications/large-concept-models-language-modeling-in-a-sentence-representation-space/">Large Concept Models: Language Modeling in a Sentence Representation Space | Research - AI at Meta</A>
									<DT><A HREF="https://www.youtube.com/watch?v=2ZLd0uZvwbU">Experimenting With LCM Models (Meta's Alternative To LLM Models) - YouTube</A>
									<DT><A HREF="https://colab.research.google.com/drive/1BxPSbAzp724qaeNducQ_tgWUasH7yBip?usp=sharing">LCM Experiments - Colab</A>
								</DL><p>
								<DT><H3 FOLDED>Activation Function</H3>
								<DL><p>
									<DT><H3 FOLDED>SwiGLU</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2002.05202">(SwiGLU) GLU Variants Improve Transformer</A>
									</DL><p>
									<DT><H3 FOLDED>GELU</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/1606.08415">[1606.08415] Gaussian Error Linear Units (GELUs)</A>
										<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.GELU.html">GELU ‚Äî PyTorch 2.3 documentation</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/39853">[proposal] Add approx variant option to F.gelu ¬∑ Issue #39853 ¬∑ pytorch/pytorch (approximate=tanh)</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=OmudSvOQhCg">Why do we need activation functions? - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>Inductive Bias</H3>
								<DL><p>
									<DT><H3 FOLDED>No bias</H3>
									<DL><p>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2207.10551">[2207.10551] Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?</A>
								<DT><A HREF="https://github.com/weigao266/Awesome-Efficient-Arch">weigao266/Awesome-Efficient-Arch: Speed Always Wins: A Survey on Efficient Architectures for Large Language Models</A>
								<DT><A HREF="http://nlp.seas.harvard.edu/annotated-transformer/">The Annotated Transformer (new version)</A>
								<DT><A HREF="http://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</A>
								<DT><A HREF="https://github.com/Mooler0410/LLMsPracticalGuide">Mooler0410/LLMsPracticalGuide</A>
								<DT><A HREF="https://twitter.com/m__dehghani/status/1524796275052498945">architecture of the model is not actually that important (T5 UL2)</A>
								<DT><A HREF="https://kipp.ly/blog/">Transformers Taxonomy</A>
								<DT><A HREF="https://bbycroft.net/llm">LLM Visualization</A>
								<DT><A HREF="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</A>
								<DT><A HREF="https://transformer-circuits.pub/2022/toy_model/index.html">Toy Models of Superposition</A>
								<DT><A HREF="https://arxiv.org/abs/2305.19370">[2305.19370] Blockwise Parallel Transformer for Long Context Large Models</A>
								<DT><A HREF="https://www.youtube.com/watch?v=1aXOXHA7Jcw&t=3032s">Greg Yang | Large N Limits: Random Matrices &amp; Neural Networks</A>
								<DT><A HREF="https://www.youtube.com/watch?v=KV5gbOmHbjU">A Mathematical Framework for Transformer Circuits</A>
								<DT><A HREF="https://www.youtube.com/watch?v=P2LTAUO1TdA">Change of basis | Chapter 13, Essence of linear algebra</A>
								<DT><A HREF="https://www.youtube.com/watch?v=PnWOeIgl3GA">Language Modeling with Reduced Densities</A>
								<DT><A HREF="https://atcold.github.io/NYU-DLSP21/en/week10/10-3/">Transformer Encoder-predictor-decoder architecture (NYU)</A>
								<DT><A HREF="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer ‚Äì Jay Alammar</A>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1651927473884655616">(Yi Tay): Clarifying misconceptions about architectures (training obj)</A>
								<DT><A HREF="https://gist.github.com/sbmaruf/4832bd9a7f66df3c8bab8ab913a7a31a">Architecture config mapping vs T5 Table 2</A>
								<DT><A HREF="https://x.com/andrewgwils/status/1800532164418867245">Andrew Gordon Wilson en X: "Another major barrier is hypers -- initializations, LR, etc. You could easily try a new structure and not realize why it fails. The naive hypers just don‚Äôt work. But adapting the great work of @TheGregYang on muP to structure-aware initialization, we achieve exciting results! 4/8 https://t.co/NucLouwFIF" / X</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-training-objectives</H3>
							<DL><p>
								<DT><H3 FOLDED>Causal</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/haileysch__/status/1691483230761857024">Causal &gt;&gt; UL2</A>
								</DL><p>
								<DT><H3 FOLDED>Non-Causal</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>UL2</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/pull/268">Megatron-LM: Add UL2 data sampling and pretraining</A>
								</DL><p>
								<DT><H3 FOLDED>Self-Play</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2312.06585.pdf">Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models</A>
									<DT><A HREF="https://github.com/lucidrains/ReST-EM-pytorch">lucidrains/ReST-EM-pytorch: Implementations and explorations into the ReSTùê∏ùëÄ algorithm in the new deepmind paper "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models"</A>
								</DL><p>
								<DT><H3 FOLDED>Self-Training</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2312.06585.pdf">Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models</A>
								</DL><p>
								<DT><H3 FOLDED>Generative Information Retrieval</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/presentation/d/19lAeVzPkh20Ly855tKDkz1uv-1pHV_9GxfntiTJPUug/edit#slide=id.g22efd0a58a4_2_0">Google DeepMind (SIGIR 2023 keynote)</A>
								</DL><p>
								<DT><H3 FOLDED>Fill In The Middle</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/blog/gpt-3-edit-insert/">New GPT-3 Capabilities: Edit &amp; Insert</A>
									<DT><A HREF="https://beta.openai.com/playground/p/default-translate-code?mode=edit&model=code-davinci-edit-001">Playground - OpenAI API</A>
									<DT><A HREF="https://community.openai.com/t/introducing-insert-and-edits-capabilities/15993">Introducing Insert and Edits Capabilities - Announcements - OpenAI API Community Forum</A>
									<DT><A HREF="https://github.com/cloneofsimo/fim-llama-deepspeed">cloneofsimo/fim-llama-deepspeed</A>
								</DL><p>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1651927473884655616">(Yi Tay): Clarifying misconceptions about architectures (training obj)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=YEUclZdj_Sc">Why next-token prediction is enough for AGI - Ilya Sutskever</A>
								<DT><A HREF="https://kexue.fm/archives/9797">EMO: Classification loss function designed based on optimal transmission</A>
								<DT><A HREF="https://twitter.com/haileysch__/status/1691483230761857024">Causal &gt;&gt; UL2</A>
								<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/pull/268">Megatron-LM: Add UL2 data sampling and pretraining</A>
								<DT><A HREF="https://github.com/lucidrains/ReST-EM-pytorch">lucidrains/ReST-EM-pytorch: Implementations and explorations into the ReSTùê∏ùëÄ algorithm in the new deepmind paper "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models"</A>
								<DT><A HREF="https://wandb.ai/ai2-llm/OLMo-7B/reports/OLMo-7B--Vmlldzo2NzQyMzk5">OLMo-7B | OLMo-7B ‚Äì Weights &amp; Biases</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1792376397278953493/photo/1">3 days in, I see gradient norm sloooowly increasing (ref Olmo)</A>
								<DT><A HREF="https://arxiv.org/abs/2309.14322">[2309.14322] Small-scale proxies for large-scale Transformer training instabilities</A>
							</DL><p>
							<DT><H3 FOLDED>training-details</H3>
							<DL><p>
								<DT><H3 FOLDED>Empirical-training-hyperparameters</H3>
								<DL><p>
									<DT><H3 FOLDED>weight decay</H3>
									<DL><p>
										<DT><H3 FOLDED>Hyperball</H3>
										<DL><p>
											<DT><A HREF="https://x.com/wen_kaiyue/status/2014049648378519906">(1) Kaiyue Wen en X: "(1/n) Introducing Hyperball ‚Äî an optimizer wrapper that keeps weight &amp;amp; update norm constant and lets you control the effective (angular) step size directly. Result: sustained speedups across scales + strong hyperparameter transfer. https://t.co/1vRMHgZgoX" / X</A>
											<DT><A HREF="https://arxiv.org/abs/2511.18890">[2511.18890] Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models</A>
											<DT><A HREF="https://arxiv.org/abs/2006.08217">[2006.08217] AdamP: Slowing Down the Slowdown for Momentum Optimizers on Scale-invariant Weights</A>
										</DL><p>
										<DT><A HREF="https://x.com/percyliang/status/2014066930164928897">(1) Percy Liang en X: "Don't use weight decay. Just normalize everything you see (updates + parameters). Works on top of your favorite optimizer (e.g., Muon). Result: 33% speedup + better hyperparameter transfer." / X</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/1812.06162">[1812.06162] An Empirical Model of Large-Batch Training</A>
									<DT><A HREF="https://arxiv.org/abs/2505.13738">[2505.13738] Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training</A>
									<DT><A HREF="https://x.com/gm8xx8/status/1925320968567697467">(1) ùöêùî™ùüæùö°ùö°ùüæ en X: "Power Lines: Scaling Laws for Weight Decay and Batch Size in LLM Pre-training Builds power laws for optimal Œª, B‚Çí‚Çö‚Çú, and B‚Ççc·µ£·µ¢‚Çú‚Çé‚Äîusing the AdamW timescale œÑ‚Çë‚Çò‚Çê = B‚ÄØ‚ÅÑ‚ÄØ(Œ∑ŒªD): - œÑ‚Çë‚Çò‚Çê ‚àù (D‚ÄØ‚ÅÑ‚ÄØN)^‚Äì0.53 - Œª‚Çí‚Çö‚Çú = B‚ÄØ‚ÅÑ‚ÄØ(Œ∑DœÑ‚Çë‚Çò‚Çê) - B‚Çí‚Çö‚Çú ‚àù D^0.38, https://t.co/ERVwRMdBPo" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Vocabulary</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2204.14268.pdf">SetencePiece 256K Vocabulary</A>
									<DT><A HREF="https://x.com/karpathy/status/1621578354024677377?lang=en">Andrej Karpathy: increase vocab size from 50257 to 50304 (nearest multiple of 64) Careful with your powers of 2</A>
									<DT><A HREF="https://arxiv.org/abs/1909.08053">[1909.08053] Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism (Section 5.1)</A>
									<DT><A HREF="https://x.com/abhi_venigalla/status/1621710130051190784">MosaicML: GPT-1.3B MFU went from 49% -&gt; 53%</A>
									<DT><A HREF="https://x.com/cHHillee/status/1630274804795445248">Horace He en X: "Recently, Karpathy tweeted that *increasing* the size of his matmul made it run faster. But... why? Many people seem content to leave this as black magic. But luckily, this *can* be understood! Here's a plot of FLOPs achieved for square matmuls. Let's explain each curve! 1/19 https://t.co/9xLVzswVmv" / X</A>
									<DT><A HREF="https://gist.github.com/Chillee/f86675147366a7a0c6e244eaa78660f7#file-4-matmul-bench-py">PT 2.0 Benchmarks</A>
									<DT><A HREF="https://www.thonking.ai/p/answer-key-what-shapes-do-matrix">Solutions: What Shapes Do Matrix Multiplications Like?</A>
									<DT><A HREF="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications">What Shapes Do Matrix Multiplications Like? [medium]</A>
								</DL><p>
								<DT><H3 FOLDED>Bitwise determinism</H3>
								<DL><p>
									<DT><A HREF="https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html">Stanford CRFM</A>
									<DT><A HREF="https://arxiv.org/pdf/2204.02311.pdf">PaLM: Section 5 "Training Details"</A>
									<DT><A HREF="https://x.com/difficultyang/status/1975558168257384505">(1) difficultyang en X: "The beautiful sound of bitwise identical loss https://t.co/ubUeHqnaI5" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Weight initialization</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/cloneofsimo/status/1741381460274331916">effective weight init scheme</A>
									<DT><A HREF="https://arxiv.org/abs/2204.02311">PaLM: Scaling Language Modeling with Pathways (fain-in variance scaling)</A>
									<DT><A HREF="https://thegregyang.com/">Greg Yang |¬†Professional page</A>
									<DT><A HREF="https://cs231n.github.io/neural-networks-2/">CS231n Convolutional Neural Networks for Visual Recognition</A>
								</DL><p>
								<DT><H3 FOLDED>Sequence length</H3>
								<DL><p>
									<DT><H3 FOLDED>RoPE</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2403.00071">[2403.00071] Resonance RoPE: Improving Context Length Generalization of Large Language Models</A>
										<DT><A HREF="https://gist.github.com/cloneofsimo/1adaec43d08f4af936b02ca151b8e1a1">rope visualization</A>
										<DT><A HREF="https://jerryxio.ng/posts/nd-rope/">N-dimensional Rotary Positional Embeddings</A>
										<DT><A HREF="https://www.youtube.com/watch?v=V8r__fXx7tU">Rotary Positional Embeddings Explained | Transformer - YouTube</A>
										<DT><A HREF="https://karthick.ai/blog/2024/Rotatory-Position-Embedding-(RoPE)/">Rotatory Position Embedding (RoPE) | Karthick Panner Selvam</A>
									</DL><p>
									<DT><H3 FOLDED>YaRN</H3>
									<DL><p>
										<DT><A HREF="https://www.modular.com/ai-resources/yarn#:~:text=Perplexity%20Performance%3A%20YaRN%20achieves%20lower,up%20to%20128k%20context%20lengths.">Yarn key concepts</A>
										<DT><A HREF="https://arxiv.org/abs/2309.00071">[2309.00071] YaRN: Efficient Context Window Extension of Large Language Models</A>
									</DL><p>
									<DT><A HREF="https://x.com/code_star/status/1991647696457957807">(1) Cody Blakeney en X: "Not for nothing the Nemotron Nano 2 paper also had one of these cool untalked about facts which lead me to make this awesome Claude Shannon meme for a slide once. You need to train at least 2x your desired effective sequence length to get good performance. https://t.co/zQNGIvpMAR" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Batch size</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/index/how-ai-training-scales/">How AI training scales | OpenAI</A>
									<DT><A HREF="https://arxiv.org/abs/1812.06162">[1812.06162] An Empirical Model of Large-Batch Training</A>
									<DT><A HREF="https://arxiv.org/abs/1711.00489">[1711.00489] Don't Decay the Learning Rate, Increase the Batch Size</A>
									<DT><A HREF="https://arxiv.org/pdf/2204.02311.pdf">PALM: progresive larger batch size (GPT-3 style)</A>
									<DT><A HREF="https://arxiv.org/abs/1907.04164">[1907.04164] Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model</A>
									<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1790024970824740949">maxing batchsize and performance</A>
									<DT><A HREF="https://twitter.com/cloneofsimo/status/1789680163133018593">larger batch size leads to more compute-efficient optimization</A>
									<DT><A HREF="https://x.com/cloneofsimo/status/1854498464861933948">An Empirical Model of Large-Batch Training</A>
									<DT><A HREF="https://x.com/SeunghyunSEO7/status/1877188952920125836?t=m1mu7IO4gpotxZrp3hz0AQ&s=31">(1) Seunghyun Seo en X: "The concept of critical batch size is quite simple. Let‚Äôs assume we have a training dataset with 1M tokens. If we use a batch size of 10, we can update model param 100,000 times. On the other hand, if we increase the batch size to 100, the step size decreases to 10,000 (1/n)." / X</A>
									<DT><A HREF="https://github.com/google-research/tuning_playbook">google-research/tuning_playbook: A playbook for systematically maximizing the performance of deep learning models.</A>
									<DT><A HREF="https://x.com/cloneofsimo/status/1828337114800628176">(1) Simo Ryu en X: "Optimal learning rate vs batch size continues to be mysterious... this new result suggests its actually linear but more importantly, (as Scaling Parameterization paper suggested as well, and its been kinda all over the place anyways) it is function of T: the total training token, https://t.co/IvXZWf5jMj" / X</A>
									<DT><A HREF="https://www.jeremyjordan.me/distributed-training/">Training extremely large neural networks across thousands of GPUs.</A>
									<DT><A HREF="https://kexue.fm/archives/11260">Rethinking the Relationship Between Learning Rate and Batch Size (Part I)</A>
								</DL><p>
								<DT><H3 FOLDED>Regularization</H3>
								<DL><p>
									<DT><H3 FOLDED>RMS</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/1910.07467">[1910.07467] Root Mean Square Layer Normalization</A>
										<DT><A HREF="https://imbue.com/research/70b-intro/">Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings - imbue</A>
									</DL><p>
									<DT><H3 FOLDED>layernom</H3>
									<DL><p>
										<DT><A HREF="https://x.com/nathancgy4/status/2008415055965286728">(1) nathan chen en X: "my intuition for why value residual is working well (i.e. the flaw with current residual, and why that's a problem): In a pre-norm transformer, ignoring MLP layers, we have: h_L = h_0 + Œ£_{l=1}^{L} Attention(LayerNorm(h_{l-1})) So h_0 is technically preserved in h_L. But https://t.co/4NhEClGX5x" / X</A>
									</DL><p>
									<DT><A HREF="https://kexue.fm/archives/7681">L2 regularization is not as good as expected? It may be caused by "weight scale shift"</A>
								</DL><p>
								<DT><H3 FOLDED>Dropout</H3>
								<DL><p>
									<DT><A HREF="https://kexue.fm/archives/8770">MLM and MAE from the perspective of Dropout: Some new inspirations</A>
									<DT><A HREF="https://arxiv.org/pdf/1912.10095">Landscape Connectivity and Dropout Stability of SGD Solutions for Over-parameterized Neural Networks</A>
									<DT><A HREF="https://arxiv.org/pdf/2303.01500">Dropout Reduces Underfitting</A>
									<DT><A HREF="https://developers.google.com/machine-learning/crash-course/training-neural-networks/best-practices">Training Neural Networks: Best Practices ¬†|¬† Machine Learning ¬†|¬† Google for Developers</A>
									<DT><A HREF="https://ramnathkumar181.github.io/Dropout-A-Simple-Way-to-Prevent-Neural-Networks-from-Overfitting/">Dropout- A Simple Way to Prevent Neural Networks from Overfitting ‚Äì Ramnath Kumar ‚Äì Predoctoral Researcher, Google DeepMind</A>
									<DT><A HREF="https://eitca.org/artificial-intelligence/eitc-ai-dltf-deep-learning-with-tensorflow/training-a-neural-network-to-play-a-game-with-tensorflow-and-open-ai/training-model/examination-review-training-model/what-is-the-purpose-of-the-dropout-process-in-the-fully-connected-layers-of-a-neural-network/">What is the purpose of the dropout process in the fully connected layers of a neural network? - EITCA Academy</A>
								</DL><p>
								<DT><H3 FOLDED>Training Instability</H3>
								<DL><p>
									<DT><A HREF="https://github.com/apple/ml-sigma-reparam">apple/ml-sigma-reparam</A>
									<DT><A HREF="https://twitter.com/Birchlabs/status/1735709582096302243">Stabilizing Transformer Training by Preventing Attention Entropy Collapse</A>
								</DL><p>
								<DT><H3 FOLDED>Gradient accumulation</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2212.14034">[2212.14034] Cramming: Training a Language Model on a Single GPU in One Day</A>
								</DL><p>
								<DT><H3 FOLDED>MFU</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2204.02311">PaLM: B Compute Usage and Environmental Impact (achieved tokens / peak tokens)</A>
									<DT><A HREF="https://arxiv.org/pdf/2304.01433.pdf">[TPUv4] Do peak FLOPS/second predict real performance?</A>
									<DT><A HREF="https://vram.asmirnov.xyz/">VRAM Calculator</A>
									<DT><A HREF="https://arxiv.org/abs/2205.05198">[2205.05198] Reducing Activation Recomputation in Large Transformer Models</A>
									<DT><A HREF="https://arxiv.org/pdf/2204.02311.pdf">PALM: 4.1 Training Efficiency</A>
									<DT><A HREF="https://pytorch.org/blog/maximizing-training-throughput/?utm_content=293931524&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Maximizing Training Throughput Using PyTorch FSDP and Torch.compile | PyTorch</A>
									<DT><A HREF="https://x.com/HamelHusain/status/1800315287574847701">managing and debugging GPU HBM</A>
									<DT><A HREF="https://parlance-labs.com/">Parlance Labs: A consultancy focused on LLMs</A>
									<DT><A HREF="https://arxiv.org/pdf/2205.05198">Reducing Activation Recomputation in Large Transformer Models sec 6.3</A>
									<DT><A HREF="https://github.com/cchan/nanoGPT-fp8/blob/master/bench.py#L115">mfu = model.estmiate_mfu(batch_size * 1 * num_steps, et)</A>
									<DT><A HREF="https://github.com/cchan/nanoGPT-fp8/blob/3ab2c33a371d684e0fc2c9ff24c0b55ce9ca0389/model.py#L363">nanoGPT: model.py#L363</A>
									<DT><A HREF="https://github.com/Aleph-Alpha/scaling/blob/main/src/scaling/transformer/utils/get_tflops.py">scaling/src/scaling/transformer/utils/get_tflops.py at main ¬∑ Aleph-Alpha/scaling</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/pull/25091">[Core] Add MFU tracking to GPU model execution by bwasti ¬∑ Pull Request #25091 ¬∑ vllm-project/vllm</A>
								</DL><p>
								<DT><H3 FOLDED>epoch</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Yuchenj_UW/status/1820912632028918094">Is one epoch all you need?</A>
									<DT><A HREF="https://x.com/kalomaze/status/1937617091525312513">overfitting at 5T+ scale takes a long time to manifest w/ multiepoch / X</A>
								</DL><p>
								<DT><A HREF="https://kexue.fm/archives/8620">A brief discussion on Transformer initialization, parameterization and sta</A>
								<DT><A HREF="https://openai.com/research/techniques-for-training-large-neural-networks">Techniques for training large neural networks</A>
								<DT><A HREF="https://www.youtube.com/watch?v=k_HMgpJKBso">LLaMA 2 w/ Thomas Scialom (LLaMA 2 lead) - YouTube</A>
								<DT><A HREF="https://github.com/stas00/ml-engineering/blob/master/insights/ai-battlefield.md#ml-engineers-heaven-and-hell">stas00: The AI Battlefield Engineering - What You Need To Know</A>
								<DT><A HREF="https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf">metaseq/projects/OPT/chronicles/OPT175B_Logbook</A>
								<DT><A HREF="https://blog.replit.com/llm-training">Replit - How to train your own Large Language Models</A>
								<DT><A HREF="https://github.com/NVIDIA/DeepLearningExamples/blob/master/TensorFlow/LanguageModeling/BERT/README.md">DeepLearningExamples/README.md at master</A>
								<DT><A HREF="https://jingfengyang.github.io/gpt">Why did all of the public reproduction of GPT-3 fail?</A>
								<DT><A HREF="https://ai.google/static/documents/palm2techreport.pdf">PaLM 2 Technical Report</A>
								<DT><A HREF="http://karpathy.github.io/2019/04/25/recipe/">A Recipe for Training Neural Networks (Andrew Karphathy)</A>
								<DT><A HREF="https://scontent.fsvq5-1.fna.fbcdn.net/v/t39.2365-6/10000000_662098952474184_2584067087619170692_n.pdf?_nc_cat=105&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=sv_RQgqDkdAAX_BgWRs&_nc_ht=scontent.fsvq5-1.fna&oh=00_AfA6QXt9YOU7MOECaRK3gKak7CECYE6GJZ6SQn6y_aji5Q&oe=65A5C63F">Llama 2 (Table 2): training duration (hours)</A>
								<DT><A HREF="https://news.ycombinator.com/item?id=38222277">Google Cloud TPU Multislice Training | Hacker News</A>
								<DT><A HREF="http://karpathy.github.io/2019/04/25/recipe/">A Recipe for Training Neural Networks (Andrew Karphathy) DATA</A>
								<DT><A HREF="https://console.cloud.google.com/storage/browser/_details/madlad-400-checkpoints/checkpoints/10b-mt/10b-mt.gin;tab=live_object">madlad-400...0b-mt.gin (training and model config file)</A>
								<DT><A HREF="https://github.com/axboe/fio">axboe/fio: Flexible I/O Tester</A>
								<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/storage">Filesystems and IO</A>
								<DT><A HREF="https://github.com/zhengzangw/awesome-huge-models">A collection of details things about LLMs</A>
								<DT><A HREF="https://arxiv.org/abs/1907.04164">[1907.04164] Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model</A>
								<DT><A HREF="https://blog.eleuther.ai/nyt-yi-34b-response/">Yi-34B, Llama 2, and common practices in LLM training: a fact check of the New York Times | EleutherAI Blog</A>
								<DT><A HREF="https://x.com/leilavclark/status/1805700631199642094">From bare metal to a 70B model: infrastructure set-up and scripts</A>
								<DT><A HREF="https://www.lesswrong.com/posts/2JJtxitp6nqu6ffak/basic-facts-about-language-models-during-training-1">Basic facts about language models during training ‚Äî LessWrong</A>
								<DT><A HREF="https://arxiv.org/abs/2407.02783">[2407.02783] 52B to 1T: Lessons Learned via Tele-FLM Series</A>
								<DT><A HREF="https://docs.google.com/spreadsheets/d/14vbBbuRMEHoqeuMHkTfw3uiZVmyXNuoSp8s-aHvfvZk/edit?gid=0#gid=0">Common LLM Settings - Google Sheets</A>
								<DT><A HREF="https://x.com/suchenzang/status/1984132522352242777">(1) Susan Zhang en X: "in other words: you can always constrain dynamic range, whereas (precision) errors accumulating can be fatal https://t.co/q5MjNsbRDy" / X</A>
							</DL><p>
							<DT><H3 FOLDED>training-scaling</H3>
							<DL><p>
								<DT><H3 FOLDED>scaling-blueprint</H3>
								<DL><p>
									<DT><H3 FOLDED>scaling-book</H3>
									<DL><p>
										<DT><A HREF="https://jax-ml.github.io/scaling-book/">How To Scale Your Model</A>
										<DT><A HREF="https://github.com/jax-ml/scaling-book">jax-ml/scaling-book: Home for "How To Scale Your Model", a short blog-style textbook about scaling LLMs on TPUs</A>
									</DL><p>
									<DT><A HREF="https://cloneofsimo.notion.site/What-to-do-to-scale-up-09e469d7c3444d6a90305397c38a46f5">What to do to scale up? (Simo Ryu)</A>
									<DT><A HREF="https://howtoscalenn.github.io/">How To Scale</A>
									<DT><A HREF="https://jax-ml.github.io/scaling-book/">How To Scale Your Model</A>
									<DT><A HREF="https://x.com/ezyang/status/1961632320550568200">(1) Edward Z. Yang en X: "It's really interesting comparing the Ultra-Scale playbook (https://t.co/76txKCUFdy) and How To Scale Your Model, aka the JAX book (https://t.co/o1qc1gWao4) side-by-side. üßµ" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=62F86YQCaE4">[Live] ScaleML Series Day 1 ‚Äî FlexOlmo: Open Language Models for Flexible Data Use - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs/2507.17702">[2507.17702] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models</A>
									<DT><A HREF="https://github.com/cloneofsimo/scaling-guide">cloneofsimo/scaling-guide</A>
									<DT><A HREF="https://arxiv.org/abs/2510.19338">[2510.19338] Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning</A>
									<DT><A HREF="https://github.com/jxbz/modula">jxbz/modula: Scalable neural net training via automatic normalization in the modular norm.</A>
									<DT><A HREF="https://jeremybernste.in/modula/bad-scaling/">Bad scaling - Modula documentation</A>
									<DT><A HREF="https://jeremybernste.in/modula/golden-rules/">Golden rules for scaling - Modula documentation</A>
									<DT><A HREF="https://aleph-alpha.com/open-source-codebase-scaling-for-non-commercial-research/">Open-sourcing Codebase Scaling for Non-commercial Research - ALEPH ALPHA - AI for Enterprises and Governments</A>
									<DT><A HREF="https://aleph-alpha.com/de/introducing-pharia-1-llm-transparent-and-compliant/">Introducing Pharia-1-LLM: transparent and compliant</A>
									<DT><A HREF="https://github.com/Aleph-Alpha/scaling">Aleph-Alpha/scaling: Scaling is a distributed training library and installable dependency designed to scale up neural networks, with a dedicated module for training large language models.</A>
									<DT><A HREF="https://www.primeintellect.ai/blog/our-approach-to-decentralized-training">Prime Intellect</A>
									<DT><A HREF="https://arxiv.org/abs/2311.05610">[2311.05610] Efficient Parallelization Layouts for Large-Scale Distributed Model Training</A>
									<DT><A HREF="https://x.com/cloneofsimo/status/1831875356116316193">Simo Ryu en X: "This is good research question and I think there are really promising three alternative axis of scaling (other than number of parameters and data) one is objective: one can scale the number of task objectives. For example, it seems to be the case that predicting multiple token" / X</A>
									<DT><A HREF="https://x.com/GCResearchTeam/status/1864322846777897103">super weights", context-parallelism, scaling laws for precision and critical batch sizes.</A>
									<DT><A HREF="https://apollo-lmms.github.io/">Apollo: An Exploration of Video Understanding in Large Multimodal Models</A>
									<DT><A HREF="https://x.com/SeunghyunSEO7/status/1877188952920125836?t=m1mu7IO4gpotxZrp3hz0AQ&s=31">(1) Seunghyun Seo en X: "The concept of critical batch size is quite simple. Let‚Äôs assume we have a training dataset with 1M tokens. If we use a batch size of 10, we can update model param 100,000 times. On the other hand, if we increase the batch size to 100, the step size decreases to 10,000 (1/n)." / X</A>
									<DT><A HREF="https://huggingface.co/spaces/nanotron/ultrascale-playbook">The Ultra-Scale Playbook - a Hugging Face Space by nanotron</A>
									<DT><A HREF="https://github.com/GHGmc2/scaling-book">GHGmc2/scaling-book: Home for "How To Scale Your Model", a short blog-style textbook about scaling LLMs on TPUs</A>
									<DT><A HREF="https://jax-ml.github.io/scaling-book/">How To Scale Your Model</A>
									<DT><A HREF="https://www.jeremyjordan.me/distributed-training/">Training extremely large neural networks across thousands of GPUs.</A>
									<DT><A HREF="https://arxiv.org/abs/1905.11946">[1905.11946] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</A>
									<DT><A HREF="https://www.cerebras.ai/blog/the-practitioners-guide-to-the-maximal-update-parameterization">The Practitioner‚Äôs Guide to the Maximal Update Parameterization - Cerebras</A>
								</DL><p>
								<DT><H3 FOLDED>Scaling laws</H3>
								<DL><p>
									<DT><H3 FOLDED>Chinchilla</H3>
									<DL><p>
										<DT><H3 FOLDED>chinchilla-trap</H3>
										<DL><p>
											<DT><A HREF="https://ai.meta.com/blog/meta-llama-3/">model performance continues to improve even after the model is trained on two orders of magnitude more data (Scaling up pretraining section)</A>
											<DT><A HREF="https://www.databricks.com/blog/how-long-should-you-train-your-language-model">How Long Should You Train Your Language Model? | Databricks Blog</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2404.10102">[2404.10102] Chinchilla Scaling: A replication attempt</A>
										<DT><A HREF="https://twitter.com/akbirthko/status/1782286554985107631">how good a text compressor we can make for a fixed compute budget</A>
										<DT><A HREF="https://github.com/kyo-takano/chinchilla">kyo-takano/chinchilla: A toolkit for scaling law research ‚öñ</A>
										<DT><A HREF="https://www.cerebras.net/model-lab/">Model Lab - Cerebras</A>
									</DL><p>
									<DT><A HREF="https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training">An empirical analysis of compute-optimal large language model training</A>
									<DT><A HREF="https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval">Gopher, ethical considerations, and retrieval</A>
									<DT><A HREF="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models</A>
									<DT><A HREF="https://twitter.com/ZeyuanAllenZhu/status/1777513016592040248">Physics of Language Models: Knowledge Capacity Scaling Laws (Meta AI)</A>
									<DT><A HREF="https://arxiv.org/abs/2404.05405">[2404.05405] Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws</A>
									<DT><A HREF="https://www.alignmentforum.org/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications">Chinchilla's Scaling Laws</A>
									<DT><A HREF="https://irhum.github.io/blog/chinchilla/">Thoughts on Chinchilla (irhum's blog)</A>
									<DT><A HREF="https://thegregyang.com/">Tensor Programs</A>
									<DT><A HREF="https://arxiv.org/abs/2310.02244">Tensor Programs VI: Feature Learning in Infinite-Depth NN</A>
									<DT><A HREF="https://arxiv.org/pdf/2001.08361.pdf">Scaling Laws For Neural Languag Models</A>
									<DT><A HREF="https://arxiv.org/pdf/2005.14165.pdf">(Brown, 2020) Language Models are Few-Shot Learners</A>
									<DT><A HREF="https://arxiv.org/abs/1712.00409">[1712.00409] Deep Learning Scaling is Predictable, Empirically</A>
									<DT><A HREF="https://arxiv.org/abs/2010.14701">[2010.14701] Scaling Laws for Autoregressive Generative Modeling</A>
									<DT><A HREF="https://ai.googleblog.com/2023/03/scaling-vision-transformers-to-22.html">Scaling vision transformers to 22 billion parameters (Google)</A>
									<DT><A HREF="https://arxiv.org/pdf/2301.03728.pdf">Scaling Laws For Generative Mixed-Modal Language Models</A>
									<DT><A HREF="https://www.youtube.com/watch?v=0D23NeBjCeQ">A Theory for Emergence of Complex Skills in Language Models</A>
									<DT><A HREF="https://www.youtube.com/watch?v=dbo3kNKPaUA">Large Language Models (in 2023) - YouTube</A>
									<DT><A HREF="https://arxiv.org/pdf/2203.17189.pdf">Scaling Up Models and Data with t5x and seqio (James Bradbury)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=K-cXYoqHxBc">More Is Different for AI - Scaling Up, Emergence</A>
									<DT><A HREF="https://www.youtube.com/watch?v=J4LzMGn6FdM">TinyLlama: An Open-Source Small Language Model (model saturation)</A>
									<DT><A HREF="https://twitter.com/khoomeik/status/1769333863401107602">language model scaling laws appear to be sensitive to data complexity</A>
									<DT><A HREF="https://twitter.com/khoomeik/status/1773248562555486588">scaling laws: gzip compression ratio and model size</A>
									<DT><A HREF="https://twitter.com/ChombaBupe/status/1777352725858029727/photo/2">multimodal scaling laws: sample efficiency</A>
									<DT><A HREF="https://github.com/bethgelab/frequency_determines_performance">Pretraining Concept Frequency Determines Multimodal Model Performance</A>
									<DT><A HREF="https://ai.meta.com/blog/meta-llama-3/">Introducing Meta Llama 3: The most capable openly available LLM to date</A>
									<DT><A HREF="https://arxiv.org/abs/2405.10938">[2405.10938] Observational Scaling Laws and the Predictability of Language Model Performance</A>
									<DT><A HREF="https://www.pnas.org/doi/10.1073/pnas.2311878121">Explaining neural scaling laws | PNAS (2024)</A>
									<DT><A HREF="https://arxiv.org/abs/2207.10551">[2207.10551] Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?</A>
									<DT><A HREF="https://x.com/yaroslavvb/status/1815206242438246709">How surprising are neural scaling laws? simple experiment</A>
								</DL><p>
								<DT><H3 FOLDED>Pretraining Without Attention</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2212.10544">[2212.10544] Pretraining Without Attention</A>
									<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1784696357892063565">(transformers) same parameter count, a wildly different architecture</A>
								</DL><p>
								<DT><A HREF="https://x.com/hwchung27/status/1712209280529727705">A counterintuitive implication of scale: trying to solve a more general version of the problem is an easier way to solve the original problem than directly tackling it</A>
								<DT><A HREF="https://irhum.github.io/blog/chinchilla/">Thoughts on Chinchilla (irhum's blog)</A>
								<DT><A HREF="https://github.com/gregorbachmann/scaling_mlps">gregorbachmann/scaling_mlps</A>
								<DT><A HREF="https://arxiv.org/pdf/2001.08361.pdf">Scaling Laws For Neural Languag Models (Pre-Chinchilla)</A>
								<DT><A HREF="https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training">An empirical analysis of compute-optimal large language model training</A>
								<DT><A HREF="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models</A>
								<DT><A HREF="https://www.deepmind.com/blog/language-modelling-at-scale-gopher-ethical-considerations-and-retrieval">Gopher, ethical considerations, and retrieval</A>
								<DT><A HREF="https://www.alignmentforum.org/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications">Chinchilla's Scaling Laws</A>
								<DT><A HREF="https://thegregyang.com/">Tensor Programs</A>
								<DT><A HREF="https://arxiv.org/abs/2310.02244">[2310.02244] Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks</A>
								<DT><A HREF="https://arxiv.org/pdf/2005.14165.pdf">(Brown, 2020) Language Models are Few-Shot Learners</A>
								<DT><A HREF="https://arxiv.org/abs/1712.00409">[1712.00409] Deep Learning Scaling is Predictable, Empirically</A>
								<DT><A HREF="https://arxiv.org/abs/2010.14701">[2010.14701] Scaling Laws for Autoregressive Generative Modeling</A>
								<DT><A HREF="https://ai.googleblog.com/2023/03/scaling-vision-transformers-to-22.html">Scaling vision transformers to 22 billion parameters (Google)</A>
								<DT><A HREF="https://arxiv.org/pdf/2301.03728.pdf">Scaling Laws For Generative Mixed-Modal Language Models</A>
								<DT><A HREF="https://www.youtube.com/watch?v=0D23NeBjCeQ">A Theory for Emergence of Complex Skills in Language Models</A>
								<DT><A HREF="https://www.youtube.com/watch?v=dbo3kNKPaUA">Large Language Models (in 2023) - YouTube</A>
								<DT><A HREF="https://arxiv.org/pdf/2203.17189.pdf">Scaling Up Models and Data with t5x and seqio (James Bradbury)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=K-cXYoqHxBc">More Is Different for AI - Scaling Up, Emergence</A>
								<DT><A HREF="https://www.youtube.com/watch?v=J4LzMGn6FdM">TinyLlama: An Open-Source Small Language Model (model saturation)</A>
								<DT><A HREF="https://twitter.com/khoomeik/status/1769333863401107602">language model scaling laws appear to be sensitive to data complexity</A>
								<DT><A HREF="https://twitter.com/khoomeik/status/1773248562555486588">scaling laws: gzip compression ratio and model size</A>
								<DT><A HREF="https://transformer-circuits.pub/2024/april-update/index.html#scaling-laws">Scaling Laws for Dictionary Learning</A>
								<DT><A HREF="https://arxiv.org/abs/2404.10102">[2404.10102] Chinchilla Scaling: A replication attempt</A>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1780639257389904013">Chinchilla Scaling: A replication attempt (twitter thread)</A>
								<DT><A HREF="https://github.com/hkust-nlp/llm-compression-intelligence">hkust-nlp/llm-compression-intelligence: Official github repo for the paper "Compression Represents Intelligence Linearly"</A>
								<DT><A HREF="https://ericjmichaud.com/quanta/">On neural scaling and the quanta hypothesis</A>
								<DT><A HREF="https://github.com/karpathy/nanochat/discussions/420">[Jan 7 2026] nanochat miniseries v1 ¬∑ karpathy/nanochat ¬∑ Discussion #420</A>
							</DL><p>
							<DT><H3 FOLDED>training-efficient</H3>
							<DL><p>
								<DT><H3 FOLDED>Activation Recomputation</H3>
								<DL><p>
									<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/03/23/eleutherai-reading-group-session-9.html">Reducing Activation Recomputation in Large Transformer Models | ML Perf Notes</A>
									<DT><A HREF="https://arxiv.org/abs/2205.05198">[2205.05198] Reducing Activation Recomputation in Large Transformer Models</A>
									<DT><A HREF="https://huggingface.co/spaces/nanotron/ultrascale-playbook">The Ultra-Scale Playbook - a Hugging Face Space by nanotron</A>
								</DL><p>
								<DT><A HREF="https://github.com/JeanKaddour/NoTrainNoGain">NoTrainNoGain: Revisiting Efficient Training Algorithms For Transformer-based Language Models</A>
								<DT><A HREF="https://github.com/Lightning-AI/lit-gpt">Lightning-AI/lit-gpt</A>
								<DT><A HREF="https://twitter.com/ZihangDai/status/1281349893873897478/photo/1">Funnel-Transformer</A>
								<DT><A HREF="https://twitter.com/edwardjhu/status/1714283903908020386">ŒºTransfer</A>
								<DT><A HREF="https://twitter.com/itsclivetime/status/1650254229620260864">LLM rules of thumb (Clive Shan)</A>
								<DT><A HREF="https://bettergpt.chat////">Better GPT</A>
							</DL><p>
							<DT><H3 FOLDED>distributed-training</H3>
							<DL><p>
								<DT><H3 FOLDED>layers</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/tree/main/server/text_generation_server/layers">text-generation-inference/server/text_generation_server/layers at main ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/text_generation_server/layers/mlp.py">text-generation-inference/server/text_generation_server/layers/mlp.py at main ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/meta-llama/llama3/blob/main/llama/model.py">llama3/llama/model.py at main ¬∑ meta-llama/llama3</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/python/sglang/srt/layers">sglang/python/sglang/srt/layers at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/thu-ml/RIFLEx/commit/61a70dc455dd0f2aaf611d69ed248b4aaa83b600#diff-75dbecddf3203cfb3c998f91c433ed4ccb15a2a4f4779ea0bda21d240d4c1d04">activation_layers (non linear functions)</A>
									<DT><A HREF="https://gist.github.com/Chillee/6f1a8995dc25c08b11494485d4a53460">Random Kernel Microbenchmarks</A>
								</DL><p>
								<DT><H3 FOLDED>model-parallelism-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=4h7YBUXiCZE">Abstractions for Expressive, Efficient Parallel and Distributed Comp</A>
									<DT><A HREF="https://www.youtube.com/watch?v=xtxxLWZznBI">Demystifying Parallel and Distributed Deep Learning (ETH) (Microsoft)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=0qoUqE695X0">Lecture 12.4 Scaling up (Mixed precision, Data-parallelism, FSDP) - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>model-parallelism</H3>
								<DL><p>
									<DT><A HREF="https://main-horse.github.io/posts/visualizing-6d/">Visualizing 6D Mesh Parallelism ¬∑ main</A>
									<DT><A HREF="https://x.com/jingyuanliu123/status/1945732051862442490">(1) JingyuanLiu en X: "I learned parallelism inside megatron-lm and zero2 and zero3 are not implemented there, so basically no fsdp. With zero2 zero3, there are some more challenges to overlap the allgather and reducescatter with computation Personally, the world without fsdp is much easier to" / X</A>
									<DT><A HREF="https://arxiv.org/pdf/2411.00284">SimpleFSDP: Simpler Fully Sharded Data Parallel with torch.compile</A>
								</DL><p>
								<DT><H3 FOLDED>data-parallelism</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2006.15704">[2006.15704] PyTorch Distributed: Experiences on Accelerating Data Parallel Training</A>
									<DT><A HREF="https://www.pdl.cmu.edu/PDL-FTP/CloudComputing/GeePS-cui-eurosys16.pdf">GeePS: Scalable deep learning on distributed GPUs with a GPU-specialized parameter server</A>
									<DT><A HREF="https://www.mishalaskin.com/posts/data_parallel">Training Deep Networks with Data Parallelism in Jax</A>
									<DT><A HREF="https://twitter.com/Muennighoff/status/1661895337248686081">How to keep scaling LLMs when data runs out?</A>
									<DT><A HREF="https://github.com/huggingface/datablations">huggingface/datablations: Scaling Data-Constrained Language Models</A>
									<DT><A HREF="https://twitter.com/MishaLaskin/status/1628880374255296512">Training Deep Networks with Data Parallelism in Jax (Twitter thread)</A>
									<DT><A HREF="https://arxiv.org/pdf/1106.5730">Hogwild!: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent</A>
									<DT><A HREF="https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/scaling/JAX/data_parallel_intro.ipynb#scrollTo=IUTeFZleFojG">data_parallel_intro.ipynb - Colab</A>
									<DT><A HREF="https://siboehm.com/articles/22/data-parallel-training">Data-Parallel Distributed Training of Deep Learning Models</A>
								</DL><p>
								<DT><H3 FOLDED>pipeline-parallelism</H3>
								<DL><p>
									<DT><H3 FOLDED>pipeline-parallelism-torch</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=_rC49PeqrWc">PiPPy: Automated Pipeline Parallelism for PyTorch - YouTube</A>
										<DT><A HREF="https://github.com/pytorch/PiPPy">pytorch/PiPPy: Pipeline Parallelism for PyTorch</A>
									</DL><p>
									<DT><H3 FOLDED>GPipe</H3>
									<DL><p>
										<DT><A HREF="https://ai.googleblog.com/2019/03/introducing-gpipe-open-source-library.html">GPipe</A>
										<DT><A HREF="https://www.youtube.com/watch?v=9s2cum25Kkc">GPipe</A>
										<DT><A HREF="https://arxiv.org/abs/1811.06965">[1811.06965] GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism</A>
									</DL><p>
									<DT><H3 FOLDED>pp-visualization</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Victarry/PP-Schedule-Visualization">Victarry/PP-Schedule-Visualization</A>
									</DL><p>
									<DT><H3 FOLDED>zero-bubble-parallelism</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sail-sg/zero-bubble-pipeline-parallelism">sail-sg/zero-bubble-pipeline-parallelism: Zero Bubble Pipeline Parallelism</A>
										<DT><A HREF="https://arxiv.org/abs/2408.03505">[2408.03505] Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation</A>
										<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/02/09/eleutherai-reading-group-session-6.html">Zero Bubble Pipeline Parallelism | ML Perf Notes</A>
									</DL><p>
									<DT><A HREF="https://siboehm.com/articles/22/pipeline-parallel-training">Pipeline-Parallelism: Distributed Training via Model Partitioning</A>
									<DT><A HREF="https://github.com/siboehm/shallowspeed">siboehm/ShallowSpeed: Small scale distributed training of sequential deep learning models, built on Numpy and MPI.</A>
									<DT><A HREF="https://x.com/fly51fly/status/1821526433682063654">[CL] Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation W Feng, Y Chen, S Wang, Y Peng... [Bytedance &amp;amp; Harvard University] (2024) https://t.co/zaxd5Oc2ax - This paper proposes Optimus, a distributed training system to accelerate large-scale</A>
								</DL><p>
								<DT><H3 FOLDED>tensor-parallelism</H3>
								<DL><p>
									<DT><A HREF="https://www.mishalaskin.com/posts/tensor_parallel">Sharding Large Models with Tensor Parallelism</A>
									<DT><A HREF="https://irhum.github.io/blog/pjit/">irhum.github.io - Tensor Parallelism with jax.pjit</A>
									<DT><A HREF="https://twitter.com/__tinygrad__/status/1742365883048284421">Tinygrad's multiGPU tensor sharding</A>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html">SPMD: Parallel Evaluation in JAX</A>
									<DT><A HREF="https://blog.eleuther.ai/transformer-math/">Transformer Math 101 | EleutherAI Blog</A>
									<DT><A HREF="https://github.com/pytorch-labs/gpt-fast/blob/main/tp.py#L124">gpt-fast/tp.py at main ¬∑ pytorch-labs/gpt-fast</A>
									<DT><A HREF="https://github.com/bytedance/flux">bytedance/flux: A fast communication-overlapping library for tensor parallelism on GPUs.</A>
									<DT><A HREF="https://www.determined.ai/blog/tp">Tensor Parallelism in Three Levels of Difficulty | Determined AI</A>
									<DT><A HREF="https://insujang.github.io/2024-01-11/tensor-parallelism-and-sequence-parallelism-detailed-analysis/">Tensor Parallelism and Sequence Parallelism: Detailed Analysis</A>
									<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/03/30/illustrated-megatron.html">An illustrated deep-dive into Megatron-style tensor parallelism | ML Perf Notes</A>
									<DT><A HREF="https://dev.to/lewis_won/tensor-parallelism-by-hand-3eh">Tensor parallelism by hand - DEV Community</A>
								</DL><p>
								<DT><H3 FOLDED>sequence-parallelism</H3>
								<DL><p>
									<DT><H3 FOLDED>SP-Ulysses</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2309.14509">[2309.14509] DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models</A>
										<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-ulysses/README.md">DeepSpeed/blogs/deepspeed-ulysses/README.md at master ¬∑ microsoft/DeepSpeed</A>
										<DT><A HREF="https://www.youtube.com/watch?v=TXoG47b-cSI">DeepSpeed Ulysses: System Optimizations for Enabling Training of Long Sequence Transformer Models - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>SP-Ring</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/distributed/tensor/experimental/_attention.py">pytorch/torch/distributed/tensor/experimental/_attention.py: _templated_ring_attention</A>
										<DT><A HREF="https://coconut-mode.com/posts/ring-attention/">Ring Attention Explained | Coconut Mode</A>
										<DT><A HREF="https://arxiv.org/abs/2310.01889">[2310.01889] Ring Attention with Blockwise Transformers for Near-Infinite Context</A>
										<DT><A HREF="https://arxiv.org/abs/2410.08368">[2410.08368] ElasticTok: Adaptive Tokenization for Image and Video</A>
										<DT><A HREF="https://arxiv.org/pdf/2402.08268">WORLD MODEL ON MILLION-LENGTH VIDEO AND LANGUAGE WITH BLOCKWISE RINGATTENTION</A>
										<DT><A HREF="https://github.com/haoliuhl/ringattention">haoliuhl/ringattention: Large Context Attention</A>
										<DT><A HREF="https://github.com/lucidrains/ring-attention-pytorch">lucidrains/ring-attention-pytorch: Implementation of üíç Ring Attention, from Liu et al. at Berkeley AI, in Pytorch</A>
										<DT><A HREF="https://github.com/LargeWorldModel/LWM">LargeWorldModel/LWM: Large World Model -- Modeling Text and Video with Millions Context</A>
										<DT><A HREF="https://github.com/zhuzilin/ring-flash-attention">zhuzilin/ring-flash-attention: Ring attention implementation with flash attention</A>
										<DT><A HREF="https://github.com/gpu-mode/ring-attention">gpu-mode/ring-attention: ring-attention experiments</A>
										<DT><A HREF="https://arxiv.org/pdf/2311.09431">STRIPED ATTENTION: Faster Ring Attention for Causal Transformers</A>
										<DT><A HREF="https://chat.deepseek.com/a/chat/s/b249b54e-af39-45fe-b6ae-40d0186f806d">Sequence Level Parallelism in Transformers</A>
									</DL><p>
									<DT><H3 FOLDED>Dynamic Sequence Parallelism (DSP)</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys?tab=readme-ov-file">NUS-HPC-AI-Lab/VideoSys: VideoSys: An easy and efficient system for video generation</A>
										<DT><A HREF="https://arxiv.org/abs/2403.10266">[2403.10266] DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers</A>
										<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys/blob/master/docs/dsp.md">VideoSys/docs/dsp.md at master ¬∑ NUS-HPC-AI-Lab/VideoSys</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2405.07719">[2405.07719] USP: A Unified Sequence Parallelism Approach for Long Context Generative AI</A>
									<DT><A HREF="https://github.com/RulinShao/LightSeq">RulinShao/LightSeq: Official repository for LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers</A>
									<DT><A HREF="https://arxiv.org/abs/2411.01783v2">[2411.01783v2] Context Parallelism for Scalable Million-Token Inference</A>
									<DT><A HREF="https://www.harmdevries.com/post/context-length/">In the long (context) run | Harm de Vries</A>
									<DT><A HREF="https://insujang.github.io/2024-01-11/tensor-parallelism-and-sequence-parallelism-detailed-analysis/">Tensor Parallelism and Sequence Parallelism: Detailed Analysis</A>
									<DT><A HREF="https://insujang.github.io/2024-09-20/introducing-context-parallelism/">Introducing Context Parallelism ¬∑ Better Tomorrow with Computer Science</A>
									<DT><A HREF="https://huggingface.co/blog/exploding-gradients/ulysses-ring-attention">Ultra-Long Sequence Parallelism: Ulysses + Ring-Attention Technical Principles and Implementation</A>
								</DL><p>
								<DT><H3 FOLDED>GSPMD</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2105.04663.pdf">General and Scalable Parallellization for ML Computation Graphs</A>
								</DL><p>
								<DT><H3 FOLDED>Collective operation</H3>
								<DL><p>
									<DT><A HREF="https://en.wikipedia.org/wiki/Collective_operation">Collective operation - Wikipedia</A>
									<DT><A HREF="https://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/">MPI Scatter, Gather, and Allgather ¬∑ MPI Tutorial</A>
									<DT><A HREF="https://dev.to/lewis_won/from-scatter-to-all-reduce-a-plain-english-guide-to-collective-operations-1695">From Scatter to All-Reduce: A Plain-English Guide to Collective Operations - DEV Community</A>
								</DL><p>
								<DT><H3 FOLDED>automate distributed training</H3>
								<DL><p>
									<DT><H3 FOLDED>Alpa</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/GoogleAI/status/1521938108568154112">Google AI en Twitter: "Alpa is a framework that uses just one line of code to easily automate the complex model parallelism process for large #DeepLearning models. Learn more and check out the code. https://t.co/xFfW5tml9v https://t.co/qYIhHnzwSG" / Twitter</A>
										<DT><A HREF="https://ai.googleblog.com/2022/05/alpa-automated-model-parallel-deep.html">Alpa: Automated Model-Parallel Deep Learning ‚Äì Google AI Blog</A>
										<DT><A HREF="https://github.com/alpa-projects/alpa">alpa-projects/alpa: Training and serving large-scale neural networks</A>
										<DT><A HREF="https://www.youtube.com/watch?v=y1NXHjcl6V0">Alpa: Automated Model-Parallel Deep Learning - Zhuohan Li | Stanford MLSys #59 - YouTube</A>
										<DT><A HREF="https://github.com/alpa-projects/mms">alpa-projects/mms: Multi model serving</A>
										<DT><A HREF="https://www.youtube.com/watch?v=oVC3SB3GqrI">OSDI '22 - Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>redco</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tanyuqian/redco">tanyuqian/redco: NAACL '24 (Best Demo Paper RunnerUp) / MlSys @ NeurIPS '23 - RedCoast: A Lightweight Tool to Automate Distributed Training and Inference</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>activation-recomputation</H3>
								<DL><p>
									<DT><A HREF="https://lilianweng.github.io/posts/2021-09-25-train-large/#mixture-of-experts-moe">How to Train Really Large Models on Many GPUs? | Lil'Log</A>
									<DT><A HREF="https://sumanthrh.com/post/distributed-and-efficient-finetuning/">Everything about Distributed Training and Efficient Finetuning | Sumanth's Personal Website</A>
								</DL><p>
								<DT><H3 FOLDED>t5x + seqio</H3>
								<DL><p>
									<DT><A HREF="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=GprA5UsAAAAJ&sortby=pubdate&citation_for_view=GprA5UsAAAAJ:roLk4NBRz8UC">Scaling Up Models and Data with t5x and seqio</A>
									<DT><A HREF="https://arxiv.org/pdf/2203.17189.pdf">Scaling Up Models and Data with t5x and seqio</A>
									<DT><A HREF="https://twitter.com/rasbt/status/1638538494887821313">(1) Sebastian Raschka en X: ""Meet in the Middle: A New Pre-training Paradigm" for large language models (LLM). In this paper, the authors propose to develop a bidirectional LLM using the full sequence information during pretraining and using context from both sides during inference. https://t.co/FHY4Vof90I... https://t.co/QFxtKO3iJb" / X</A>
									<DT><A HREF="https://twitter.com/rasbt/status/1638538494887821313">Meet in the Middle: A New Pre-training Paradigm</A>
									<DT><A HREF="https://github.com/google-research/t5x">google-research/t5x</A>
								</DL><p>
								<DT><H3 FOLDED>training-distributed-parallelism-heterogenous</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2206.01288v1">Decentralized Training of Foundation Models in Heterogeneous Environments</A>
								</DL><p>
								<DT><H3 FOLDED>DiLoCo</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2311.08105">[2311.08105] DiLoCo: Distributed Low-Communication Training of Language Models</A>
									<DT><A HREF="https://arxiv.org/pdf/2407.07852">https://arxiv.org/pdf/2407.07852</A>
									<DT><A HREF="https://arxiv.org/abs/2407.07852">[2407.07852] OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training</A>
									<DT><A HREF="https://github.com/PrimeIntellect-ai/OpenDiloco?tab=readme-ov-file">PrimeIntellect-ai/OpenDiloco: OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training</A>
									<DT><A HREF="https://github.com/PrimeIntellect-ai/diloco_simple">PrimeIntellect-ai/diloco_simple: torch implementation of diloco</A>
									<DT><A HREF="https://www.primeintellect.ai/blog/our-approach-to-decentralized-training">Prime Intellect</A>
									<DT><A HREF="https://x.com/NousResearch/status/1828121648383566270">(1) Nous Research en X: "What if you could use all the computing power in the world to train a shared, open source AI model? Preliminary report: https://t.co/b1XgJylsnV Nous Research is proud to release a preliminary report on DisTrO (Distributed Training Over-the-Internet) a family of https://t.co/h2gQJ4m7lB" / X</A>
									<DT><A HREF="https://x.com/Ar_Douillard/status/1836706696086847779">(1) Arthur Douillard en X: "So DisTrO is a kind of a ElasticSGD (https://t.co/Y7pbei6zIf) / PAPA (https://t.co/JndN7kIyl7)?" / X</A>
									<DT><A HREF="https://x.com/nearcyan/status/1836598231415054705">DisTrO mathemathical expression</A>
									<DT><A HREF="https://arxiv.org/abs/2405.17517">[2405.17517] WASH: Train your Ensemble with Communication-Efficient Weight Shuffling, then Average</A>
									<DT><A HREF="https://x.com/mlia_isir">(1) MLIA (@mlia_isir) / X</A>
									<DT><A HREF="https://github.com/NousResearch/DisTrO">NousResearch/DisTrO: Distributed Training Over-The-Internet</A>
								</DL><p>
								<DT><A HREF="https://lilianweng.github.io/posts/2021-09-25-train-large/">How to Train Really Large Models on Many GPUs? | Lil'Log</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-uyXE7dY5H0">NIPS: Oral Session 4 - Ilya Sutskever - YouTube</A>
								<DT><A HREF="https://imbue.com/research/70b-infrastructure/">From bare metal to a 70B model: infrastructure set-up and scripts - imbue</A>
								<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/training/model-parallelism">ml-engineering/training/model-parallelism at master ¬∑ stas00/ml-engineering</A>
								<DT><A HREF="https://arxiv.org/abs/2311.08105">[2311.08105] DiLoCo: Distributed Low-Communication Training of Language Models</A>
								<DT><A HREF="https://sumanthrh.com/post/distributed-and-efficient-finetuning/">Everything about Distributed Training and Efficient Finetuning</A>
								<DT><A HREF="https://www.databricks.com/blog/mosaic-ai-training-capabilities">Building DBRX-class Custom LLMs with Mosaic AI Training | Databricks Blog</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1803941734629388590">HSDP, GPU sharding and node recover (Mihir Patel)</A>
								<DT><A HREF="https://cloneofsimo.notion.site/What-to-do-to-scale-up-09e469d7c3444d6a90305397c38a46f5">What to do to scale up?</A>
								<DT><A HREF="https://github.com/siboehm/shallowspeed">siboehm/ShallowSpeed: Small scale distributed training of sequential deep learning models, built on Numpy and MPI.</A>
								<DT><A HREF="https://github.com/FZJ-JSC/tutorial-multi-gpu">FZJ-JSC/tutorial-multi-gpu: Efficient Distributed GPU Programming for Exascale, an SC/ISC Tutorial</A>
								<DT><A HREF="https://arxiv.org/abs/2205.01068">[2205.01068] OPT: Open Pre-trained Transformer Language Models</A>
								<DT><A HREF="https://arxiv.org/abs/2203.12533">[2203.12533] Pathways: Asynchronous Distributed Dataflow for ML</A>
								<DT><A HREF="https://pytorch.org/docs/stable/distributed.html#distributed-key-value-store">Distributed communication package - torch.distributed</A>
								<DT><A HREF="https://github.com/stanford-crfm/levanter">stanford-crfm/levanter</A>
								<DT><A HREF="https://arxiv.org/abs/2204.06745">GPT-NeoX-20B: An Open-Source Autoregressive Language Model</A>
								<DT><A HREF="https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e">the world‚Äôs largest distributed LLM training job on TPU v5e</A>
								<DT><A HREF="https://arxiv.org/abs/2303.06318">[2303.06318] A Hybrid Tensor-Expert-Data Parallelism Approach to Optimize Mixture-of-Experts Training</A>
								<DT><A HREF="http://giantpandacv.com/project/PyTorch/AI%20Infra%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%B9%8B%E3%80%8A%E5%9C%A8LLM%E8%AE%AD%E7%BB%83%E4%B8%AD%E5%87%8F%E5%B0%91%E6%BF%80%E6%B4%BB%E5%80%BC%E5%86%85%E5%AD%98%E3%80%8B/">AI Infra paper reading: "Reducing activation value memory in LLM training"</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1805629542914211951">Imbue blogs</A>
								<DT><A HREF="https://github.com/imbue-ai/cluster-health">imbue-ai/cluster-health</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1803446449796989021">Nemotron-340B was trained on 768x8 H100: visualization</A>
								<DT><A HREF="https://twitter.com/dlwh/status/1677923909763747840">JAX/Haliax/Levanter</A>
								<DT><A HREF="https://colab.research.google.com/drive/18_BrtDpe1lu89M4T6fKzda8DdSLtFJhi">Tensor Parallelism in Haliax - Colaboratory</A>
								<DT><A HREF="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf">TensorFlow: A System for Large-Scale Machine Learning</A>
								<DT><A HREF="https://arxiv.org/abs/2204.06514">[2204.06514] Scalable Training of Language Models using JAX pjit and TPUv4</A>
								<DT><A HREF="https://arxiv.org/abs/1904.00962">[1904.00962] Large Batch Optimization for Deep Learning: Training BERT in 76 minutes</A>
								<DT><A HREF="https://github.com/stanford-crfm/levanter">stanford-crfm/levanter: Legibile, Scalable, Reproducible Foundation Models with Named Tensors and Jax</A>
								<DT><A HREF="https://github.com/froystig">froystig (Roy Frostig)</A>
								<DT><A HREF="https://x.com/awnihannun/status/1815516199876452393">How to shard your LLM</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Hr2FWHBuNXs">L12b Parallelization -- Instructor: Wilson Yan - YouTube</A>
								<DT><A HREF="https://drive.google.com/file/d/1GFL3XMB96EZs5Yg0tbQal8ZEyqHQ58hp/view">L12 Multi-Modal Models (SP24).pdf - Google Drive</A>
								<DT><A HREF="https://arxiv.org/abs/2311.05610">[2311.05610] Efficient Parallelization Layouts for Large-Scale Distributed Model Training</A>
								<DT><A HREF="https://github.com/intelligent-machine-learning/dlrover/blob/master/atorch/README.md">dlrover/atorch/README.md at master ¬∑ intelligent-machine-learning/dlrover</A>
								<DT><A HREF="https://github.com/AlibabaPAI/torchacc">AlibabaPAI/torchacc: PyTorch distributed training acceleration framework</A>
								<DT><A HREF="https://irrationalanalysis.substack.com/p/a-background-proof-guide-on-communication">A Background-Proof Guide on Communication Systems</A>
								<DT><A HREF="https://huggingface.co/spaces/nanotron/ultrascale-playbook">The Ultra-Scale Playbook - a Hugging Face Space by nanotron</A>
								<DT><A HREF="https://arxiv.org/pdf/2303.06318">what are all the ways the ops in a transformer can be parallelized across GPUs + pretty diagrams?</A>
								<DT><A HREF="https://www.jeremyjordan.me/distributed-training/">Training extremely large neural networks across thousands of GPUs.</A>
								<DT><A HREF="https://main-horse.github.io/posts/visualizing-6d/">Visualizing 6D Mesh Parallelism ¬∑ main</A>
								<DT><A HREF="https://huggingface.co/nanotron">The Ultra-Scale Playbook: Training LLMs on GPU Clusters</A>
								<DT><A HREF="https://www.youtube.com/watch?v=9MvD-XsowsE">Stanford CS231N | Spring 2025 | Lecture 11: Large Scale Distributed Training - YouTube</A>
								<DT><A HREF="https://blog.ezyang.com/2025/08/the-parallelism-mesh-zoo/">The Parallelism Mesh Zoo : ezyang‚Äôs blog</A>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/">How To Scale Your Model</A>
								<DT><A HREF="https://handbook.eng.kempnerinstitute.harvard.edu/s5_ai_scaling_and_engineering/scalability/distributed_gpu_computing.html">17.4. Distributed GPU Computing ‚Äî Kempner Institute Computing Handbook</A>
							</DL><p>
							<DT><H3 FOLDED>training-optimizer</H3>
							<DL><p>
								<DT><H3 FOLDED>optimization-hyperparameters</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/Guodzh/status/1489371872777191437/photo/1">Aggressive learning rate</A>
									<DT><A HREF="https://twitter.com/Guodzh/status/1489371872777191437">The right moment to decay is always as late as possible</A>
									<DT><A HREF="https://twitter.com/borisdayma/status/1489292077313703939">Impact of learning rate</A>
									<DT><A HREF="https://arxiv.org/pdf/1803.02021.pdf">UNDERSTANDING SHORT-HORIZON BIAS IN STOCHASTIC META-OPTIMIZATION (aggresive)</A>
								</DL><p>
								<DT><H3 FOLDED>bf16-optimizer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/imoneoi/bf16_fused_adam">imoneoi/bf16_fused_adam: BFloat16 Fused Adam Operator for PyTorch</A>
									<DT><A HREF="https://github.com/AmericanPresidentJimmyCarter/test-torch-bfloat16-vit-training">AmericanPresidentJimmyCarter/test-torch-bfloat16-vit-training</A>
								</DL><p>
								<DT><H3 FOLDED>Adam</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2304.09871">theory on Adam Instability in Large-Scale Machine Learning</A>
									<DT><A HREF="https://x.com/thecharlieblake/status/1800875303486861735">Adam Per Parameter Memory Usage, Excluding Activations</A>
									<DT><A HREF="https://kexue.fm/archives/11267">‰∏∫‰ªÄ‰πàAdamÁöÑUpdate RMSÊòØ0.2Ôºü - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
								</DL><p>
								<DT><H3 FOLDED>MUON</H3>
								<DL><p>
									<DT><H3 FOLDED>muon-parallel</H3>
									<DL><p>
										<DT><A HREF="https://main-horse.github.io/posts/parallelizing-muon/">Various approaches to parallelizing Muon ¬∑ main</A>
									</DL><p>
									<DT><A HREF="https://github.com/microsoft/dion/blob/main/optimizers/muon.py">dion/optimizers/muon.py at main ¬∑ microsoft/dion</A>
									<DT><A HREF="https://jeremybernste.in/writing/deriving-muon">Deriving Muon</A>
									<DT><A HREF="https://x.com/torchcompiled/status/1861177127317708964">(1) Ethan üá¶üá∫ en X: "FSDP2 support for MUON has just landed as well! https://t.co/ZnKfxQnbJZ" / X</A>
									<DT><A HREF="https://github.com/ethansmith2000/fsdp_optimizers">ethansmith2000/fsdp_optimizers: supporting pytorch FSDP for optimizers</A>
									<DT><A HREF="https://x.com/rami_mmo/status/1862349005600301444">rami en X: "I ran 80000 simulations and muon (with adam embed/unembed) seems to outperform adam (tuned) when training a DiT model. https://t.co/HYpwmTUONB" / X</A>
									<DT><A HREF="https://x.com/cloneofsimo/status/1907731069878825400">Adam vs Shampoo vs Muon on MNIST. All follow the lr approx sqrt(BS) law</A>
									<DT><A HREF="https://x.com/iScienceLuvr/status/1919587480866849194">Practical Efficiency of Muon For Pretraining</A>
									<DT><A HREF="https://arxiv.org/abs/2505.02222">[2505.02222] Practical Efficiency of Muon for Pretraining</A>
									<DT><A HREF="https://x.com/attentionmech/status/1923294254811513018">learning about muon thread</A>
									<DT><A HREF="https://x.com/Kimi_Moonshot/status/1893379158472044623">(1) Kimi.ai en X: "üöÄ Introducing our new tech report: Muon is Scalable for LLM Training We found that Muon optimizer can be scaled up using the follow techniques: ‚Ä¢ Adding weight decay ‚Ä¢ Carefully adjusting the per-parameter update scale ‚ú® Highlights: ‚Ä¢ ~2x computational efficiency vs AdamW https://t.co/tazxtnE9NM" / X</A>
									<DT><A HREF="https://www.linkedin.com/posts/yang-zhou-a706a5174_1n-debugging-nccl-performance-problems-ugcPost-7345533776720003072-BllB/?utm_source=share&utm_medium=member_ios&rcm=ACoAAAYYSEkB7J8dsqWZRvjmd9VM-ODi9QFXRrQ">bugging NCCL performance problems for LLM workloads is always challenging. In this blog post, we explore various perf-critical parameters in NCCL and tackle datacenter network congestions with UCCL</A>
									<DT><A HREF="https://kexue.fm/archives/11126">Interpreting the Key Training Techniques Behind Kimi K2: QK-Clip and MuonClip.</A>
									<DT><A HREF="https://kexue.fm/archives/11267">‰∏∫‰ªÄ‰πàAdamÁöÑUpdate RMSÊòØ0.2Ôºü - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://x.com/jingyuanliu123/status/1963084684784734543?s=12">the update RMS of AdamW is actually O(1), and in "Muon is scalable for LLM training" paper, we empirically observe that AdamW's RMS is usually around 0.2</A>
									<DT><A HREF="https://kexue.fm/archives/11241">ÊµÅÂΩ¢‰∏äÁöÑÊúÄÈÄü‰∏ãÈôçÔºö4. Muon + Ë∞±ÁêÉÈù¢ - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://www.youtube.com/watch?v=-Cto66pAUXQ">YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=bO5nvE289ec">This Simple Optimizer Is Revolutionizing How We Train AI [Muon] - YouTube</A>
									<DT><A HREF="https://github.com/karpathy/nanochat/blob/dd6ff9a1cc23b38ce69ddc119fb220f9ee96cedd/nanochat/muon.py#L4">nanochat/nanochat/muon.py</A>
									<DT><A HREF="https://github.com/pytorch/torchtitan/pull/1630">Distributed Scion/Muon by rakkit ¬∑ Pull Request #1630 ¬∑ pytorch/torchtitan</A>
									<DT><A HREF="https://docs.pytorch.org/docs/2.9/generated/torch.optim.Muon.html">Muon ‚Äî PyTorch 2.9 documentation</A>
									<DT><A HREF="https://kexue.fm/archives/11340">Beyond MuP: 1. The Self-Cultivation of a Good Model</A>
									<DT><A HREF="https://gist.github.com/YouJiacheng/393c90cbdc23b09d5688815ba382288b/5bff1f7781cf7d062a155eecd2f13075756482ae">muon coefficients</A>
									<DT><A HREF="https://kexue.fm/archives/11416">Muon Optimizer Guide: Quick Start &amp; Key Details</A>
									<DT><A HREF="https://x.com/damekdavis/status/1996018764341805507">(1) Damek en X: "New paper studies when spectral gradient methods (e.g., Muon) help in deep learning: 1. We identify a pervasive form of ill-conditioning in DL: post-activations matrices are low-stable rank. 2. We then explain why spectral methods can perform well despite this. Long thread https://t.co/xEcpPvr32n" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2512.04299">[2512.04299] When do spectral gradient updates help in deep learning?</A>
									<DT><A HREF="https://kellerjordan.github.io/posts/muon/">Muon: An optimizer for hidden layers in neural networks | Keller Jordan blog</A>
								</DL><p>
								<DT><H3 FOLDED>Dion</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/dion">microsoft/dion: Dion optimizer algorithm</A>
									<DT><A HREF="https://x.com/JingyuanLiu123/status/1951885788855345221">Some good details about Muon</A>
								</DL><p>
								<DT><H3 FOLDED>Shampo</H3>
								<DL><p>
									<DT><H3 FOLDED>shampo-impl</H3>
									<DL><p>
										<DT><A HREF="https://github.com/google-research/google-research/tree/master/scalable_shampoo">Distributed Shampoo Implementation</A>
										<DT><A HREF="https://github.com/cloneofsimo/zeroshampoo">cloneofsimo/zeroshampoo</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2002.09018.pdf">Scalable Second Order Optimization for Deep Learning (Shampo)</A>
									<DT><A HREF="https://twitter.com/_arohan_/status/1713343013563576540">Rohan Anil en X: "From ICLR, ŒºP ü§ù Shampoo</A>
									<DT><A HREF="https://x.com/jxbz/status/1821610272454537459">Jeremy Bernstein: Okay, executive summary on Shampoo, zeroth matrix powers, stochastic spectral descent and Modula.</A>
									<DT><A HREF="https://x.com/_arohan_/status/1819102492468396315">(1) rohan anil en X: "Distributed Shampoo has dethroned Nesterov Adam marking a new era for deep learning optimization. üëë ü§ò Non-diagonal preconditioning is here! This is the AlexNet moment for optimization for deep learning. I am extremely happy. An email from 2021. https://t.co/iARx990Ji1" / X</A>
									<DT><A HREF="https://rosanneliu.com/dlctfs/dlct_210312.pdf">Scalable Second Order Optimization for Deep Learning</A>
									<DT><A HREF="https://mlcommons.org/2024/08/mlc-algoperf-benchmark-competition/">Announcing the results of the inaugural AlgoPerf: Training Algorithms benchmark competition - MLCommons</A>
									<DT><A HREF="https://arxiv.org/abs/2405.18144">[2405.18144] 4-bit Shampoo for Memory-Efficient Network Training</A>
									<DT><A HREF="https://arxiv.org/abs/2309.06497">[2309.06497] A Distributed Data-Parallel PyTorch Implementation of the Distributed Shampoo Optimizer for Training Neural Networks At-Scale</A>
									<DT><A HREF="https://proceedings.mlr.press/v80/gupta18a">Shampoo: Preconditioned Stochastic Tensor Optimization</A>
									<DT><A HREF="https://arxiv.org/abs/1910.02054">[1910.02054] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</A>
									<DT><A HREF="https://arxiv.org/abs/1909.08053">[1909.08053] Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</A>
									<DT><A HREF="https://x.com/ShamKakade6/status/1836476197968187778">ShampoO with Adam in Preconditioner</A>
								</DL><p>
								<DT><H3 FOLDED>Lion</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/automl/tree/master/lion#language-modeling">Google AutoML: Lion Optimizer over Adam</A>
								</DL><p>
								<DT><H3 FOLDED>Sophia</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/tengyuma/status/1714708089205912004">Sophia</A>
									<DT><A HREF="https://github.com/Liuhong99/Sophia#tuning-the-hyperparameter-rho">Sophia: The official implementation of ‚ÄúSophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training‚Äù</A>
									<DT><A HREF="https://arxiv.org/abs/2305.14342">[2305.14342] Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training</A>
								</DL><p>
								<DT><H3 FOLDED>ADOPT</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2411.02853">[2411.02853] ADOPT: Modified Adam Can Converge with Any $Œ≤_2$ with the Optimal Rate</A>
									<DT><A HREF="https://github.com/iShohei220/adopt">iShohei220/adopt: Official Implementation of "ADOPT: Modified Adam Can Converge with Any Œ≤2 with the Optimal Rate"</A>
									<DT><A HREF="https://x.com/ishohei220/status/1859785311808876998">(1) Shohei Taniguchi en X: "**Update on the ADOPT optimizer** To address several reports that ADOPT sometimes gets unstable, a minor modification has been made to the algorithm. We observe that this modification greatly improves stability in many cases. https://t.co/dHuo4Z2GMz" / X</A>
									<DT><A HREF="https://x.com/torchcompiled/status/1865556474501714193">Adam, LaProp &amp; ADOPT updates differences made simple</A>
								</DL><p>
								<DT><H3 FOLDED>MARS</H3>
								<DL><p>
									<DT><A HREF="https://x.com/QuanquanGu/status/1858602326434738621">(2) Quanquan Gu en X: "Today‚Äôs the day to launch! Introducing MARS (Make vAriance Reduction Shine): the ultimate LLM optimizer. Let‚Äôs unite, innovate, and take our shot at MARS! üöÄüöÄüöÄ Paper: https://t.co/cjTGJV5yCR Code: https://t.co/azBai8UnSd https://t.co/XrJ9ucjMe1" / X</A>
									<DT><A HREF="https://arxiv.org/pdf/2411.10438">MARS: Unleashing the Power of Variance Reduction for Training Large Models</A>
									<DT><A HREF="https://github.com/AGI-Arena/MARS">AGI-Arena/MARS: The official implementation of MARS: Unleashing the Power of Variance Reduction for Training Large Models</A>
								</DL><p>
								<DT><H3 FOLDED>SOAP</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ethansmith2000/fsdp_optimizers/blob/main/soap.py">fsdp_optimizers/soap.py at main ¬∑ ethansmith2000/fsdp_optimizers</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=5exL8UYxpsI&t=63s">IFML SEMINAR: 1/26/24 - Meta Optimization (Google DeepMind)</A>
								<DT><A HREF="https://arxiv.org/pdf/1510.01799.pdf">efficient technique for computing the norm of the gradient of the loss function for a neural network with respect to its parameters</A>
								<DT><A HREF="https://arxiv.org/abs/2308.01814">[2308.01814] Tensor Programs IVb: Adaptive Optimization in the Infinite-Width Limit</A>
								<DT><A HREF="https://twitter.com/Guodzh/status/1489371872777191437/photo/1">Aggressive learning rate</A>
								<DT><A HREF="https://twitter.com/sytelus/status/1713462676838588565">loss scaling FP16 training</A>
								<DT><A HREF="https://twitter.com/zacharynado/status/1729582361115848789">training algorithm* that is faster** than Adam**</A>
								<DT><A HREF="https://arxiv.org/abs/2310.18313">[2310.18313] FP8-LM: Training FP8 Large Language Models</A>
								<DT><A HREF="https://nn.labml.ai/optimizers/index.html">Optimizers</A>
								<DT><A HREF="https://github.com/SonicCodes/hyperada">SonicCodes/hyperada: Linear hypernetwork ada</A>
								<DT><A HREF="https://github.com/apple/ml-ademamix">apple/ml-ademamix</A>
								<DT><A HREF="https://x.com/jxbz/status/1922365878168895999">(1) Jeremy Bernstein en X: "I was really grateful to have the chance to speak at @Cohere_Labs and @ml_collective last week. My goal was to make the most helpful talk that I could have seen as a first-year grad student interested in neural network optimization. Sharing some info about the talk here... (1/6) https://t.co/VXArQTaFpK" / X</A>
								<DT><A HREF="https://docs.google.com/presentation/d/1PIAChMGGwhmdUxDPyOo1o8Qlhq3h_ofV2mhBb6JHH04/edit?slide=id.g313117c0c90_0_5#slide=id.g313117c0c90_0_5">depths-of-first-order-optimization - Google Slides (2025)</A>
								<DT><A HREF="https://x.com/bozavlado/status/1944733628023407056">SGD alone, small batch size</A>
							</DL><p>
							<DT><H3 FOLDED>training-hyperparameters</H3>
							<DL><p>
								<DT><H3 FOLDED>hyperparameter-tuning</H3>
								<DL><p>
									<DT><H3 FOLDED>CARBS</H3>
									<DL><p>
										<DT><A HREF="https://imbue.com/research/70b-intro/">Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings - imbue</A>
									</DL><p>
									<DT><A HREF="https://x.com/jsuarez5341/status/1937192462486769950">(1) Joseph Suarez (e/üê°) en X: "Hyperparameter Tuning that Works: Protein is our brand new sweep algorithm. It's a heavily modified version of ImbueAI's CARBS that has set SOTA out-of-the-box for multiple clients. Blog post later this week! https://t.co/rZtneEqjMP" / X</A>
								</DL><p>
								<DT><H3 FOLDED>mup</H3>
								<DL><p>
									<DT><H3 FOLDED>ezmup</H3>
									<DL><p>
										<DT><A HREF="https://github.com/cloneofsimo/ezmup">cloneofsimo/ezmup: Simple implementation of muP, based on Spectral Condition for Feature Learning</A>
									</DL><p>
									<DT><H3 FOLDED>mup-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/cloneofsimo/min-max-gpt/blob/7b017b8a0680e8eec6328c7ea3edfca7592107e0/tweakablegpt.py#L53">tweakablegpt.py#L53 (Simo)</A>
										<DT><A HREF="https://github.com/huggingface/nanotron/blob/03d67f2103d5be0dc15ea6022a6cf16d6a633064/examples/mup/README.md">nanotron/examples/mup/README.md at 03d67f2103d5be0dc15ea6022a6cf16d6a633064 ¬∑ huggingface/nanotron</A>
										<DT><A HREF="https://wandb.ai/neuralink/exp14_mup_grid_search/reports/-Spectral-Transfer-MLP-s-Experiment-Results--Vmlldzo3NDQ0NTQw?accessToken=xe0mkunx3y8t0xzbzxu9caqcre57or5la58d9o209hinanlmzoaj7es24m4elvdj">[Spectral ¬µTransfer] MLP's Experiment Results | exp14_mup_grid_search ‚Äì Weights &amp; Biases</A>
										<DT><A HREF="https://graphcore-research.github.io/posts/how-to-scale/">Scale-preserving nonlinearities for u-ŒºP - Graphcore Research Blog</A>
									</DL><p>
									<DT><H3 FOLDED>mup-implementation</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Laz4rz/mup">Laz4rz/mup: Minimal (truly) muP implementation, consistent with TP4 and TP5 papers notation</A>
									</DL><p>
									<DT><A HREF="https://kexue.fm/archives/10795">È´òÈò∂muPÔºöÊõ¥ÁÆÄÊòé‰ΩÜÊõ¥È´òÊòéÁöÑË∞±Êù°‰ª∂Áº©Êîæ - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://www.microsoft.com/en-us/research/blog/%C2%B5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/">¬µtransfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks</A>
									<DT><A HREF="https://www.youtube.com/watch?v=1aXOXHA7Jcw&t=3032s">Greg Yang | Large N Limits: Random Matrices &amp; Neural Networks</A>
									<DT><A HREF="https://arxiv.org/abs/2203.03466">[2203.03466] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer</A>
									<DT><A HREF="https://twitter.com/cloneofsimo/status/1741381460274331916">muP is effective weight init scheme everyone should use. With ezmup 3 LOC is all you need+ it's model agnostic (Simo)</A>
									<DT><A HREF="https://arxiv.org/abs/2305.19268">[2305.19268] Intriguing Properties of Quantization at Scale (Emergent LLM properties &gt; 6B)</A>
									<DT><A HREF="https://github.com/microsoft/mup">mup</A>
									<DT><A HREF="https://decentdescent.org/tp5.html">Tuning GPT-3 on a Single GPU</A>
									<DT><A HREF="https://github.com/cloneofsimo/ezmup">cloneofsimo/ezmup: Simple implementation of muP, based on Spectral Condition for Feature Learning</A>
									<DT><A HREF="https://www.youtube.com/watch?v=z8-C42mAwBc">ŒºTransfer</A>
									<DT><A HREF="https://blog.speechmatics.com/mup">Reduce Model Tuning Costs with MuP</A>
									<DT><A HREF="https://x.com/CerebrasSystems/status/1796578819400442033">(1) Cerebras en X: "(1/n) Paper drop: https://t.co/fcr3Jr2ckD TLDR: We introduce the sparse maximal update parameterization (SŒºPar), which ensures optimal HPs remain the same for any width or sparsity level. This dramatically reduces HP tuning costs, allowing SŒºPar to achieve superior losses. üßµ üëá https://t.co/K0sY4kOKVT" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2405.15743">[2405.15743] Sparse maximal update parameterization: A holistic approach to sparse training dynamics</A>
									<DT><A HREF="https://x.com/andrewgwils/status/1800532164418867245">Andrew Gordon Wilson en X: "Another major barrier is hypers -- initializations, LR, etc. You could easily try a new structure and not realize why it fails. The naive hypers just don‚Äôt work. But adapting the great work of @TheGregYang on muP to structure-aware initialization, we achieve exciting results! 4/8 https://t.co/NucLouwFIF" / X</A>
									<DT><A HREF="https://github.com/imbue-ai/carbs">imbue-ai/carbs: Cost aware hyperparameter tuning algorithm</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XpU3mDKJOak">Greg Yang - "Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer" - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=DuBQCBWcq4M&t=340s">Greg Yang ‚Äî Feature Learning in Infinite-Width Neural Networks - YouTube</A>
									<DT><A HREF="https://jeremybernste.in/modula/bad-scaling/">Bad scaling - Modula documentation</A>
									<DT><A HREF="https://jeremybernste.in/modula/golden-rules/">Golden rules for scaling - Modula documentation</A>
									<DT><A HREF="https://graphcore-research.github.io/posts/how-to-scale/">Scale-preserving nonlinearities for u-ŒºP - Graphcore Research Blog</A>
									<DT><A HREF="https://arxiv.org/abs/2407.17465">[2407.17465] u-$Œº$P: The Unit-Scaled Maximal Update Parametrization</A>
									<DT><A HREF="https://blog.eleuther.ai/mutransfer/">The Practitioner's Guide to the Maximal Update Parameterization | EleutherAI Blog</A>
									<DT><A HREF="https://x.com/edwardjhu">(1) Edward Hu (@edwardjhu) / X</A>
									<DT><A HREF="https://x.com/DeyNolan/status/1919769658355306860">CompleteP: Depth-wise hyperparameter transfer, compute-efficient width/depth</A>
									<DT><A HREF="https://x.com/___Harald___/status/1919438867666473453">(2) Harald Sch√§fer en X: "Our models at @comma_ai have always been open-source. But now we're also publishing all the loss graphs, metrics, and reports. You can now see everything we do when evaluating the quality of a driving model! https://t.co/NafwwIZq5W" / X</A>
									<DT><A HREF="https://x.com/JingyuanLiu123/status/1945748264084779515">(1) JingyuanLiu en X: "This is so funny, even inside Greg's personal website, he recommends reading the spectral condition instead of the whole Tensor Program series lol My personal learning experience is to learn from Su's blog: https://t.co/0JW8sIu0xr (it is in Chinese though...) it basically covers https://t.co/fbXwBhaFT7" / X</A>
									<DT><A HREF="https://x.com/cloneofsimo/status/1948797767821980134">ReLU MLP with width / depth going to infinity</A>
									<DT><A HREF="https://x.com/JingyuanLiu123/status/1959666553424855345">(1) JingyuanLiu en X: "XAI got Great Greg, so I believe in their MuP, and generally optimization and spectral norm control recipes. Definitely worth reading into more details! Next, I would hope to see thinky's oss and understand what's in @jxbz 's head now! However, I am generally not a big fan of https://t.co/e5n9klJMgV" / X</A>
									<DT><A HREF="https://kexue.fm/archives/11340">Beyond MuP: 1. The Self-Cultivation of a Good Model</A>
								</DL><p>
								<DT><H3 FOLDED>learning rate</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/Guodzh/status/1489371872777191437">The right moment to decay is always as late as possible</A>
									<DT><A HREF="https://twitter.com/borisdayma/status/1489292077313703939">Impact of learning rate</A>
									<DT><A HREF="https://optax.readthedocs.io/en/latest/api/optimizer_schedules.html#optax.linear_schedule">Optimizer Schedules ‚Äî Optax documentation</A>
									<DT><A HREF="https://gist.github.com/fabianp/4d44c21fca10cd4dc4bc0d27774fd48e">linear_schedule.ipynb</A>
									<DT><A HREF="https://kexue.fm/archives/11260">Rethinking the Relationship Between Learning Rate and Batch Size (Part I)</A>
								</DL><p>
								<DT><H3 FOLDED>clip gradient norm</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>Modula</H3>
								<DL><p>
									<DT><A HREF="https://jeremybernste.in/modula/">Modula is a deep learning framework designed for graceful scaling. Neural networks written in Modula automatically transfer learning rate across scale</A>
									<DT><A HREF="https://x.com/jxbz/status/1851328119539429487">The General Theory of Modular Duality</A>
									<DT><A HREF="https://thinkingmachines.ai/blog/modular-manifolds/">Modular Manifolds - Thinking Machines Lab</A>
									<DT><A HREF="https://gist.github.com/YouJiacheng/393c90cbdc23b09d5688815ba382288b/5bff1f7781cf7d062a155eecd2f13075756482ae">muon coefficients</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=-uyXE7dY5H0">NIPS: Oral Session 4 - Ilya Sutskever  batch_size, learning rate, init scale, norm of gradient is clipped to</A>
								<DT><A HREF="https://twitter.com/cloneofsimo/status/1741381460274331916">muP is effective weight init scheme everyone should use. With ezmup 3 LOC is all you need+ it's model agnostic (Simo)</A>
								<DT><A HREF="https://arxiv.org/abs/2304.05187">[2304.05187] Automatic Gradient Descent: Deep Learning without Hyperparameters</A>
								<DT><A HREF="https://github.com/google-research/tuning_playbook">google-research/tuning_playbook: A playbook for systematically maximizing the performance of deep learning models.</A>
								<DT><A HREF="https://drive.google.com/file/d/1oRI98PnSKFZLIMNTePmRCufuz-F0_aBb/view?usp=sharing">efficient pre/post-training for large language models</A>
							</DL><p>
							<DT><H3 FOLDED>training-scheduler</H3>
							<DL><p>
								<DT><A HREF="https://x.com/_clashluke/status/1813911399049089437/photo/2">Accelerated FusedSMA RMSProp</A>
								<DT><A HREF="https://github.com/ClashLuke/schedule_free">ClashLuke/schedule_free: Schedule-Free Optimization in PyTorch</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-training-profiling</H3>
							<DL><p>
								<DT><A HREF="https://github.com/bigcode-project/bigcode-analysis/blob/main/multi_query_experiments/attention_types_imp.py">BigCode: Experiment analysis and profiling. Attention Types</A>
								<DT><A HREF="https://mlcommons.org/en/">MLCommons</A>
								<DT><A HREF="https://gist.github.com/jboner/2841832">Latency Numbers Every Programmer Should Know</A>
							</DL><p>
							<DT><H3 FOLDED>training-multilingual</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2205.06266.pdf">Lifting the Curse of Multilinguality by Pre-training Modular Transformers</A>
								<DT><A HREF="https://twitter.com/PfeiffJo/status/1525009949478330368">Lifting the Curse of Miltilinguality by Pre-training Modular Transformers</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ghL31wWlpFY">Massively Multilingual Shallow Fusion with Large Language Model</A>
								<DT><A HREF="https://arxiv.org/abs/2304.09151">[2304.09151] UniMax (mT5)</A>
								<DT><A HREF="https://arxiv.org/abs/2010.11934">[2010.11934] mT5: A massively multilingual pre-trained text-to-text transformer</A>
								<DT><A HREF="https://twitter.com/LucasBandarkar/status/1697650503726125294">Bebele: multilingual capabilities of LLMs</A>
								<DT><A HREF="https://unbabel.com/announcing-tower-an-open-multilingual-llm-for-translation-related-tasks/?utm_campaign=Tower%20Announcement&utm_content=278163588&utm_medium=social&utm_source=linkedin&hss_channel=lcp-3327165">Tower : An Open Multilingual LLM for Translation-Related Tasks</A>
								<DT><A HREF="https://www.microsoft.com/en-us/research/project/llmlingua/">LLMLingua - Microsoft Research</A>
								<DT><A HREF="https://twitter.com/arankomatsuzaki/status/1742369432091976085">Llama Beyond English: An Empirical Study on Language Capability</A>
								<DT><A HREF="https://www.youtube.com/watch?v=f1ZayIAz210">NeurIPS 2023 Oral 2A Efficient Learning - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-training-lectures</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=k_HMgpJKBso">LLaMA 2 w/ Thomas Scialom (LLaMA 2 lead) - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=5RUOrXl3nag&list=PLBoQnSflObcltw2wSTV1UYMkSgyrRcjcb">OPT-175B: Open Pretrained Transformer</A>
								<DT><A HREF="https://www.youtube.com/watch?v=g0gREwiDbis">Neural Networks Efficient Training Fundamentals</A>
								<DT><A HREF="https://www.youtube.com/watch?v=DK-QXsiycpk&list=PLBoQnSflObcltw2wSTV1UYMkSgyrRcjcb&index=2">GPT-NeoX-20B | BigScience BLOOM</A>
								<DT><A HREF="https://www.youtube.com/watch?v=hc0u4avAkuM&list=PLBoQnSflObcltw2wSTV1UYMkSgyrRcjcb&index=3">Megatron-LM | ZeRO | DeepSpeed | Mixed Precision</A>
								<DT><A HREF="https://www.youtube.com/watch?v=pTChDs5uD8I&list=PLBoQnSflObcltw2wSTV1UYMkSgyrRcjcb&index=4">BigScience BLOOM | 3D Parallelism</A>
								<DT><A HREF="https://www.youtube.com/watch?v=iJ0IVZgGjTM&list=PLBoQnSflObcltw2wSTV1UYMkSgyrRcjcb&index=5">T0: Multitask Prompted Training Enables</A>
								<DT><A HREF="https://www.youtube.com/watch?v=CAbHbm9769Q">Hugging Face: Accelerating Transformers in Production</A>
								<DT><A HREF="https://www.youtube.com/watch?v=jyOqtw4ry2w">8-bit Methods for Efficient Deep Learning with Tim Dettmers</A>
								<DT><A HREF="https://www.youtube.com/watch?v=B3Az2EONCHE">Large Language Models - Michael Douglas</A>
								<DT><A HREF="https://www.youtube.com/watch?v=R_o6nUC1Nzo&list=PLgKuh-lKre11GbZWneln-VZDLHyejO7YD&index=14">Tutorial on Deep Learning II - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=b1c1yh6I594">Math Reading Group - Neural Tangent Kernels (07/05/23)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=XfpMkf4rD6E">Transformers United 2023: Introduction to Transformers</A>
								<DT><A HREF="https://www.youtube.com/watch?v=tfWPCeyh77k">Lessons from scale for large language models</A>
								<DT><A HREF="https://www.youtube.com/watch?v=bZQun8Y4L2A&t=723s">State of GPT | BRK216HFS - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=nUSvsLLlz9U">Tesla CVPR2023 Workshop - YouTube (Data Engine)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=DHjwbleAgPQ">Why do Neural Networks use Linear Algebra?</A>
								<DT><A HREF="https://www.youtube.com/watch?v=tndPB8z98Zg">Machine Learning and Theory Calculations</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ytbYRIN0N4g">Softmax Function Explained In Depth with 3D Visuals</A>
								<DT><A HREF="https://www.youtube.com/watch?v=DZoICV92VGE">The Magic Behind QLORA: Efficient Finetuning of Quantized LLMs</A>
								<DT><A HREF="https://www.youtube.com/watch?v=0QczhVg5HaI&t=558s">Why Neural Networks can learn (almost) anything</A>
								<DT><A HREF="https://www.youtube.com/watch?v=j4yz1k3Ueso">The Power of Symmetry III</A>
								<DT><A HREF="https://www.youtube.com/watch?v=SGInyKjzF7A">Optimizing Large Language Models with Reinforcement Learning</A>
								<DT><A HREF="https://www.youtube.com/watch?v=2Zi6wFQQl3E">Generalization bounds for Neural Network Based Decoders</A>
								<DT><A HREF="https://www.youtube.com/watch?v=g0gREwiDbis">SLXCA 2021 featuring Dr. Geoffrey Hinton &amp; Jennifer Smith</A>
							</DL><p>
							<DT><H3 FOLDED>mixed-precision-training</H3>
							<DL><p>
								<DT><H3 FOLDED>qat</H3>
								<DL><p>
									<DT><H3 FOLDED>fp8-training</H3>
									<DL><p>
										<DT><H3 FOLDED>fp8-training-coat</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVlabs/COAT">NVlabs/COAT: Compressing Optimizer states and Activations for Memory-Efficient FP8 training</A>
											<DT><A HREF="https://arxiv.org/abs/2410.19313">[2410.19313] COAT: Compressing Optimizer states and Activation for Memory-Efficient FP8 Training</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2309.17224">(Graphcore) Training and inference of LLMs using FP8</A>
										<DT><A HREF="https://arxiv.org/abs/2310.18313">[2310.18313] FP8-LM: Training FP8 Large Language Models</A>
										<DT><A HREF="https://github.com/graphcore-research/out-of-the-box-fp8-training/blob/main/out_of_the_box_fp8_training.ipynb">out-of-the-box-fp8-training/out_of_the_box_fp8_training.ipynb at main ¬∑ graphcore-research/out-of-the-box-fp8-training</A>
										<DT><A HREF="https://x.com/papers_anon/status/1836953617602887910?s=12">Scaling FP8 training to trillion-token LLMs</A>
										<DT><A HREF="https://arxiv.org/abs/2502.05967">[2502.05967] $Œº$nit Scaling: Simple and Scalable FP8 LLM Training</A>
										<DT><A HREF="https://x.com/davisblalock/status/1939956579698094166">fp8 training, hyperparameter transfer, training stability, and more.</A>
									</DL><p>
									<DT><H3 FOLDED>fp4-training</H3>
									<DL><p>
										<DT><A HREF="https://www.arxiv.org/abs/2509.25149">[2509.25149] Pretraining Large Language Models with NVFP4</A>
										<DT><A HREF="https://www.radicalnumerics.ai/blog/nvfp4-part1">NVFP4 Pretraining: From Theory to Implementation (Part 1) ¬∑ Radical Numerics</A>
										<DT><A HREF="https://www.radicalnumerics.ai/blog/nvfp4-part2">NVFP4 Pretraining: Systems Optimizations (Part 2) ¬∑ Radical Numerics</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>amp-dtypes</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2209.05433">[2209.05433] FP8 Formats for Deep Learning</A>
									<DT><A HREF="https://github.com/P3109/Public/blob/main/Value%20Tables/make-value-tables.ipynb">P3109 - Arithmetic Formats for Machine Learning</A>
									<DT><A HREF="https://github.com/P3109/Public/blob/main/Shared%20Reports/P3109%20WG%20Interim%20Report.pdf">8-bit formats</A>
									<DT><A HREF="https://axil.github.io/a-comprehensive-guide-to-numpy-data-types.html">A Comprehensive Guide to NumPy Data Types</A>
									<DT><A HREF="https://github.com/google/jaxtyping">google/jaxtyping: Type annotations and runtime checking for shape and dtype of JAX/NumPy/PyTorch/etc. arrays.</A>
								</DL><p>
								<DT><H3 FOLDED>quantization-aware-training</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2505.14302">Scaling Law for Quantization-Aware Training</A>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/">Stable and Scalable FP8 Deep Learning Training on Blackwell S72778 | GTC 2025 | NVIDIA On-Demand</A>
								</DL><p>
								<DT><H3 FOLDED>MS-AMP</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Azure/MS-AMP">Azure/MS-AMP: Microsoft Automatic Mixed Precision Library</A>
								</DL><p>
								<DT><A HREF="https://github.com/tspeterkim/mixed-precision-from-scratch">tspeterkim/mixed-precision-from-scratch: Mixed precision training from scratch with Tensors and CUDA</A>
								<DT><A HREF="https://arxiv.org/pdf/1710.03740.pdf">MIXED PRECISION TRAINING</A>
								<DT><A HREF="https://tspeterkim.github.io/posts/mixed-precision-from-scratch">Mixed Precision Training from Scratch | Taeksang Peter Kim</A>
								<DT><A HREF="https://arxiv.org/abs/2310.10537">[2310.10537] Microscaling Data Formats for Deep Learning</A>
								<DT><A HREF="https://azure.github.io/MS-AMP/">MS-AMP Documentation | MS-AMP</A>
								<DT><A HREF="https://twitter.com/sytelus/status/1713462676838588565">loss scaling FP16 training (training stability)</A>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/performance/mixed-precision-training/index.html">NVIDIA: Train With Mixed Precision</A>
								<DT><A HREF="https://arxiv.org/abs/2310.10537">language models at sub-8-bit weights, activations, and gradients</A>
								<DT><A HREF="https://arxiv.org/abs/1905.12322">[1905.12322] A Study of BFLOAT16 for Deep Learning Training</A>
								<DT><A HREF="https://github.com/P3109/Public/blob/main/Briefs/Discusson%20on%20Rounding.pdf">Public/Briefs/Discusson on Rounding.pdf</A>
								<DT><A HREF="https://www.youtube.com/watch?v=xnBDg0lYQdU">Weekly AI paper overview- 6/18/24 - YouTube</A>
								<DT><A HREF="https://github.com/pytorch/ao/tree/v0.5.0/torchao/prototype/quantized_training">torchao: Quantized training</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1834221330390290807">NVIDIA doesn't want you to know this one trick: train ML models with INT8 Tensor Coresü§Ø
Up to 70% end2end speedup on 1x 4090 and 40% speedup on 1x A100 with 4 lines of code. No noticeable accuracy loss.</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/441591808">The most comprehensive mixed precision training principle on the entire network</A>
							</DL><p>
							<DT><H3 FOLDED>sparse-training</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2310.06927">Sparse Fine-tuning for Inference Acceleration of Large Language Models</A>
								<DT><A HREF="https://huggingface.co/collections/neuralmagic/sparse-finetuning-mpt-65241d875b29204d6d42697d">Sparse Finetuning MPT - a neuralmagic Collection</A>
							</DL><p>
							<DT><H3 FOLDED>pre-training</H3>
							<DL><p>
								<DT><H3 FOLDED>pre-training-data</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Sauers_/status/1937583905051173323">Anthropic prepretraining pipeline</A>
									<DT><A HREF="https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0.pdf">https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.231.0.pdf</A>
								</DL><p>
								<DT><H3 FOLDED>RLPT</H3>
								<DL><p>
									<DT><A HREF="https://apaz.dev/blog/Thoughts_About_Entropy_and_Objectives.html">Thoughts About Entropy and Objectives</A>
									<DT><A HREF="https://arxiv.org/abs/2512.03442">[2512.03442] PretrainZero: Reinforcement Active Pretraining</A>
									<DT><A HREF="https://arxiv.org/abs/2506.08007">[2506.08007] Reinforcement Pre-Training</A>
									<DT><A HREF="https://arxiv.org/abs/2510.01265">[2510.01265] RLP: Reinforcement as a Pretraining Objective</A>
									<DT><A HREF="https://arxiv.org/abs/2509.19249">[2509.19249] Reinforcement Learning on Pre-Training Data</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>mid-training</H3>
							<DL><p>
								<DT><A HREF="https://x.com/_jasonwei/status/1923091260354531612">(1) Jason Wei en X: "AlphaEvolve is deeply disturbing for RL diehards like yours truly Maybe midtrain + good search is all you need for AI for scientific innovation And what an alpha move to keep it secret for a year Congrats big G" / X</A>
								<DT><A HREF="https://x.com/iScienceLuvr/status/1938179978732196075">OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling</A>
								<DT><A HREF="https://x.com/HuggingPapers/status/1951192388770181575">midtraining-math-reasoning</A>
							</DL><p>
							<DT><H3 FOLDED>post-training</H3>
							<DL><p>
								<DT><H3 FOLDED>language-rl</H3>
								<DL><p>
									<DT><H3 FOLDED>language-models-rl-lectures</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=SGInyKjzF7A">Optimizing Large Language Models with Reinforcement Learning</A>
										<DT><A HREF="https://www.youtube.com/watch?v=dbo3kNKPaUA">Large Language Models (in 2023)</A>
										<DT><A HREF="https://www.youtube.com/watch?v=zjrM-MW-0y0&t=5s">Instruction finetuning and RLHF lecture (NYU CSCI 2590)</A>
										<DT><A HREF="https://www.youtube.com/playlist?list=PL_vLws1T4Nx1LSx7bXag7mc2IZIgcY6We">RL for LLM from Scratch with 1 GPU - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=OkEGJ5G3foU">[Full Workshop] Reinforcement Learning, Kernels, Reasoning, Quantization &amp; Agents ‚Äî Daniel Han - YouTube</A>
										<DT><A HREF="https://x.com/willccbb/status/1998087040999837988">entropy collapse that trades pass@N for pass@1</A>
									</DL><p>
									<DT><H3 FOLDED>veRL</H3>
									<DL><p>
										<DT><H3 FOLDED>sglang-verl</H3>
										<DL><p>
											<DT><H3 FOLDED>rl-multi-turn</H3>
											<DL><p>
												<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md">Awesome-ML-SYS-Tutorial/rlhf/verl/multi-turn/verl-multiturn-rollout-Release.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
											</DL><p>
											<DT><H3 FOLDED>AgentLoop</H3>
											<DL><p>
												<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/agent-loop/agentLoop_EN.md">Awesome-ML-SYS-Tutorial/rlhf/verl/agent-loop/agentLoop_EN.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
											</DL><p>
											<DT><H3 FOLDED>sglang-verl-multi-turn-profiling</H3>
											<DL><p>
												<DT><A HREF="https://www.linkedin.com/pulse/systemic-profiling-time-consumption-multi-turn-agent-rl-chenyang-zhao-yphfe/">Systemic Profiling of Time Consumption in Multi-Turn Agent RL | LinkedIn</A>
											</DL><p>
											<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/issues/74">veRL-SGLang Roadmap ¬∑ Issue #74 ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
											<DT><A HREF="https://verl.readthedocs.io/en/latest/workers/sglang_worker.html">SGLang Backend ‚Äî verl documentation</A>
											<DT><A HREF="https://www.linkedin.com/pulse/sglang-verl-openbmb-tsinghua-university-pioneering-end-to-end-zhao-mb6ce/">(1) SGLang, verl, OpenBMB and Tsinghua University: Pioneering End-to-End Multi-Turn RLHF | LinkedIn</A>
										</DL><p>
										<DT><H3 FOLDED>verl.single_controller</H3>
										<DL><p>
											<DT><A HREF="https://verl.readthedocs.io/en/latest/single_controller.html">The Design of verl.single_controller ‚Äî verl documentation</A>
										</DL><p>
										<DT><H3 FOLDED>verl-retool</H3>
										<DL><p>
											<DT><A HREF="https://github.com/volcengine/verl/blob/main/recipe/retool/README.md">ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</A>
										</DL><p>
										<DT><H3 FOLDED>verl-coding-agent</H3>
										<DL><p>
											<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:share:7386653121529372672/">Du LiDu Li LLM Systems @ ByteDance Seed</A>
											<DT><A HREF="https://lightning.ai/lightning-ai/environments/training-a-coding-agent-with-verl?section=featured">Training a Coding Agent with veRL</A>
										</DL><p>
										<DT><A HREF="https://github.com/volcengine/verl">volcengine/verl: verl: Volcano Engine Reinforcement Learning for LLMs</A>
										<DT><A HREF="https://x.com/tbpn/status/1931054774415495415">"RL is a more naively parallelizable and scalable than pre-training."</A>
										<DT><A HREF="https://github.com/tensorzero/tensorzero?tab=readme-ov-file">tensorzero/tensorzero: TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.</A>
										<DT><A HREF="https://www.youtube.com/watch?v=fct7Jd8-bW8&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=3">verl: An Open Source Large Scale LLM RL Framework for Agentic Tasks - Yuxuan Tong, Bytedance - YouTube</A>
										<DT><A HREF="https://www.linkedin.com/pulse/rl-system-deep-thinking-weight-update-mechanisms-chenyang-zhao-g1are/">RL System Deep Thinking: Weight Update Mechanisms | LinkedIn</A>
										<DT><A HREF="https://x.com/verl_project/status/1920656559237198140">veRL FSDP2</A>
										<DT><A HREF="https://github.com/ISEEKYAN/verl_megatron_practice">ISEEKYAN/verl_megatron_practice: (best/better) practices of megatron on veRL and tuning guide</A>
										<DT><A HREF="https://gist.github.com/ezyang/48dce330ed0504b5dba3eaf54ec42864">verl example</A>
									</DL><p>
									<DT><H3 FOLDED>Miles</H3>
									<DL><p>
										<DT><H3 FOLDED>Slime</H3>
										<DL><p>
											<DT><H3 FOLDED>slime-docs</H3>
											<DL><p>
												<DT><H3 FOLDED>slime-code-walk-through</H3>
												<DL><p>
													<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/slime/code-walk-through/readme_en.md">Awesome-ML-SYS-Tutorial/rlhf/slime/code-walk-through/readme_en.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
												</DL><p>
												<DT><A HREF="https://zhuanlan.zhihu.com/p/1921606246454239436">In-depth analysis of the Slime framework: Integrated training and inference practices for large-scale RL</A>
											</DL><p>
											<DT><H3 FOLDED>slime-release</H3>
											<DL><p>
												<DT><A HREF="https://zhuanlan.zhihu.com/p/1945237948166547268">slime v0.1.0: Redefining the high-performance RL training framework</A>
												<DT><A HREF="https://github.com/THUDM/slime/releases/tag/v0.1.0">Release v0.1.0 ¬∑ THUDM/slime</A>
											</DL><p>
											<DT><H3 FOLDED>slime-retool</H3>
											<DL><p>
												<DT><A HREF="https://github.com/THUDM/slime/tree/main/examples/retool">slime/examples/retool at main ¬∑ THUDM/slime</A>
											</DL><p>
											<DT><H3 FOLDED>slime-multi-node</H3>
											<DL><p>
												<DT><A HREF="https://github.com/THUDM/slime/blob/main/scripts/run-qwen3-235B-A22B.sh">slime/scripts/run-qwen3-235B-A22B.sh at main ¬∑ THUDM/slime</A>
											</DL><p>
											<DT><H3 FOLDED>slime-memory</H3>
											<DL><p>
												<DT><A HREF="https://hebiao064.github.io/rl-weight-sync">Efficient RL Training - Optimizing Weight Sync in slime ¬∑ Biao's Blog</A>
												<DT><A HREF="https://github.com/THUDM/slime/issues/132">[perf] Weight Sync Optimization in Colocate Mode ¬∑ Issue #132 ¬∑ THUDM/slime</A>
												<DT><A HREF="https://www.linkedin.com/pulse/optimizing-large-scale-rl-sglang-huapeng-zhou-vphnc/?trackingId=wwSlzlv0SQSv9RhP0yfcEw%3D%3D">(2) Optimizing Large-Scale RL with SGLang | LinkedIn</A>
											</DL><p>
											<DT><H3 FOLDED>slime-b200</H3>
											<DL><p>
												<DT><A HREF="https://wcnlmhu0029w.feishu.cn/wiki/HiygwCjzJiL2wNkelW4cU1KZnCb">b200 slime sftÂØπÊØî - Feishu Docs</A>
												<DT><A HREF="https://github.com/THUDM/slime/commit/b7938c83f6eea589d327c2327a899656c800521c#diff-d52c5f0d40292afde43fe19ce0a5eb3c23544ec776d99f37e771eb48d2c7bef7">add dockerfile and patch for b200 (#340) ¬∑ THUDM/slime@b7938c8</A>
												<DT><A HREF="https://lmsys.org/blog/2025-11-24-fp8-rl/">Unified FP8: Moving Beyond Mixed Precision for Stable and Accelerated MoE RL | LMSYS Org</A>
											</DL><p>
											<DT><H3 FOLDED>slime-speculative-decoding</H3>
											<DL><p>
												<DT><A HREF="https://jiajunli-guapisolo.notion.site/Power-Up-Speculative-Decoding-In-Reinforcement-Learning-2ae2d24a293b80918847e99c6804ae52">Power Up Speculative Decoding In Reinforcement Learning</A>
											</DL><p>
											<DT><H3 FOLDED>slime-checkpoint</H3>
											<DL><p>
												<DT><A HREF="https://github.com/THUDM/slime/pull/677">[FSDP] Migrate FSDP Checkpointing to PyTorch Distributed Checkpoint by Hecate0821 ¬∑ Pull Request #677 ¬∑ THUDM/slime</A>
											</DL><p>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/1921606246454239436">Slime Ê°ÜÊû∂Ê∑±Â∫¶Ëß£ÊûêÔºöÈù¢ÂêëÂ§ßËßÑÊ®°RLÁöÑËÆ≠Êé®‰∏Ä‰ΩìÂåñÂÆûË∑µ - Áü•‰πé</A>
											<DT><A HREF="https://github.com/THUDM/slime">THUDM/slime: slime is a LLM post-training framework aiming at scaling RL.</A>
											<DT><A HREF="https://github.com/THUDM/slime/pull/82/files">Tiny add assertion to avoid Megatron error by fzyzcjy ¬∑ Pull Request #82 ¬∑ THUDM/slime</A>
											<DT><A HREF="https://github.com/search?q=repo%3ATHUDM%2Fslime%20glm&type=code">GLM 4.5 slime</A>
											<DT><A HREF="https://github.com/THUDM/slime/blob/main/docs/en/quick_start.md">slime/docs/en/quick_start.md at main ¬∑ THUDM/slime</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/1948441967211030335">Slime's training and recommendation separation parameter update</A>
											<DT><A HREF="https://le.qun.ch/en/blog/2025/09/07/rl-weight-transfer/">Journey to 2-second Inter-node RL Weight Transfer</A>
											<DT><A HREF="https://x.com/tugot17/status/1989983826886697374/photo/1">composer training infra</A>
											<DT><A HREF="https://lmsys.org/blog/2025-11-24-fp8-rl/">Unified FP8: Moving Beyond Mixed Precision for Stable and Accelerated MoE RL | LMSYS Org</A>
											<DT><A HREF="https://github.com/THUDM/slime/tree/main/examples/true_on_policy">slime/examples/true_on_policy at main ¬∑ THUDM/slime</A>
											<DT><A HREF="https://x.com/slime_framework/status/2012751019495792655?s=12">(1) slime en X: "slime v0.2.2 is out! This release brings multiple memory + performance optimizations, plus major new capabilities: ‚Ä¢ Int4-QAT training ‚Ä¢ Full R3 (Rollout Routing Replay) support with DeepEP + MTP ‚Ä¢ Upgraded to SGLang v0.5.7 and Megatron dev branch Huge thanks to everyone who" / X</A>
										</DL><p>
										<DT><H3 FOLDED>miles-int4-qat</H3>
										<DL><p>
											<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/slime/int4/readme-en.md">Awesome-ML-SYS-Tutorial/rlhf/slime/int4/readme-en.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
											<DT><A HREF="https://x.com/slime_framework/status/2012751019495792655?s=12">(1) slime en X: "slime v0.2.2 is out! This release brings multiple memory + performance optimizations, plus major new capabilities: ‚Ä¢ Int4-QAT training ‚Ä¢ Full R3 (Rollout Routing Replay) support with DeepEP + MTP ‚Ä¢ Upgraded to SGLang v0.5.7 and Megatron dev branch Huge thanks to everyone who" / X</A>
										</DL><p>
										<DT><A HREF="https://lmsys.org/blog/2025-11-19-miles/">Introducing Miles ‚Äî RL Framework To Fire Up Large-Scale MoE Training | LMSYS Org</A>
										<DT><A HREF="https://lmsys.org/blog/2025-11-25-fp8-rl/">Unified FP8: Moving Beyond Mixed Precision for Stable and Accelerated MoE RL | LMSYS Org</A>
										<DT><A HREF="https://x.com/lmsysorg/status/2003249936734028073">(1) LMSYS Org en X: "SGLang + Miles: Rollout Routing Replay (R3) is Now Live! üéâ We're excited to announce that SGLang and Miles now support Rollout Routing Replay (R3) for stable reinforcement learning training on MoE models! Training MoE models with RL has been notoriously unstable, often leading https://t.co/EZL2hjJyfk" / X</A>
										<DT><A HREF="https://github.com/radixark/miles/pull/449">Support speculative information in mock sglang server by fzyzcjy ¬∑ Pull Request #449 ¬∑ radixark/miles</A>
									</DL><p>
									<DT><H3 FOLDED>torchforge</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-pytorch/torchforge">meta-pytorch/torchforge: PyTorch-native post-training at scale</A>
									</DL><p>
									<DT><H3 FOLDED>language-models-rl-one-example</H3>
									<DL><p>
										<DT><H3 FOLDED>Reinforcement Learning for Reasoning in Large anguage Models with One Training Example</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2504.20571">[2504.20571] Reinforcement Learning for Reasoning in Large Language Models with One Training Example</A>
										</DL><p>
										<DT><A HREF="https://x.com/YouJiacheng/status/1917474498477187297">Interesting, even over-fitting ONE problem like this can IMPROVE test performance.</A>
									</DL><p>
									<DT><H3 FOLDED>language-models-self-play</H3>
									<DL><p>
										<DT><H3 FOLDED>Absolute Zero</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2505.03335">[2505.03335] Absolute Zero: Reinforced Self-play Reasoning with Zero Data</A>
											<DT><A HREF="https://x.com/YouJiacheng/status/1920064316793029110">So actually Absolute Zero's r_{propose} satisfies E[r_{propose}] = pass@n - pass@1</A>
											<DT><A HREF="https://x.com/gm8xx8/status/1920011805037826270">(1) ùöêùî™ùüæùö°ùö°ùüæ en X: "Absolute Zero: Reinforced Self-play Reasoning with Zero Data Built on RLVR, AZR self-evolves by proposing and solving code-grounded tasks, no curated data. ùòõùò©ùò¶ ùòÆùò∞ùò•ùò¶ùò≠ ùò±ùò≠ùò¢ùò∫ùò¥ ùò£ùò∞ùòµùò© ùò≥ùò∞ùò≠ùò¶ùò¥: - Proposer: generates tasks to maximize learning progress. - Solver: https://t.co/V2TulSLjmp" / X</A>
										</DL><p>
										<DT><A HREF="https://github.com/spiral-rl/spiral">spiral-rl/spiral: SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning</A>
									</DL><p>
									<DT><H3 FOLDED>GSPO</H3>
									<DL><p>
										<DT><A HREF="https://www.arxiv.org/abs/2507.18071">[2507.18071] Group Sequence Policy Optimization</A>
										<DT><A HREF="https://huggingface.co/papers/2507.18071">Paper page - Group Sequence Policy Optimization</A>
										<DT><A HREF="https://x.com/Alibaba_Qwen/status/1949412072942612873">GSPO: Group Sequence Policy Optimization</A>
										<DT><A HREF="https://x.com/ChujieZheng/status/1948693461512904754">Chujie Zheng: Introducing Group Sequence Policty Optimization</A>
										<DT><A HREF="https://x.com/mgostIH/status/1949413256327725155">They found a bug in a common definition of importance sampling for sequence models</A>
										<DT><A HREF="https://simonxin.com/blogs/llm_reasoning_materials/index.html#section-9">Learn LLMs Only with Good Materials (Reasoning) - Xin Dong</A>
										<DT><A HREF="https://x.com/SimonXinDong/status/1949638757810135137">GSPO is performing the geometric mean --&gt; sequence-level scaling</A>
										<DT><A HREF="https://x.com/semianalysis_/status/2014760411048870102">GSPO treats the whole sequence as an action to match the reward modeling giving rewards at the sequence level. As a result, GSPO computes importance sampling ratio at the token level, then computes a length-normalized importance sampling ratio with a geometric mean. For loss aggregation, GSPO sums across the group.</A>
									</DL><p>
									<DT><H3 FOLDED>DAPO</H3>
									<DL><p>
										<DT><A HREF="https://x.com/semianalysis_/status/2014760411048870102">DAPO computes importance sampling ratio like GRPO. In addition to its many innovations (clip higher, dynamic sampling, etc), DAPO uses token-level policy gradient loss, meaning it averages across all tokens in the group for loss aggregation.</A>
										<DT><A HREF="https://arxiv.org/pdf/2503.14476">DAPO: An Open-Source LLM Reinforcement Learning System at Scale</A>
									</DL><p>
									<DT><H3 FOLDED>ShiQ</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2505.11081">ShiQ: Bringing back Bellman to LLMs</A>
									</DL><p>
									<DT><H3 FOLDED>PPO</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2307.04964">[2307.04964] Secrets of RLHF in Large Language Models Part I: PPO</A>
										<DT><A HREF="https://x.com/_apoorvnandan/status/1866331177067725136">numpy proximal policy optimization implemenation</A>
										<DT><A HREF="https://yugeten.github.io/posts/2025/01/ppogrpo/">A vision researcher‚Äôs guide to some RL stuff: PPO &amp; GRPO - Yuge (Jimmy) Shi</A>
									</DL><p>
									<DT><H3 FOLDED>DPO</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2305.18290.pdf">Direct Preference Optimization (DPO): Your Language Model is Secretly a Reward Model</A>
									</DL><p>
									<DT><H3 FOLDED>RLHF</H3>
									<DL><p>
										<DT><A HREF="https://www.lesswrong.com/posts/vwu4kegAEZTBtpT6p/thoughts-on-the-impact-of-rlhf-research">Thoughts on the impact of RLHF research</A>
										<DT><A HREF="https://www.youtube.com/watch?v=SGInyKjzF7A">Optimizing Large Language Models with Reinforcement Learning</A>
										<DT><A HREF="https://twitter.com/vwxyzjn/status/1716818343133659598">RLHF codebase</A>
										<DT><A HREF="https://www.youtube.com/watch?v=fqC3D-zNJUM">AI Safety, RLHF, and Self-Supervision - Jared Kaplan</A>
										<DT><A HREF="https://twitter.com/_robertkirk/status/1712083230965280784">understanding the effects of RLHF on LLM generalisation</A>
										<DT><A HREF="https://huggingface.co/blog/rlhf">Illustrating Reinforcement Learning from Human Feedback (RLHF)</A>
										<DT><A HREF="https://twitter.com/rm_rafailov/status/1781145338759533016">Language models are not a reward function, but Q func</A>
										<DT><A HREF="https://x.com/natolambert/status/1859643351441535345">Tulu: (1) Nathan Lambert en X: "I've spent the last two years scouring all available resources on RLHF specifically and post training broadly. Today, with the help of a totally cracked team, we bring you the fruits of that labor ‚Äî T√ºlu 3, an entirely open frontier model post training recipe. We beat Llama 3.1 https://t.co/bcJwYk0HVV" / X</A>
									</DL><p>
									<DT><H3 FOLDED>RLVR</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=z3awgfU4yno">The LLM's RL Revelation We Didn't See Coming - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>mindLink</H3>
									<DL><p>
										<DT><A HREF="https://github.com/SkyworkAI/MindLink">SkyworkAI/MindLink</A>
									</DL><p>
									<DT><H3 FOLDED>RL2</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ChenmienTan/RL2">ChenmienTan/RL2</A>
										<DT><A HREF="https://github.com/PrimeIntellect-ai/prime-rl">PrimeIntellect-ai/prime-rl: Decentralized RL Training at Scale</A>
									</DL><p>
									<DT><H3 FOLDED>TreePO</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2508.17445">[2508.17445] TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling</A>
									</DL><p>
									<DT><H3 FOLDED>POLARIS</H3>
									<DL><p>
										<DT><A HREF="https://honorable-payment-890.notion.site/POLARIS-A-POst-training-recipe-for-scaling-reinforcement-Learning-on-Advanced-ReasonIng-modelS-1dfa954ff7c38094923ec7772bf447a1">üí• POLARIS: A POst-training recipe for scaling reinforcement Learning on Advanced ReasonIng modelS</A>
									</DL><p>
									<DT><H3 FOLDED>RARO</H3>
									<DL><p>
										<DT><A HREF="https://x.com/couplefire12/status/1999169943267381265">(1) Locke Cai en X: "RL for reasoning often rely on verifiers ‚Äî great for math, but tricky for creative writing or open-ended research. Meet RARO: a new paradigm that teaches LLMs to reason via adversarial games instead of verification. No verifiers. No environments. Just demonstrations. üßµüëá https://t.co/jZYeqBTSdl" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2511.21667">[2511.21667] Escaping the Verifier: Learning to Reason via Demonstrations</A>
										<DT><A HREF="https://x.com/luoluo/status/1999217181444440080">(1) christina ¬®ÃÆ en X: "someone made self-play work! RARO is cool to tackle the unstable adversarial training setup with shared weight update for both generator and discriminator with regularized entropy to ‚Äúdistill‚Äù the implicit expert policy by minimizing the reverse KL. Long live GAN lol" / X</A>
									</DL><p>
									<DT><H3 FOLDED>fork-tokens</H3>
									<DL><p>
										<DT><A HREF="https://shenzhi-wang.github.io/high-entropy-minority-tokens-rlvr/">High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning</A>
										<DT><A HREF="https://arxiv.org/abs/2506.01939">[2506.01939] Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning</A>
									</DL><p>
									<DT><H3 FOLDED>rl-infra</H3>
									<DL><p>
										<DT><H3 FOLDED>sgl-rl</H3>
										<DL><p>
											<DT><A HREF="https://docs.sglang.io/advanced_features/sglang_for_rl.html">SGLang for RL Systems ‚Äî SGLang</A>
											<DT><A HREF="https://x.com/genai_is_real/status/2015889870913470765?s=12">(1) Chayenne Zhao en X: "We just spent weeks documenting our best practices for RL on SGLang. One year of building this taught me that the biggest bottleneck in AI infra isn't hardware, it's the mindset of legacy engineers. People love to say we've always done it this way as an excuse to ignore superior" / X</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2505.24298">[2505.24298] AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning</A>
										<DT><A HREF="https://arxiv.org/abs/2506.10910">[2506.10910] Magistral</A>
										<DT><A HREF="https://x.com/redtachyon/status/1986177621357691263">(1) Ariel en X: "Aight let's talk about frameworks, libraries, RL, and why I probably don't like your favorite RL codebase. Yes, including that one. The unusual thing about RL is that the algorithm is the easy part. GRPO is a single-line equation on some logprobs. If you have the data, computing" / X</A>
										<DT><A HREF="https://x.com/agarwl_/status/1986228285815103960">PipelineRL</A>
										<DT><A HREF="https://x.com/maxrumpf/status/2001128217030304240">(1) Max Rumpf en X: "Most RL frameworks are fundamentally unstable. We wasted more H100 hours on debugging this than any other issue fornour multi-turn, multi-env RL run (below). When using OpenAI-style messages for env interactions, parsing and retokenizing leads to subtly different tokens. This https://t.co/UsJP258jBs" / X</A>
									</DL><p>
									<DT><H3 FOLDED>rl-scaling</H3>
									<DL><p>
										<DT><A HREF="https://x.com/agarwl_/status/1981395940415005170">(1) Rishabh Agarwal en X: "What's the next big unblock for scaling up RL? - Maximize throughput for inference - Maximize MFU for training - (The hard part) Do the above while keeping RL training stable. Interestingly, this is mostly an algorithmic challenge and we have infrastructure pieces already in" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2511.03773">[2511.03773] Scaling Agent Learning via Experience Synthesis</A>
										<DT><A HREF="https://x.com/ChengZhoujun/status/2013686575499223474">(4) Zhoujun (Jorge) Cheng en X: "Pretraining has scaling laws to guide compute allocation. But for RL on LLMs, we lack a practical guide on how to spend compute wisely. We show the optimal compute allocation in LLM RL scales predictably. ‚Üì Key takeaways below https://t.co/XThoGPy2O1" / X</A>
										<DT><A HREF="https://compute-optimal-rl-llm-scaling.github.io/">IsoCompute Playbook: Optimally Scaling Sampling Compute for RL Training of LLMs</A>
									</DL><p>
									<DT><H3 FOLDED>rl-reasoning</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2504.13837">[2504.13837] Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?</A>
										<DT><A HREF="https://limit-of-rlvr.github.io/">Limit of RLVR</A>
										<DT><A HREF="https://snowclipsed.xyz/blog/rubiks-cube-1/">Teaching Language Models to Solve Rubik's Cubes (Part I)</A>
									</DL><p>
									<DT><H3 FOLDED>rl-long-horizon</H3>
									<DL><p>
										<DT><A HREF="https://yingru.notion.site/The-Optimal-Token-Baseline-399211a558b782cfa936014c0d42dfb8">The Optimal Token Baseline</A>
										<DT><A HREF="https://github.com/volcengine/verl/pull/4678">feat: add optimal token baseline and variance proxy by jiawei415 ¬∑ Pull Request #4678 ¬∑ volcengine/verl</A>
									</DL><p>
									<DT><H3 FOLDED>language-models-rl-training-details</H3>
									<DL><p>
										<DT><H3 FOLDED>rl-fp16-bf16</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/abs/2510.26788">[2510.26788] Defeating the Training-Inference Mismatch via FP16</A>
											<DT><A HREF="https://x.com/rosinality/status/1984113018867941493">FP16 can have a smaller training-inference gap compared to BFloat16, thus fits better for RL. Even the difference between RL algorithms vanishes once FP16 is adopted. Surprising!</A>
											<DT><A HREF="https://x.com/suchenzang/status/1984132522352242777">you can always constrain dynamic range, whereas (precision) errors accumulating can be fatal</A>
											<DT><A HREF="https://yingru.notion.site/When-Speed-Kills-Stability-Demystifying-RL-Collapse-from-the-Training-Inference-Mismatch-271211a558b7808d8b12d403fd15edda">When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch</A>
											<DT><A HREF="https://x.com/RichardYRLi/status/1984858850143715759">disable_cascade_attn</A>
											<DT><A HREF="https://x.com/_xjdr/status/1984138487772414250">serve what you train. bf16 is the one true precision. your inference should always match your training.</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>language-models-rl-format</H3>
									<DL><p>
										<DT><H3 FOLDED>\{boxed}</H3>
										<DL><p>
											<DT><A HREF="https://x.com/Grad62304977/status/1984464048738496674">(1) Grad en X: "Just to scare the timeline a bit more, I was observing that RL with the data formatted as in the first image would crash and go unstable while image 2 was fully stable https://t.co/3g4L8RRbpC" / X</A>
										</DL><p>
										<DT><A HREF="https://x.com/Grad62304977/status/1984464048738496674">(1) Grad en X: "Just to scare the timeline a bit more, I was observing that RL with the data formatted as in the first image would crash and go unstable while image 2 was fully stable https://t.co/3g4L8RRbpC" / X</A>
									</DL><p>
									<DT><H3 FOLDED>language-models-long-horizon</H3>
									<DL><p>
										<DT><A HREF="https://snowclipsed.xyz/blog/rubiks-cube-1/">Teaching Language Models to Solve Rubik's Cubes (Part I)</A>
									</DL><p>
									<DT><H3 FOLDED>rl-lora</H3>
									<DL><p>
										<DT><A HREF="https://kalomaze.bearblog.dev/rl-lora-ddd/">RL Learning with LoRA: A Diverse Deep Dive | kalomaze's kalomazing blog</A>
										<DT><A HREF="https://x.com/kalomaze/status/1987372966460391648">(1) kalomaze en X: "https://t.co/pNypFjfUcx" / X</A>
										<DT><A HREF="https://github.com/LeonGuertler/UnstableBaselines">LeonGuertler/UnstableBaselines</A>
									</DL><p>
									<DT><H3 FOLDED>rl-on-policy</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>train‚Äìinfer-mismatch</H3>
									<DL><p>
										<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/slime/int4/readme-en.md">Awesome-ML-SYS-Tutorial/rlhf/slime/int4/readme-en.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
									</DL><p>
									<DT><H3 FOLDED>rl-aggregation-aware</H3>
									<DL><p>
										<DT><A HREF="https://github.com/HyperPotatoNeo/RSA">HyperPotatoNeo/RSA</A>
									</DL><p>
									<DT><A HREF="https://x.com/Grad62304977/status/1967548295816819184">(Grad) RL papers curated list</A>
									<DT><A HREF="https://arxiv.org/abs/2508.06471">[2508.06471] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models</A>
									<DT><A HREF="https://arxiv.org/abs/2504.13914">[2504.13914] Seed1.5-Thinking: Advancing Superb Reasoning Models with Reinforcement Learning</A>
									<DT><A HREF="https://arxiv.org/abs/2505.08311">[2505.08311] AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale</A>
									<DT><A HREF="https://pytorch.org/blog/a-primer-on-llm-post-training/">A Primer on LLM Post-Training ‚Äì PyTorch</A>
									<DT><A HREF="https://gist.github.com/yoavg/6bff0fecd65950898eba1bb321cfbd81">Reinforcement Learning for Language Models</A>
									<DT><A HREF="https://github.com/huggingface/trl">huggingface/trl: Train transformer language models with reinforcement learning.</A>
									<DT><A HREF="https://github.com/OpenRLHF/OpenRLHF">OpenRLHF/OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework (70B+ PPO Full Tuning &amp; Iterative DPO &amp; LoRA &amp; RingAttention &amp; RFT)</A>
									<DT><A HREF="https://github.com/leanprover/lean4">leanprover/lean4: Lean 4 programming language and theorem prover</A>
									<DT><A HREF="https://github.com/pytorch/rl">pytorch/rl: A modular, primitive-first, python-first PyTorch library for Reinforcement Learning.</A>
									<DT><A HREF="https://x.com/karpathy/status/1944435412489171119">scaling up RL</A>
									<DT><A HREF="https://simonxin.com/blogs/llm_reasoning_materials/index.html#section-9">Learn LLMs Only with Good Materials (Reasoning) - Xin Dong</A>
									<DT><A HREF="https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers">xhyumiracle/Awesome-AgenticLLM-RL-Papers</A>
									<DT><A HREF="https://arxiv.org/abs/2509.02547">[2509.02547] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey</A>
									<DT><A HREF="https://arxiv.org/abs/2505.22312">[2505.22312] Skywork Open Reasoner 1 Technical Report</A>
									<DT><A HREF="https://arxiv.org/abs/2506.13284">[2506.13284] AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy</A>
									<DT><A HREF="https://arxiv.org/abs/2508.08221">[2508.08221] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning</A>
									<DT><A HREF="https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/report/Hunyuan_A13B_Technical_Report.pdf">Hunyuan-A13B/report/Hunyuan_A13B_Technical_Report.pdf at main ¬∑ Tencent-Hunyuan/Hunyuan-A13B</A>
									<DT><A HREF="https://pretty-radio-b75.notion.site/DeepCoder-A-Fully-Open-Source-14B-Coder-at-O3-mini-Level-1cf81902c14680b3bee5eb349a512a51">DeepCoder: A Fully Open-Source 14B Coder at O3-mini Level</A>
									<DT><A HREF="https://arxiv.org/abs/2507.20534">[2507.20534] Kimi K2: Open Agentic Intelligence</A>
									<DT><A HREF="https://arxiv.org/abs/2508.09726">[2508.09726] Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning</A>
									<DT><A HREF="https://arxiv.org/abs/2509.06870">[2509.06870] The Majority is not always right: RL training for solution aggregation</A>
									<DT><A HREF="https://x.com/bycloudai/status/1966820419622584415">(1) bycloud en X: "i swear Chinese AI labs are just having fun turning LLM finetuning into a game of pathfinding https://t.co/qiQqodbSca" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2509.06160v1">(bytedn) Reverse-Engineered Reasoning for Open-Ended Generation</A>
									<DT><A HREF="https://arxiv.org/abs/2509.09284">[2509.09284] Tree-OPO: Off-policy Monte Carlo Tree-Guided Advantage Optimization for Multistep Reasoning</A>
									<DT><A HREF="https://arxiv.org/abs/2408.08152">[2408.08152] DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search</A>
									<DT><A HREF="https://fengyao.notion.site/off-policy-rl">‚ö†Ô∏è Your Efficient RL Framework Secretly Brings You Off-Policy RL Training | Notion</A>
									<DT><A HREF="https://x.com/eliebakouch/status/1980642834404319388">(1) elie en X: "Here is what the future looks like for training at scale: 1) Pre training: torchtitan -&amp;gt; for coms: torchcoms (new) -&amp;gt; low precision: torchao -&amp;gt; framework: monarch -&amp;gt; decentralize: torchft 2) Post training: torchforge (new) -&amp;gt; training: torchtitan -&amp;gt; inference: vllm -&amp;gt; RL env:" / X</A>
									<DT><A HREF="https://x.com/agarwl_/status/1981000175129702584">(1) Rishabh Agarwal en X: "I learned today that the impact of scaling RL compute on LLM performance follows the same behavior as the biological effect of increasing the dose of a drug! Specifically, the sigmoidal scaling curve we fit in the "Art of Scaling RL" to predict RL performance when scaling https://t.co/HdnZFdKjkr" / X</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Hill_equation_(biochemistry)">Hill equation (biochemistry) - Wikipedia</A>
									<DT><A HREF="https://x.com/khoomeik/status/1980709550203482375">(1) Rohan Pandey en X: "btw the exploration problem in LLM RL ~= synthetic data‚Äôs low dimension manifold problem (mentioned by @karpathy on @dwarkesh_sp) https://t.co/8t9jauuzsG" / X</A>
									<DT><A HREF="https://x.com/agarwl_/status/1978874743680843886">(1) Rishabh Agarwal en X: "*checks chatgpt* This paper costs ~4.2 million USD (400K GB200 hours) -- science! Our most expensive run was a 100K GPU hour (same amount as Deepseek-R1-zero but on GB200s). One finding here was that once we have a scalable RL algorithm, RL compute scaling becomes predictable" / X</A>
									<DT><A HREF="https://x.com/Devvrit_Khatri/status/1978864275658871099">(1) Devvrit en X: "Wish to build scaling laws for RL but not sure how to scale? Or what scales? Or would RL even scale predictably? We introduce: The Art of Scaling Reinforcement Learning Compute for LLMs https://t.co/gmpxOCPSJx" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2510.13786">[2510.13786] The Art of Scaling Reinforcement Learning Compute for LLMs</A>
									<DT><A HREF="https://x.com/_xjdr/status/1979274661449076886">(1) xjdr en X: "saying (current) rl is terrible saying we need PRMs and adversarial training (sic: MuZero) lamenting entropy collapse and explaining the need to preserve entropy in training and sampling wanting sparse attention (and attn sparse layer over kvcache) https://t.co/KoEM7c8OMu" / X</A>
									<DT><A HREF="https://x.com/saagnikkk/status/1924885542468256212">Sagnik Mukherjee @ NeurIPS 2025 en X: "üö® Paper Alert: ‚ÄúRL Finetunes Small Subnetworks in Large Language Models‚Äù From DeepSeek V3 Base to DeepSeek R1 Zero, a whopping 86% of parameters were NOT updated during RL training üòÆüòÆ And this isn‚Äôt a one-off. The pattern holds across RL algorithms and models. üßµA Deep Dive https://t.co/iaJ17aPucx" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2505.11711">[2505.11711] Reinforcement Learning Finetunes Small Subnetworks in Large Language Models</A>
									<DT><A HREF="https://www.notion.so/sagnikm/Who-is-Adam-SGD-Might-Be-All-We-Need-For-RLVR-In-LLMs-1cd2c74770c080de9cbbf74db14286b6">Who is Adam? SGD Might Be All We Need For RLVR In LLMs</A>
								</DL><p>
								<DT><H3 FOLDED>chat</H3>
								<DL><p>
									<DT><H3 FOLDED>nanochat</H3>
									<DL><p>
										<DT><A HREF="https://github.com/karpathy/nanochat">karpathy/nanochat: The best ChatGPT that $100 can buy.</A>
										<DT><A HREF="https://github.com/karpathy/nanochat/blob/master/nanochat/adamw.py">nanochat/nanochat/adamw.py at master ¬∑ karpathy/nanochat</A>
										<DT><A HREF="https://x.com/zhzHNN/status/2013138889775382974">(1) Huaizheng Zhang en X: "I always love nano projects as big projects add lots of non-core code to cover every scenario ‚Äî it often distracts beginners from the fundamentals. Here are some LLM infra nano projects I recommend you try. https://t.co/AWWsu0fExc" / X</A>
										<DT><A HREF="https://x.com/karpathy/status/2009037707918626874">(1) Andrej Karpathy en X: "New post: nanochat miniseries v1 The correct way to think about LLMs is that you are not optimizing for a single specific model but for a family models controlled by a single dial (the compute you wish to spend) to achieve monotonically better results. This allows you to do https://t.co/84OwpSODcS" / X</A>
										<DT><A HREF="https://github.com/karpathy/nanochat/discussions/420">[Jan 7 2026] nanochat miniseries v1 ¬∑ karpathy/nanochat ¬∑ Discussion #420</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>Instruction Tuning</H3>
								<DL><p>
									<DT><H3 FOLDED>Datasets</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/yuntiandeng/status/1724503257601458575">WildChat: 650K user-ChatGPT interactions in the wild</A>
									</DL><p>
									<DT><H3 FOLDED>FLAN</H3>
									<DL><p>
										<DT><H3 FOLDED>flan-prompt-template</H3>
										<DL><p>
											<DT><A HREF="https://jrodthoughts.medium.com/this-google-model-combines-reasoning-and-acting-in-a-single-language-model-935317c3b111">Combine Reasoning and Acting in a Single Language Model</A>
										</DL><p>
										<DT><A HREF="https://jrodthoughts.medium.com/this-google-model-combines-reasoning-and-acting-in-a-single-language-model-935317c3b111">Combine Reasoning and Acting in a Single Language Model</A>
										<DT><A HREF="https://github.com/google-research/FLAN/blob/main/flan/baseline_templates.py">Templates for baseline guide language models (GLM) prompts</A>
										<DT><A HREF="https://arxiv.org/abs/2109.01652">[2109.01652] Finetuned Language Models Are Zero-Shot Learners</A>
										<DT><A HREF="https://arxiv.org/abs/2301.13688">[2301.13688] The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</A>
										<DT><A HREF="https://huggingface.co/docs/transformers/model_doc/flan-t5">FLAN-T5</A>
										<DT><A HREF="https://arxiv.org/abs/2210.11416">Flan-PaLM: Scaling Instruction-Finetuned Language Models</A>
										<DT><A HREF="https://chat.openai.com/c/e261dbd6-8206-4e2d-8fdc-17cb3aafd611">Textual graph structures representations</A>
									</DL><p>
									<DT><A HREF="https://openai.com/blog/instruction-following/">InstructGPT</A>
									<DT><A HREF="https://twitter.com/ShayneRedford/status/1683927467436937219">The FLAN Collection</A>
									<DT><A HREF="https://twitter.com/burkov/status/1715541145881624617">chatting capability</A>
									<DT><A HREF="https://twitter.com/karpathy/status/1728143712059056467">(Andrej Karpathy) special tokens &lt;|BROWSE|&gt;  tooling usage</A>
									<DT><A HREF="https://twitter.com/Muennighoff/status/1717212559584149674">complexity of instruction data</A>
									<DT><A HREF="https://www.youtube.com/watch?v=mcep6W8oB1I&list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&index=22">Stanford CS25: V3 I Recipe for Training Helpful Chatbots - YouTube</A>
									<DT><A HREF="https://github.com/character-ai/prompt-poet?ref=research.character.ai">character-ai/prompt-poet at research.character.ai</A>
									<DT><A HREF="https://github.com/alibaba/ChatLearn">alibaba/ChatLearn: A flexible and efficient training framework for large-scale alignment tasks</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/torchtune">pytorch/torchtune: PyTorch native finetuning library</A>
								<DT><A HREF="https://x.com/hsu_byron/status/1866577403918917655">(1) Byron Hsu en X: "Introducing the first open-source optimized post-training losses in Liger Kernel with ~80% memory reduction, featuring DPO, CPO, ORPO, SimPO, JSD, and more, achieving up to 70% end-to-end speedup through larger batch size. Use it as any PyTorch module - Available today in Liger https://t.co/dqKSzNd0Me" / X</A>
								<DT><A HREF="https://github.com/linkedin/Liger-Kernel/blob/main/src/liger_kernel/chunked_loss/orpo_loss.py#L12">Liger-Kernel/src/liger_kernel/chunked_loss/orpo_loss.py at main ¬∑ linkedin/Liger-Kernel</A>
								<DT><A HREF="https://www.mechanize.work/blog/sweatshop-data-is-over/">Sweatshop data is over | Mechanize Inc: Good RL environments are the bottleneck</A>
							</DL><p>
							<DT><H3 FOLDED>training-logbook</H3>
							<DL><p>
								<DT><H3 FOLDED>opt-logbook</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf">metaseq/projects/OPT/chronicles/OPT175B_Logbook</A>
								</DL><p>
								<DT><A HREF="https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf">metaseq/projects/OPT/chronicles/OPT175B_Logbook.pdf at main ¬∑ facebookresearch/metaseq</A>
							</DL><p>
							<DT><H3 FOLDED>dots.llm1</H3>
							<DL><p>
								<DT><A HREF="https://github.com/rednote-hilab/dots.llm1">rednote-hilab/dots.llm1: The official repository of the dots.llm1 base and instruct models proposed by rednote-hilab.</A>
								<DT><A HREF="https://www.arxiv.org/abs/2506.05767">[2506.05767] dots.llm1 Technical Report</A>
								<DT><A HREF="https://huggingface.co/collections/rednote-hilab/dotsllm1">dots.llm1 - a rednote-hilab Collection</A>
							</DL><p>
							<DT><A HREF="https://openai.com/research/techniques-for-training-large-neural-networks">Techniques for training large neural networks</A>
							<DT><A HREF="https://www.youtube.com/watch?v=fKMB5UlVY1E&list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&index=27">Stanford CS25: V4 I Overview of Transformers - YouTube</A>
							<DT><A HREF="https://github.com/JonasGeiping/cramming">JonasGeiping/cramming: Cramming the training of a (BERT-type) language model into limited compute.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=2Zi6wFQQl3E">Generalization bounds for Neural Network Based Decoders</A>
							<DT><A HREF="https://www.youtube.com/watch?v=0D23NeBjCeQ">A Theory for Emergence of Complex Skills in Language Models</A>
							<DT><A HREF="https://www.youtube.com/watch?v=g0gREwiDbis">Dr. Geoffrey Hinton: A brief study of neural networks</A>
							<DT><A HREF="https://www.lesswrong.com/posts/diutNaWF669WgEt3v/the-scaling-inconsistency-openai-s-new-insight">One Epoch: the scaling¬†‚Äúinconsistency‚Äù</A>
							<DT><A HREF="https://twitter.com/Yampeleg/status/1672600308365623296">Cheatsheet: Full Training vs. LoRA Adapters VS. VS VS. Smaller Models</A>
							<DT><A HREF="https://vram.asmirnov.xyz/">VRAM Calculator</A>
							<DT><A HREF="https://x.com/typedfemale/status/1848216197080260712">(2) typedfemale en X: "i've talked to multiple very experienced people about how they would organize their ideal training codebase - all of them said "i'd put everything in a single file"" / X</A>
							<DT><A HREF="https://x.com/PytorchToAtoms/status/1848230941635776752">(2) Pytorch To Atoms en X: "Top 5 bloatware: 1. Hugging face transformer 2. Megatron-lm 3. NeMo 4. Mosaicml Composer/LLM Foundry 5. Hugging face diffuser" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2311.08105">[2311.08105] DiLoCo: Distributed Low-Communication Training of Language Models</A>
						</DL><p>
						<DT><H3 FOLDED>multimodal</H3>
						<DL><p>
							<DT><H3 FOLDED>multimodal-theory</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ArmenAgha/status/2014428868636270885">one harsh realization was that standard architectures don't allocate compute intelligently across modalities</A>
								<DT><A HREF="https://www.perceptron.inc/blog/composing-weight-and-data-sparsity-in-moe">Composing Weight and Data Sparsity in MoE Improving compute efficiency through varying compute per token</A>
								<DT><A HREF="https://papers.perceptron.inc/data_sparsity.pdf">IMPROVING MOE COMPUTE EFFICIENCY BY COMPOSING WEIGHT AND DATA SPARSITY</A>
							</DL><p>
							<DT><H3 FOLDED>reasoning-images</H3>
							<DL><p>
								<DT><H3 FOLDED>DiffThinker</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2512.24165">[2512.24165] DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models</A>
									<DT><A HREF="https://x.com/jiqizhixin/status/2011438155124093058">(1) Êú∫Âô®‰πãÂøÉ JIQIZHIXIN en X: "What if AI could "think" in pictures instead of words for complex visual puzzles? Researchers from Shanghai AI Lab, Nanjing University, and CUHK present DiffThinker. It reframes reasoning as a direct image-to-image generation task, using a diffusion model to visually work https://t.co/ylUt0DucMo" / X</A>
									<DT><A HREF="https://github.com/lcqysl/DiffThinker">lcqysl/DiffThinker: DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models</A>
									<DT><A HREF="https://mp.weixin.qq.com/s/mBdlQ2At-ACq5q6oi8MCtg">Â§öÊ®°ÊÄÅÊé®ÁêÜÊñ∞ËåÉÂºèÔºÅDiffThinkerÔºöÁî®Êâ©Êï£Ê®°Âûã„ÄåÁîª„ÄçÂá∫Êé®ÁêÜÂíåÁ≠îÊ°à</A>
									<DT><A HREF="https://diffthinker-project.github.io/">DiffThinker: Generative Multimodal Reasoning</A>
								</DL><p>
								<DT><H3 FOLDED>think-with-images</H3>
								<DL><p>
									<DT><A HREF="https://openai.com/index/thinking-with-images/">Thinking with images | OpenAI</A>
									<DT><A HREF="https://x.com/jhyuxm/status/1912562461624131982">‚ÄúThinking with Images‚Äù has been one of our core bets in Perception since the earliest o-series launch.</A>
								</DL><p>
								<DT><H3 FOLDED>reasoning-images-tools</H3>
								<DL><p>
									<DT><H3 FOLDED>pyvision</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2507.07998">[2507.07998] PyVision: Agentic Vision with Dynamic Tooling</A>
										<DT><A HREF="https://agent-x.space/pyvision/">PyVision - Agents-X</A>
										<DT><A HREF="https://github.com/agents-x-project/PyVision">agents-x-project/PyVision: Official implementation of "PyVision: Agentic Vision with Dynamic Tooling."</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>UniVG-R1</H3>
								<DL><p>
									<DT><A HREF="https://amap-ml.github.io/UniVG-R1-page/">UniVG-R1: Reasoning Guided Universal Visual Grounding with Reinforcement Learning</A>
								</DL><p>
								<DT><H3 FOLDED>MindCube</H3>
								<DL><p>
									<DT><A HREF="https://x.com/ManlingLi_/status/1939760677133987952">Can VLMs build Spatial Mental Models like humans?</A>
									<DT><A HREF="https://mll-lab-nu.github.io/mind-cube/">Mind Cube - Spatial Mental Modeling from Limited Views | MLL Lab</A>
									<DT><A HREF="https://arxiv.org/pdf/2506.21458">Spatial Mental Modeling from Limited Views</A>
									<DT><A HREF="https://huggingface.co/datasets/MLL-Lab/MindCube">MLL-Lab/MindCube ¬∑ Datasets at Hugging Face</A>
									<DT><A HREF="https://github.com/mll-lab-nu/MindCube">mll-lab-nu/MindCube</A>
								</DL><p>
								<DT><H3 FOLDED>Moondream</H3>
								<DL><p>
									<DT><A HREF="https://moondream.ai/blog/moondream-3-preview">Moondream 3 Preview: Frontier-level reasoning at a blazing speed | Moondream</A>
									<DT><A HREF="https://huggingface.co/moondream/moondream3-preview">moondream/moondream3-preview ¬∑ Hugging Face</A>
								</DL><p>
								<DT><A HREF="https://github.com/zhaochen0110/Awesome_Think_With_Images">zhaochen0110/Awesome_Think_With_Images: Resources and paper list for "Thinking with Images for LVLMs". This repository accompanies our survey on how LVLMs can leverage visual information for complex reasoning, planning, and generation.</A>
								<DT><A HREF="https://www.linkedin.com/pulse/bringing-intelligence-interaction-video-voice-chunyuan-li-mv2vc/">video and voice understanding xAI</A>
								<DT><A HREF="https://moondream.ai/">Moondream</A>
								<DT><A HREF="https://arxiv.org/abs/2503.17352">[2503.17352] OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL Cycles</A>
								<DT><A HREF="https://x.com/Yihe__Deng/status/2006079525810229477">(1) Yihe Deng en X: "guess it's time to wrap up 2025 :) - OpenVLThinker: iterative SFT-RL cycles https://t.co/pwgn4Q1zco - Supervised RL: step-wise rewards via seq similarity w/ expert traces https://t.co/8j4PaeFsPz - Joined our amazing multimodal team @xAI üöÄ And earlier this year: - DuoGuard:" / X</A>
							</DL><p>
							<DT><H3 FOLDED>VLA</H3>
							<DL><p>
								<DT><H3 FOLDED>UI-TARS-1.5</H3>
								<DL><p>
									<DT><A HREF="https://x.com/TsingYoga/status/1912890960897626176">Yujia Qin en X: "Introducing UI-TARS-1.5, a vision-language model that beats OpenAI Operator and Claude 3.7 on GUI Agent and Game Agent tasks. We've open-sourced a small-size version model for research purposes, more details can be found in our blog. TARS learns solely from a screen, but https://t.co/Y43RUzd99R" / X</A>
									<DT><A HREF="https://github.com/bytedance/UI-TARS">bytedance/UI-TARS</A>
									<DT><A HREF="https://openai.com/index/computer-using-agent/">Computer-Using Agent | OpenAI</A>
									<DT><A HREF="https://seed-tars.com/1.5/">computer user agent/controller (OpenAI, Claude)</A>
									<DT><A HREF="https://huggingface.co/ByteDance-Seed/UI-TARS-1.5-7B">ByteDance-Seed/UI-TARS-1.5-7B ¬∑ Hugging Face</A>
									<DT><A HREF="https://arxiv.org/abs/2501.12326">[2501.12326] UI-TARS: Pioneering Automated GUI Interaction with Native Agents</A>
									<DT><A HREF="https://x.com/hcompany_ai/status/1929877733582021003">(1) H en X: "2Ô∏è‚É£ Holo-1: We are Open-Sourcing our Visual-Language Model powering Surfer H We‚Äôve beefed up Surfer H‚Äôs web automation with Holo-1, our 3B &amp;amp; 7B-parameters Action Models. It now achieves industry-leading UI localization and navigation accuracy while staying compact and https://t.co/HixDKMc4Sv" / X</A>
									<DT><A HREF="https://cdn.prod.website-files.com/67e2dbd9acff0c50d4c8a80c/683ec8095b353e8b38317f80_h_tech_report_v1.pdf">Surfer-H Meets Holo1 Cost-Efficient Web Agent Powered by Open Weights</A>
								</DL><p>
								<DT><H3 FOLDED>UI-TARS-2</H3>
								<DL><p>
									<DT><H3 FOLDED>bytedn-agents-infra</H3>
									<DL><p>
										<DT><A HREF="https://sandbox.agent-infra.com/">AIO Sandbox</A>
										<DT><A HREF="https://github.com/agent-infra/sandbox">agent-infra/sandbox: All-in-One Sandbox for AI Agents that combines Browser, Shell, File, MCP and VSCode Server in a single Docker container.</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2509.02544">[2509.02544] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning</A>
									<DT><A HREF="https://x.com/tsingyoga/status/1963629621326614940">(1) Yujia Qin en X: "We can finally share UI-TARS-2ü•≥ü•≥ ‚Äî a native GUI agent trained with multi-turn agent RL ‚ö°Ô∏è‚ö°Ô∏èKey highlights (all-in-one model!): üíªComputer Use: 47.5 OSWorld ¬∑ 50.6 WindowsAgentArena üì±Phone Use: 73.3 AndroidWorld üõúBrowser Use: 88.2% Online-Mind2Web üéÆGameplay: ~60% human https://t.co/lcMdZHaJdS" / X</A>
									<DT><A HREF="https://seed-tars.com/showcase/ui-tars-2/write-a-function-that-40c278">UI-TARSÔºöNext-generation native GUI agent model designed to interact seamlessly with GUIs using human-like perception</A>
								</DL><p>
								<DT><H3 FOLDED>Gemini Robotics 1.5</H3>
								<DL><p>
									<DT><H3 FOLDED>Gemini Robotics-ER 1.5</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>Gemini Robotics 1.5</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://x.com/xiao_ted/status/1971248874875650547?s=46&t=dlA6_trf9GvyNjTGMUaclA">(1) Ted Xiao @ CoRL 2025 en X: "üì¢The next milestone for intelligent general-purpose robots has arrived! Announcing Gemini Robotics 1.5, our flagship system which brings breakthroughs from frontier models to the physical world with two new SOTA generalists: the GR 1.5 VLA and GR 1.5 embodied reasoning model üßµ https://t.co/c3pBg3ZFVj" / X</A>
									<DT><A HREF="https://deepmind.google/models/gemini-robotics/">Gemini Robotics - Google DeepMind</A>
									<DT><A HREF="https://deepmind.google/discover/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/">Gemini Robotics 1.5 brings AI agents into the physical world - Google DeepMind</A>
									<DT><A HREF="https://storage.googleapis.com/deepmind-media/gemini-robotics/Gemini-Robotics-1-5-Tech-Report.pdf">Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer</A>
								</DL><p>
								<DT><H3 FOLDED>Redwood</H3>
								<DL><p>
									<DT><A HREF="https://www.1x.tech/discover/redwood-ai">Redwood AI | 1X</A>
									<DT><A HREF="https://www.1x.tech/1x-world-model.pdf">1X World Model: Evaluating Bits, not Atoms</A>
								</DL><p>
								<DT><H3 FOLDED>CoT-VLA</H3>
								<DL><p>
									<DT><A HREF="https://x.com/qingqing_zhao_/status/1906759214246355357">(1) Qingqing Zhao en X: "Introduce CoT-VLA ‚Äì Visual Chain-of-Thought reasoning for Robot Foundation Models! ü§ñ By leveraging next-frame prediction as visual chain-of-thought reasoning, CoT-VLA uses future prediction to guide action generation and unlock large-scale video data for training. #CVPR2025 https://t.co/fwSrkKKlx7" / X</A>
									<DT><A HREF="https://cot-vla.github.io/">Visual Chain-of-Thought Reasoning for Vision-Language-Action Models</A>
									<DT><A HREF="https://x.com/qingqing_zhao_">(1) Qingqing Zhao (@qingqing_zhao_) Foundation Models @Tesla_AI</A>
								</DL><p>
								<DT><H3 FOLDED>game-tars</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2510.23691">[2510.23691] Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents</A>
								</DL><p>
								<DT><H3 FOLDED>vla-real-time</H3>
								<DL><p>
									<DT><A HREF="https://www.physicalintelligence.company/research/real_time_chunking">Real-Time Action Chunking with Large Models</A>
								</DL><p>
								<DT><H3 FOLDED>GR-Dexter</H3>
								<DL><p>
									<DT><A HREF="https://byte-dexter.github.io/gr-dexter/">GR-Dexter Technical Report</A>
									<DT><A HREF="https://x.com/yusufma555/status/2006542134397292594">(1) Xiao Ma en X: "Scaling vision-language-action (VLA) models to high-DoF dexterous hands has long been a "holy grail" challenge due to the high-dimensional action space and data scarcity. As a wrap up of the year 2025, we are releasing GR-Dexter, a holistic hardware-model-data framework for https://t.co/u5JnT6XlJP" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2512.24210">[2512.24210] GR-Dexter Technical Report</A>
								</DL><p>
								<DT><A HREF="https://openai.com/index/thinking-with-images/">Thinking with images | OpenAI</A>
								<DT><A HREF="https://www.pi.website/research/real_time_chunking">Real-Time Action Chunking with Large Models</A>
								<DT><A HREF="https://www.physicalintelligence.company/research/knowledge_insulation">VLAs that Train Fast, Run Fast, and Generalize Better</A>
								<DT><A HREF="https://www.physicalintelligence.company/blog/pi05">A VLA with Open-World Generalization</A>
								<DT><A HREF="https://www.physicalintelligence.company/research/hirobot">Teaching Robots to Listen and Think Harder</A>
								<DT><A HREF="https://www.physicalintelligence.company/blog/openpi">Open Sourcing œÄ0</A>
								<DT><A HREF="https://www.physicalintelligence.company/research/fast">FAST: Efficient Robot Action Tokenization</A>
								<DT><A HREF="https://www.physicalintelligence.company/blog/pi0">Our First Generalist Policy</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1962678456325248819">DriveVLA-W0 in Brief: World Model + VLA + Self-Supervised Scaling?</A>
								<DT><A HREF="https://arxiv.org/pdf/2510.12796">DRIVEVLA-W0: WORLD MODELS AMPLIFY DATA SCALING LAW IN AUTONOMOUS DRIVING</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1957018167432946036">[LLM Sparse] DSA: DeepSeek Sparse Attention (DS V3.2-Exp)</A>
								<DT><A HREF="https://x.com/physical_int/status/2001096200456692114">(1) Physical Intelligence en X: "We discovered an emergent property of VLAs like œÄ0/œÄ0.5/œÄ0.6: as we scale up pre-training, the model learns to align human videos and robot data! This gives us a simple way to leverage human videos. Once œÄ0.5 knows how to control robots, it can naturally learn from human video. https://t.co/K9BC78HtqN" / X</A>
								<DT><A HREF="https://arxiv.org/pdf/2512.15692">mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs</A>
								<DT><A HREF="https://x.com/TheHumanoidHub/status/2011176025733075315">A video world model seems to be a much better pretraining objective for robot policy.</A>
							</DL><p>
							<DT><H3 FOLDED>VLM</H3>
							<DL><p>
								<DT><H3 FOLDED>vlm-training</H3>
								<DL><p>
									<DT><H3 FOLDED>nanoVLM</H3>
									<DL><p>
										<DT><A HREF="https://www.linkedin.com/posts/luiswiedmann_weve-just-open-sourced-nanovlm-a-pure-pytorch-activity-7325531868412456960-a2bd/">(2) Post | LinkedIn</A>
										<DT><A HREF="https://github.com/huggingface/nanoVLM">huggingface/nanoVLM: The simplest, fastest repository for training/finetuning small-sized VLMs.</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>vlm-positional-encoding</H3>
								<DL><p>
									<DT><A HREF="https://x.com/yongyuanxi/status/1939779851386544615">Adding horizontal lines to images improves VLM (vision language model) performance of tasks</A>
									<DT><A HREF="https://arxiv.org/abs/2506.22146">[2506.22146] Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs</A>
								</DL><p>
								<DT><H3 FOLDED>DeepSeek-OCR</H3>
								<DL><p>
									<DT><H3 FOLDED>DeepSeek-OCR-training</H3>
									<DL><p>
										<DT><A HREF="https://x.com/atasteoff/status/1986290457064980504">(1) Shilong Liu en X: "Discover DeepOCR: a fully open-source reproduction of DeepSeek-OCR, complete with training &amp;amp; evaluation code! #DeepLearning #OCR" / X</A>
										<DT><A HREF="https://pkulium.github.io/DeepOCR_website/">Technical Report-v1: DeepOCR | DeepOCR</A>
										<DT><A HREF="https://github.com/pkulium/DeepOCR">pkulium/DeepOCR</A>
									</DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-OCR">deepseek-ai/DeepSeek-OCR: Contexts Optical Compression</A>
									<DT><A HREF="https://x.com/RayFernando1337/status/1980180029125628374">(11) Ray Fernando en X: "This is the JPEG moment for AI. Optical compression doesn't just make context cheaper. It makes AI memory architectures viable. Training data bottlenecks? Solved. - 200k pages/day on ONE GPU - 33M pages/day on 20 nodes - Every multimodal model is data-constrained. Not anymore. https://t.co/eqxgiyIDbK" / X</A>
									<DT><A HREF="https://x.com/vllm_project/status/1980235518706401405">vLLM en X: "üöÄ DeepSeek-OCR ‚Äî the new frontier of OCR from @deepseek_ai , exploring optical context compression for LLMs, is running blazingly fast on vLLM ‚ö° (~2500 tokens/s on A100-40G) ‚Äî powered by vllm==0.8.5 for day-0 model support. üß† Compresses visual contexts up to 20√ó while keeping https://t.co/bx3d7LnfaR" / X</A>
									<DT><A HREF="https://x.com/willccbb/status/1980160732236042604">will brown en X: "is it just me or is this deepseek paper really...weird? like the flagship results are all about compression ratios and they‚Äôre gesturing at implications for LLM memory but... it‚Äôs an OCR model? are they suggesting that LLMs should ingest OCR embeddings of screenshots of old notes?? https://t.co/ptxkgANIeW" / X</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1980160624140456370">Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Massively unexpected update from DeepSeek: a powerful, high-compression MoE OCR model. &amp;gt; In production, DeepSeek-OCR can generate 33 million pages of data per day for LLMs/VLMs using 20 nodes (x8 A100-40G). They want ALL the tokens. You're welcome to have some too. https://t.co/mXV08ifRle" / X</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1980165682516869575">Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Whale insanity. ¬´Theoretically unlimited context architectures¬ª through turning old text into ¬´vision¬ª tokens at 10x and higher ratios. How crazy is that? But actually I think... we need to go even further beyond. Fully multimodal encoders. Language for intelligent machines. https://t.co/gv6dFYoJ6N" / X</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1980167320887869455">Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "&amp;gt; they were pursuing unlimited context but as a side quest went and built a machine for fully parsing internet PDF data https://t.co/hHW1syURd1" / X</A>
									<DT><A HREF="https://x.com/Dorialexander/status/1980289147609776232">(1) Alexander Doria en X: "So longer read of DeepSeek-OCR It‚Äôs an engineering achievement. It has been suspected for a while that VLM/OCR models could be significantly smaller. The pre-VLM state of the art, Google Cloud OCR would not be more than a 100m model. More recently, relatively small open weights" / X</A>
									<DT><A HREF="https://x.com/MaziyarPanahi/status/1980273244235067892">(1) Maziyar PANAHI en X: "DeepSeek-OCR on doctor's hand written note! https://t.co/zfsnjCvcEQ" / X</A>
									<DT><A HREF="https://x.com/zephyr_z9/status/1980556915819376695">(4) Zephyr en X: "Zhipu also dropped "Glyph, a framework that renders long texts into images and processes them with vision‚Äìlanguage models (VLMs). This approach substantially compresses textual input while preserving semantic information" https://t.co/HjqkDlwCeX" / X</A>
									<DT><A HREF="https://x.com/karpathy/status/1980397031542989305">(1) Andrej Karpathy en X: "I quite like the new DeepSeek-OCR paper. It's a good OCR model (maybe a bit worse than dots), and yes data collection etc., but anyway it doesn't matter. The more interesting part for me (esp as a computer vision at heart who is temporarily masquerading as a natural language" / X</A>
									<DT><A HREF="https://x.com/askalphaxiv/status/1980722479405678593">(1) alphaXiv en X: "We used DeepSeek OCR to extract every dataset from tables/charts across 500k+ AI arXiv papers for $1000 üöÄ See which benchmarks are trending and discover datasets you didn't know existed Doing the same task with Mistral OCR would've cost $7500 üëÄ https://t.co/OTzh1HJDma" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2510.17800">[2510.17800] Glyph: Scaling Context Windows via Visual-Text Compression</A>
									<DT><A HREF="https://x.com/Zai_org/status/1982804366475063446">(1) Z.ai en X: "Glyph: Scaling Context Windows via Visual-Text Compression Paper: https://t.co/oxDsNJZXRz Weights: https://t.co/IYn2pAQjAn Repo: https://t.co/lFW7ajnHCk Glyph is a framework for scaling the context length through visual-text compression. It renders long textual sequences into https://t.co/3TgYGEaaZ7" / X</A>
									<DT><A HREF="https://x.com/HarveenChadha/status/1982327891389268258">(1) Harveen Singh Chadha en X: "No, its not the best OCR ever here is the result from olmoOCR2 on the same and it does have a frightening degree of accuracy https://t.co/u9UIpRmmnN" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Qwen-VL</H3>
								<DL><p>
									<DT><H3 FOLDED>Qwen3-VL-235B-A22B</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/collections/Qwen/qwen3-vl-68d2a7c1b8a8afce4ebd2dbe">Qwen3-VL - a Qwen Collection</A>
										<DT><A HREF="https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Thinking">Qwen/Qwen3-VL-235B-A22B-Thinking ¬∑ Hugging Face</A>
										<DT><A HREF="https://huggingface.co/Qwen/Qwen3-VL-235B-A22B-Instruct">Qwen/Qwen3-VL-235B-A22B-Instruct ¬∑ Hugging Face</A>
										<DT><A HREF="https://qwen.ai/blog?id=99f0335c4ad9ff6153e517418d48535ab6d8afef&from=research.latest-advancements-list">Qwen3-VL: Sharper Vision, Deeper Thought, Broader Action</A>
									</DL><p>
									<DT><H3 FOLDED>Qwen-VLo</H3>
									<DL><p>
										<DT><A HREF="https://qwenlm.github.io/blog/qwen-vlo/">Qwen VLo: From "Understanding" the World to "Depicting" It | Qwen</A>
										<DT><A HREF="https://seed.bytedance.com/en/tech/seededit">SeedEdit Fast and High-Quality Generative Image Editing</A>
										<DT><A HREF="https://arxiv.org/abs/2506.05083">[2506.05083] SeedEdit 3.0: Fast and High-Quality Generative Image Editing</A>
									</DL><p>
									<DT><H3 FOLDED>Qwen2.5-VL</H3>
									<DL><p>
										<DT><A HREF="https://github.com/QwenLM/Qwen2.5-VL">QwenLM/Qwen2.5-VL: Qwen2.5-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.</A>
										<DT><A HREF="https://arxiv.org/abs/2502.13923">[2502.13923] Qwen2.5-VL Technical Report</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>InternVL</H3>
								<DL><p>
									<DT><H3 FOLDED>InternVL-3</H3>
									<DL><p>
										<DT><A HREF="https://internvl.github.io/blog/2025-04-11-InternVL-3.0/">InternVL3</A>
									</DL><p>
									<DT><H3 FOLDED>InternVL3.5</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2508.18265">[2508.18265] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility, Reasoning, and Efficiency</A>
										<DT><A HREF="https://internvl.github.io/blog/2025-08-26-InternVL-3.5/">InternVL3.5</A>
										<DT><A HREF="https://x.com/gm8xx8/status/1960076908088922147">(1) ùöêùî™ùüæùö°ùö°ùüæ en X: "InternVL3.5-241B-A28B: 241B parameters ~28B active with Qwen3 and GPT-OSS backbone and InternViT-6B vision encoder. Part of the InternVL3.5 family spanning 1B to 241B, all trained with the same four-stage pipeline (CPT, SFT, CascadeRL, with ViCO added for Flash) They‚Äôre https://t.co/jjRRBf6e4c" / X</A>
										<DT><A HREF="https://huggingface.co/OpenGVLab/InternVL3_5-241B-A28B">OpenGVLab/InternVL3_5-241B-A28B ¬∑ Hugging Face</A>
									</DL><p>
									<DT><A HREF="https://github.com/InternLM/InternLM-XComposer">InternLM/InternLM-XComposer: InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output</A>
									<DT><A HREF="https://github.com/OpenGVLab/InternVL">OpenGVLab/InternVL: [CVPR 2024 Oral] InternVL Family: A Pioneering Open-Source Alternative to GPT-4o. Êé•ËøëGPT-4oË°®Áé∞ÁöÑÂèØÂïÜÁî®ÂºÄÊ∫êÂ§öÊ®°ÊÄÅÂØπËØùÊ®°Âûã</A>
									<DT><A HREF="https://github.com/InternLM/lmdeploy">InternLM/lmdeploy: LMDeploy is a toolkit for compressing, deploying, and serving LLMs.</A>
									<DT><A HREF="https://internvl.github.io/blog/2025-04-11-InternVL-3.0/">InternVL3</A>
								</DL><p>
								<DT><H3 FOLDED>cogVLM</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>Florence</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>grok-2</H3>
								<DL><p>
									<DT><A HREF="https://x.ai/blog/grok-2">Grok-2 Beta Release</A>
									<DT><A HREF="https://x.com/AlpinDale/status/1959359089953341906">(1) Alpin en X: "It would seem that grok-2 is now open-source. Taking a quick look at the arch, it seems to be mostly the same as grok-1, but with a few changes: - attention logits are scaled based on seqlen - residual MoE (moe and mlp outputs are combined) - tiktoken tokenizer https://t.co/3wTe2TRQLd" / X</A>
								</DL><p>
								<DT><A HREF="https://www.microsoft.com/en-us/research/publication/florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks - Microsoft Research</A>
								<DT><A HREF="https://www.youtube.com/watch?v=446QYqELoIs">Vision Language Models: PaLI-3 and COMM - YouTube</A>
								<DT><A HREF="https://x.com/huybery/status/1829187788153204776">Binyuan Hui en X: "Try our new Qwen2-VL: https://t.co/uyIeCOtRUa ‚ö†Ô∏è Three Secrets of Success for Qwen2-VL ‚ö†Ô∏è 1Ô∏è‚É£ A key architectural improvement in Qwen2-VL is the implementation of Naive Dynamic Resolution support. Unlike its predecessor, Qwen2-VL can handle arbitrary image resolutions, mapping https://t.co/QtokQgJcqT" / X</A>
								<DT><A HREF="https://x.com/A_K_Nain/status/1850719695164649929">(1) Aakash Kumar Nain en X: "With the Ferret-v2 paper, Apple demonstrated the power of building multimodal models for mobile devices. Now, Microsoft has done the same, but for the desktop UI. Presenting Omniparser, the latest advancement from Microsoft for vision-based multimodal workflows. Here is a summary https://t.co/ag6MCIk2Yd" / X</A>
								<DT><A HREF="https://github.com/PKU-YuanGroup/LLaVA-o1">PKU-YuanGroup/LLaVA-o1</A>
								<DT><A HREF="https://github.com/jingyaogong/minimind-v">jingyaogong/minimind-v: üöÄ „ÄåÂ§ßÊ®°Âûã„Äç1Â∞èÊó∂‰ªé0ËÆ≠ÁªÉ26MÂèÇÊï∞ÁöÑËßÜËßâÂ§öÊ®°ÊÄÅVLMÔºÅüåè Train a 26M-parameter VLM from scratch in just 1 hours!</A>
								<DT><A HREF="https://github.com/jingyaogong/minimind">jingyaogong/minimind: üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!</A>
								<DT><A HREF="https://x.com/vikhyatk/status/1925466306515804240">ablations at small scale  are a waste of time -&gt; few VLM ideas made a difference ater training &gt; 1M image-text pairs</A>
								<DT><A HREF="https://huggingface.co/BytedanceDouyinContent">BytedanceDouyinContent: SAIL-VL2</A>
								<DT><A HREF="https://moondream.ai/">Moondream</A>
							</DL><p>
							<DT><H3 FOLDED>GLM-4.1V-Thinking</H3>
							<DL><p>
								<DT><A HREF="https://github.com/THUDM/GLM-4.1V-Thinking">THUDM/GLM-4.1V-Thinking: GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning.</A>
								<DT><A HREF="https://arxiv.org/abs/2507.01006">[2507.01006] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning</A>
							</DL><p>
							<DT><H3 FOLDED>omniGen</H3>
							<DL><p>
								<DT><A HREF="https://github.com/VectorSpaceLab/OmniGen">VectorSpaceLab/OmniGen: OmniGen: Unified Image Generation. https://arxiv.org/pdf/2409.11340</A>
								<DT><A HREF="https://x.com/mtschannen/status/1863622784376586499">JetFormer</A>
								<DT><A HREF="https://huggingface.co/papers/2411.16318">Paper page - One Diffusion to Generate Them All</A>
							</DL><p>
							<DT><H3 FOLDED>adept labs</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/adept/fuyu-8b">adept/fuyu-8b ¬∑ Hugging Face</A>
								<DT><A HREF="https://www.adept.ai/">Adept: Useful General Intelligence</A>
								<DT><A HREF="https://www.adept.ai/blog/fuyu-8b">Fuyu-8B: A Multimodal Architecture for AI Agents</A>
								<DT><A HREF="https://www.adept.ai/blog/adept-fuyu-heavy">Adept Fuyu-Heavy: A new multimodal model</A>
								<DT><A HREF="https://www.adept.ai/blog/persimmon-8b">Releasing Persimmon-8B</A>
								<DT><A HREF="https://github.com/grahamannett/finetune-fuyu/blob/main/train-simple.py">finetune-fuyu/multimodal-train-simple.py</A>
							</DL><p>
							<DT><H3 FOLDED>LLaVA</H3>
							<DL><p>
								<DT><A HREF="https://github.com/haotian-liu/LLaVA#install">haotian-liu/LLaVA: [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond.</A>
							</DL><p>
							<DT><H3 FOLDED>multimodal-bytedance</H3>
							<DL><p>
								<DT><A HREF="https://github.com/bytedance/MoMA">bytedance/MoMA: MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation</A>
							</DL><p>
							<DT><H3 FOLDED>multimodal-data-sparsity</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ArmenAgha/status/2014428868636270885">one harsh realization was that standard architectures don't allocate compute intelligently across modalities</A>
								<DT><A HREF="https://www.perceptron.inc/blog/composing-weight-and-data-sparsity-in-moe">Composing Weight and Data Sparsity in MoE Improving compute efficiency through varying compute per token</A>
								<DT><A HREF="https://papers.perceptron.inc/data_sparsity.pdf">IMPROVING MOE COMPUTE EFFICIENCY BY COMPOSING WEIGHT AND DATA SPARSITY</A>
							</DL><p>
							<DT><H3 FOLDED>multimodal-mcp</H3>
							<DL><p>
								<DT><A HREF="https://wavespeed.ai/blog/posts/20250601">FLUX.1 Kontext MCP Global Premiere: Unlock Real-Time Multimodal Agent Power with One Click - WaveSpeedAI Blog</A>
							</DL><p>
							<DT><A HREF="https://huggingface.co/papers/2311.00571">Paper page - LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation, Generation and Editing</A>
							<DT><A HREF="https://www.youtube.com/watch?v=DTpKUnbkT_k">Multimodal Reasoning: PaLM-E &amp; Gemini - Aakanksha Chowdhery | Stanford MLSys #90 - YouTube</A>
							<DT><A HREF="https://arxiv.org/abs//2404.04125">[2404.04125] No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance</A>
							<DT><A HREF="https://github.com/xinyu1205/recognize-anything">xinyu1205/recognize-anything: Open-source and strong foundation image recognition models.</A>
							<DT><A HREF="https://github.com/mlfoundations/clip_quality_not_quantity">mlfoundations/clip_quality_not_quantity</A>
							<DT><A HREF="https://publications.reka.ai/reka-core-tech-report.pdf">Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models</A>
							<DT><A HREF="https://x.com/DrJimFan/status/1793318771932995793">(1) Jim Fan en X: "What makes up the abstract concept of an apple? We read the word "apple" as a string, see 2D pictures online, 3D shape in real life, and moving apples in videos. We touch the apple, feel its geometry in our palms and texture through the rich tactile sensation on our fingers. Do https://t.co/2LzxYa4f3N" / X</A>
							<DT><A HREF="https://x.com/Ethan_smith_20/status/1792024324464857197">(1) Ethan en X: "if you like this, you'll really like this https://t.co/NHgBACYxGT pretraining on text is merely an adequately challenging modality to learn computational primitives for universal transfer. there are other modalities which we can do causal modeling on and develop similar https://t.co/A8X0NRZpuP" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2103.05247">[2103.05247] Pretrained Transformers as Universal Computation Engines</A>
							<DT><A HREF="https://www.youtube.com/watch?v=IwYiETZEGY0">What does AI have to do with Plato's Allegory of the Cave? - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=IwYiETZEGY0&list=LL&index=11&t=25s">What does AI have to do with Plato's Allegory of the Cave? - YouTube</A>
							<DT><A HREF="https://arxiv.org/abs/2405.07987">[2405.07987] The Platonic Representation Hypothesis</A>
							<DT><A HREF="https://github.com/facebookresearch/ImageBind">facebookresearch/ImageBind: ImageBind One Embedding Space to Bind Them All</A>
							<DT><A HREF="https://x.com/olivierhenaff/status/1805995802352910557">multimodal dataset creation: joint example selection (JEST)</A>
							<DT><A HREF="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">BradyFU/Awesome-Multimodal-Large-Language-Models: :sparkles::sparkles:Latest Advances on Multimodal Large Language Models</A>
							<DT><A HREF="https://www.youtube.com/watch?v=vAmKB7iPkWw&list=LL&index=10&t=15s">Coding a Multimodal (Vision) Language Model from scratch in PyTorch with full explanation - YouTube</A>
							<DT><A HREF="https://x.com/_weiping/status/1836226447863877837">NVLM</A>
							<DT><A HREF="https://x.com/songhan_mit/status/1849109966898008133">VILA-U: multi-modal token in, multi-modal token out, single autoregresive</A>
							<DT><A HREF="https://github.com/PKU-YuanGroup/LLaVA-o1">PKU-YuanGroup/LLaVA-o1</A>
							<DT><A HREF="https://arxiv.org/abs/2412.14164">[2412.14164] MetaMorph: Multimodal Understanding and Generation via Instruction Tuning</A>
							<DT><A HREF="https://x.com/wenhaocha1/status/2000274974855372870">(1) Wenhao Chai en X: "I believe that long-context multimodal modeling is a key path toward making advanced AI (whether AGI or ASI) truly useful for everyone. Today we are closer than ever, but major challenges remain. Broadly, I see two core problems: encoding and decoding. Encoding. An AI system" / X</A>
						</DL><p>
						<DT><H3 FOLDED>DeepSeek</H3>
						<DL><p>
							<DT><H3 FOLDED>deepseek-people</H3>
							<DL><p>
								<DT><A HREF="https://scholar.google.com/citations?user=1s79Z5cAAAAJ&hl=zh-CN">‚Ä™Fuli LuoÔºàÁΩóÁ¶èËéâÔºâ‚Ä¨ - ‚Ä™Google Â≠¶ÊúØÊêúÁ¥¢‚Ä¨</A>
							</DL><p>
							<DT><H3 FOLDED>dpsk-v3.2</H3>
							<DL><p>
								<DT><H3 FOLDED>DSA</H3>
								<DL><p>
									<DT><A HREF="https://nathanchen.me/public/Flash-Attention-Tilelang.html">Implementing Flash Attention in TileLang (1.3x Faster Than FA-2): Part 1</A>
									<DT><A HREF="https://github.com/tile-ai/tilelang">tile-ai/tilelang: Domain-specific language designed to streamline the development of high-performance GPU/CPU/Accelerators kernels</A>
									<DT><A HREF="https://x.com/YouJiacheng/status/1972614232228425957">(Jiacheng) As expected, NSA is not compatible with MLA, so DeepSeek chose another method: use a smaller (d=128) attention (w/o value) as the indexer.</A>
									<DT><A HREF="https://x.com/kriztalzmuse/status/1972598225816469608">V3.2 MQA kernels for the indexer</A>
									<DT><A HREF="https://kexue.fm/archives/10091">The ultimate tug-of-war between cache and effects: from MHA, MQA, GQA</A>
									<DT><A HREF="https://x.com/vllm_project/status/1972617272901644345">How does @deepseek_ai Sparse Attention (DSA) work?</A>
									<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/blob/main/docs/20250929-hopper-fp8-sparse-deep-dive.md">FlashMLA/docs/20250929-hopper-fp8-sparse-deep-dive.md at main ¬∑ deepseek-ai/FlashMLA</A>
									<DT><A HREF="https://x.com/_xjdr/status/1972680858835488892">(1) xjdr en X: "first set of thoughts after quickly reading: DSA feels like a small step in between MLA -&amp;gt; and NSA's selection approach. While the DSA sparsity is interesting from a efficiency standpoint, i am more interested in its actual pure performance. Attention activation is something that" / X</A>
									<DT><A HREF="https://x.com/awnihannun/status/1972763521185436088">DSA simle sketch derivation</A>
									<DT><A HREF="https://www.zhihu.com/question/1956137082197083536/answer/1956300827774935213">Why dpskv3.2 is exciting for both sparse attn and linear attn</A>
									<DT><A HREF="https://x.com/JingyuanLiu123/status/1972896110424576021">(1) JingyuanLiu en X: "https://t.co/mxn8tCLTWH Why dpskv3.2 is exciting for both sparse attn and linear attn communities from @SonglinYang4 (Alert: this is in Chinese) the basic summary is: 1. after all, though swa and linear attn are popular, it is still hard to get rid of the full attn layer for" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2502.13189">[2502.13189] MoBA: Mixture of Block Attention for Long-Context LLMs</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1973209017603465324">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "As @_xjdr says this is not yet profiled fully but we can provisionally accept that DSA had just enabled 1M contexts for ‚âàeveryone. Some "prototype", hah. They always underhype their work. Btw, you can drop "sparse". Just DeepSeek Attention, it's cleaner. https://t.co/xkF7KmqdoT" / X</A>
									<DT><A HREF="https://x.com/_xjdr/status/1973195881387270461">(1) xjdr en X: "from what i can see, DSA has no measurable degradation in performance compared to MLA (its usually better) even on very long context. The whale cooked once again" / X</A>
									<DT><A HREF="https://x.com/nekofneko/status/1974172979639779570">(1) Rookie en X: "Many people are curious about the performance of Whale's new model on long texts. I conducted a comparative test between DeepSeek-V3.1-Terminus and DeepSeek-V3.2-Exp under the OpenAI mrcr-2needle. The detailed logs of both models' responses will be open-sourced tomorrow. https://t.co/5YC6pPXUX0" / X</A>
									<DT><A HREF="https://github.com/PaperPlaneDeemo/deepseek-mrcr">PaperPlaneDeemo/deepseek-mrcr</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1975973344672245268">DSA vs NSA &amp; DSAÁ®ÄÁñèËÆ≠ÁªÉÁÆóÂ≠êÂÆûÁé∞(TileLang) - Áü•‰πé</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Y-o545eYjXM">How Attention Got So Efficient [GQA/MLA/DSA] - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>dpsk-v3.2-speciale</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/deepseek-ai/DeepSeek-V3.2/blob/main/assets/paper.pdf">assets/paper.pdf ¬∑ deepseek-ai/DeepSeek-V3.2 at main</A>
								</DL><p>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf">DeepSeek-V3.2-Exp/DeepSeek_V3_2.pdf at main ¬∑ deepseek-ai/DeepSeek-V3.2-Exp</A>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V3.2-Exp">deepseek-ai/DeepSeek-V3.2-Exp</A>
								<DT><A HREF="https://x.com/jingyuanliu123/status/1972896110424576021">(1) JingyuanLiu en X: "https://t.co/mxn8tCLTWH Why dpskv3.2 is exciting for both sparse attn and linear attn communities from @SonglinYang4 (Alert: this is in Chinese) the basic summary is: 1. after all, though swa and linear attn are popular, it is still hard to get rid of the full attn layer for" / X</A>
								<DT><A HREF="https://www.zhihu.com/question/1956137082197083536/answer/1956300827774935213">Why dpskv3.2 is exciting for both sparse attn and linear attn communities</A>
							</DL><p>
							<DT><H3 FOLDED>deepseek-infra</H3>
							<DL><p>
								<DT><H3 FOLDED>dpsk-inference-engine</H3>
								<DL><p>
									<DT><H3 FOLDED>deepseek-vllm</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/open-infra-index/blob/main/OpenSourcing_DeepSeek_Inference_Engine/README.md">open-infra-index/OpenSourcing_DeepSeek_Inference_Engine/README.md at main ¬∑ deepseek-ai/open-infra-index</A>
									<DT><A HREF="https://github.com/zartbot/shallowsim">zartbot/shallowsim: DeepSeek-V3/R1 inference performance simulator</A>
								</DL><p>
								<DT><H3 FOLDED>DeepEP</H3>
								<DL><p>
									<DT><H3 FOLDED>deepEP-profiling</H3>
									<DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/DeepEP/pull/239">Support displaying separate send and recv time by fzyzcjy ¬∑ Pull Request #239 ¬∑ deepseek-ai/DeepEP</A>
										<DT><A HREF="https://github.com/fzyzcjy/DeepEP/blob/a9603352a2efaf1ec860032ab15107b1f3887fd9/tests/utils.py">DeepEP/tests/utils.py</A>
										<DT><A HREF="https://github.com/deepseek-ai/DeepEP/pull/239/files">prof.export_chrome_trace(tmp.name)</A>
									</DL><p>
									<DT><H3 FOLDED>DeepEP-install</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/docker/Dockerfile">sglang/docker/Dockerfile at main ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/DeepEP">deepseek-ai/DeepEP: DeepEP: an efficient expert-parallel communication library</A>
									<DT><A HREF="https://mp.weixin.qq.com/s/WFJxnTF9fGIIXPA7GQ5V2w">DeepSeek V3 MoE Expert Parallelism</A>
									<DT><A HREF="https://chatgpt.com/c/67af31b2-c114-800c-b939-3ba7a9477731">MoE EP320 Efficiency in Torch</A>
									<DT><A HREF="https://nvidia.github.io/TensorRT-LLM/advanced/expert-parallelism.html">Expert Parallelism in TensorRT-LLM ‚Äî tensorrt_llm documentation</A>
									<DT><A HREF="https://www.youtube.com/watch?v=upZf-BWF1i0">George Hotz | mixture of experts (like deepseek) on tinygrad sovereign AMD stack | AMD YOLO - YouTube</A>
									<DT><A HREF="https://github.com/Infrawaves/DeepEP_ibrc_dual-ports_multiQP">Infrawaves/DeepEP_ibrc_dual-ports_multiQP: Aims to implement dual-port and multi-qp solutions in deepEP ibrc transport</A>
									<DT><A HREF="https://github.com/KuangjuX/AttnLink">KuangjuX/AttnLink: :construction: An experimental communicating attention kernel based on DeepEP.</A>
									<DT><A HREF="https://github.com/KuangjuX/NVSHMEM-Tutorial">KuangjuX/NVSHMEM-Tutorial: NVSHMEM‚ÄëTutorial: Build a DeepEP‚Äëlike GPU Buffer</A>
									<DT><A HREF="https://arxiv.org/abs/2510.27656">[2510.27656] RDMA Point-to-Point Communication for LLM Systems</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1961841132536338098">Expert as a Service (EaaS) Explained: Efficient Communication Implementation for Inference in Large-Scale DeepSeek-like MoE Models and Some Random Thoughts</A>
									<DT><A HREF="https://github.com/viralbhadeshiya/Research-docs/blob/main/DeepEP-Communication/internode_communication_flow.md">Research-docs/DeepEP-Communication/internode_communication_flow.md at main ¬∑ viralbhadeshiya/Research-docs</A>
									<DT><A HREF="https://github.com/deepseek-ai/DeepEP/blob/92fe2deaec24bc92ebd9de276daa6ca9ed602ed4/tests/test_internode.py#L4">DeepEP/tests/test_internode.py at 92fe2deaec24bc92ebd9de276daa6ca9ed602ed4 ¬∑ deepseek-ai/DeepEP</A>
									<DT><A HREF="https://x.com/_xjdr/status/2001436350634168737">(1) xjdr en X: "On RD/EP: in a MoE you have a bunch of mlps (‚Äúexperts‚Äù), and a router that picks a few experts per token (top‚Äëk). you only run those experts. the catch is that the router shatters your batch. instead of one big matmul (what gpus love), you get E little matmuls (one per expert)," / X</A>
									<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/0939a052893b29e458aad73d91316cf4f2275c5e/large-language-model-note/DeepEP%EF%BC%9A%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.md">how-to-optim-algorithm-in-cuda/large-language-model-note/DeepEPÔºö‰ªãÁªç‰∏éÊúÄ‰Ω≥ÂÆûË∑µ.md at 0939a052893b29e458aad73d91316cf4f2275c5e ¬∑ BBuf/how-to-optim-algorithm-in-cuda</A>
									<DT><A HREF="https://uccl-project.github.io/posts/uccl-ep/">Previewing UCCL-EP: Flexible and Efficient Expert Parallelism for Cloud and Beyond</A>
									<DT><A HREF="https://github.com/uccl-project/uccl/tree/main/ep">uccl/ep at main ¬∑ uccl-project/uccl</A>
									<DT><A HREF="https://nousresearch.com/moe-scaling-field-notes/">Foundation MoE Training Worklogs Part 1 - NOUS RESEARCH</A>
								</DL><p>
								<DT><H3 FOLDED>deepseek-cost-model</H3>
								<DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/open-infra-index/blob/main/202502OpenSourceWeek/day_6_one_more_thing_deepseekV3R1_inference_system_overview.md">open-infra-index/202502OpenSourceWeek/day_6_one_more_thing_deepseekV3R1_inference_system_overview.md at main ¬∑ deepseek-ai/open-infra-index</A>
								</DL><p>
								<DT><A HREF="https://github.com/deepseek-ai/open-infra-index?tab=readme-ov-file">deepseek-ai/open-infra-index</A>
								<DT><A HREF="https://github.com/deepseek-ai/smallpond">deepseek-ai/smallpond: A lightweight data processing framework built on DuckDB and 3FS.</A>
								<DT><A HREF="http://sortbenchmark.org/2014_06_CloudSort_v_0_4.pdf">CloudSort: A TCO Sort Benchmark Microsoft</A>
								<DT><A HREF="https://arxiv.org/pdf/2505.09343v1">Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures</A>
								<DT><A HREF="https://www.tensoreconomics.com/p/moe-inference-economics-from-first">MoE Inference Economics from First Principles</A>
								<DT><A HREF="https://x.com/JingyuanLiu123/status/1959093411283443726">(1) JingyuanLiu en X: "i was literally shocked by the huge llm infra diff in US vs China and GPU vs TPU... I was chatting with senior folks about how global batch aux loss is hard under the ppvp constrain, as basically you have to do all f all b to get the fi correct and that's challenging for peak</A>
								<DT><A HREF="https://github.com/shenh10/DeepSeek_Simulator">shenh10/DeepSeek_Simulator</A>
								<DT><A HREF="https://x.com/difficultyang/status/1980330978158735851">(1) difficultyang en X: "The more I learn about DSv3 training the more I realize how completely insane it is" / X</A>
								<DT><A HREF="https://www.bilibili.com/video/BV1mpMwz9Ey5/">FP8 Training Recipes, Performance and Convergence. A video in Chinese introduces FP8 training recipes, performance and convergence.</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/">Stable and Scalable FP8 Deep Learning Training on Blackwell S72778 | GTC 2025 | NVIDIA On-Demand</A>
								<DT><A HREF="https://github.com/pytorch/ao/issues/3290">FP8 Blockwise Training Tracker ¬∑ Issue #3290 ¬∑ pytorch/ao</A>
								<DT><A HREF="https://x.com/_xjdr/status/2001455303347593614">xjdr en X: "TL;DR with the nmoe repo and architecture: I can do actual nvfp4 native 16B param model training on a single 8xB200 node and can do full training run (~7T tokens) on less than 128 GPUs in ~30 days (including the data pipeline) Projected out, this means I could theoretically do a" / X</A>
								<DT><A HREF="https://x.com/cHHillee/status/1959112887743783166">Horace He, JingyuanLiu123: This is the advantage of large nvlink domains or TPUs topology - the main reason to do PP is that you are bottlenecked on your DP comms and cannot scale TP further. But if you have high enough bandwidth across a large enough domain (like TPUs or NVL72), you don't need to do PP" / X</A>
							</DL><p>
							<DT><H3 FOLDED>dpsk-r1</H3>
							<DL><p>
								<DT><H3 FOLDED>deepseek-rl</H3>
								<DL><p>
									<DT><A HREF="https://yugeten.github.io/posts/2025/01/ppogrpo/">A vision researcher‚Äôs guide to some RL stuff: PPO &amp; GRPO - Yuge (Jimmy) Shi</A>
								</DL><p>
								<DT><H3 FOLDED>GRPO</H3>
								<DL><p>
									<DT><A HREF="https://www.k-a.in/grpo.html">GRPO</A>
									<DT><A HREF="https://yugeten.github.io/posts/2025/01/ppogrpo/">A vision researcher‚Äôs guide to some RL stuff: PPO &amp; GRPO - Yuge (Jimmy) Shi</A>
									<DT><A HREF="https://github.com/goddoe/RLYX">goddoe/RLYX: A hackable, simple, and reseach-friendly GRPO Training Framework with high speed weight synchronization in a multinode environment.</A>
									<DT><A HREF="https://arxiv.org/pdf/2503.20783">Understanding R1-Zero-Like Training: A Critical Perspective</A>
									<DT><A HREF="https://x.com/hemuyu0327/status/2000420585004998773">(1) Muyu He en X: "As I want to understand how @deepseek_ai v3.2 "fixed" GRPO, I break down the math behind the KL term. What is in the original GRPO: the DS math/R1 papers borrowed what @johnschulman2 calls the k3 estimator. Starting from the true KL term (in green square, "the k1 estimator") https://t.co/aIcRZ5zX5G" / X</A>
									<DT><A HREF="https://x.com/gabriberton/status/1999297082465878334">(1) Gabriele Berton en X: "NeurIPS 2025 paper by the Qwen team: Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning TLDR: in GRPO-like RLVR you should apply the loss only to the 20% highest entropy tokens. [1/7] https://t.co/049rZ3FSdo" / X</A>
									<DT><A HREF="https://x.com/semianalysis_/status/2014760411048870102">GRPO treats a token as an action and computes importance sampling ratio at the token level. For loss aggregation, GRPO first averages across tokens in a ample, then averages across the group.</A>
									<DT><A HREF="https://yumoxu.notion.site/async-grpo-in-the-wild">Async GRPO in the Wild</A>
								</DL><p>
								<DT><H3 FOLDED>QwQ</H3>
								<DL><p>
									<DT><A HREF="https://qwenlm.github.io/blog/qwq-32b-preview/">QwQ: Reflect Deeply on the Boundaries of the Unknown | Qwen</A>
								</DL><p>
								<DT><H3 FOLDED>alibaba-Marco-o1</H3>
								<DL><p>
									<DT><A HREF="https://github.com/AIDC-AI/Marco-o1">AIDC-AI/Marco-o1: An Open Large Reasoning Model for Real-World Solutions</A>
									<DT><A HREF="https://arxiv.org/abs/2411.14405">[2411.14405] Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2501.12948">[2501.12948] DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</A>
								<DT><A HREF="https://x.com/zizhpan/status/1859196598871277856">deepseek reassoning</A>
								<DT><A HREF="https://x.com/_xjdr/status/1859272181844422813">(1) xjdr en X: "whalebros cooked here. Not only does it seem to replicate the o1-preview results, it seems to pretty effectively replicate (at least parts of) the process. My guess is it uses something very similar to the lets verify step-by-step ORMs / PRMs to train and reward the the CoT in" / X</A>
								<DT><A HREF="https://x.com/deepseek_ai/status/1859200141355536422">DeepSeek-R1-Lite-Preview</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1859874409894511092">(1) Simo Ryu en X: "Well deepseek hype is real They both got roughly right but deepseek was better https://t.co/qhHc4KeYjm" / X</A>
								<DT><A HREF="https://x.com/natolambert/status/1859643355698786549">(1) Nathan Lambert en X: "Right to the fun stuff. To finish our models, we use a new technique called Reinforcement Learning with Verifiable Rewards, where we train on math problems or prompts with constraints, and only reward the algorithm if the generation is correct. We find this improves performance https://t.co/iViDGmgRBB" / X</A>
								<DT><A HREF="https://chat.deepseek.com/">DeepSeek - Into the Unknown</A>
								<DT><A HREF="https://x.com/cloneofsimo/status/1861153771159724457">(1) Simo Ryu en X: "Wait o1 mightve been this work all along? https://t.co/7JFjtXnJo8 https://t.co/PRAi2b8Yi9" / X</A>
								<DT><A HREF="https://x.com/edwardjhu">(1) Edward Hu (@edwardjhu) / X</A>
								<DT><A HREF="https://cdn.openai.com/o1-system-card-20241205.pdf">https://cdn.openai.com/o1-system-card-20241205.pdf</A>
								<DT><A HREF="https://x.com/zhyncs42/status/1881246950663901454">DeepSeek-R1 released (21/01/25)</A>
								<DT><A HREF="https://huggingface.co/deepseek-ai/DeepSeek-R1/tree/main">deepseek-ai/DeepSeek-R1 at main</A>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-R1">deepseek-ai/DeepSeek-R1</A>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf">DeepSeek-R1/DeepSeek_R1.pdf at main ¬∑ deepseek-ai/DeepSeek-R1</A>
								<DT><A HREF="https://github.com/facebookresearch/coconut">facebookresearch/coconut: Training Large Language Model to Reason in a Continuous Latent Space</A>
								<DT><A HREF="https://github.com/feifeibear/DPSKV3MFU/blob/main/dpskv3_flops.py">DPSKV3MFU/dpskv3_flops.py at main ¬∑ feifeibear/DPSKV3MFU</A>
								<DT><A HREF="https://github.com/ganler/code-r1">ganler/code-r1: Reproducing R1 for Code with Reliable Rewards</A>
								<DT><A HREF="https://github.com/sail-sg/understand-r1-zero">sail-sg/understand-r1-zero: Understanding R1-Zero-Like Training: A Critical Perspective</A>
								<DT><A HREF="https://www.nature.com/articles/s41586-025-09422-z">DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning | Nature</A>
								<DT><A HREF="https://arxiv.org/pdf/2503.20783">Understanding R1-Zero-Like Training: A Critical Perspective</A>
								<DT><A HREF="https://x.com/jiqizhixin/status/2008805570145644849">(1) Êú∫Âô®‰πãÂøÉ JIQIZHIXIN en X: "DeepSeek-R1‚Äôs paper was updated 2 days ago, expanding from 22 pages to 86 pages and adding a substantial amount of detail. The new content covers topics such as the self-evolution of DeepSeek-R1-Zero, evaluation of DeepSeek-R1, further analysis, and DeepSeek-R1 distillation. https://t.co/zA4RnBybgj" / X</A>
							</DL><p>
							<DT><H3 FOLDED>dpsk-v3</H3>
							<DL><p>
								<DT><H3 FOLDED>dpsk-moe</H3>
								<DL><p>
									<DT><A HREF="https://github.com/zartbot/blog/issues/1">Discuss the technological evolution related to DeepSeek¬†MoE ¬∑ Issue #1 ¬∑ zartbot/blog</A>
									<DT><A HREF="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUxNzQ5MTExNw==&action=getalbum&album_id=3210156532718403586#wechat_redirect">Â§ßÊ®°ÂûãÊï∞Â≠¶Âü∫Á°Ä</A>
									<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247494744&idx=1&sn=20f307c5e0fe7c5c5d62a46d81f48646&chksm=f995fc9acee2758c9a03a17f7feea8a7b0db439b42f504305cc4b5db22e64feacb30904344ca&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Zarbot Let's discuss some of the evolutions of Transformer: UT, MoD, MoR...</A>
									<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247493157&idx=1&sn=51c0e27a347dd3fe1ed868d87f667897&chksm=f995f6e7cee27ff1a95d59aefe6bcf4117115343b301dddcc3ea7646dfeb61b582a90d507a16&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Zarbot Let's discuss in detail the technological development of DeepSeek MoE.</A>
								</DL><p>
								<DT><H3 FOLDED>dpsk-v3-architecture</H3>
								<DL><p>
									<DT><A HREF="https://bench.flashinfer.ai/models/deepseek-v3">DeepSeek V3/R1 Architecture Overview</A>
									<DT><A HREF="https://www.drawio.com/">The architecture is shown below (drawio provided)</A>
									<DT><A HREF="https://github.com/zartbot/blog/issues/1">Discuss the technological evolution related to DeepSeek¬†MoE ¬∑ Issue #1 ¬∑ zartbot/blog</A>
								</DL><p>
								<DT><H3 FOLDED>dpsk-v3-inference</H3>
								<DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V3/blob/4cc6253d5c225e2c5fea32c54573449c1c46470a/inference/generate.py#L140">DeepSeek-V3/inference/generate.py</A>
									<DT><A HREF="https://x.com/GenAI_is_real/status/2016042118150766713">(1) Chayenne Zhao en X: "kimi k2.5 just dropped and the agent swarm beta is actually insane. 1,500 tool calls at 4.5x speed? openai is still trying to get o1 to follow simple instructions while moonshot is literally building an autonomous workforce. hle 50.2% is the new ceiling. if you aren't thinking" / X</A>
								</DL><p>
								<DT><H3 FOLDED>dpsk-v3-sft</H3>
								<DL><p>
									<DT><A HREF="https://github.com/character-ai/pipelining-sft">character-ai/pipelining-sft: Simple and efficient DeepSeek V3 SFT using pipeline parallel and expert parallel, with both FP8 and BF16 trainings</A>
								</DL><p>
								<DT><H3 FOLDED>dpsk-v3-mfu</H3>
								<DL><p>
									<DT><A HREF="https://github.com/feifeibear/DPSKV3MFU/blob/main/dpskv3_flops.py">DPSKV3MFU/dpskv3_flops.py at main ¬∑ feifeibear/DPSKV3MFU</A>
									<DT><A HREF="https://github.com/GHGmc2/deepseek-projection">GHGmc2/deepseek-projection: DeepSeek-V2/V3 projection of num_params, FLOPs and MFU.</A>
									<DT><A HREF="https://gist.github.com/YouJiacheng/10b91c7b48ac8939b028180744826c54">based on https://github.com/feifeibear/DPSKV3MFU</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/16480858047">‰πüÁÆó‰∏Ä‰∏ãDeepSeek-V3ÁöÑMFU - Áü•‰πé</A>
									<DT><A HREF="https://x.com/reinerpope/status/1884056513628819716">Reiner Pope en X: "*Technical followup on MFU. DeepSeek doesn‚Äôt report MFU. I calculated it as (6*activated params * tokens)/(GPU hours * hardware flops/s): (6*37e9*14.8e12)/(2.788e6 hours * 2e15/s) = 16.3%. The same methodology applied to Llama3 405B gives (6*405e9*15e12)/(30.8e6 hours * 1e15/s)" / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V3">deepseek-ai/DeepSeek-V3</A>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf">DeepSeek-V3/DeepSeek_V3.pdf at main ¬∑ deepseek-ai/DeepSeek-V3</A>
								<DT><A HREF="https://x.com/_xjdr/status/1873074545818812911">xjdr en X: "i think the optimal way to run DSv3 at scale is have the experts on an 8xH100 machine and then the rest of the layers on their own H100. You could then theoretically have 2 DGX machines with 8 instances of the model running and then load balancing to the expert machines over IB." / X</A>
								<DT><A HREF="https://x.com/srush_nlp/status/1876640795765379531">LLM Infrastructure, pages 12-18</A>
								<DT><A HREF="https://www.youtube.com/watch?v=8v2l6SJECW4">DeepSeek-V3 - YouTube</A>
								<DT><A HREF="https://github.com/danielvegamyhre/ml-perf-reading-group/tree/main/session_7">ml-perf-reading-group/session_7 at main ¬∑ danielvegamyhre/ml-perf-reading-group</A>
								<DT><A HREF="https://mp.weixin.qq.com/s/WFJxnTF9fGIIXPA7GQ5V2w">DeepSeek V3 MoE Expert Parallelism</A>
								<DT><A HREF="https://www.youtube.com/watch?v=4YC8LsuFe7s">Understand DeepSeek V3 From Scratch | Full Course - YouTube</A>
								<DT><A HREF="https://huggingface.co/unsloth/DeepSeek-V3-bf16">unsloth/DeepSeek-V3-bf16 weights</A>
								<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/02/23/eleutherai-reading-group-session-7.html">DeepSeek V3 | ML Perf Notes</A>
								<DT><A HREF="https://arxiv.org/abs/2507.17702">[2507.17702] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts Language Models</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/27292649125">DeepSeek V3/R1 Êé®ÁêÜÊïàÁéáÂàÜÊûêÔºà1ÔºâÔºöÂÖ≥‰∫éDeepSeek V3/R1 DecodingÂêûÂêêÊûÅÈôêÁöÑ‰∏Ä‰∫õ‰∏çË¥üË¥£‰ªª‰º∞ËÆ° - Áü•‰πé</A>
							</DL><p>
							<DT><H3 FOLDED>dpsk-v2</H3>
							<DL><p>
								<DT><A HREF="https://x.com/_xjdr/status/1838248197531279640">DeepSeek reference implemetation</A>
								<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/main/mla/modeling_deepseek.py">deepseekv2-profile/mla/modeling_deepseek.py at main ¬∑ madsys-dev/deepseekv2-profile</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/700214123?utm_psn=1779287628619632640">DeepSeek-V2 È´òÊÄßËÉΩÊé®ÁêÜ (1)ÔºöÈÄöËøáÁü©ÈòµÂê∏Êî∂ÂçÅÂÄçÊèêÈÄü MLA ÁÆóÂ≠ê - Áü•‰πé</A>
							</DL><p>
							<DT><H3 FOLDED>dpsk-moe-fine-tuning</H3>
							<DL><p>
								<DT><H3 FOLDED>ESFT</H3>
								<DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/ESFT">deepseek-ai/ESFT: Expert Specialized Fine-Tuning</A>
									<DT><A HREF="https://arxiv.org/pdf/2407.01906">Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models</A>
								</DL><p>
								<DT><H3 FOLDED>DenseMixer</H3>
								<DL><p>
									<DT><A HREF="https://x.com/fengyao1909/status/1940146697075925476">an MoE post-training method that offers more ùê©ùê´ùêûùêúùê¢ùê¨ùêû ùê´ùê®ùêÆùê≠ùêûùê´ ùê†ùê´ùêöùêùùê¢ùêûùêßùê≠</A>
									<DT><A HREF="https://fengyao.notion.site/moe-posttraining">üé® DenseMixer: Improving MoE Post-Training with Precise Router Gradient | Notion</A>
									<DT><A HREF="https://github.com/yaof20/DenseMixer">yaof20/DenseMixer: Official implementation for DenseMixer: Improving MoE Post-Training with Precise Router Gradient</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>dpsk-claude-code</H3>
							<DL><p>
								<DT><H3 FOLDED>deepseek-api</H3>
								<DL><p>
									<DT><A HREF="https://api-docs.deepseek.com/">Your First API Call | DeepSeek API Docs</A>
								</DL><p>
								<DT><A HREF="https://api-docs.deepseek.com/guides/anthropic_api">Anthropic API | DeepSeek API Docs</A>
							</DL><p>
							<DT><H3 FOLDED>mHC</H3>
							<DL><p>
								<DT><H3 FOLDED>Hyper-Connections</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2409.19606">[2409.19606] Hyper-Connections</A>
								</DL><p>
								<DT><A HREF="https://x.com/YouJiacheng/status/2006968360471601287">Multiple Input Multiple Output (MIMO) system</A>
								<DT><A HREF="https://x.com/YouJiacheng/status/2006966886639219127">v2: and MoE routers can be viewed as a sparse communication channel.</A>
								<DT><A HREF="https://x.com/YouJiacheng/status/2006966294042788085">My final-v1 thought about it.</A>
								<DT><A HREF="https://x.com/YouJiacheng/status/2006961742681985497">The whole purpose of expanding model dim is to diversify the communication channel between layers.</A>
								<DT><A HREF="https://research.google/blog/alternating-updates-for-efficient-transformers/">Alternating updates for efficient transformers</A>
								<DT><A HREF="https://github.com/AndreSlavescu/mHC.cu">AndreSlavescu/mHC.cu: mHC kernels implemented in CUDA</A>
								<DT><A HREF="https://x.com/mufan_li/status/2006748995201159441">known depth scaling to avoid this. E.g. downscale the res-block or shape the non-linearities. I wish I had more reach at times</A>
								<DT><A HREF="https://x.com/norxornor/status/2006649194690257285">You want to increase residual size from 1√óC to n√óC (n streams instead of 1).</A>
								<DT><A HREF="https://x.com/Dorialexander/status/2006680750230249839">mHC notes</A>
								<DT><A HREF="https://arxiv.org/abs/2512.24880">[2512.24880] mHC: Manifold-Constrained Hyper-Connections</A>
								<DT><A HREF="https://x.com/chensun92/status/2014612341082751073?s=12">(1) Chen Sun ü§ñ en X: "DeepSeek's Engram succeeds where others failed in this endeavor to replace a transformer's crappy FFN with a symbolic-ish lookup table. And in the process, it reveals what I think is a truly gorgeous, monumental even, paradigm shift in our understanding of transformer capability https://t.co/DvqbMvHAD7" / X</A>
								<DT><A HREF="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzUxNzQ5MTExNw==&action=getalbum&album_id=3210156532718403586#wechat_redirect">Â§ßÊ®°ÂûãÊï∞Â≠¶Âü∫Á°Ä</A>
								<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247497138&idx=1&sn=8215a15d8e196d412ab908ec3302c857&chksm=f995e570cee26c66841bfa4f7e7c39ed2e8bccf3ca71f021894431a4fda95dd41ec6572ca175&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Let's talk about DeepSeek mHC</A>
								<DT><A HREF="https://taylorkolasinski.com/notes/mhc-reproduction-part2/">10,924x: The Instability Bomb at 1.7B Scale - Taylor Kolasinski</A>
								<DT><A HREF="https://x.com/giffmana/status/2012248488428355711">mhc + canon + engram</A>
								<DT><A HREF="https://www.youtube.com/watch?v=jYn_1PpRzxI">How Residual Connections Are Getting an Upgrade [mHC] - YouTube</A>
								<DT><A HREF="https://www.zhihu.com/question/1995200812075480347/answer/1995926034290321405">How should we evaluate the relationship between DeepSeek's latest "conditional memory" and ByteSeed's "over-encoding"?</A>
							</DL><p>
							<DT><H3 FOLDED>dpsk-engram</H3>
							<DL><p>
								<DT><A HREF="https://github.com/deepseek-ai/Engram/blob/main/engram_demo_v1.py">Engram/engram_demo_v1.py at main ¬∑ deepseek-ai/Engram</A>
								<DT><A HREF="https://www.zhihu.com/question/1994233409871050526/answer/1994354520864600584">How would you evaluate DeepSeek's publication of the paper authored by Liang Wenfeng, which proposes "conditional memory" and an engram memory retrieval architecture? What are its highlights?</A>
								<DT><A HREF="https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf">Engram/Engram_paper.pdf at main ¬∑ deepseek-ai/Engram</A>
								<DT><A HREF="https://github.com/deepseek-ai/Engram">deepseek-ai/Engram: Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models</A>
								<DT><A HREF="https://www.drawio.com/">The architecture is shown below (drawio provided)</A>
								<DT><A HREF="https://x.com/nathancgy4/status/2010759368242053423">tl;dr intuition for why Engram works:
It is not because the model 'memorized the answers,' but because Engram handles rote memorization, so attention can focus on processing complex logical dependencies.</A>
								<DT><A HREF="https://x.com/ziv_ravid/status/2012244873936592991">The problem they're solving is how to process things we already know more efficiently</A>
								<DT><A HREF="https://x.com/_xjdr/status/2011136386141970549">xjdr en X: "ok so: engram is moe over ngramed memory mHC is moe over the residual stream NSA is moe over attention MoE is moe over FFNs ... im sensing a theme ...." / X</A>
								<DT><A HREF="https://x.com/_xjdr/status/2011112325605155118/photo/2">Detailed Model Architecture and Hyper Parameters enegram</A>
								<DT><A HREF="https://x.com/eliebakouch/status/2010866010182562273">Engram: conditional memory via scalable lookup, visual recap</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/2010907977927311697">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Rant: I feel the opposite, and imo it goes to illustrate Whale philosophy. Most of their work can feel like janky engineering. Decoupled RoPE in MLA, really? They don't care about diagram elegance. Infra is a means to an end. They can't afford cute efficient models that won't https://t.co/r5u7DZx53u" / X</A>
								<DT><A HREF="https://x.com/YouJiacheng/status/2010769228949856465">Over-Tokenized Transformer(BD)‚ÜíEngram(DS)</A>
							</DL><p>
							<DT><A HREF="https://github.com/deepseek-ai/open-infra-index/blob/main/OpenSourcing_DeepSeek_Inference_Engine/README.md">open-infra-index/OpenSourcing_DeepSeek_Inference_Engine/README.md at main ¬∑ deepseek-ai/open-infra-index</A>
							<DT><A HREF="https://arxiv.org/abs/2401.02954">[2401.02954] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism ( LLM (hyperparams, dataset basics))</A>
							<DT><A HREF="https://arxiv.org/abs/2401.14196">[2401.14196] DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence (Coder (data engineering, continued pretraining)</A>
							<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf">DeepSeek-Coder-V2/paper.pdf at main ¬∑ deepseek-ai/DeepSeek-Coder-V2</A>
							<DT><A HREF="https://arxiv.org/abs/2401.06066">[2401.06066] DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models (Fine-grained MoE (architecture design)</A>
							<DT><A HREF="https://arxiv.org/abs/2402.03300">[2402.03300] DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models (Math (better data, RL)</A>
							<DT><A HREF="https://arxiv.org/abs/2403.05525">[2403.05525] DeepSeek-VL: Towards Real-World Vision-Language Understanding (VL (multimodality)</A>
							<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-VL">deepseek-ai/DeepSeek-VL: DeepSeek-VL: Towards Real-World Vision-Language Understanding</A>
							<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V2/blob/main/deepseek-v2-tech-report.pdf">DeepSeek-V2/deepseek-v2-tech-report.pdf at main ¬∑ deepseek-ai/DeepSeek-V2 (MLA)</A>
							<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V2">deepseek-ai/DeepSeek-V2: DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</A>
							<DT><A HREF="https://x.com/teortaxesTex/status/1787866166242763217">DeepSeek mid 2024 status</A>
							<DT><A HREF="https://arxiv.org/abs/2504.21801">[2504.21801] DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition</A>
							<DT><A HREF="https://arxiv.org/html/2405.04434v2">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</A>
							<DT><A HREF="https://arxiv.org/abs/1911.02150">[1911.02150] Fast Transformer Decoding: One Write-Head is All You Need</A>
							<DT><A HREF="https://github.com/deepseek-ai">DeepSeek</A>
							<DT><A HREF="https://x.com/AdeptAILabs/status/1699835884097651145">AdeptAI Persimmon--8B</A>
							<DT><A HREF="https://x.com/teortaxesTex/status/1805055350011232352/photo/1">DeepSeek timeline</A>
							<DT><A HREF="https://github.com/THUDM/CodeGeeX4">THUDM/CodeGeeX4: CodeGeeX4-ALL-9B, a versatile model for all AI software development scenarios, including code completion, code interpreter, web search, function calling, repository-level Q&amp;A and much more.</A>
							<DT><A HREF="https://x.com/deepseek_ai/status/1829137969719984345">Auxiliary-Loss-Free Load Balancing Strategy for MoE</A>
							<DT><A HREF="https://arxiv.org/abs/2408.15664">[2408.15664] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts</A>
							<DT><A HREF="https://x.com/deepseek_ai/status/1832026579180163260">(1) DeepSeek en X: "üöÄ Exciting news! We‚Äôve officially launched DeepSeek-V2.5 ‚Äì a powerful combination of DeepSeek-V2-0628 and DeepSeek-Coder-V2-0724! Now, with enhanced writing, instruction-following, and human preference alignment, it‚Äôs available on Web and API. Enjoy seamless Function Calling, https://t.co/dXF2hFvnKK" / X</A>
							<DT><A HREF="https://drive.google.com/file/d/1DW5ohZWxoCEOdrUQjokKreuArHqJdtKb/view">Unveiling_DeepSeek.pdf - Google Drive</A>
							<DT><A HREF="https://x.com/deepseek_ai/status/1866459751053488344">DeepSeek-V2.5-1210: Internet Search</A>
							<DT><A HREF="https://x.com/Guodaya">(1) Daya Guo (@Guodaya) / X</A>
							<DT><A HREF="https://github.com/datawhalechina/unlock-deepseek">datawhalechina/unlock-deepseek: DeepSeek Á≥ªÂàóÂ∑•‰ΩúËß£ËØª„ÄÅÊâ©Â±ïÂíåÂ§çÁé∞„ÄÇ</A>
							<DT><A HREF="https://github.com/hkust-nlp/CodeIO">hkust-nlp/CodeIO: CodeI/O: Condensing Reasoning Patterns via Code Input-Output Prediction</A>
							<DT><A HREF="https://www.youtube.com/watch?v=CNA1sb2fJS4">Inference Time Scaling for Generalist Reward Modeling - YouTube</A>
							<DT><A HREF="https://x.com/teortaxesTex/status/1999500893734023531">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "In May 2024, Wenfeng said there are 3 routes to AGI he‚Äôs considering: what we now know as code&amp;amp;math RLVR (‚Äúclosed-loop game of Go‚Äù), multimodality (‚Äúinteraction in the real world‚Äù) and ‚Äúnatural language itself‚Äù (scaling pretraining?). Google invented all and is doing all at once. https://t.co/KQlSmN45nt" / X</A>
						</DL><p>
						<DT><H3 FOLDED>ByteDance-Seed</H3>
						<DL><p>
							<DT><H3 FOLDED>Seed-1.8</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ByteDance-Seed/Seed-1.8">ByteDance-Seed/Seed-1.8</A>
							</DL><p>
							<DT><H3 FOLDED>Seed-Thinking-v1.6</H3>
							<DL><p>
								<DT><A HREF="https://seed.bytedance.com/en/seed1_6">Introduction to Techniques Used in Seed1.6</A>
							</DL><p>
							<DT><H3 FOLDED>Seed-Thinking-v1.5</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5">ByteDance-Seed/Seed-Thinking-v1.5</A>
								<DT><A HREF="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5/blob/main/seed-thinking-v1.5.pdf">Seed-Thinking-v1.5/seed-thinking-v1.5.pdf at main ¬∑ ByteDance-Seed/Seed-Thinking-v1.5</A>
							</DL><p>
							<DT><H3 FOLDED>Seed1.5-VL</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2505.07062">Seed1.5-VL Technical Report</A>
								<DT><A HREF="https://x.com/sarahookr/status/1939783443463967000">preference training tends to be much more painful for multimodal, largely because of lack of calibrated rewards</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-embeddigns</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/ByteDance-Seed/Doubao-1.5-Embedding">ByteDance-Seed/Doubao-1.5-Embedding ¬∑ Hugging Face</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-serving</H3>
							<DL><p>
								<DT><H3 FOLDED>AIBrix</H3>
								<DL><p>
									<DT><A HREF="https://blog.vllm.ai/2025/02/21/aibrix-release.html">Introducing AIBrix: A Scalable, Cost-Effective Control Plane for vLLM | vLLM Blog</A>
									<DT><A HREF="https://github.com/vllm-project/aibrix/blob/main/docs/paper/AIBrix_White_Paper_0219_2025.pdf">aibrix/docs/paper/AIBrix_White_Paper_0219_2025.pdf at main ¬∑ vllm-project/aibrix</A>
									<DT><A HREF="https://www.linkedin.com/in/jiaxin-shan/">Jiaxin Shan | LinkedIn</A>
									<DT><A HREF="https://github.com/AlibabaPAI/llumnix">AlibabaPAI/llumnix: Efficient and easy multi-instance LLM serving</A>
									<DT><A HREF="https://aibrix.github.io/posts/2025-08-04-v0.4.0-release/">AIBrix v0.4.0 Release: P/D Disaggregation and Expert Parallelism Support, KVCache v1 Connector, KV Event Synchronization &amp; Multi‚ÄëEngine Support | AIBrix Blogs</A>
									<DT><A HREF="https://aibrix.github.io/posts/2025-11-26-priskv-intro/">PrisKV: A Colocated Tiered KVCache Store for LLM Serving | AIBrix Blogs</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>Seed-OSS-36B</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/ByteDance-Seed/Seed-OSS-36B-Base-woSyn">ByteDance-Seed/Seed-OSS-36B-Base-woSyn ¬∑ Hugging Face</A>
								<DT><A HREF="https://huggingface.co/ByteDance-Seed/Seed-OSS-36B-Base">ByteDance-Seed/Seed-OSS-36B-Base ¬∑ Hugging Face</A>
								<DT><A HREF="https://seed.bytedance.com/en/blog/seed-oss-open-source-models-release">Seed News - ByteDance Seed Team</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2504.11536">[2504.11536] ReTool: Reinforcement Learning for Strategic Tool Use in LLMs</A>
							<DT><A HREF="https://github.com/ByteDance-Seed/Agent-R?tab=readme-ov-file">ByteDance-Seed/Agent-R: Resources for our paper: "Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training"</A>
							<DT><A HREF="https://github.com/ByteDance-Seed/DeepFlow">ByteDance-Seed/DeepFlow</A>
							<DT><A HREF="https://arxiv.org/pdf/2503.20313">TileLink: Generating Efficient Compute-Communication Overlapping Kernels using Tile-Centric Primitives</A>
							<DT><A HREF="https://github.com/ByteDance-Seed/SDP4Bit">ByteDance-Seed/SDP4Bit: official implementation of paper SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training</A>
							<DT><A HREF="https://arxiv.org/pdf/2502.19811">Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</A>
						</DL><p>
						<DT><H3 FOLDED>Kimi</H3>
						<DL><p>
							<DT><H3 FOLDED>kimi-K2</H3>
							<DL><p>
								<DT><H3 FOLDED>QK-Clip</H3>
								<DL><p>
									<DT><A HREF="https://kexue.fm/archives/11126">QK-ClipÔºöËÆ©MuonÂú®Scaleup‰πãË∑Ø‰∏äÊõ¥Ëøõ‰∏ÄÊ≠• - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://x.com/vikhyatk/status/1949976438070816922">(1) vik en X: "qk clipping changed my life. my skin is clear. my vision has been corrected. my experts have better load balance. i no longer hate the sun https://t.co/qvTKKR8jzP" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Kimi-K2-Instruct-0905</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/moonshotai/Kimi-K2-Instruct-0905">moonshotai/Kimi-K2-Instruct-0905 ¬∑ Hugging Face</A>
								</DL><p>
								<DT><H3 FOLDED>kimi-K2-thinking</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Kimi_Moonshot/status/1986449512538513505">(1) Kimi.ai en X: "üöÄ Hello, Kimi K2 Thinking! The Open-Source Thinking Agent Model is here. üîπ SOTA on HLE (44.9%) and BrowseComp (60.2%) üîπ Executes up to 200 ‚Äì 300 sequential tool calls without human interference üîπ Excels in reasoning, agentic search, and coding üîπ 256K context window Built https://t.co/lZCNBIgbV2" / X</A>
									<DT><A HREF="https://moonshotai.github.io/Kimi-K2/thinking.html">Kimi K2 Thinking</A>
									<DT><A HREF="https://huggingface.co/moonshotai">moonshotai (Moonshot AI)</A>
									<DT><A HREF="https://huggingface.co/moonshotai/Kimi-K2-Thinking">moonshotai/Kimi-K2-Thinking ¬∑ Hugging Face</A>
								</DL><p>
								<DT><H3 FOLDED>kimi-k2-int4</H3>
								<DL><p>
									<DT><A HREF="https://x.com/suchenzang/status/1987381992619683981">(1) Susan Zhang en X: "&amp;gt; Unfortunately, K2-Thinking's INT4 QAT doesn't have the "godlike technology" some people on social media are hoping for. &amp;gt; We found that a relatively basic QAT solution can easily achieve lossless performance relative to the baseline, which is why we haven't spent too much time https://t.co/vTB9T4bpfn" / X</A>
									<DT><A HREF="https://www.zhihu.com/question/1969558404759544488/answer/1970539327902679960">Kimi K2 INT4 QAT</A>
									<DT><A HREF="https://x.com/ZhihuFrontier/status/1987125624599970218">(1) Zhihu Frontier en X: "üöÄ "Quantization is not a compromise ‚Äî it's the next paradigm." After K2-Thinking's release, many developers have been curious about its native INT4 quantization format. ÂàòÂ∞ë‰ºü, infra engineer at @Kimi_Moonshot and Zhihu contributor, shares an insider's view on why this choice https://t.co/Nblj9kdBYP" / X</A>
									<DT><A HREF="https://x.com/ShengyuanS/status/1987023480391671898">INT4 QAT is weight-only with fake-quantization</A>
								</DL><p>
								<DT><H3 FOLDED>kimi-k2.5</H3>
								<DL><p>
									<DT><A HREF="https://x.com/teortaxesTex/status/2016027034653164004">&gt; built through continual pretraining on approximately 15 trillion mixed visual and text tokens atop Kimi-K2-Base</A>
									<DT><A HREF="https://www.kimi.com/blog/kimi-k2-5.html">Kimi K2.5: Visual Agentic Intelligence</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/2016009804259487850">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "initial impressions of Kimi K2.5: it needs a Speciale/Heavy version or agent straitjacket to shine it's too lazy a thinker. 5.2 and Speciale destroy it on Ph.D level tasks where they go for &amp;gt;&amp;gt;20K thinking tokens Per token, it's frontier level Surprisingly good vision too</A>
									<DT><A HREF="https://x.com/Kimi_Moonshot/status/2017249233775260021">(1) Kimi.ai en X: "Kimi K2.5 tech report just dropped! Quick hits: - Joint text‚Äìvision training: pretrained with 15T vision-text tokens, zero-vision SFT (text-only) to activate visual reasoning - Agent Swarm + PARL: dynamically orchestrated parallel sub-agents, up to 4.5√ó lower latency, 78.4% on https://t.co/vpmepE3AX4" / X</A>
									<DT><A HREF="https://github.com/MoonshotAI/Kimi-K2.5/blob/master/tech_report.pdf">Kimi-K2.5/tech_report.pdf Visual Agentic Intelligence</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2507.20534">[2507.20534] Kimi K2: Open Agentic Intelligence</A>
								<DT><A HREF="https://arxiv.org/pdf/2507.20534?">KIMI K2: OPEN AGENTIC INTELLIGENCE</A>
								<DT><A HREF="https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf">Kimi-K2/tech_report.pdf at main ¬∑ MoonshotAI/Kimi-K2</A>
								<DT><A HREF="https://x.com/bigeagle_xd/status/1946410599375884731">we now use K2 + some in-house agentic envs to fetch and process datasets.  AI is feeding its own children.</A>
								<DT><A HREF="https://x.com/ZhihuFrontier/status/1945020841093476703">(1) Zhihu Frontier en X: "ü§ñ Zhihu contributor &amp;amp; @Kimi_Moonshot RL Lead @RotekSong shares how they pushed Kimi K2 toward better general-purpose Agent abilities - by scaling up tool-use data. In short: a fully automated agent data factory üè≠ that simulates end-to-end workflows to filter out high-quality https://t.co/8R7XyYIhFZ" / X</A>
								<DT><A HREF="https://www.zhihu.com/question/1927140506573435010/answer/1927646858873905506">Kimi releases the first trillion-parameter open source model K2 model. What information is worth paying attention to?</A>
								<DT><A HREF="https://www.zhihu.com/question/1927140506573435010/answer/1928417232230277397">Kimi ÂèëÂ∏ÉÈ¶ñ‰∏™‰∏á‰∫øÂèÇÊï∞ÂºÄÊ∫êÊ®°Âûã K2 Ê®°ÂûãÔºåÂì™‰∫õ‰ø°ÊÅØÂÄºÂæóÂÖ≥Ê≥®Ôºü - Áü•‰πé</A>
								<DT><A HREF="https://bigeagle.me/2025/07/kimi-k2/">Written after the release of Kimi K2: No longer just a ChatBot</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/1944059679912382765">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "I really hope Kimi shares the paper on K2. in the meantime, these are our sources on their thinking about LLM pre- and post-training that likely went into it. https://t.co/F2LMTsY0B6" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=91fmhAnECVc">Kimi Founder Yang Zhilin: K2, Agentic LLMs, Brains in Vats, and the Beginning of Infinity - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=QLDpiOOyyrE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=148&pp=iAQB">Kimi K2 and Our Contributions to Open Source - Yuxin Wu, Moonshot AI - YouTube</A>
								<DT><A HREF="https://x.com/dbreunig/status/1981953870126592444">(1) Drew Breunig en X: "For people wondering today, yes, Kimi K2 RL‚Äôed writing quality. https://t.co/tsPLYb6wcd" / X</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/1987175426356129939">kimi k2 architecture is dpsk-v3</A>
							</DL><p>
							<DT><H3 FOLDED>kimi-cot</H3>
							<DL><p>
								<DT><A HREF="https://x.com/JingyuanLiu123/status/1984283306524131536">(1) JingyuanLiu en X: "https://t.co/zwpED4c98h kimi folks usually share their cot on model training, this is a great reflection from @yzhang_cs" / X</A>
								<DT><A HREF="https://www.zhihu.com/question/1967345030881584585/answer/1967730385816385407">Â¶Ç‰ΩïËØÑ‰ª∑Kimi LinearÔºü - Áü•‰πé kimi cot</A>
							</DL><p>
							<DT><H3 FOLDED>claude-code-kimi</H3>
							<DL><p>
								<DT><H3 FOLDED>kimi-code</H3>
								<DL><p>
									<DT><A HREF="https://www.kimi.com/code?track_id=fc320bee-8624-4bf3-9f19-ea7f9baa93e0">Kimi Code - Next-Gen AI Code Agent | Automated Programming &amp; CLI</A>
								</DL><p>
								<DT><A HREF="https://x.com/YouJiacheng/status/1943730619667624429">CLAUDE_CODE_MAX_OUTPUT_TOKENS=4096 Kimi-K2</A>
								<DT><A HREF="https://github.com/musistudio/claude-code-router">musistudio/claude-code-router: Use Claude Code as the foundation for coding infrastructure, allowing you to decide how to interact with the model while enjoying updates from Anthropic.</A>
								<DT><A HREF="https://github.com/zai-org/GLM-4.5/tree/main/example/claude_code">GLM-4.5/example/claude_code at main ¬∑ zai-org/GLM-4.5</A>
								<DT><A HREF="https://x.com/bigeagle_xd/status/1951870677662978167">How I use claude-code with K2</A>
								<DT><A HREF="https://cursor.com/blog/composer">Composer: Building a fast frontier model with RL ¬∑ Cursor</A>
							</DL><p>
							<DT><A HREF="https://github.com/MoonshotAI/Kimina-Prover-Preview">MoonshotAI/Kimina-Prover-Preview: Technical report of Kimina-Prover Preview.</A>
						</DL><p>
						<DT><H3 FOLDED>Qwen</H3>
						<DL><p>
							<DT><H3 FOLDED>Qwen-3</H3>
							<DL><p>
								<DT><H3 FOLDED>qwen3-weights</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f">Qwen3 - a Qwen Collection</A>
								</DL><p>
								<DT><H3 FOLDED>qwen3-moe</H3>
								<DL><p>
									<DT><A HREF="https://x.com/kalomaze/status/1918238263330148487">QwenMoE router distributions are... VERY biased</A>
								</DL><p>
								<DT><H3 FOLDED>qwen3-chat</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/collections/willcb/qwen3-68434f4883925bfdb4570ee5">Qwen3 - a willcb Collection</A>
								</DL><p>
								<DT><H3 FOLDED>qwen3-30B-A3B</H3>
								<DL><p>
									<DT><H3 FOLDED>qwen3-30B-A3B-architecture</H3>
									<DL><p>
										<DT><A HREF="https://bench.flashinfer.ai/models/qwen3-30b-a3b">Qwen3 30B A3B architecture overview</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>Qwen3-235B-A22B-Instruct-2507</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Alibaba_Qwen/status/1947344511988076547">we‚Äôll train Instruct and Thinking models separately so we can get the best quality possible.</A>
								</DL><p>
								<DT><H3 FOLDED>Qwen3-235B-A22B-Thinking-2507</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Alibaba_Qwen/status/1948688466386280706">(1) Qwen en X: "üöÄ We‚Äôre excited to introduce Qwen3-235B-A22B-Thinking-2507 ‚Äî our most advanced reasoning model yet! Over the past 3 months, we‚Äôve significantly scaled and enhanced the thinking capability of Qwen3, achieving: ‚úÖ Improved performance in logical reasoning, math, science &amp;amp; coding https://t.co/vO6UHlW7pf" / X</A>
									<DT><A HREF="https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507">Qwen/Qwen3-235B-A22B-Thinking-2507 ¬∑ Hugging Face</A>
								</DL><p>
								<DT><H3 FOLDED>qwen3-coder</H3>
								<DL><p>
									<DT><H3 FOLDED>qwen3-coder-flash</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct">Qwen/Qwen3-Coder-30B-A3B-Instruct ¬∑ Hugging Face</A>
										<DT><A HREF="https://x.com/alibaba_qwen/status/1950925444057792808?s=12">(1) Qwen en X: "ü¶• Qwen3-Coder-Flash: Qwen3-Coder-30B-A3B-Instruct üíö Just lightning-fast, accurate code generation. ‚úÖ Native 256K context (supports up to 1M tokens with YaRN) ‚úÖ Optimized for platforms like Qwen Code, Cline, Roo Code, Kilo Code, etc. ‚úÖ Seamless function calling &amp;amp; agent https://t.co/eqjeYManhS" / X</A>
									</DL><p>
									<DT><A HREF="https://x.com/Alibaba_Qwen/status/1947766835023335516">&gt;&gt;&gt; Qwen3-Coder is here! ‚úÖ</A>
									<DT><A HREF="https://qwenlm.github.io/blog/qwen3-coder/">Qwen3-Coder: Agentic Coding in the World | Qwen</A>
									<DT><A HREF="https://github.com/QwenLM/Qwen3-Coder">QwenLM/Qwen3-Coder: Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team, Alibaba Cloud.</A>
									<DT><A HREF="https://arxiv.org/abs/2505.09388">[2505.09388] Qwen3 Technical Report</A>
									<DT><A HREF="https://arxiv.org/abs/2409.12186">[2409.12186] Qwen2.5-Coder Technical Report</A>
									<DT><A HREF="https://www.cerebras.ai/blog/introducing-cerebras-code">Introducing Cerebras Code</A>
								</DL><p>
								<DT><H3 FOLDED>Qwen3-Max-Preview</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Alibaba_Qwen/status/1963991502440562976">(1) Qwen en X: "Big news: Introducing Qwen3-Max-Preview (Instruct) ‚Äî our biggest model yet, with over 1 trillion parameters! üöÄ Now available via Qwen Chat &amp;amp; Alibaba Cloud API. Benchmarks show it beats our previous best, Qwen3-235B-A22B-2507. Internal tests + early user feedback confirm: https://t.co/7vQTfHup1Z" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Qwen3-Max</H3>
								<DL><p>
									<DT><A HREF="https://qwen.ai/blog?id=241398b9cd6353de490b0f82806c7848c5d2777d&from=research.latest-advancements-list">Qwen3-Max: Just Scale it</A>
								</DL><p>
								<DT><H3 FOLDED>qwen3-adaptive-tool-call</H3>
								<DL><p>
									<DT><A HREF="https://x.com/GenAI_is_real/status/2016019909491482768">(1) Chayenne Zhao en X: "heard rumors from the bay area that the adaptive tool-use in qwen3 is making gemini‚Äôs agents look like legacy software. multi-round self-reflection is finally hitting the scaling wall and breaking through. no more manual tool selection? that‚Äôs the death of the agent orchestration" / X</A>
								</DL><p>
								<DT><A HREF="https://qwenlm.github.io/blog/qwen3/">Qwen3: Think Deeper, Act Faster | Qwen</A>
								<DT><A HREF="https://github.com/QwenLM/Qwen3">QwenLM/Qwen3: Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud.</A>
								<DT><A HREF="https://x.com/Alibaba_Qwen/status/1916962087676612998/photo/2">(2) Junyang Lin en X: "Qwen3 is finally out! It really takes some time for our guys to figure out methods to solve some problems that are not fancy. How to scale RL with stable training, how to balance data from different domains, how to increase the support of more languages with performance" / X</A>
								<DT><A HREF="https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/11_qwen3/standalone-qwen3-moe.ipynb">LLMs-from-scratch/ch05/11_qwen3/standalone-qwen3-moe.ipynb at main ¬∑ rasbt/LLMs-from-scratch</A>
								<DT><A HREF="https://www.byhand.ai/p/qwen-3">Qwen 3 - by Prof. Tom Yeh - AI by Hand ‚úçÔ∏è</A>
								<DT><A HREF="https://qwen.ai/blog?id=qwen3-max-thinking">Qwen3-Max-Thinking</A>
							</DL><p>
							<DT><H3 FOLDED>QwQ</H3>
							<DL><p>
								<DT><A HREF="https://qwenlm.github.io/blog/qwq-32b-preview/">QwQ: Reflect Deeply on the Boundaries of the Unknown | Qwen</A>
							</DL><p>
							<DT><H3 FOLDED>Qwen2.5-Max</H3>
							<DL><p>
								<DT><A HREF="https://qwenlm.github.io/blog/qwen2.5-max/">Qwen2.5-Max: Exploring the Intelligence of Large-scale MoE Model | Qwen</A>
								<DT><A HREF="https://huggingface.co/collections/Qwen/qwen25-1m-679325716327ec07860530ba">Qwen2.5-1M - a Qwen Collection</A>
							</DL><p>
							<DT><A HREF="https://qwenlm.github.io/blog/qwen2.5-turbo/">Extending the Context Length to 1M Tokens! | Qwen</A>
							<DT><A HREF="https://github.com/QwenLM/Qwen2.5-Coder">QwenLM/Qwen2.5-Coder: Qwen2.5-Coder is the code version of Qwen2.5, the large language model series developed by Qwen team, Alibaba Cloud.</A>
							<DT><A HREF="https://github.com/QwenLM/Qwen">QwenLM/Qwen: The official repo of Qwen (ÈÄö‰πâÂçÉÈóÆ) chat &amp; pretrained large language model proposed by Alibaba Cloud.</A>
							<DT><A HREF="https://huggingface.co/Qwen/Qwen2.5-14B-Instruct-1M">Qwen/Qwen2.5-14B-Instruct-1M ¬∑ Hugging Face</A>
							<DT><A HREF="https://gist.github.com/YouJiacheng/42d54de78d37821ff606aef686e9e50a">qwen_pretok.py</A>
							<DT><A HREF="https://docs.google.com/presentation/d/1f1Et0Mz8zb1yVCnCgdYSy4tAa0Kv_gKT4wPEg1XPdUA/edit?slide=id.p#slide=id.p">[10 05 2025 The Curve] Open Models - Google Slides</A>
						</DL><p>
						<DT><H3 FOLDED>GLM</H3>
						<DL><p>
							<DT><H3 FOLDED>GLM-4.7</H3>
							<DL><p>
								<DT><H3 FOLDED>GLM 4.7-flash</H3>
								<DL><p>
									<DT><A HREF="https://x.com/teortaxestex/status/2013467545882235256?s=12">Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "So me and Gemini3/5.2 concur that GLM 4.7 Flash should indeed consume ‚âà1MB per 1 token of context when inferenced in the naive MHA regime and that's what currently happens in vLLM for this guy, but ‚âà54 KB from first principles. Who is wrong? @vllm_project https://t.co/yqi5Vdnuf9" / X</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>GLM-4.5</H3>
							<DL><p>
								<DT><A HREF="https://github.com/zai-org/GLM-4.5">zai-org/GLM-4.5: GLM-4.5: An open-source large language model designed for intelligent agents by Z.ai</A>
								<DT><A HREF="https://z.ai/blog/glm-4.5">GLM-4.5: Reasoning, Coding, and Agentic Abililties Technical Report</A>
								<DT><A HREF="https://x.com/Zai_org/status/1949831552189518044">GLM-4.5 release thread</A>
								<DT><A HREF="https://x.com/eliebakouch/status/1949822769782231244">GLM 4.5 training recap</A>
								<DT><A HREF="https://x.com/gm8xx8/status/1972932103462400133">GLM 4.6</A>
								<DT><A HREF="https://x.com/gum1h0x/status/1974579164272603334">GLM-4.6 outperforms claude-4-5-sonnet while being ~8x cheaper</A>
							</DL><p>
							<DT><A HREF="https://x.com/SinclairWang1/status/1940331927724232712">Solit data engineering on multimodal data</A>
							<DT><A HREF="https://x.com/kalomaze/status/1937203985884254609">GLM 32b</A>
							<DT><A HREF="https://huggingface.co/zai-org">zai-org (Z.ai)</A>
							<DT><A HREF="https://github.com/zai-org/GLM-V">zai-org/GLM 4.6</A>
						</DL><p>
						<DT><H3 FOLDED>MiniMax</H3>
						<DL><p>
							<DT><H3 FOLDED>MiniMax-Text-01</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2501.08313">[2501.08313] MiniMax-01: Scaling Foundation Models with Lightning Attention</A>
							</DL><p>
							<DT><H3 FOLDED>MiniMax-M1</H3>
							<DL><p>
								<DT><H3 FOLDED>MiniMax-M1-weights</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://x.com/MiniMax__AI/status/1934637031193514237">1m-token input, 80K-token output, agentic use, efficient RL post-training</A>
								<DT><A HREF="https://github.com/MiniMax-AI/MiniMax-M1/blob/main/MiniMax_M1_tech_report.pdf">MiniMax-M1/MiniMax_M1_tech_report.pdf at main ¬∑ MiniMax-AI/MiniMax-M1</A>
								<DT><A HREF="https://github.com/MiniMax-AI/MiniMax-M1/tree/main">MiniMax-AI/MiniMax-M1: MiniMax-M1, the world's first open-weight, large-scale hybrid-attention reasoning model. inference code</A>
								<DT><A HREF="https://x.com/ArtificialAnlys/status/1935311012137402678">(1) Artificial Analysis en X: "MiniMax launches their first reasoning model: MiniMax M1, the second most intelligent open weights model after DeepSeek R1, with a much longer 1M token context window @MiniMax__AI M1 is based on their Text-01 model (released 14 Jan 2025) - an MoE with 456B total and 45.9B active https://t.co/JltMYrm0te" / X</A>
							</DL><p>
							<DT><H3 FOLDED>MiniMax-M2</H3>
							<DL><p>
								<DT><A HREF="https://x.com/chetaslua/status/1984291291308741006">(1) Chetaslua en X: "MiniMax M2 mogs every closed source model in coding at 8% of price of claude ü§Ø This is the SVG of new york city compared to upcoming Gemini 3 @MiniMax__AI cooked hard in agentic coding capabilities I have attached there benchmark in thread Codepen Link and Prompt in the https://t.co/O1IZAoUT1j" / X</A>
								<DT><A HREF="https://www.zhihu.com/question/1965302088260104295/answer/1966810157473335067">Â¶Ç‰ΩïËØÑ‰ª∑MiniMax Êé®Âá∫ÁöÑMiniMax-M2Ê®°Âûã? - Áü•‰πé</A>
								<DT><A HREF="https://x.com/Jianlin_S/status/1983090907114315940">why MiniMax v2 uses full dense attention instead of NSA</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>MiMo</H3>
						<DL><p>
							<DT><H3 FOLDED>MiMo-V2-Flash</H3>
							<DL><p>
								<DT><A HREF="https://x.com/banghuaz/status/2002248105543283139">(1) Banghua Zhu en X: "This is amazing as a 309B MoE! Huge congrats to @XiaomiMiMo and @luo_fuli14427!! With SGLang day 0 support, one can inference with Mimi V2 at 150 token/s. It‚Äôs currently free on openrouter and great in agentic capabilities." / X</A>
								<DT><A HREF="https://github.com/XiaomiMiMo/MiMo-V2-Flash/blob/main/paper.pdf">MiMo-V2-Flash/paper.pdf at main ¬∑ XiaomiMiMo/MiMo-V2-Flash</A>
								<DT><A HREF="https://github.com/XiaomiMiMo/MiMo-V2-Flash">XiaomiMiMo/MiMo-V2-Flash: MiMo-V2-Flash: Efficient Reasoning, Coding, and Agentic Foundation Model</A>
							</DL><p>
							<DT><A HREF="https://x.com/teortaxesTex/status/2001842563293286717">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "MiMo-V2 is underrated. it's funny that people have a strong prejudice against Xiaomi. LLM-Core Lab is not the same team that's selling air purifiers. Serious Chinese companies are now running internal DeepSeeks, the mindset has evolved. Update your priors. https://t.co/aKJF5zvrrN" / X</A>
							<DT><A HREF="https://x.com/XiaomiMiMo">(1) Xiaomi MiMo (@XiaomiMiMo) / X</A>
							<DT><A HREF="https://x.com/_LuoFuli/status/2001002838953222653">(1) Fuli Luo en X: "MiMo-V2-Flash is live. It‚Äôs just step 2 on our AGI roadmap, but I wanted to dump some notes on the engineering choices that actually moved the needle. Architecture: We settled on a Hybrid SWA. It‚Äôs simple, elegant, and in our internal benchmarks, it outperformed other Linear" / X</A>
						</DL><p>
						<DT><H3 FOLDED>Nemotron</H3>
						<DL><p>
							<DT><H3 FOLDED>Nemotron-3</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ctnzr/status/2000567575462502865">(1) Bryan Catanzaro en X: "Nemotron 3 Super (~4X bigger than Nano) and Ultra (~16X bigger than Nano) are pretrained using NVFP4, a new "Latent Mixture of Experts" architecture that allows us to use 4X more experts for the same inference cost, and Multi-Token Prediction." / X</A>
								<DT><A HREF="https://research.nvidia.com/labs/nemotron/Nemotron-3/?ncid=ref-inor-399942">NVIDIA Nemotron 3 Family of Models - NVIDIA Nemotron</A>
								<DT><A HREF="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-White-Paper.pdf">https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-White-Paper.pdf</A>
								<DT><A HREF="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-Nano-Technical-Report.pdf">Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>LongCat</H3>
						<DL><p>
							<DT><H3 FOLDED>LongCat-Flash-Thinking</H3>
							<DL><p>
								<DT><A HREF="https://github.com/meituan-longcat/LongCat-Flash-Thinking-2601/blob/main/LongCat_Flash_Thinking_2601_Technical_Report.pdf">LongCat-Flash-Thinking-2601/LongCat_Flash_Thinking_2601_Technical_Report.pdf at main ¬∑ meituan-longcat/LongCat-Flash-Thinking-2601</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/2011532416977104913">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "Meituan (yes the food delivery company) catches up to the current synthetic environment meta of DeepSeek/Kimi/Xiaomi, and in some ways steps further, with their take on data generation and Heavy mode. Their sparse attention: ¬´coming soon¬ª. Potentially another Tier 1 lab. https://t.co/FRLaGjQLgc" / X</A>
							</DL><p>
							<DT><A HREF="https://huggingface.co/meituan-longcat/papers">meituan-longcat (LongCat) technical reports</A>
						</DL><p>
						<DT><H3 FOLDED>Prime</H3>
						<DL><p>
							<DT><H3 FOLDED>Trinity Large</H3>
							<DL><p>
								<DT><A HREF="https://x.com/samsja19/status/2016283855888773277">samsja en X: "Today we‚Äôre releasing Trinity Large, a 400B MoE LLM with 13B active parameters, trained over 17T tokens The base model is on par with GLM-4.5 Base, while being significantly faster at inference because it‚Äôs sparser and hybrid The architecture we picked is one of my favorites:" / X</A>
								<DT><A HREF="https://x.com/PrimeIntellect/status/2016280792037785624">Prime Intellect en X: "We're excited to introduce @arcee_ai's Trinity Large model. An open 400B parameter Mixture of Experts model, delivering frontier-level performance with only 13B active parameters. Trained in collaboration between Arcee, Datology and Prime Intellect. https://t.co/Y6jCDgv4UK" / X</A>
								<DT><A HREF="https://github.com/arcee-ai/trinity-large-tech-report/">arcee-ai/trinity-large-tech-report</A>
								<DT><A HREF="https://www.arcee.ai/blog/trinity-large">Arcee AI | Trinity Large: An Open 400B Sparse MoE Model</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>language-models-code-generation</H3>
						<DL><p>
							<DT><H3 FOLDED>language-models-code-generation-evaluation</H3>
							<DL><p>
								<DT><A HREF="https://github.com/microsoft/CodeXGLUE">microsoft/CodeXGLUE: CodeXGLUE</A>
								<DT><A HREF="https://paperswithcode.com/dataset/humaneval">HumanEval Dataset | Papers With Code</A>
								<DT><A HREF="https://openai.com/blog/grade-school-math/">Solving Math Word Problems</A>
								<DT><A HREF="https://arxiv.org/pdf/2210.14868.pdf">Multi-Lingual Code Generation (Execution Evaluation)</A>
								<DT><A HREF="https://huggingface.co/datasets/THUDM/humaneval-x">THUDM/humaneval-x ¬∑ Datasets at Hugging Face</A>
								<DT><A HREF="https://arxiv.org/abs/2211.11501">[2211.11501] DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation</A>
								<DT><A HREF="https://twitter.com/amanrsanger/status/1588585377946021888?s=12&amp;t=WP151JoXlub3KMUA8iqo0g">Model pass@k evaluation comparison</A>
								<DT><A HREF="https://huggingface.co/spaces/evaluate-metric/code_eval">Hugging Face Evaluation: pass@k</A>
								<DT><A HREF="https://arxiv.org/pdf/2107.03374.pdf">Evaluating Large Language Models Trained on Code</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-code-generation-multilingual</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/TransCoder">facebookresearch/TransCoder: Public release of the TransCoder research project https://arxiv.org/pdf/2006.03511.pdf</A>
								<DT><A HREF="https://github.com/facebookresearch/TransCoder">facebookresearch/TransCoder</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-coder</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/ByteDance-Seed/Seed-Coder-8B-Reasoning">ByteDance-Seed/Seed-Coder-8B-Reasoning ¬∑ Hugging Face</A>
								<DT><A HREF="https://github.com/ByteDance-Seed/Seed-Coder/blob/master/Seed-Coder.pdf">Seed-Coder: Let the Code Model Curate Data for Itself</A>
								<DT><A HREF="https://x.com/teortaxesTex/status/1921081607504507176">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "ByteDance Seed shares coding LLMs: Seed-Coder-8B. 6T tokens, outperforms Qwen3-8B. Base, Instruct, Reasoner. The core point: Let the Code Model Curate Data for Itself Immediate SoTA data recipe, far expanding on DeepSeek's early papers. Probably #1 AGI team in China already. https://t.co/GGafzivKJU" / X</A>
							</DL><p>
							<DT><H3 FOLDED>DeepSeek-coder</H3>
							<DL><p>
								<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-Coder-V2?tab=readme-ov-file">deepseek-ai/DeepSeek-Coder-V2</A>
								<DT><A HREF="https://x.com/deepseek_ai/status/1813921111694053644">DeepSeek-V2-0628</A>
								<DT><A HREF="https://x.com/gm8xx8/status/1947215735417192819">CUDA-L1: DeepSeek V3 model to optimize CUDA kernels</A>
							</DL><p>
							<DT><H3 FOLDED>llama-coder</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>Codestral</H3>
							<DL><p>
								<DT><A HREF="https://mistral.ai/news/codestral/">Codestral: Hello, World! | Mistral AI | Frontier AI in your hands</A>
								<DT><A HREF="https://x.com/GuillaumeLample/status/1813231491154899012">Guillaume Lample @ ICLR 2024 en X: "Today we are releasing two small models: Mathstral 7B and Codestral Mamba 7B. On the MATH benchmark, Mathstral 7B obtains 56.6% pass@1, outperforming Minerva 540B by more than 20%. Mathstral scores 68.4% on MATH with majority voting@64, and 74.6% using a reward model. Codestral https://t.co/k125XPnur4" / X</A>
							</DL><p>
							<DT><H3 FOLDED>InCoder</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2204.05999.pdf">InCoder</A>
								<DT><A HREF="https://arxiv.org/abs/2204.05999">InCoder: A Generative Model for Code Infilling and Synthesis</A>
								<DT><A HREF="https://sites.google.com/view/incoder-code-models">InCoder</A>
							</DL><p>
							<DT><H3 FOLDED>CodeGen</H3>
							<DL><p>
								<DT><A HREF="https://github.com/salesforce/CodeGen/tree/main/codegen25">CodeGen/codegen25 at main ¬∑ salesforce/CodeGen</A>
								<DT><A HREF="https://github.com/facebookresearch/CodeGen">facebookresearch/CodeGen: Reference implementation of code generation projects from Facebook AI Research. General toolkit to apply machine learning to code, from dataset creation to model training and evaluation. Comes with pretrained models.</A>
								<DT><A HREF="https://arxiv.org/pdf/2203.13474.pdf">CodeGen (JAX): Conversational</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/pdf/2107.03374.pdf">(Chen, 2021) Codex: Evaluating Large Language Models Trained on Code</A>
							<DT><A HREF="https://arxiv.org/pdf/2203.07814.pdf">(Deepmind, 2022) Competition-Level Code Generationwith AlphaCode</A>
							<DT><A HREF="https://arxiv.org/pdf/2207.14502.pdf">(HOT) Languages Models Can Teach Themselves (Kaplan Theorem)</A>
							<DT><A HREF="https://arxiv.org/abs/2207.10397">CodeT: Code Generation with Generated Tests</A>
							<DT><A HREF="https://arxiv.org/abs/2207.14255">Efficient Training of Language Models to Fill in the Middle</A>
							<DT><A HREF="https://github.com/microsoft/CodeT/tree/main/DIVERSE">CodeT/DIVERSE at main ¬∑ microsoft/CodeT</A>
							<DT><A HREF="https://arxiv.org/pdf/2208.05950.pdf">Interactive Code Generation via Test-Driven User-Intent Formalization</A>
							<DT><A HREF="https://arxiv.org/pdf/2102.07350.pdf">Prompt Programming: choice of prompts that determine the quality of output</A>
							<DT><A HREF="https://twitter.com/davisblalock/status/1558347542101839873">"Language Models Can Teach Themselves to Program Better"</A>
							<DT><A HREF="https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/?utm_source=linkedin&utm_medium=organic_social&utm_content=image&utm_campaign=fair">Meta Large Language Model Compiler: Foundation Models of Compiler Optimization | Research - AI at Meta</A>
							<DT><A HREF="https://x.com/BigCodeProject/status/1813618988246790452">BigCodeBench-Hard</A>
							<DT><A HREF="https://x.com/MinyangTian1/status/1813182904593199553">SciCode</A>
							<DT><A HREF="https://x.com/lmarena_ai/status/1856444009323082093">Which language model is best for coding? Copilot Arena leaderboard</A>
						</DL><p>
						<DT><H3 FOLDED>machine-translation</H3>
						<DL><p>
							<DT><H3 FOLDED>bytedn-seedx</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/collections/ByteDance-Seed/seed-x-6878753f2858bc17afa78543">Seed-X - a ByteDance-Seed Collection</A>
								<DT><A HREF="https://arxiv.org/pdf/2507.13618">Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters</A>
							</DL><p>
							<DT><H3 FOLDED>COMET</H3>
							<DL><p>
								<DT><A HREF="https://chatgpt.com/c/682366e4-e32c-800c-9559-fec946021b4d">Open-Source LLM Translation Comparison</A>
								<DT><A HREF="https://unbabel.com/research/comet/">COMET: The New Standard in MT Evaluation - Unbabel</A>
								<DT><A HREF="https://github.com/Unbabel/COMET">Unbabel/COMET: A Neural Framework for MT Evaluation</A>
							</DL><p>
							<DT><H3 FOLDED>mT5</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2304.09151">[2304.09151] UniMax (mT5)</A>
								<DT><A HREF="https://arxiv.org/abs/2010.11934">[2010.11934] mT5: A massively multilingual pre-trained text-to-text transformer</A>
							</DL><p>
							<DT><H3 FOLDED>Tower</H3>
							<DL><p>
								<DT><A HREF="https://unbabel.com/announcing-tower-an-open-multilingual-llm-for-translation-related-tasks/">Announcing Tower : An Open Multilingual LLM for Translation-Related Tasks</A>
							</DL><p>
							<DT><H3 FOLDED>ALMA</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2401.08417">[2401.08417] Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation</A>
								<DT><A HREF="https://ar5iv.labs.arxiv.org/html/2309.11674">[2309.11674] A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models</A>
								<DT><A HREF="https://huggingface.co/haoranxu/ALMA-13B">haoranxu/ALMA-13B ¬∑ Hugging Face</A>
							</DL><p>
							<DT><H3 FOLDED>nllb-moe-54b</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/facebook/nllb-moe-54b">facebook/nllb-moe-54b ¬∑ Hugging Face</A>
								<DT><A HREF="https://arxiv.org/abs/2207.04672">[2207.04672] No Language Left Behind: Scaling Human-Centered Machine Translation</A>
							</DL><p>
							<DT><A HREF="https://ar5iv.labs.arxiv.org/html/2309.11674">[2309.11674] A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models</A>
							<DT><A HREF="https://arxiv.org/abs/2309.11674">[2309.11674] A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models (2023)</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-embeddings</H3>
						<DL><p>
							<DT><H3 FOLDED>embeddings-semantic-search</H3>
							<DL><p>
								<DT><A HREF="https://www.patterns.app/blog/2023/02/19/ask-hn-gpt-embeddings-question-answering/">AskHN - The collective GPT-embodied wisdom of Hacker News | Patterns</A>
								<DT><A HREF="https://www.youtube.com/watch?v=HAseTSX6FT8">Fast, Accurate and Robust Multilingual Syntactic Analysis ‚Äì Slav Petrov (Google) - 2012 - YouTube</A>
								<DT><A HREF="https://urimerhav.substack.com/p/vector-similarity-search-is-hopeless?utm_campaign=post&triedRedirect=true">Vector Similarity Search is Hopeless - by Uri Merhav</A>
								<DT><A HREF="https://huggingface.co/papers/2411.12644">Paper page - CodeXEmbed: A Generalist Embedding Model Family for Multiligual and Multi-task Code Retrieval</A>
								<DT><A HREF="https://arxiv.org/pdf/2503.07891">Gemini Embedding: Generalizable Embeddings from Gemini</A>
							</DL><p>
							<DT><H3 FOLDED>command-a</H3>
							<DL><p>
								<DT><A HREF="https://cohere.com/blog/command-a-vision">Introducing Command A Vision: Multimodal AI Built for Business</A>
								<DT><A HREF="https://www.linkedin.com/posts/reimersnils_%F0%9D%90%84%F0%9D%90%A7%F0%9D%90%9D%F0%9D%9F%90%F0%9D%90%84%F0%9D%90%A7%F0%9D%90%9D-%F0%9D%90%95%F0%9D%90%A2%F0%9D%90%AC%F0%9D%90%A2%F0%9D%90%A8%F0%9D%90%A7-%F0%9D%90%91%F0%9D%90%80%F0%9D%90%86-%F0%9D%90%B0%F0%9D%90%A2%F0%9D%90%AD-activity-7356975330227617792-wUmL/">ùêÑùêßùêùùüêùêÑùêßùêù ùêïùê¢ùê¨ùê¢ùê®ùêß-ùêëùêÄùêÜ ùê∞ùê¢ùê≠ùê° ùêÇùê®ùê°ùêûùê´ùêû</A>
							</DL><p>
							<DT><H3 FOLDED>embeddings-limit</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google-deepmind/limit">google-deepmind/limit: On the Theoretical Limitations of Embedding-Based Retrieval</A>
								<DT><A HREF="https://x.com/jxmnop/status/1925224612872233081">All Embedding Models Learn The Same Thing</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=RkYuH_K7Fx4">What is?</A>
							<DT><A HREF="https://twitter.com/_akhaliq/status/1742034428619096327">Improving Text Embeddings with Large Language Models (MS)</A>
							<DT><A HREF="https://twitter.com/din0s_/status/1742235150530851120">trained on synthetic retrieval data</A>
							<DT><A HREF="https://arxiv.org/abs/1911.02116">[1911.02116] Unsupervised Cross-lingual Representation Learning at Scale (Meta AI)</A>
							<DT><A HREF="https://ai.meta.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/">XLM-R: State-of-the-art cross-lingual understanding through self-supervision</A>
							<DT><A HREF="https://arxiv.org/abs/2401.00368">[ Improving Text Embeddings with Large Language Models (MSFT)</A>
							<DT><A HREF="https://github.com/RAIVNLab/MRL">RAIVNLab/MRL: Code repository for the paper - "Matryoshka Representation Learning"</A>
							<DT><A HREF="https://twitter.com/adityakusupati/status/1541554858829815809">(1) Aditya Kusupati ü™Ü en X: "Introductingü™ÜMatryoshka Representations for Adaptive Deploymentü™Ü TL;DR: up to 14√ó lower real-world classification &amp;amp; retrival costs at web-scale at no loss in accuracy &amp;amp; w/o any overhead across setups. Paper: https://t.co/JMP9ED72L2 Code: https://t.co/SEccseeDxz [1/11] https://t.co/dXl03V1CUc" / X</A>
							<DT><A HREF="https://huggingface.co/blog/embedding-quantization">Binary and Scalar Embedding Quantization for Significantly Faster &amp; Cheaper Retrieval</A>
							<DT><A HREF="https://github.com/tensorchord/pgvecto.rs">tensorchord/pgvecto.rs: Scalable, Low-latency and Hybrid-enabled Vector Search in Postgres. Revolutionize Vector Search, not Database.</A>
							<DT><A HREF="https://github.com/UKPLab/sentence-transformers/releases/tag/v2.7.0">Release v2.7.0 - CachedGISTEmbedLoss, easy Matryoshka inference &amp; evaluation, CrossEncoder, Intel Gaudi2 ¬∑ UKPLab/sentence-transformers</A>
							<DT><A HREF="https://x.com/victorialslocum/status/1830955879803318650">(1) Victoria Slocum en X: "There‚Äôs this super scary-looking equation in the Matryoshka Representation Learning paper (https://t.co/5tn1VOIK7D), but once you break it down, it‚Äôs actually not that bad. So, let‚Äôs go through it, inside to out: üü° Yellow: This is the data label corresponding to the input (x). https://t.co/PyemCI8u7K" / X</A>
							<DT><A HREF="https://arxiv.org/pdf/2205.13147">Matryoshka Representation Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2410.02525">[2410.02525] Contextual Document Embeddings</A>
							<DT><A HREF="https://x.com/XingyouSong/status/1861190895623667754">(1) Richard Song en X: "LLM embeddings are surprisingly great for high dimensional regression. Why? Because they preserve Lipschitz continuity better than traditional methods! But bigger models aren‚Äôt always better, due to confounding factors like RL-HF. Tweeting on behalf of @erictang000 whom I had a https://t.co/AefM4dXaT7" / X</A>
							<DT><A HREF="https://x-tabdeveloping.github.io/turftopic/clustering/">Clustering Models - Turftopic</A>
							<DT><A HREF="https://x.com/jxmnop/status/1925224612872233081">All Embedding Models Learn The Same Thing</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-fine-tuning</H3>
						<DL><p>
							<DT><H3 FOLDED>Supervised-Fine-Tuning (SFT)</H3>
							<DL><p>
								<DT><A HREF="https://liyuan24.github.io/writings/supervised_fine_tuning.html">Supervised Fine Tuning From Scratch | Liyuan‚Äôs Log</A>
							</DL><p>
							<DT><H3 FOLDED>Parameter-Efficient Fine-Tuning-(PEFT)</H3>
							<DL><p>
								<DT><H3 FOLDED>LoRA</H3>
								<DL><p>
									<DT><H3 FOLDED>QLoRA</H3>
									<DL><p>
										<DT><A HREF="https://x.com/laurensweitkamp/status/1899853378877817052">Laurens: QLoRA dequantization kernel using Triton, Llama models</A>
									</DL><p>
									<DT><H3 FOLDED>lora-serving</H3>
									<DL><p>
										<DT><A HREF="https://github.com/punica-ai/punica">punica-ai/punica: Serving multiple LoRA finetuned LLM as one</A>
									</DL><p>
									<DT><A HREF="https://thinkingmachines.ai/blog/lora/">LoRA Without Regret - Thinking Machines Lab</A>
									<DT><A HREF="https://www.youtube.com/watch?v=NDV65M-2T3g">Flat minima generalize for low-rank matrix recovery - YouTube</A>
									<DT><A HREF="https://gist.github.com/Chillee/a8d2070b1b7b3f97d8c87bac3c366f8e">lora_example.py</A>
									<DT><A HREF="https://irhum.github.io/blog/lorawd/">irhum.github.io - LoRA and Weight Decay</A>
									<DT><A HREF="https://x.com/datavistics/status/1805929136390656137">(1) Derek Thomas en X: "Check out this animation on LoRA Inference! https://t.co/0ixOHmUcQR" / X</A>
									<DT><A HREF="https://dev.to/lewis_won/how-do-low-rank-adaptation-of-large-language-models-work-3ga6">lora by hand</A>
									<DT><A HREF="https://x.com/MechanizeWork/status/1972814533891862929">RL yields sparse feedback (~10 bits/episode, even on 100k-token episodes).</A>
									<DT><A HREF="https://x.com/zzlccc/status/1973612326747336767">(1) Zichen Liu en X: "much more convinced after getting my own results: LoRA with rank=1 learns (and generalizes) as well as full-tuning while saving 43% vRAM usage! allows me to RL bigger models with limited resourcesüòÜ script: https://t.co/p6IIiBQA6c https://t.co/LickCrTgyQ" / X</A>
									<DT><A HREF="https://x.com/johnschulman2/status/1974948097500582254">(1) John Schulman en X: "Really happy to see people reproducing the result that LoRA rank=1 closely matches full fine-tuning on many RL fine-tuning problems. Here are a couple nice ones: https://t.co/x7hcgNL3Bd https://t.co/5JyKuKd9wS" / X</A>
									<DT><A HREF="https://x.com/ProfTomYeh/status/1984625277792551247">LoRA by Hand</A>
								</DL><p>
								<DT><H3 FOLDED>Prompt-Tuning</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2102.07350.pdf">Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm</A>
									<DT><A HREF="https://arxiv.org/pdf/2202.13169.pdf">A SYSTEMATIC EVALUATION OF LARGE LANGUAGE MODELS OF CODE</A>
									<DT><A HREF="https://arxiv.org/pdf/2208.05950.pdf">Interactive Code Generation via Test-Driven User-Intent Formalization</A>
									<DT><A HREF="https://openreview.net/pdf?id=NiEtU7blzN">LARGE LANGUAGE MODELS CAN SELF-IMPROVE</A>
									<DT><A HREF="https://arxiv.org/pdf/2107.03374.pdf">Evaluating Large Language Models Trained on Code</A>
									<DT><A HREF="https://www.youtube.com/watch?v=80jwVkYOu0w">The Power of Scale for Parameter-Efficient Prompt Tuning - YouTube</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2403.14608">[2403.14608] Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</A>
								<DT><A HREF="https://arxiv.org/pdf/2401.01286.pdf">A Comprehensive Study of Knowledge Editing for Large Language Models</A>
								<DT><A HREF="https://arxiv.org/pdf/2205.05638.pdf">T-FEW: Few-Shot Parameter-Efficient Fine-Tuning vs In-Context Learning</A>
								<DT><A HREF="https://www.youtube.com/watch?v=MQwryfkydc0">Unsloth.ai: Easily finetune &amp; train LLMs - YouTube</A>
								<DT><A HREF="https://x.com/danielhanchen/status/1866548183729410423">(1) Daniel Han en X: "Unsloth can now do 89K context finetuning on a 80GB GPU for Llama 3.3 70B in 4bit - 13x longer than HF+FA2! 1. We worked with the Cut Cross Entropy authors to make it work in @UnslothAI. CCE is like FA2, but for cross entropy. Via on the fly matrix mults, one does not have to https://t.co/kP34vHWJCF" / X</A>
							</DL><p>
							<DT><H3 FOLDED>language-models-merge</H3>
							<DL><p>
								<DT><H3 FOLDED>bytedn-model-merging</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2505.12082v1">Model Merging in Pre-training of Large Language Models</A>
									<DT><A HREF="https://x.com/giffmana/status/1924849877634449878">Lucas Beyer (bl16) en X: "They study model merging (EMA, soups), which is well-understood for fine-tunings of a base model, but they investigate *pre-training* of LLMs. My summary thread. (YoU wOn'T bEliEvE the surprise in post #5 which makes me like this group a lot more!)" / X</A>
								</DL><p>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1725513067293724897">CombLM</A>
								<DT><A HREF="https://arxiv.org/abs/2312.15166">[2312.15166] SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling</A>
								<DT><A HREF="https://huggingface.co/papers/2312.15166">Paper page - SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling</A>
								<DT><A HREF="https://arxiv.org/abs/2305.15296">[2305.15296] MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation</A>
								<DT><A HREF="https://x.com/_akhaliq/status/1794938544336568380">Stacking Your Transformers A Closer Look at Model Growth for Efficient LLM Pre-Training LLMs are computationally expensive to pre-train</A>
								<DT><A HREF="https://x.com/nikdimitriadis/status/1797638468610466044">(1) Dimitriadis Nikos en X: "Wouldn't it be great if we could merge the knowledge of 20 specialist models into a single one without losing performance? üí™üèª Introducing our new ICML paper "Localizing Task Information for Improved Model Merging and Compression". üéâ üìú: https://t.co/JC4mdujKkd üßµ1/9 https://t.co/JrCE0DBYlT" / X</A>
								<DT><A HREF="https://x.com/gabriel_ilharco/status/1603415656699162624">(1) Gabriel Ilharco en X: "Introducing task vectors! A new way to steer models by doing arithmetic with model weights. Subtract to make models forget, add to make them learn üìú: https://t.co/YNQvdYtdSN üñ•Ô∏è: https://t.co/CVFM68u322 https://t.co/FBgdpByhUB" / X</A>
								<DT><A HREF="https://github.com/mlfoundations/task_vectors">mlfoundations/task_vectors: Editing Models with Task Arithmetic</A>
								<DT><A HREF="https://arxiv.org/pdf/2405.07813">Localizing Task Information for Improved Model Merging and Compression</A>
								<DT><A HREF="https://x.com/francoisfleuret/status/1797652614366339545">(1) Fran√ßois Fleuret en X: "TL;DR: You fine-tune a model on T tasks, and store a bit per task / parameter that indicates to use the base or the multi-task value. So only 2 x 16 + T bits per parameter, and performance are virtually as good as with T dedicated models." / X</A>
								<DT><A HREF="https://x.com/giffmana/status/1924849885230354846">Does the way you average ckpts matter? Once you've trained long enough, not really, all work the same</A>
								<DT><A HREF="https://cohere.com/research/papers/command-a-technical-report.pdf">Command A: An Enterprise-Ready Large Language Model</A>
								<DT><A HREF="https://x.com/prateeky2806/status/1843643582432854171">What matters for model merging at scale</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2405.05904#:~:text=We%20demonstrate%20that%20large%20language,consistent%20with%20the%20model's%20knowledge.">[2405.05904] Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</A>
							<DT><A HREF="https://blog.scottlogic.com/2023/11/24/llm-mem.html">LLM finetuning memory requirements</A>
							<DT><A HREF="https://www.youtube.com/watch?v=mcep6W8oB1I">Stanford CS25: V3 I Recipe for Training Helpful Chatbots</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Ckz8XA2hW84&list=LL&index=14&t=1s">Ilya Sutskever (OpenAI) and Jensen Huang (NVIDIA CEO) : AI Today and Vision of the Future (3/2023) - YouTube</A>
							<DT><A HREF="https://github.com/InternLM/xtuner">InternLM/xtuner: An efficient, flexible and full-featured toolkit for fine-tuning LLM (InternLM2, Llama3, Phi3, Qwen, Mistral, ...)</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-retrieval</H3>
						<DL><p>
							<DT><H3 FOLDED>Semantic Search</H3>
							<DL><p>
								<DT><H3 FOLDED>Embedding</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=RkYuH_K7Fx4">What is?</A>
									<DT><A HREF="https://twitter.com/_akhaliq/status/1742034428619096327">Improving Text Embeddings with Large Language Models (MS)</A>
									<DT><A HREF="https://twitter.com/din0s_/status/1742235150530851120">trained on synthetic retrieval data</A>
									<DT><A HREF="https://arxiv.org/abs/1911.02116">[1911.02116] Unsupervised Cross-lingual Representation Learning at Scale (Meta AI)</A>
									<DT><A HREF="https://ai.meta.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/">XLM-R: State-of-the-art cross-lingual understanding through self-supervision</A>
									<DT><A HREF="https://arxiv.org/abs/2401.00368">[ Improving Text Embeddings with Large Language Models (MSFT)</A>
									<DT><A HREF="https://github.com/RAIVNLab/MRL">RAIVNLab/MRL: Code repository for the paper - "Matryoshka Representation Learning"</A>
									<DT><A HREF="https://twitter.com/adityakusupati/status/1541554858829815809">(1) Aditya Kusupati ü™Ü en X: "Introductingü™ÜMatryoshka Representations for Adaptive Deploymentü™Ü TL;DR: up to 14√ó lower real-world classification &amp;amp; retrival costs at web-scale at no loss in accuracy &amp;amp; w/o any overhead across setups. Paper: https://t.co/JMP9ED72L2 Code: https://t.co/SEccseeDxz [1/11] https://t.co/dXl03V1CUc" / X</A>
									<DT><A HREF="https://huggingface.co/blog/embedding-quantization">Binary and Scalar Embedding Quantization for Significantly Faster &amp; Cheaper Retrieval</A>
									<DT><A HREF="https://github.com/tensorchord/pgvecto.rs">tensorchord/pgvecto.rs: Scalable, Low-latency and Hybrid-enabled Vector Search in Postgres. Revolutionize Vector Search, not Database.</A>
									<DT><A HREF="https://github.com/UKPLab/sentence-transformers/releases/tag/v2.7.0">Release v2.7.0 - CachedGISTEmbedLoss, easy Matryoshka inference &amp; evaluation, CrossEncoder, Intel Gaudi2 ¬∑ UKPLab/sentence-transformers</A>
								</DL><p>
								<DT><A HREF="https://www.patterns.app/blog/2023/02/19/ask-hn-gpt-embeddings-question-answering/">AskHN - The collective GPT-embodied wisdom of Hacker News | Patterns</A>
								<DT><A HREF="https://www.youtube.com/watch?v=HAseTSX6FT8">Fast, Accurate and Robust Multilingual Syntactic Analysis ‚Äì Slav Petrov (Google) - 2012 - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>RETRO</H3>
							<DL><p>
								<DT><A HREF="https://deepmind.google/discover/blog/improving-language-models-by-retrieving-from-trillions-of-tokens/">Improving language models by retrieving from trillions of tokens - Google DeepMind</A>
								<DT><A HREF="https://arxiv.org/abs/2112.04426">[2112.04426] Improving language models by retrieving from trillions of tokens</A>
							</DL><p>
							<DT><H3 FOLDED>REFRAG</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2509.01092">[2509.01092] REFRAG: Rethinking RAG based Decoding</A>
							</DL><p>
							<DT><H3 FOLDED>RAGO</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2503.14649">[2503.14649] RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/pdf/2407.12854">Scaling Retrieval-Based Language Models with a Trillion-Token Datastore</A>
							<DT><A HREF="https://media.licdn.com/dms/image/D4E22AQENEUGr4PY3Tg/feedshare-shrink_800/0/1699343585425?e=1702512000&v=beta&t=V7uFCIOwllfoE0Is1EpAWSqidGHcZJ2VBGEOpkgmzu8">OpenAI: RAG Success Story</A>
							<DT><A HREF="https://docs.google.com/presentation/d/19lAeVzPkh20Ly855tKDkz1uv-1pHV_9GxfntiTJPUug/edit#slide=id.g2584b5dafc1_0_2025">SIGIR 2023 keynote - Google DeepMind</A>
							<DT><A HREF="https://www.youtube.com/watch?v=g-VvYLhYhOg">Jerry Liu‚ÄìLlamaIndex ‚Äì Practical Data Considerations for building Production-Ready LLM Applications - YouTube</A>
							<DT><A HREF="https://github.com/tantaraio/voy">tantaraio/voy: üï∏Ô∏èü¶Ä A WASM vector similarity search written in Rust</A>
							<DT><A HREF="https://twitter.com/_akhaliq/status/1742369195034099731">DocLLM: A layout-aware generative language model for multimodal document understanding</A>
							<DT><A HREF="https://arxiv.org/pdf/2209.11755.pdf">Promptagator: Few-shot Dense Retrieval From 8 Examples</A>
							<DT><A HREF="https://arxiv.org/abs/2401.00368">[2401.00368] Improving Text Embeddings with Large Language Models</A>
							<DT><A HREF="https://www.youtube.com/watch?v=mE7IDf2SmJg">Stanford CS25: V3 I Retrieval Augmented Language Models - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=SgVZBn5QNHk">UMass CS685 S24 (Advanced NLP) #21: Detecting LLM-generated text / LLM security - YouTube</A>
							<DT><A HREF="https://x.com/headinthebox/status/1799642956657508585">(1) Erik Meijer en X: "The world's ugliest poster for https://t.co/duXtHCj3mF Yet it captures everything I want to say. https://t.co/ieQGpOdm4q" / X</A>
							<DT><A HREF="https://x.com/din0s_/status/1801271625309937771">(1) dinos en X: "üìö Awesome Information Retrieval üîç I‚Äôve compiled a list of some of my favorite IR papers from the past few years. If you‚Äôre new to the field and want to understand how Transformer-based retrieval models work before building your RAG application, this should serve as a great https://t.co/SiMm6WKTZR" / X</A>
							<DT><A HREF="https://x.com/RulinShao/status/1813563054459875594">(1) Rulin Shao en X: "üî•We release the first open-source 1.4T-token RAG datastore and present a scaling study for RAG on perplexity and downstream tasks! We show LM+RAG scales better than LM alone, with better performance for the same training compute (pretraining+indexing) https://t.co/5QChH9Jn6u üßµ https://t.co/OKXsgDV1kv" / X</A>
							<DT><A HREF="https://github.com/togethercomputer/together-cookbook/blob/main/Open_Contextual_RAG.ipynb">together-cookbook/Open_Contextual_RAG.ipynb at main ¬∑ togethercomputer/together-cookbook</A>
							<DT><A HREF="https://arxiv.org/abs/2503.14649">[2503.14649] RAGO: Systematic Performance Optimization for Retrieval-Augmented Generation Serving</A>
							<DT><A HREF="https://x.com/XinxiLyu/status/1942291244220309610">(1) Xinxi Lyu en X: "Reasoning benchmarks (e.g., MMLU Pro and GPQA) have seen little benefit from naive RAG. But can we flip this? üî•Introducing CompactDS: ‚úÖWeb-scale coverage ‚úÖRuns with just 100GB RAM ‚úÖMatches search engines The simplest RAG pipeline can even compete with agentic https://t.co/7WCKhnhGED" / X</A>
							<DT><A HREF="https://arxiv.org/abs/2406.10149">[2406.10149] BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-safety</H3>
						<DL><p>
							<DT><H3 FOLDED>Red Teaming</H3>
							<DL><p>
								<DT><A HREF="https://openai.com/blog/red-teaming-network">OpenAI Red Teaming Network</A>
								<DT><A HREF="https://twitter.com/rharang/status/1725161975976497627">NVIDIA NeMo-Guardrails</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2212.08073">Constitutional AI: Harmlessness from AI Feedback (Antrophic)</A>
							<DT><A HREF="https://ai.meta.com/llama/purple-llama/">Purple Llama - AI at Meta</A>
							<DT><A HREF="https://developer.nvidia.com/blog/best-practices-for-securing-llm-enabled-applications/">Best Practices for Securing LLM-Enabled Applications</A>
							<DT><A HREF="https://github.com/NVIDIA/NeMo-Guardrails">NVIDIA/NeMo-Guardrails: NeMo Guardrails</A>
							<DT><A HREF="https://arxiv.org/abs/2302.10149">[2302.10149] Poisoning Web-Scale Training Datasets is Practical</A>
							<DT><A HREF="https://arxiv.org/pdf/2404.13208">The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions</A>
							<DT><A HREF="https://openai.com/index/openai-safety-update/">OpenAI safety practices | OpenAI</A>
						</DL><p>
						<DT><H3 FOLDED>ASR</H3>
						<DL><p>
							<DT><H3 FOLDED>speech-to-text</H3>
							<DL><p>
								<DT><H3 FOLDED>whisper</H3>
								<DL><p>
									<DT><A HREF="https://github.com/openai/whisper">openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision</A>
									<DT><A HREF="https://github.com/ggerganov/whisper.cpp/pull/1500">whisper : quantize encoder only by ggerganov ¬∑ Pull Request #1500 ¬∑ ggerganov/whisper.cpp</A>
									<DT><A HREF="https://huggingface.co/ylacombe/whisper-large-v3-turbo">ylacombe/whisper-large-v3-turbo ¬∑ Hugging Face</A>
									<DT><A HREF="https://x.com/FireworksAI_HQ/status/1866218532738109891">(1) Fireworks AI en X: "We made Whisper 20x faster than OpenAI*! Today, we‚Äôre beta launching the fastest and most feature-complete audio APIs - transcribe ONE HOUR of audio in as little as 4 seconds. (900:1 transcription speed!) We‚Äôre offering it FREE for 2 weeks to celebrate launch - try it https://t.co/Q0PpolyJOZ" / X</A>
									<DT><A HREF="https://x.com/phonic_co">(1) Phonic (@phonic_co) / X</A>
								</DL><p>
								<DT><H3 FOLDED>voxtral</H3>
								<DL><p>
									<DT><H3 FOLDED>voxtral-weights</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://x.com/MistralAI/status/1945130173751288311">Introducing the world's best (and open) speech recognition models! 15-07-25</A>
									<DT><A HREF="https://mistral.ai/news/voxtral">Voxtral | Mistral AI</A>
									<DT><A HREF="https://huggingface.co/mistralai/Voxtral-Small-24B-2507">mistralai/Voxtral-Small-24B-2507 ¬∑ Hugging Face</A>
									<DT><A HREF="https://arxiv.org/abs/2507.13264">[2507.13264] Voxtral</A>
								</DL><p>
								<DT><H3 FOLDED>yutai-stt</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/kyutai/stt-2.6b-en">kyutai/stt-2.6b-en ¬∑ Hugging Face</A>
									<DT><A HREF="https://github.com/kyutai-labs/delayed-streams-modeling/">kyutai-labs/delayed-streams-modeling: Kyutai's Speech-To-Text and Text-To-Speech models based on the Delayed Streams Modeling framework.</A>
								</DL><p>
								<DT><H3 FOLDED>parakeet</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2">nvidia/parakeet-tdt-0.6b-v2 ¬∑ Hugging Face</A>
								</DL><p>
								<DT><A HREF="https://bytedancespeech.github.io/seedtts_tech_report/">Seed-TTS</A>
								<DT><A HREF="https://www.youtube.com/watch?v=uKuPZiV5c68">Review ByteDance/Tiktok's Seed-TTS: A Family of High-Quality Versatile Speech Generation Models - YouTube</A>
								<DT><A HREF="https://arxiv.org/html/2406.02430v1">Seed-TTS: A Family of High-Quality Versatile Speech Generation Models</A>
							</DL><p>
							<DT><H3 FOLDED>text-to-speech</H3>
							<DL><p>
								<DT><H3 FOLDED>qwen3-tts</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2601.15621">[2601.15621] Qwen3-TTS Technical Report</A>
									<DT><A HREF="https://github.com/QwenLM/Qwen3-TTS">QwenLM/Qwen3-TTS: Qwen3-TTS is an open-source series of TTS models developed by the Qwen team at Alibaba Cloud, supporting stable, expressive, and streaming speech generation, free-form voice design, and vivid voice cloning.</A>
									<DT><A HREF="https://huggingface.co/collections/Qwen/qwen3-tts">Qwen3-TTS - a Qwen Collection</A>
									<DT><A HREF="https://x.com/prompt_tunes/status/2015100370171912663">(1) Andy en X: "very interesting! for the 25Hz tokenizer's decoder they use a modified BigVGAN vocoder (responsible for the final audio waveforms), which uses snake activation (instead of a standard activation like ReLU) in its AMP blocks. this helps in modeling the periodic nature of audio https://t.co/gJHPUCvI41" / X</A>
									<DT><A HREF="https://x.com/cherry_cc12/status/2014333565237186844?s=12">(1) Chen Cheng en X: "Yes‚Äîthis is the amazing Qwen3-TTS family! I use it almost daily: Base (Voice Clone) to narrate bedtime stories for my kids in familiar voices, VoiceDesign and CustomVoice to bring dynamic, multilingual personality to my video and AI podcast. Each model feels like it has its own" / X</A>
								</DL><p>
								<DT><H3 FOLDED>Kyutai-tts</H3>
								<DL><p>
									<DT><A HREF="https://kyutai.org/next/tts">Kyutai TTS</A>
									<DT><A HREF="https://huggingface.co/kyutai/tts-1.6b-en_fr">kyutai/tts-1.6b-en_fr ¬∑ Hugging Face</A>
								</DL><p>
								<DT><H3 FOLDED>zonos</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Zyphra/Zonos">Zyphra/Zonos: Zonos-v0.1 is a leading open-weight text-to-speech model trained on more than 200k hours of varied multilingual speech, delivering expressiveness and quality on par with‚Äîor even surpassing‚Äîtop TTS providers.</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices">Navigating the Challenges and Opportunities of Synthetic Voices</A>
							<DT><A HREF="https://huggingface.co/datasets/mozilla-foundation/common_voice_17_0">mozilla-foundation/common_voice_17_0 ¬∑ Datasets at Hugging Face</A>
							<DT><A HREF="https://stability.ai/news/stability-ai-introduces-stable-audio-25-the-first-audio-model-built-for-enterprise-sound-production-at-scale">Stability AI Introduces Stable Audio 2.5, the First Audio Model Built for Enterprise Sound Production at Scale ‚Äî Stability AI</A>
							<DT><A HREF="https://huggingface.co/collections/Soul-AILab/soulx-podcast">SoulX-Podcast - a Soul-AILab Collection</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-biology</H3>
						<DL><p>
							<DT><H3 FOLDED>proteins</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2305.16634">[2305.16634] Machine Learning for Protein Engineering</A>
								<DT><A HREF="https://310.ai/">End 2 End AI Molecule Design ‚Äì We generate diverse de novo protein sequences from just a text description of the desired properties by Mol.E , a state-of-the-art ML model</A>
								<DT><A HREF="https://www.exscientia.ai/">Exscientia | AI Drug Discovery | Pharmatech</A>
							</DL><p>
							<DT><H3 FOLDED>medical</H3>
							<DL><p>
								<DT><H3 FOLDED>Baichuan-M2</H3>
								<DL><p>
									<DT><A HREF="https://x.com/HuggingPapers/status/1964179479330271565">(1) DailyPapers en X: "China's Baichuan-Inc unveils Baichuan-M2: a 32B medical LLM with a dynamic verifier system for real-world clinical reasoning. It sets new state-of-the-art on HealthBench Hard, outperforming most advanced models, previously exceeded only by GPT-5. https://t.co/pK8tZcQSLf" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2509.02208">[2509.02208] Baichuan-M2: Scaling Medical Capability with Large Verifier System</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>molecular-design</H3>
							<DL><p>
								<DT><H3 FOLDED>Chai-2</H3>
								<DL><p>
									<DT><A HREF="https://x.com/chaidiscovery/status/1939684680447746050">Chai-2 enables zero-shot antibody discovery in a 24-well plate</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>virtual-cell</H3>
							<DL><p>
								<DT><A HREF="https://centuryofbio.com/p/virtual-cell">What Are Virtual Cells? - by Elliot Hershberg</A>
							</DL><p>
							<DT><H3 FOLDED>evolutionaryscale</H3>
							<DL><p>
								<DT><H3 FOLDED>ESM3</H3>
								<DL><p>
									<DT><A HREF="https://www.evolutionaryscale.ai/blog/esm3-release">Evolutionary Scale ¬∑ ESM3: Simulating 500 million years of evolution with a language model</A>
									<DT><A HREF="https://www.biorxiv.org/content/10.1101/2024.07.01.600583v2">Simulating 500 million years of evolution with a language model | bioRxiv</A>
								</DL><p>
								<DT><A HREF="https://www.evolutionaryscale.ai/">EvolutionaryScale</A>
							</DL><p>
							<DT><A HREF="https://www.abzu.ai/">Bring drugs to market faster with Abzu¬Æ</A>
							<DT><A HREF="https://github.com/epfLLM/meditron">epfLLM/meditron: Meditron is a suite of open-source medical Large Language Models (LLMs).</A>
							<DT><A HREF="https://atelfo.github.io/2023/12/23/biopharma-from-janssen-to-today.html">The pharma industry from Paul Janssen to today: why drugs got harder to develop and what we can do about it | Alex‚Äôs blog</A>
							<DT><A HREF="https://github.com/google-deepmind/alphafold3">google-deepmind/alphafold3: AlphaFold 3 inference pipeline.</A>
							<DT><A HREF="https://github.com/bytedance/Protenix">bytedance/Protenix: A trainable PyTorch reproduction of AlphaFold 3.</A>
							<DT><A HREF="https://www.microsoft.com/en-us/research/blog/biomedparse-a-foundation-model-for-smarter-all-in-one-biomedical-image-analysis/">BiomedParse: A foundation model for smarter, all-in-one biomedical image analysis - Microsoft Research</A>
							<DT><A HREF="https://www.markov.bio/research/mech-interp-path-to-e2e-biology">Through a Glass Darkly | Markov Bio</A>
							<DT><A HREF="https://x.com/shae_mcl/status/1859817929614950431">(1) Shae Mclaughlin en X: "Visualizing transformer model attention in the UCSC genome browser (üßµ). I've been exploring how DNA sequence might influence genome organization in the nucleus using transformer models. Started by pretraining a model on reference genomes from multiple species 1/7 https://t.co/hWQqnMSbju" / X</A>
							<DT><A HREF="https://x.com/miangoar/status/1857135910774514101">(1) GAMA Miguel Angel en X: "MMseqs2-GPU has been introduced, showing a 177x speed improvement. Also, a GPU back-end for FoldSeek is coming! üî• The future of bioinfo will be rewritten in CUDA. I'm really grateful for the work of amazing scientist like @milot_mirdita and the lab of @thesteinegger https://t.co/9hjtylIrcM" / X</A>
							<DT><A HREF="https://x.com/alexrives/status/1864345082713002437">(1) Alex Rives en X: "Introducing ESM Cambrian. Unsupervised learning can invert biology at scale to reveal the hidden structure of the natural world. We‚Äôve scaled up compute and data to train a new generation of protein language models. ESM C defines a new state of the art for protein https://t.co/GS1ShMvadv" / X</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-byte-models</H3>
						<DL><p>
							<DT><H3 FOLDED>byte-latent-transformer</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/blt">facebookresearch/blt: Code for BLT research paper</A>
								<DT><A HREF="https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf">https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf</A>
								<DT><A HREF="https://huggingface.co/facebook/blt/tree/main">facebook/blt at main model weights</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=9U1L5qEvly0">[short] Beyond Language Models: Byte Models are Digital World Simulators - YouTube</A>
							<DT><A HREF="https://arxiv.org/abs//2402.19155">[2402.19155] Beyond Language Models: Byte Models are Digital World Simulators</A>
							<DT><A HREF="https://arxiv.org/abs/2401.13660">[2401.13660] MambaByte: Token-free Selective State Space Model</A>
							<DT><A HREF="https://x.com/ArtidoroPagnoni/status/1867601413741981804">Artidoro Pagnoni en X: "üöÄ Introducing the Byte Latent Transformer (BLT) ‚Äì An LLM architecture that scales better than Llama 3 using byte-patches instead of tokens ü§Ø Paper üìÑ https://t.co/5QGrlJdK0y Code üõ†Ô∏è https://t.co/jCdDI5BXwe https://t.co/7XyZdcXWoR" / X</A>
							<DT><A HREF="https://dl.fbaipublicfiles.com/blt/BLT__Patches_Scale_Better_Than_Tokens.pdf">Byte Latent Transformer: Patches Scale Better Than Tokens</A>
						</DL><p>
						<DT><H3 FOLDED>language-models-small</H3>
						<DL><p>
							<DT><H3 FOLDED>phi</H3>
							<DL><p>
								<DT><H3 FOLDED>phi-reasoning</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/microsoft/Phi-4-reasoning-plus">microsoft/Phi-4-reasoning-plus ¬∑ Hugging Face</A>
									<DT><A HREF="https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning">microsoft/Phi-4-mini-flash-reasoning ¬∑ Hugging Face</A>
								</DL><p>
								<DT><A HREF="https://x.com/suchenzang/status/1991771756676399497/photo/1">phi synthethic data generation approach is flawed</A>
							</DL><p>
							<DT><A HREF="https://deepmind.google/models/gemma/gemma-3n/">Gemma 3n - Google DeepMind</A>
						</DL><p>
						<DT><H3 FOLDED>Gemini</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2312.11805">[2312.11805] Gemini: A Family of Highly Capable Multimodal Models</A>
							<DT><A HREF="https://arxiv.org/abs/2403.05530">[2403.05530] Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context</A>
							<DT><A HREF="https://arxiv.org/abs/2404.18416">[2404.18416] Capabilities of Gemini Models in Medicine</A>
							<DT><A HREF="https://arxiv.org/abs/2312.11444">[2312.11444] An In-depth Look at Gemini's Language Abilities</A>
							<DT><A HREF="https://aistudio.google.com/app/prompts/new_chat">Untitled prompt | Google AI Studio</A>
							<DT><A HREF="https://arxiv.org/abs/2503.19786">[2503.19786] Gemma 3 Technical Report</A>
						</DL><p>
						<DT><H3 FOLDED>OpenAI</H3>
						<DL><p>
							<DT><H3 FOLDED>openAI-MoE</H3>
							<DL><p>
								<DT><A HREF="https://x.com/danielhanchen/status/1951212068583120958">120B MoE 5B active + 20B text only, fp4, SwiGLU clip (-7,7) like ReLU6, 128k CONTEXT VIDA YaRN from 4K, Sliding window 128 + attention sinks, Llama arch + biases</A>
								<DT><A HREF="https://gist.github.com/main-horse/aa9b5f6a76b09074eff509a11c680109">o3 gen, not correct</A>
								<DT><A HREF="https://x.com/main_horse/status/1951201925778776530">dtypes (which are always [BF16,FP4,UE8])</A>
								<DT><A HREF="https://github.com/openai/gpt-oss">openai/gpt-oss: gpt-oss-120b and gpt-oss-20b are two open-weight language models by OpenAI</A>
								<DT><A HREF="https://github.com/openai/harmony">openai/harmony: Renderer for the harmony response format to be used with gpt-oss</A>
								<DT><A HREF="https://newsletter.languagemodels.co/p/the-illustrated-gpt-oss">The Illustrated GPT-OSS - by Jay Alammar</A>
								<DT><A HREF="https://www.perplexity.ai/hub/blog/gpt-oss-on-day-0">GPT-OSS on Day 0</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>OLMo</H3>
						<DL><p>
							<DT><H3 FOLDED>Tulu</H3>
							<DL><p>
								<DT><A HREF="https://x.com/allen_ai/status/1859643404847808935">(1) Ai2 en X: "Meet T√ºlu 3 -- a set of state-of-the-art instruct models with fully open data, eval code, and training algorithms. We invented new methods for fine-tuning language models with RL and built upon best practices in the community to scale synthetic instruction and preference data. https://t.co/HFJtfmoqZH" / X</A>
								<DT><A HREF="https://allenai.org/tulu">Tulu | Ai2</A>
								<DT><A HREF="https://allenai.org/papers/tulu-3-report.pdf">T√úLU 3: Pushing Frontiers in Open Language Model Post-Training</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=qMTzor0j418">Hannaneh Hajishirzi - OLMo: Accelerating the Science of Language Modeling (COLM) - YouTube</A>
							<DT><A HREF="https://github.com/allenai/open-instruct">allenai/open-instruct</A>
							<DT><H3 FOLDED>FlexOLMO</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=62F86YQCaE4">[Live] ScaleML Series Day 1 ‚Äî FlexOlmo: Open Language Models for Flexible Data Use - YouTube</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>large-languages-models-intuitions</H3>
						<DL><p>
							<DT><A HREF="https://x.com/_jasonwei/status/1729585618311950445">(1) Jason Wei en X: "It was an honor to give a guest lecture yesterday at Stanford‚Äôs CS330 class, "Deep Multi-Task and Meta-Learning"! I discussed a few very simple intuitions for how I personally think about large language models. Slides: https://t.co/NmusNTUVXb Here are the six intuitions: (1) https://t.co/qjmy7FGWWv" / X</A>
							<DT><A HREF="https://docs.google.com/presentation/d/1hQUd3pF8_2Gr2Obc89LKjmHL0DlH-uof9M0yFVd3FA4/edit#slide=id.g16197112905_0_0">jason wei cs330 talk - Google Slides</A>
							<DT><A HREF="https://x.com/hwchung27/status/1710003293223821658">(1) Hyung Won Chung en X: "I gave a talk at Seoul National University. I titled the talk ‚ÄúLarge Language Models (in 2023)‚Äù. This was an ambitious attempt to summarize our exploding field. Video: https://t.co/91GKf7kLQy Slides: https://t.co/cigAj0M4PD Trying to summarize the field forced me to think https://t.co/PjzWf5H8vU" / X</A>
						</DL><p>
						<DT><H3 FOLDED>Meituan</H3>
						<DL><p>
							<DT><H3 FOLDED>LongCat-Flash-Omni</H3>
							<DL><p>
								<DT><A HREF="https://x.com/teortaxesTex/status/1986011617658560745">(1) Teortaxes‚ñ∂Ô∏è (DeepSeek Êé®ÁâπüêãÈìÅÁ≤â 2023 ‚Äì ‚àû) en X: "I don't think people have paid enough attention to Meituan's tech report. The amount of engineering work this 131-person-strong team has done, and shared, is pretty astonishing even in this late era https://t.co/ysDvIAysMM" / X</A>
								<DT><A HREF="https://github.com/meituan-longcat/LongCat-Flash-Omni">meituan-longcat/LongCat-Flash-Omni: This is the official repo for the paper "LongCat-Flash-Omni Technical Report"</A>
								<DT><A HREF="https://github.com/meituan-longcat/LongCat-Flash-Omni/blob/main/tech_report.pdf">LongCat-Flash-Omni/tech_report.pdf at main ¬∑ meituan-longcat/LongCat-Flash-Omni</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>Apple Intelligence</H3>
						<DL><p>
							<DT><H3 FOLDED>hybrid-inference</H3>
							<DL><p>
								<DT><H3 FOLDED>minions</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HazyResearch/minions">HazyResearch/minions: Big &amp; Small LLMs working together</A>
									<DT><A HREF="https://www.youtube.com/watch?v=70Kot0_DFNs">Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models - YouTube</A>
									<DT><A HREF="https://arxiv.org/pdf/2502.15964">Minions: Cost-efficient Collaboration Between On-device and Cloud
Language Models</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://machinelearning.apple.com/research/apple-intelligence-foundation-language-models">Apple Intelligence Foundation Language Models - Apple Machine Learning Research</A>
							<DT><A HREF="https://x.com/papers_anon/status/1859807437081149928">Multimodal Autoregressive Pre-training of Large Vision Encoders From Apple. V2 of the AIM generalist vision encoders (L/H/1B/3B). Pairs the vision encoder with a multimodal decoder that autoregressively generates raw image patches and text tokens. Outperforms CLIP, SigLIP</A>
							<DT><A HREF="https://x.com/TimDarcet/status/1859964751419507066">(1) TimDarcet en X: "AIMv2 looks great! When SSL and text-supervised training both work so well, it was inevitable that combining both would be a great idea Big congrats to @DonkeyShot21 @alaa_nouby @MustafaShukor1 and team!" / X</A>
						</DL><p>
						<DT><H3 FOLDED>Hunyuan</H3>
						<DL><p>
							<DT><A HREF="https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/report/Hunyuan_A13B_Technical_Report.pdf">Hunyuan_A13B_Technical_Report</A>
							<DT><A HREF="https://github.com/Tencent-Hunyuan/Hunyuan-A13B">Tencent-Hunyuan/Hunyuan-A13B: Tencent Hunyuan A13B (short as Hunyuan-A13B), an innovative and open-source LLM built on a fine-grained MoE architecture.</A>
						</DL><p>
						<DT><H3 FOLDED>Baidu</H3>
						<DL><p>
							<DT><H3 FOLDED>Ernie-4.5</H3>
							<DL><p>
								<DT><A HREF="https://github.com/PaddlePaddle/Paddle">PaddlePaddle/Paddle: PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice Ôºà„ÄéÈ£ûÊ°®„ÄèÊ†∏ÂøÉÊ°ÜÊû∂ÔºåÊ∑±Â∫¶Â≠¶‰π†&amp;Êú∫Âô®Â≠¶‰π†È´òÊÄßËÉΩÂçïÊú∫„ÄÅÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÂíåË∑®Âπ≥Âè∞ÈÉ®ÁΩ≤Ôºâ</A>
								<DT><A HREF="https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf">ERNIE 4.5 Technical Report</A>
								<DT><A HREF="https://x.com/zephyr_z9/status/1939507997958717493">From 0.3B to 424B Multiple checkpoints (Pretrained, Post-trained, and base models)</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://github.com/deepseek-ai/DeepSeek-V2">deepseek-ai/DeepSeek-V2: DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</A>
						<DT><A HREF="https://x.com/teortaxesTex/status/1787866166242763217">papers. Deepseek Core Readings, Volume 1: 1 LLM (hyperparams, dataset basics)</A>
						<DT><A HREF="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2: Language Models are Unsupervised Multitask Learners</A>
						<DT><A HREF="https://arxiv.org/abs/2204.02311">PaLM: Scaling Language Modeling with Pathways (Arch &amp; Training Setup)</A>
						<DT><A HREF="https://arxiv.org/abs/2305.10403">[2305.10403] PaLM 2 Technical Report</A>
						<DT><A HREF="https://openai.com/research/better-language-models">GPT-2: Better language models and their implications</A>
						<DT><A HREF="https://arxiv.org/abs/2203.15556">Training Compute-Optimal Large Language Models</A>
						<DT><A HREF="https://research.nvidia.com/publication/2024-06_nemotron-4-340b">Nemotron-4 340B | Research</A>
						<DT><A HREF="https://d1qx31qr3h6wln.cloudfront.net/publications/Nemotron_4_340B_8T.pdf">Nemotron-4 340B Technical Report</A>
						<DT><A HREF="https://arxiv.org/abs/2210.11416">FLAN: Scaling Instruction-Finetuned Language Models</A>
						<DT><A HREF="https://arxiv.org/abs/1706.03762">[1706.03762] Attention Is All You Need</A>
						<DT><A HREF="https://openai.com/research/ai-and-compute#appendix-methods">AI and compute</A>
						<DT><A HREF="https://github.com/lucidrains/self-rewarding-lm-pytorch">lucidrains/self-rewarding-lm-pytorch: Implementation of the training framework proposed in Self-Rewarding Language Model, from MetaAI</A>
						<DT><A HREF="https://www.youtube.com/watch?v=KCXDr-UOb9A">Large Language Models in Five Formulas</A>
						<DT><A HREF="https://arxiv.org/abs/2403.15360">[2403.15360] SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series</A>
						<DT><A HREF="https://twitter.com/_akhaliq/status/1772833121609679216">InternLM2 Technical Report</A>
						<DT><A HREF="https://github.com/badripatro/Simba">badripatro/simba: Simba</A>
						<DT><A HREF="https://www.snowflake.com/blog/arctic-open-efficient-foundation-language-models-snowflake/">Snowflake Arctic - LLM for Enterprise AI</A>
						<DT><A HREF="https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm">Introducing DBRX: A New State-of-the-Art Open LLM | Databricks Blog</A>
						<DT><A HREF="https://huggingface.co/collections/ibm-granite/granite-code-models-6624c5cec322e4c148c8b330">Granite Code Models - a ibm-granite Collection</A>
						<DT><A HREF="https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8">Yi-1.5 (2024/05) - a 01-ai Collection</A>
						<DT><A HREF="https://cohere.com/blog/command-r">Command R: RAG at Production Scale</A>
						<DT><A HREF="https://github.com/xai-org/grok-1">xai-org/grok-1: Grok open release</A>
						<DT><A HREF="https://www.youtube.com/watch?v=zJKGhiZp1uU">Math Reading Group - Kolmogorov Arnold Networks (EvelynM) - (08/06/2024) - YouTube</A>
						<DT><A HREF="https://github.com/kyegomez/Reka-Torch">kyegomez/Reka-Torch: Implementation of the model: "Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models" in PyTorch</A>
						<DT><A HREF="https://www.evolutionaryscale.ai/">EvolutionaryScale</A>
						<DT><A HREF="https://cloneofsimo.notion.site/What-to-do-to-scale-up-09e469d7c3444d6a90305397c38a46f5">What to do to scale up?</A>
						<DT><A HREF="https://imbue.com/research/70b-intro/">Training a 70B model from scratch: open-source tools, evaluation datasets, and learnings - imbue</A>
						<DT><A HREF="https://github.com/imbue-ai/cluster-health">imbue-ai/cluster-health</A>
						<DT><A HREF="https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/?utm_source=twitter&utm_medium=organic_social&utm_content=link&utm_campaign=fair">Meta Large Language Model Compiler: Foundation Models of Compiler Optimization | Research - AI at Meta</A>
						<DT><A HREF="https://proceedings.mlr.press/v202/geiping23a.html">Cramming: Training a Language Model on a single GPU in one day.</A>
						<DT><A HREF="https://www.youtube.com/watch?v=orDKvo8h71o">Stanford CS25: V4 I Hyung Won Chung of OpenAI - YouTube</A>
						<DT><A HREF="https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0">Language Language Models (in 2023) - Google Slides</A>
						<DT><A HREF="https://arxiv.org/abs/2207.09238">[2207.09238] Formal Algorithms for Transformers</A>
						<DT><A HREF="https://publications.reka.ai/reka-core-tech-report.pdf">Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models</A>
						<DT><A HREF="https://blogs.nvidia.com/blog/mistral-nvidia-ai-model/">Mistral AI and NVIDIA Unveil Mistral NeMo 12B, a Cutting-Edge Enterprise AI Model | NVIDIA Blog</A>
						<DT><A HREF="https://github.com/microsoft/unilm">microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities</A>
						<DT><A HREF="https://arxiv.org/abs/2407.02783">[2407.02783] 52B to 1T: Lessons Learned via Tele-FLM Series</A>
						<DT><A HREF="https://01-ai.github.io/blog.html?post=en/2024-03-18-Dive-Deeper-into-Yi-9B.md">Dive Deeper into Yi-9B - 01.AI Blog</A>
						<DT><A HREF="https://arxiv.org/pdf/2205.05198">Reducing Activation Recomputation in Large Transformer Models</A>
						<DT><A HREF="https://arxiv.org/abs/2410.14940">[2410.14940] Nova: A Practical and Advanced Alignment</A>
						<DT><A HREF="https://mistral.ai/news/pixtral-large/">Pixtral Large | Mistral AI | Frontier AI in your hands</A>
						<DT><A HREF="https://github.com/NVlabs/hymba">NVlabs/hymba</A>
						<DT><A HREF="https://arxiv.org/abs/2501.08313">[2501.08313] MiniMax-01: Scaling Foundation Models with Lightning Attention</A>
						<DT><A HREF="https://x.com/jingyuanliu123/status/1966887747622453560">(1) JingyuanLiu en X: "I was lucky to work in both China and the US LLM labs, and I've been thinking this for a while. The current values of pretraining are indeed different: US labs be like: - lots of GPUs and much larger flops run - Treating stabilities more seriously, and could not tolerate spikes" / X</A>
						<DT><A HREF="https://arxiv.org/abs/2503.19786">[2503.19786] Gemma 3 Technical Report</A>
						<DT><A HREF="https://www.youtube.com/watch?v=91fmhAnECVc">Kimi Founder Yang Zhilin: K2, Agentic LLMs, Brains in Vats, and the Beginning of Infinity - YouTube</A>
						<DT><A HREF="https://rohin-garg.github.io/kexue-en/index.html">Scientific Spaces - English Translations kexue.fm by Su Jianlin</A>
						<DT><A HREF="https://kexue.fm/content.html">Readers can also view a list of articles with specific tags via https://kexue.fm/content.html?tag=muon .</A>
					</DL><p>
					<DT><H3 FOLDED>Large Transformer Model Inference Optimization</H3>
					<DL><p>
						<DT><H3 FOLDED>distillation</H3>
						<DL><p>
							<DT><H3 FOLDED>distillation-theory</H3>
							<DL><p>
								<DT><A HREF="https://drive.google.com/file/d/1xMohjQcTmQuUd_OiZ3hB1r47WB1WM3Am/view?pli=1">llm_distillation.pdf - Google Drive</A>
								<DT><A HREF="https://www.youtube.com/watch?v=O1AR4iL30mg">The Magic of LLM Distillation ‚Äî Rishabh Agarwal, Google DeepMind - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/1503.02531">[1503.02531] Distilling the Knowledge in a Neural Network</A>
								<DT><A HREF="https://arxiv.org/abs/1506.03099">[1506.03099] Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks</A>
								<DT><A HREF="https://arxiv.org/abs/1011.0686">[1011.0686] A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning</A>
								<DT><A HREF="https://arxiv.org/abs/2306.13649">[2306.13649] On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes</A>
								<DT><A HREF="https://arxiv.org/pdf/2408.11796">LLM Pruning and Distillation in Practice: The Minitron Approach</A>
								<DT><A HREF="https://x.com/agarwl_/status/1983929387797115298">(1) Rishabh Agarwal en X: "Sometimes I think about the small world hypothesis. I have a paper jointly with Rich Caruana, the OG author of distillation, and @geoffreyhinton, who brought the distillation work of "Caruana and collaborators" (as mentioned in his paper) to neural networks! Now, what are" / X</A>
								<DT><A HREF="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf">Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context</A>
								<DT><A HREF="https://x.com/iScienceLuvr/status/2001651246688845859">because it's almost always better to distill a huge model into a small model than training the small model from scratch!!</A>
							</DL><p>
							<DT><H3 FOLDED>on-policy-distillation</H3>
							<DL><p>
								<DT><A HREF="https://thinkingmachines.ai/blog/on-policy-distillation/">On-Policy Distillation - Thinking Machines Lab</A>
							</DL><p>
							<DT><A HREF="https://x.com/giffmana/status/1402836863954599936">(1) Lucas Beyer (bl16) en X: "So you think you know distillation; it's easy, right?</A>
							<DT><A HREF="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/#gemini-model-updates">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</A>
							<DT><A HREF="https://www.youtube.com/watch?v=FKsARHV3ZTI">Model Distilation: Student Models</A>
							<DT><A HREF="https://github.com/HuangOwen/Awesome-LLM-Compression">HuangOwen/Awesome-LLM-Compression: Awesome LLM compression research papers and tools.</A>
							<DT><A HREF="https://github.com/microsoft/TransformerCompression">microsoft/TransformerCompression: For releasing code related to compression methods for transformers, accompanying our publications</A>
							<DT><A HREF="https://arxiv.org/abs/2106.05237">[2106.05237] Knowledge distillation: A good teacher is patient and consistent</A>
							<DT><A HREF="https://x.com/PavloMolchanov/status/1815721057203925180">Minitron-4B/8B</A>
							<DT><A HREF="https://github.com/NVlabs/Minitron?tab=readme-ov-file">NVlabs/Minitron: A family of compressed models obtained via pruning and knowledge distillation</A>
							<DT><A HREF="https://x.com/AIatMeta/status/1824133790224224291">(1) AI at Meta en X: "Using structured weight pruning and knowledge distillation, the @NVIDIAAI research team refined Llama 3.1 8B into a new Llama-3.1-Minitron 4B. They're releasing the new models on @huggingface and shared a deep dive on how they did it ‚û°Ô∏è https://t.co/fJTrcfzx9m https://t.co/hTNVFwGjjh" / X</A>
							<DT><A HREF="https://pytorch.org/blog/llama-into-torchtune/?utm_content=316721961&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Distilling Llama3.1 8B into 1B in torchtune | PyTorch</A>
							<DT><A HREF="https://www.youtube.com/watch?v=jrf76uNs77k">The Unreasonable Effectiveness of Reasoning Distillation: using DeepSeek R1 to beat OpenAI o1 - YouTube</A>
							<DT><A HREF="https://www.bespokelabs.ai/blog/bespoke-stratos-the-unreasonable-effectiveness-of-reasoning-distillation">Bespoke-Stratos: The unreasonable effectiveness of reasoning distillation</A>
							<DT><A HREF="https://github.com/horus-ai-labs/DistillFlow">horus-ai-labs/DistillFlow</A>
							<DT><A HREF="https://x.com/agarwl_/status/1887758048237920374">(1) Rishabh Agarwal en X: "I recently gave a tutorial on knowledge distillation for LLMs, explaining the mathematical derivations behind the commonly used methods. Sharing the slides here given the recent interest in this topic. https://t.co/u1LYcY4s7G https://t.co/1bdCQ9o9Vy" / X</A>
							<DT><A HREF="https://x.com/agarwl_/status/1960034048698388795">(1) Rishabh Agarwal en X: "This is my last week at @AIatMeta. It was a tough decision not to continue with the new Superintelligence TBD lab, especially given the talent and compute density. But after 7.5 years across Google Brain, DeepMind, and Meta, I felt the pull to take on a different kind of risk." / X</A>
							<DT><A HREF="https://arxiv.org/pdf/2601.15394">Memorization Dynamics in Knowledge Distillation for Language Models</A>
						</DL><p>
						<DT><H3 FOLDED>model compression</H3>
						<DL><p>
							<DT><A HREF="https://x.com/karpathy/status/1814038096218083497">(1) Andrej Karpathy en X: "LLM model size competition is intensifying... backwards! My bet is that we'll see models that "think" very well and reliably that are very very small. There is most likely a setting even of GPT-2 parameters for which most people will consider GPT-2 "smart". The reason current" / X</A>
							<DT><A HREF="https://github.com/zipnn/zipnn/blob/main/images/table2.png">zipnn/images/table2.png at main ¬∑ zipnn/zipnn</A>
							<DT><A HREF="https://github.com/zipnn/zipnn">zipnn/zipnn: A lossless and near-lossless compression method optimized for numbers/tensors in the Foundation Models environment</A>
							<DT><A HREF="https://github.com/neuralmagic/compressed-tensors">neuralmagic/compressed-tensors: A safetensors extension to efficiently store sparse quantized tensors on disk</A>
							<DT><A HREF="https://github.com/neuralmagic/AutoFP8">neuralmagic/AutoFP8</A>
							<DT><A HREF="https://arxiv.org/abs/2410.05437">[2410.05437] ESPACE: Dimensionality Reduction of Activations for Model Compression</A>
						</DL><p>
						<DT><H3 FOLDED>throughput-bandwidth-latency</H3>
						<DL><p>
							<DT><H3 FOLDED>Continuity equation</H3>
							<DL><p>
								<DT><A HREF="https://www.fisimat.com.mx/ecuacion-de-continuidad/">Ecuaci√≥n de Continuidad - Ejercicios Resueltos - Fisimat</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=jlMAX2Oaht0">Text-generation-inference (TGI) deployment optimization and benchmarking - YouTube</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Continuity_equation">Continuity equation - Wikipedia</A>
							<DT><A HREF="https://cursor.sh/blog/instant-apply?utm_source=ainews&utm_medium=email&utm_campaign=ainews-to-be-named-9199">Cursor: Near-Instant Full-File Edits (OpenAI fund)</A>
							<DT><A HREF="https://www.youtube.com/watch?v=mYRqvB1_gRk&t=835s">Exploring the Latency/Throughput &amp; Cost Space for LLM Inference // TimotheÃÅe Lacroix // CTO Mistral - YouTube</A>
							<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62031/">Speeding up LLM Inference With TensorRT-LLM | NVIDIA On-Demand</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-quantization</H3>
						<DL><p>
							<DT><H3 FOLDED>model-quantization</H3>
							<DL><p>
								<DT><A HREF="https://leimao.github.io/article/Neural-Networks-Quantization/">Quantization for Neural Networks - Lei Mao's Log Book</A>
								<DT><A HREF="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization">A Visual Guide to Quantization - by Maarten Grootendorst</A>
								<DT><A HREF="https://github.com/htqin/awesome-model-quantization">htqin/awesome-model-quantization: A list of papers, docs, codes about model quantization. This repo is aimed to provide the info for model quantization research, we are continuously improving the project. Welcome to PR the works (papers, repositories) that are missed by the repo.</A>
								<DT><A HREF="https://github.com/htqin">htqin (Haotong Qin)</A>
								<DT><A HREF="https://github.com/bytedance/decoupleQ">bytedance/decoupleQ: A quantization algorithm for LLM</A>
								<DT><A HREF="https://github.com/bytedance/AffineQuant">bytedance/AffineQuant: Official implementation of the ICLR 2024 paper AffineQuant</A>
								<DT><A HREF="https://arxiv.org/abs/2302.04304">[2302.04304] Q-Diffusion: Quantizing Diffusion Models</A>
								<DT><A HREF="https://github.com/microsoft/BitBLAS">microsoft/BitBLAS: BitBLAS is a library to support mixed-precision matrix multiplications, especially for quantized LLM deployment.</A>
								<DT><A HREF="https://github.com/htqin/cnn-quantization">htqin/cnn-quantization: Quantization of Convolutional Neural networks.</A>
								<DT><A HREF="https://github.com/Macaronlin/LLaMA3-Quantization">Macaronlin/LLaMA3-Quantization: A repository dedicated to evaluating the performance of quantizied LLaMA3 using various quantization methods..</A>
								<DT><A HREF="https://x.com/realGeorgeHotz/status/1819963680739512550">(1) George Hotz üåë en X: "This is one of the coolest papers I've seen in a while. "Self-Compressing Neural Networks" is dynamic quantization-aware training that puts size (in bytes) of the model in the loss! Paper: https://t.co/2nnOb0m8kz My implementation (in @__tinygrad__): https://t.co/ChW4kdGygE" / X</A>
								<DT><A HREF="https://arxiv.org/pdf/2301.13142">Self-Compressing Neural Networks</A>
								<DT><A HREF="https://github.com/geohot/ai-notebooks/blob/master/mnist_self_compression.ipynb">ai-notebooks/mnist_self_compression.ipynb at master ¬∑ geohot/ai-notebooks</A>
								<DT><A HREF="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization?utm_campaign=post&utm_medium=web">A Visual Guide to Quantization - by Maarten Grootendorst</A>
								<DT><A HREF="https://static.sched.com/hosted_files/pytorch2024/c3/dmx-compressor.pdf">https://static.sched.com/hosted_files/pytorch2024/c3/dmx-compressor.pdf</A>
								<DT><A HREF="https://github.com/microsoft/microxcaling?tab=readme-ov-file#Spec-Configuration">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
								<DT><A HREF="https://github.com/microsoft/VPTQ">microsoft/VPTQ: VPTQ, A Flexible and Extreme low-bit quantization algorithm</A>
								<DT><A HREF="https://github.com/mit-han-lab/nunchaku">mit-han-lab/nunchaku: SVDQuant: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models</A>
								<DT><A HREF="https://arxiv.org/abs/2405.16406">[2405.16406] SpinQuant: LLM quantization with learned rotations</A>
								<DT><A HREF="https://www.together.ai/blog/even-better-even-faster-quantized-llms-with-qtip">Even Better, Even Faster Quantized LLMs with QTIP</A>
								<DT><A HREF="https://arxiv.org/abs/2404.00456">[2404.00456] QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs</A>
								<DT><A HREF="https://github.com/spcl/QuaRot">spcl/QuaRot: Code for Neurips24 paper: QuaRot, an end-to-end 4-bit inference of large language models.</A>
								<DT><A HREF="https://github.com/facebookresearch/SpinQuant">facebookresearch/SpinQuant: Code repo for the paper "SpinQuant LLM quantization with learned rotations"</A>
								<DT><A HREF="https://github.com/usyd-fsalab/fp6_llm">usyd-fsalab/fp6_llm: An efficient GPU support for LLM inference with x-bit quantization (e.g. FP6,FP5).</A>
								<DT><A HREF="https://github.com/chengzeyi/AdaptiveFloat4">chengzeyi/AdaptiveFloat4: A novel high-precision 4bit quantization format</A>
								<DT><A HREF="https://arxiv.org/abs/2411.02355">[2411.02355] "Give Me BF16 or Give Me Death"? Accuracy-Performance Trade-Offs in LLM Quantization</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/55842eb81a782da7e522ec0210c3fa1f3f74dc0a/python/sglang/srt/layers/quantization/__init__.py#L100">sglang/python/sglang/srt/layers/quantization/__init__.py: QUANTIZATION_METHODS</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/">Stable and Scalable FP8 Deep Learning Training on Blackwell S72778 | GTC 2025 | NVIDIA On-Demand</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=61">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
								<DT><A HREF="https://x.com/elonmusk/status/1987885633004831109">(1) Elon Musk en X: "@itsclivetime AI is moving to primarily 4 bit weights. Int4 for Tesla inference. Like a physical address, which has state, city and street. If you already know the state and city, only street need be specified. You still get the precision you need with far fewer bits." / X</A>
								<DT><A HREF="https://www.radicalnumerics.ai/blog/nvfp4-part1">NVFP4 Pretraining: From Theory to Implementation (Part 1) ¬∑ Radical Numerics</A>
							</DL><p>
							<DT><H3 FOLDED>transformer-inference-quantization-people</H3>
							<DL><p>
								<DT><A HREF="https://twitter.com/Tim_Dettmers">Tim Dettmers (@Tim_Dettmers) / Twitter</A>
							</DL><p>
							<DT><H3 FOLDED>Post-training quantization (PTQ)</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2106.09685">[2106.09685] LoRA: Low-Rank Adaptation of Large Language Models</A>
								<DT><A HREF="https://github.com/TimDettmers/bitsandbytes">TimDettmers/bitsandbytes: 8-bit CUDA functions for PyTorch</A>
								<DT><A HREF="https://arxiv.org/pdf/2004.09602.pdf">Integer Quantization For Deep Learning Inference: Principles and Empirical Evaluation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=AlASZb93rrc">Lecture 05 - Quantization (Part I) | MIT 6.S965 - YouTube</A>
								<DT><A HREF="https://twitter.com/atiorh/status/1684659953716584452">Atila @ ICML en Twitter: "Applying 1, 2, 4, 6 and 8-bit quantization via palettization yields much better results, e.g. We can use 1, 2, 4, 6 or 8-bits palettes to achieve the same compression rate as linear 8-bit quant (50%) but maintain correctness as high as 80dB (2dB loss vs 17dB for linear 8-bit) https://t.co/lA6ldVXYSW" / X</A>
								<DT><A HREF="https://twitter.com/amanrsanger/status/1690828443699847168">Quantitative quantization analysis at scale (bfp16 vs int)</A>
								<DT><A HREF="https://arxiv.org/pdf/2206.01861.pdf">ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers</A>
								<DT><A HREF="https://github.com/spcl/QuaRot">spcl/QuaRot: Code for QuaRot, an end-to-end 4-bit inference of large language models.</A>
							</DL><p>
							<DT><H3 FOLDED>transformer-inference-quantization-1-BitNet</H3>
							<DL><p>
								<DT><A HREF="https://mobiusml.github.io/1bit_blog/">Towards 1-bit Machine Learning Models</A>
								<DT><A HREF="https://github.com/rafacelente/bllama?tab=readme-ov-file">rafacelente/bllama: 1.58-bit LLaMa model</A>
								<DT><A HREF="https://github.com/microsoft/BitBLAS">microsoft/BitBLAS: BitBLAS is a library to support mixed-precision matrix multiplications, especially for quantized LLM deployment.</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2212.09720">[2212.09720] The case for 4-bit precision: k-bit Inference Scaling Laws</A>
							<DT><A HREF="https://arxiv.org/abs/2305.19268?utm_source=Cohere_For_AI&utm_medium=LinkedIn">[2305.19268] Intriguing Properties of Quantization at Scale</A>
							<DT><A HREF="https://twitter.com/awnihannun/status/1773185727997825406">MLX low-RAM lazy quantiztion procedure</A>
							<DT><A HREF="https://github.com/Vahe1994/AQLM">Vahe1994/AQLM: Official Pytorch repository for Extreme Compression of Large Language Models via Additive Quantization</A>
							<DT><A HREF="https://arxiv.org/pdf/2401.06118.pdf">Extreme Compression of Large Language Models via Additive Quantization</A>
							<DT><A HREF="https://github.com/snap-research/BitsFusion">snap-research/BitsFusion</A>
							<DT><A HREF="https://github.com/HanGuo97/flute">HanGuo97/flute: Fast Matrix Multiplications for Lookup Table-Quantized LLMs</A>
							<DT><A HREF="https://www.databricks.com/blog/serving-quantized-llms-nvidia-h100-tensor-core-gpus">Serving Quantized LLMs on NVIDIA H100 Tensor Core GPUs | Databricks Blog</A>
							<DT><A HREF="https://x.com/casper_hansen_/status/1861457676346998791">AutoAWQ to use Flash Decoding: flash_attn_with_kvcache</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-sparsity</H3>
						<DL><p>
							<DT><H3 FOLDED>transformer-inference-sparsity-deepspeed</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>Sparse Tensor Computation</H3>
							<DL><p>
								<DT><A HREF="https://github.com/microsoft/SparTA/tree/nmsparse_artifact">microsoft/SparTA at nmsparse_artifact</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2302.02596">[2302.02596] Ten Lessons We Have Learned in the New "Sparseland": A Short Handbook for Sparse Neural Network Researchers</A>
							<DT><A HREF="https://arxiv.org/abs/1902.09574">[1902.09574] The State of Sparsity in Deep Neural Networks</A>
							<DT><A HREF="https://twitter.com/lzcemma15/status/1683916730052268032">Contextual Sparsity for Efficient LLMs at Inference Time</A>
							<DT><A HREF="https://www.youtube.com/watch?v=0g351WQTaf8">[REFAI Seminar 04/20/23] Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time</A>
							<DT><A HREF="https://blogs.nvidia.com/blog/2020/05/14/sparsity-ai-inference/">What Is Sparsity in AI Inference and Machine Learning?</A>
							<DT><A HREF="https://www.youtube.com/watch?v=mGDnOLcfE8g">Lecture 11: Sparsity - YouTube</A>
							<DT><A HREF="https://github.com/neuralmagic/sparseml">neuralmagic/sparseml: Libraries for applying sparsification recipes to neural networks with a few lines of code, enabling faster and smaller models</A>
							<DT><A HREF="https://github.com/neuralmagic/sparsezoo">neuralmagic/sparsezoo: Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes</A>
							<DT><A HREF="https://github.com/google-research/jaxpruner">google-research/jaxpruner</A>
							<DT><A HREF="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/">Accelerating Inference with Sparsity Using the NVIDIA Ampere Architecture and NVIDIA TensorRT | NVIDIA Technical Blog</A>
							<DT><A HREF="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/">Accelerating Inference with Sparsity Using the NVIDIA Ampere Architecture and NVIDIA TensorRT</A>
							<DT><A HREF="https://arxiv.org/abs/2302.02596">[2302.02596] Ten Lessons We Have Learned in the New "Sparseland"</A>
							<DT><A HREF="https://twitter.com/_akhaliq/status/1734046582805344492">SparQ Attention: Bandwidth-Efficient LLM Inference</A>
							<DT><A HREF="https://arxiv.org/abs/2405.15743">[2405.15743] Sparse maximal update parameterization: A holistic approach to sparse training dynamics</A>
							<DT><A HREF="https://x.com/_EldarKurtic/status/1861084914327658865">2:4 Sparsity: Sparase-LLaMA-3.1-8B-2of4</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-pruning</H3>
						<DL><p>
							<DT><H3 FOLDED>experts-pruning</H3>
							<DL><p>
								<DT><A HREF="https://x.com/bigeagle_xd/status/1983094393553990152">(1) üêªÁÜäÁã∏ en X: "earlier this yr we had a toy experiment, that simply cut-off/drop half experts of K2, the k2-half can still generate meaningful text. i guess weight-average or other similar tricks should also work, and the performance should recover after some continuous training." / X</A>
							</DL><p>
							<DT><A HREF="https://openreview.net/pdf?id=0GRBKLBjJE">A Fast Post-Training Pruning Framework for Transformers</A>
							<DT><A HREF="https://www.youtube.com/watch?v=sZzc6tAtTrM">Lecture 03 - Pruning and Sparsity (Part I) | MIT 6.S965 - YouTube</A>
							<DT><A HREF="https://github.com/google-research/jaxpruner">google-research/jaxpruner</A>
							<DT><A HREF="https://x.com/AIatMeta/status/1824133790224224291">Minitron 4B</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-architectural-optimization</H3>
						<DL><p>
							<DT><H3 FOLDED>Attention</H3>
							<DL><p>
								<DT><H3 FOLDED>attention-theory</H3>
								<DL><p>
									<DT><A HREF="https://liyuan24.github.io/writings/attention_backprop.html">Attention Backpropagation | Liyuan‚Äôs Log</A>
									<DT><A HREF="https://github.com/lcy-seso/EfficientAttention-Notes">lcy-seso/EfficientAttention-Notes</A>
								</DL><p>
								<DT><H3 FOLDED>MHA (Multi-Head Attention)</H3>
								<DL><p>
									<DT><A HREF="https://kexue.fm/archives/10091">ÁºìÂ≠ò‰∏éÊïàÊûúÁöÑÊûÅÈôêÊãâÊâØÔºö‰ªéMHA„ÄÅMQA„ÄÅGQAÂà∞MLA - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://x.com/mrsiipa/status/1941111588964204768/photo/1">one line multi-head attention using einops</A>
									<DT><A HREF="https://arxiv.org/abs/2003.02436">[2003.02436] Talking-Heads Attention (Noam Shazeer)</A>
								</DL><p>
								<DT><H3 FOLDED>MQA (Multi-Query Attention)</H3>
								<DL><p>
									<DT><A HREF="https://kexue.fm/archives/10091">ÁºìÂ≠ò‰∏éÊïàÊûúÁöÑÊûÅÈôêÊãâÊâØÔºö‰ªéMHA„ÄÅMQA„ÄÅGQAÂà∞MLA - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://papers.cool/arxiv/1911.02150">Fast Transformer Decoding: One Write-Head is All You Need | Cool Papers - Immersive Paper Discovery</A>
									<DT><A HREF="https://arxiv.org/abs/1911.02150">[1911.02150] Fast Transformer Decoding: One Write-Head is All You Need</A>
									<DT><A HREF="https://gist.github.com/eqy/24246e2c70072aa5f3e3a803ef98f58f">cuDNN GQA</A>
								</DL><p>
								<DT><H3 FOLDED>GQA (Grouped-Query Attention)</H3>
								<DL><p>
									<DT><H3 FOLDED>GQA-profie</H3>
									<DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/715609504">Performance Analysis of LLM Decode GQA &amp; GEMV Operators (Part 2)</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/715091838">LLM Decode GQA &amp; GEMVÁÆóÂ≠êÊÄßËÉΩÂàÜÊûêÔºà‰∏ÄÔºâ - Áü•‰πé</A>
									</DL><p>
									<DT><A HREF="https://kexue.fm/archives/10091">ÁºìÂ≠ò‰∏éÊïàÊûúÁöÑÊûÅÈôêÊãâÊâØÔºö‰ªéMHA„ÄÅMQA„ÄÅGQAÂà∞MLA - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://arxiv.org/abs/2305.13245">[2305.13245] GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints</A>
								</DL><p>
								<DT><H3 FOLDED>MLA (Multi-head Latent Attention)</H3>
								<DL><p>
									<DT><H3 FOLDED>mla-tilelang</H3>
									<DL><p>
										<DT><A HREF="https://x.com/ZhihuFrontier/status/1980170674112188440">(1) Zhihu Frontier en X: "After DeepSeek-V3.2-Exp added TileLang &amp;amp; CUDA ops, many asked: what exactly is TileLang? ü§î In his post "TileLang: 80 lines of Python kernel code to reach 95% of FlashMLA's performance", developer &amp;amp; Zhihu contributor ryume gives a full breakdown of this new AI programming https://t.co/5NiR9MYI5Y" / X</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/27965825936">TileLang: 80Ë°åPython kernel‰ª£Á†ÅÂÆûÁé∞FlashMLA 95%ÁöÑÊÄßËÉΩ - Áü•‰πé</A>
										<DT><A HREF="https://github.com/tile-ai/tilelang/blob/main/examples/deepseek_mla/example_mla_decode.py">tilelang/examples/deepseek_mla/example_mla_decode.py at main ¬∑ tile-ai/tilelang</A>
									</DL><p>
									<DT><H3 FOLDED>mla-cute</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/b1d6e2c9b334dfa811e4183dfbd02419249e4b52/examples/python/CuTeDSL/blackwell/mla.py">cutlass/examples/python/CuTeDSL/blackwell/mla.py</A>
									</DL><p>
									<DT><A HREF="https://kexue.fm/archives/10907">Transformer Upgrade Road: 20. What is the advantage of MLA?</A>
									<DT><A HREF="https://arxiv.org/html/2405.04434v2">DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model</A>
									<DT><A HREF="https://kexue.fm/archives/10091">ÁºìÂ≠ò‰∏éÊïàÊûúÁöÑÊûÅÈôêÊãâÊâØÔºö‰ªéMHA„ÄÅMQA„ÄÅGQAÂà∞MLA - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
									<DT><A HREF="https://github.com/google/maxtext/blob/f7ee8c636fd500995e76c227b351d48680ab7890/MaxText/layers/attentions.py#L435">maxtext/MaxText/layers/attentions.py at f7ee8c636fd500995e76c227b351d48680ab7890 ¬∑ google/maxtext</A>
									<DT><A HREF="https://gist.github.com/Chillee/2e270fc5413dbbce58c779f8c4eac66c">flex_attention_tutorial.py</A>
									<DT><A HREF="https://pytorch.org/blog/flexattention/">FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention | PyTorch</A>
									<DT><A HREF="https://docs.google.com/presentation/d/1wB_Ul0LZwIDL47qFl64b8hVhH1_ya-1YPAPSSv0cKMs/edit#slide=id.g3031bdfe4db_0_8">SGLang DeepSeek MLA - Google Slides</A>
									<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/tree/924174cb5dc11fad24bdaad3fd820ebf87506368/mla">deepseekv2-profile/mla at 924174cb5dc11fad24bdaad3fd820ebf87506368 ¬∑ madsys-dev/deepseekv2-profile</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/23574608727">SGLang DP MLA ÁâπÊÄßËß£ËØª - Áü•‰πé</A>
									<DT><A HREF="https://github.com/deepseek-ai/FlashMLA">deepseek-ai/FlashMLA</A>
									<DT><A HREF="https://arxiv.org/abs/2502.14837">[2502.14837] Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs</A>
									<DT><A HREF="https://github.com/JT-Ushio/MHA2MLA">JT-Ushio/MHA2MLA: Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs</A>
									<DT><A HREF="https://www.youtube.com/watch?v=0VLAoVGf_74">The Genius of DeepSeek‚Äôs 57X Efficiency Boost [MLA] - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=s9R5s4U1WH8">Gentle Introduction to Causal Transformer Optimization and Multi-Head Latent Attention! - YouTube</A>
									<DT><A HREF="https://github.com/fxmeng/TransMLA">fxmeng/TransMLA: TransMLA: Multi-Head Latent Attention Is All You Need</A>
									<DT><A HREF="https://www.youtube.com/watch?v=0VLAoVGf_74&t=1s">How DeepSeek Rewrote the Transformer [MLA] - YouTube</A>
									<DT><A HREF="https://bench.flashinfer.ai/viewer?solution=mla_paged_prefill_causal_h16_ckv512_kpe64_ps1-gpt-5_cuda_fd76fe">mla_paged_prefill_causal_h16_ckv512_kpe64_ps1 gpt-5-cuda</A>
									<DT><A HREF="https://www.bilibili.com/video/BV1rJLtzMEfD/?spm_id_from=333.788.recommend_more_video.17&trackid=web_related_0.router-related-2206419-t6cb9.1762360943090.576">„ÄêTransformerÊ®°Âûã„ÄëË∂ÖÂº∫Âä®ÁîªÊºîÁ§∫Ôºå‰∏ÄÊ≠•‰∏ÄÊ≠•Ê∑±ÂÖ•ÊµÖÂá∫Ëß£ÈáäTransformerÂéüÁêÜÔºÅËøôÂ∫îËØ•ÊòØÊàëÂú®BÁ´ôÁúãÂà∞ËøáÊúÄÈÄö‰øóÊòìÊáÇÁöÑTransformerÊïôÁ®ã‰∫ÜÂêßÔºÅ_ÂìîÂì©ÂìîÂì©_bilibili</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Y-o545eYjXM">How Attention Got So Efficient [GQA/MLA/DSA] - YouTube</A>
									<DT><A HREF="https://x.com/teortaxestex/status/2013365105627472316?s=12">My list of models using MLA or derivatives:</A>
									<DT><A HREF="https://github.com/ambisinister/mla-experiments">ambisinister/mla-experiments: Experiments on Multi-Head Latent Attention</A>
								</DL><p>
								<DT><H3 FOLDED>Ring attention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/mgmalek/ring-attention">mgmalek/ring-attention</A>
									<DT><A HREF="https://github.com/zhuzilin/ring-flash-attention">zhuzilin/ring-flash-attention: Ring attention implementation with flash attention</A>
									<DT><A HREF="https://github.com/gpu-mode/ring-attention">gpu-mode/ring-attention: ring-attention experiments</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/distributed/tensor/experimental/_attention.py">pytorch/torch/distributed/tensor/experimental/_attention.py: _templated_ring_attention</A>
								</DL><p>
								<DT><H3 FOLDED>Linear Attention</H3>
								<DL><p>
									<DT><H3 FOLDED>hybrid-linear-attention</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2507.06457">A Systematic Analysis of Hybrid Linear Attention</A>
									</DL><p>
									<DT><H3 FOLDED>JetBlock</H3>
									<DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1954940949126939783">Jet-Nemotron-2B and Grok 4 code fast</A>
										<DT><A HREF="https://arxiv.org/pdf/2508.15884v1">Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search</A>
										<DT><A HREF="https://x.com/hancai_hm/status/1972794734747033985">(1) Han Cai en X: "üöÄ Jet-Nemotron ‚Äì Code &amp;amp; pre-trained checkpoints now available! ‚ö°Ô∏è Achieve up to 53.6√ó higher generation throughput on H100 GPUs with cost-efficient finetuning. üîó GitHub: https://t.co/XGX7MTMm7J üîó Hugging Face: https://t.co/AMEGIq5zOp üîó Paper: https://t.co/iWfL4HNrlf" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2508.15884">[2508.15884] Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search</A>
										<DT><A HREF="https://github.com/NVlabs/Jet-Nemotron">NVlabs/Jet-Nemotron</A>
									</DL><p>
									<DT><H3 FOLDED>KDA</H3>
									<DL><p>
										<DT><H3 FOLDED>DeltaNet</H3>
										<DL><p>
											<DT><A HREF="https://sustcsonglin.github.io/blog/2024/deltanet-1/">DeltaNet Explained (Part I) | Songlin Yang</A>
											<DT><A HREF="https://kexue.fm/archives/11563">The elements of the core inverse matrix of DeltaNet are always within the range of [-1, 1]</A>
											<DT><A HREF="https://x.com/ID_AA_Carmack/status/2009728677718712655">(1) John Carmack en X: "#PaperADay 2 2026: Deep Delta Learning https://t.co/fcNuN6bPmt The standard residual network blocks are limited to adding on top of the existing state, which limits the expressivity of each layer. It is still a universal approximator, but we can always hope for function blocks" / X</A>
										</DL><p>
										<DT><A HREF="https://x.com/zhihufrontier/status/1984321210055082207">Inside Kimi Linear: First-Hand Insights</A>
										<DT><A HREF="https://www.zhihu.com/question/1967345030881584585/answer/1967730385816385407">Â¶Ç‰ΩïËØÑ‰ª∑Kimi LinearÔºü - Áü•‰πé</A>
										<DT><A HREF="https://www.zhihu.com/question/1966873359510906300/answer/1967522190103679345">Â¶Ç‰ΩïÁúãÂæÖKimiDeltaAttention‰∏éRWKV-7ÁöÑÂÆûÁé∞Âå∫Âà´Ôºü - Áü•‰πé</A>
										<DT><A HREF="https://github.com/MoonshotAI/Kimi-Linear">MoonshotAI/Kimi-Linear</A>
										<DT><A HREF="https://x.com/nrehiew_/status/1983921817925419172">(1) wh en X: "@Grad62304977 @stochasticchasm tldr. is this right? https://t.co/6JySeeja9g" / X</A>
										<DT><A HREF="https://x.com/Grad62304977/status/1983900639177462244">attention intuition kda</A>
										<DT><A HREF="https://x.com/nrehiew_/status/1986079207513075854">You can see how I start from practically 0 and am trying to understand Kimi Delta Attention and related linear attention literature by spamming Grad with questions.</A>
										<DT><A HREF="https://arxiv.org/abs/2510.26692">[2510.26692] Kimi Linear: An Expressive, Efficient Attention Architecture</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/27654">[FLA] Introduce Kimi Delta Attention(KDA) to VLLM by zhiyuan1i ¬∑ Pull Request #27654 ¬∑ vllm-project/vllm</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/1812.01243">[1812.01243] Efficient Attention: Attention with Linear Complexities</A>
									<DT><A HREF="https://arxiv.org/abs/2006.04768">[2006.04768] Linformer: Self-Attention with Linear Complexity</A>
									<DT><A HREF="https://arxiv.org/abs/2001.04451">[2001.04451] Reformer: The Efficient Transformer</A>
									<DT><A HREF="https://openai.com/research/requests-for-research-2">Transformers with Linear Attention (OpenAI)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=dVH1dRoMPBc">Do we need Attention? A Mamba Primer - YouTube</A>
									<DT><A HREF="https://x.com/simran_s_arora/status/1845909074774475125">LLaMA 405B linear-time inference, KV-state</A>
									<DT><A HREF="https://haileyschoelkopf.github.io/blog/2024/linear-attn/">Linear Attention Fundamentals | Hailey Schoelkopf</A>
									<DT><A HREF="https://www.youtube.com/watch?v=d0HJvGSWw8A">Linear Attention and Beyond (Interactive Tutorial with Songlin Yang) - YouTube</A>
									<DT><A HREF="https://github.com/sustcsonglin/linear-attention-and-beyond-slides">sustcsonglin/linear-attention-and-beyond-slides</A>
									<DT><A HREF="https://kexue.fm/archives/11320">Why does linear attention need Short Conv?</A>
									<DT><A HREF="https://x.com/VukRosic99/status/1977372955672752384">Qwen 3 next uses 1:3 attn:linear | Nemotron-H is 1:6</A>
									<DT><A HREF="https://arxiv.org/pdf/2406.07887">An Empirical Study of Mamba-based Language Models</A>
									<DT><A HREF="https://arxiv.org/abs/2507.06457">[2507.06457] A Systematic Analysis of Hybrid Linear Attention</A>
									<DT><A HREF="https://pytorch.org/blog/hybrid-models-as-first-class-citizens-in-vllm/">Hybrid Models as First-Class Citizens in vLLM ‚Äì PyTorch</A>
									<DT><A HREF="https://sustcsonglin.github.io/assets/pdf/talk_250117.pdf">What‚Äôs Next for Mamba? Towards More Expressive Recurrent Update Rules Songlin Yang</A>
									<DT><A HREF="https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&from=research.latest-advancements-list">Qwen3-Next architecture details</A>
									<DT><A HREF="https://neurips.cc/virtual/2024/poster/93040">NeurIPS Poster Parallelizing Linear Transformers with the Delta Rule over Sequence Length</A>
									<DT><A HREF="https://arxiv.org/pdf/2510.26692">KIMI LINEAR</A>
									<DT><A HREF="https://github.com/fla-org/flash-linear-attention">fla-org/flash-linear-attention: üöÄ Efficient implementations of state-of-the-art linear attention models</A>
									<DT><A HREF="https://x.com/jbhuang0604/status/2013653888402886792">(4) Jia-Bin Huang en X: "Beyond softmax attention Linear attention and its variants enable faster inference without growing the KV cache. Let‚Äôs learn the core ideas behind efficient sequence modeling. üëá https://t.co/geNiBXKdlI https://t.co/tCDldDuida" / X</A>
									<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247494744&idx=1&sn=20f307c5e0fe7c5c5d62a46d81f48646&chksm=f995fc9acee2758c9a03a17f7feea8a7b0db439b42f504305cc4b5db22e64feacb30904344ca&scene=178&cur_album_id=3210156532718403586&search_click_id=#rd">Zarbot Let's discuss some of the evolutions of Transformer: UT, MoD, MoR...</A>
								</DL><p>
								<DT><H3 FOLDED>Adaptive Attention</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2207.07061.pdf">Confident Adaptive Language Modeling (CALM)</A>
								</DL><p>
								<DT><H3 FOLDED>Attention Free</H3>
								<DL><p>
									<DT><H3 FOLDED>Mamba</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=dVH1dRoMPBc&t=10s">Do we need Attention? A Mamba Primer - YouTube</A>
										<DT><A HREF="https://x.com/TXhunyuan/status/1899105803073958010">Hunyuan-TurboS</A>
										<DT><A HREF="https://sustcsonglin.github.io/assets/pdf/talk_250117.pdf">What‚Äôs Next for Mamba? Towards More Expressive Recurrent Update Rules Songlin Yang</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2212.10544">[2212.10544] Pretraining Without Attention</A>
									<DT><A HREF="https://arxiv.org/abs/2105.14103">[2105.14103] An Attention Free Transformer</A>
									<DT><A HREF="https://github.com/rish-16/aft-pytorch">rish-16/aft-pytorch: Unofficial PyTorch implementation of Attention Free Transformer (AFT) layers by Apple Inc.</A>
								</DL><p>
								<DT><H3 FOLDED>RVKV</H3>
								<DL><p>
									<DT><A HREF="https://github.com/BlinkDL/RWKV-LM">BlinkDL/RWKV-LM: RWKV is an RNN with transformer-level LLM performance. It can be directly trained like a GPT (parallelizable). So it's combining the best of RNN and transformer - great performance, fast inference, saves VRAM, fast training, "infinite" ctx_len, and free sentence embedding.</A>
								</DL><p>
								<DT><H3 FOLDED>PagedAttention</H3>
								<DL><p>
									<DT><A HREF="https://vllm.ai/">vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention</A>
									<DT><A HREF="https://github.com/microsoft/vattention">microsoft/vattention: Dynamic Memory Management for Serving LLMs without PagedAttention</A>
									<DT><A HREF="https://github.com/Wenyueh/MinivLLM/blob/main/benchmark_decoding.py">paged_attention_decode_kernel benchmark</A>
									<DT><A HREF="https://www.youtube.com/watch?v=5ZlavKF_98U">Fast LLM Serving with vLLM and PagedAttention - YouTube</A>
									<DT><A HREF="https://x.com/kimbochen/status/2014610058156638726">(1) Kimbo en X: "Re-reading vLLM with FlexAttention to understand the paged attention mechanism better. I went through PyTorch's blog post with Claude's help, but I prefer @ChangJonathanC 's nano-flex-vllm better. Essentially, for every request, your attention mask is [query length, the whole KV" / X</A>
								</DL><p>
								<DT><H3 FOLDED>SageAttention</H3>
								<DL><p>
									<DT><H3 FOLDED>SageAttention-hopper</H3>
									<DL><p>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0e5ea838b6d72e552f82d4d6d60c40312ecf5237/sageattention/core.py#L746">sageattn_qk_int8_pv_fp8_cuda_sm90</A>
										<DT><A HREF="https://github.com/search?q=repo%3Athu-ml%2FSageAttention%20_qattn_sm90&type=code">_qattn_sm90</A>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/setup.py#L152">CudaExtension "sageattention._qattn_sm90"</A>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/csrc/qattn/attn_cuda_sm90.h">SageAttention/csrc/qattn/attn_cuda_sm90.h at 0c8f308164b2d19025dec082520aea6084ff3626 ¬∑ thu-ml/SageAttention</A>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/csrc/qattn/pybind_sm90.cpp">SageAttention/csrc/qattn/pybind_sm90.cpp at 0c8f308164b2d19025dec082520aea6084ff3626 ¬∑ thu-ml/SageAttention</A>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/csrc/qattn/qk_int_sv_f8_cuda_sm90.cu">SageAttention/csrc/qattn/qk_int_sv_f8_cuda_sm90.cu at 0c8f308164b2d19025dec082520aea6084ff3626 ¬∑ thu-ml/SageAttention</A>
									</DL><p>
									<DT><H3 FOLDED>SageAttention-blackwell</H3>
									<DL><p>
										<DT><H3 FOLDED>SageAttention-sm120</H3>
										<DL><p>
											<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/sageattention/core.py#L136C16-L136C44">core.py#L136C16-L136C44: sageattn_qk_int8_pv_fp8_cuda same to SM89 kernel</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>SageAttention3</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2505.11594">[2505.11594] SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training</A>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/commit/96a29ccfaf3bcf5fada4731ac050456458f617f7">Update README.md ¬∑ thu-ml/SageAttention@96a29cc</A>
									</DL><p>
									<DT><A HREF="https://github.com/thu-ml/SageAttention">thu-ml/SageAttention: Quantized Attention that achieves speedups of 2.1x and 2.7x compared to FlashAttention2 and xformers, respectively, without lossing end-to-end metrics across various models.</A>
									<DT><A HREF="https://arxiv.org/abs/2410.02367">[2410.02367] SageAttention: Accurate 8-Bit Attention for Plug-and-play Inference Acceleration</A>
									<DT><A HREF="https://github.com/feifeibear/ChituAttention">feifeibear/ChituAttention: Quantized Attention on GPU</A>
									<DT><A HREF="https://arxiv.org/html/2411.10958v1">SageAttention2 Technical Report: Accurate 4 Bit Attention for Plug-and-play Inference Acceleration</A>
									<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0e5ea838b6d72e552f82d4d6d60c40312ecf5237/sageattention/core.py#L746">sageattn_qk_int8_pv_fp8_cuda_sm90</A>
									<DT><A HREF="https://github.com/modelscope/DiffSynth-Engine/blob/45ab89bf062d87a5b3c41a304dc0112409e04429/diffsynth_engine/models/basic/attention.py#L56">DiffSynth-Engine/diffsynth_engine/models/basic/attention.py</A>
									<DT><A HREF="https://arxiv.org/abs/2505.21136">[2505.21136] SageAttention2++: A More Efficient Implementation of SageAttention2</A>
								</DL><p>
								<DT><H3 FOLDED>DuoAttention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/mit-han-lab/duo-attention/tree/main">mit-han-lab/duo-attention: DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads</A>
								</DL><p>
								<DT><H3 FOLDED>KV-cache-efficient</H3>
								<DL><p>
									<DT><H3 FOLDED>RadixAttention</H3>
									<DL><p>
										<DT><A HREF="https://lmsys.org/blog/2024-01-17-sglang/">Fast and Expressive LLM Inference with RadixAttention and SGLang | LMSYS Org</A>
										<DT><A HREF="https://arxiv.org/pdf/2312.07104">SGLang: Efficient Execution of Structured Language Model Programs</A>
										<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-4-kv-caching-a-deeper-look-4ba9a77746c8">LLM Inference Series: 4. KV caching, a deeper look | by Pierre Lienhart | Medium</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/7310aede97a0fdacc0be3219b6f8174b53351075/python/sglang/srt/layers/radix_attention.py#L21">sglang/python/sglang/srt/layers/radix_attention.py at 7310aede97a0fdacc0be3219b6f8174b53351075 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://www.youtube.com/watch?v=Ny4xxErgFgQ">Efficient LLM Inference with SGLang, Lianmin Zheng, xAI - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>KV-cache-compression</H3>
									<DL><p>
										<DT><A HREF="https://neurips.cc/virtual/2025/loc/san-diego/poster/119605">NeurIPS Poster Inference-Time Hyper-Scaling with KV Cache Compression</A>
										<DT><A HREF="https://arxiv.org/abs/2506.05345">[2506.05345] Inference-Time Hyper-Scaling with KV Cache Compression</A>
									</DL><p>
									<DT><A HREF="https://github.com/chengzeyi/AsyncKVAttention">chengzeyi/AsyncKVAttention</A>
									<DT><A HREF="https://github.com/shadowpa0327/Palu">shadowpa0327/Palu: Code for Palu: Compressing KV-Cache with Low-Rank Projection</A>
									<DT><A HREF="https://github.com/JerryYin777/Cross-Layer-Attention">JerryYin777/Cross-Layer-Attention: Self Reproduction Code of Paper "Reducing Transformer Key-Value Cache Size with Cross-Layer Attention (MIT CSAIL)</A>
									<DT><A HREF="https://x.com/Ar_Douillard/status/1845791796569260202">KV Prediction for Improved Time to First Token</A>
									<DT><A HREF="https://x.com/hkproj/status/1828778411814236173">Writing in the Margins (WiM)</A>
									<DT><A HREF="https://github.com/NVIDIA/kvpress">NVIDIA/kvpress: LLM KV cache compression made easy</A>
									<DT><A HREF="https://github.com/jzhang38/EasyContext">jzhang38/EasyContext: Memory optimization and training recipes to extrapolate language models' context length to 1 million tokens, with minimal hardware.</A>
									<DT><A HREF="https://qwenlm.github.io/blog/qwen2.5-turbo/">Extending the Context Length to 1M Tokens! | Qwen</A>
									<DT><A HREF="https://github.com/NVIDIA/Star-Attention">NVIDIA/Star-Attention: Efficient LLM Inference over Long Sequences</A>
									<DT><A HREF="https://x.com/iofu728/status/1868588111246283047">(1) Huiqiang Jiang en X: "üï∏Ô∏è KV cache has its own lifecycle, but previous benchs focus solely on single-req, ignore full lifecycle. ü™ªSCBench fills the gap with a KV-cache-centric angle, covering 4 kv cache stage across 12 tasks, 4 capability, and 2 shared-context mode https://t.co/lVeuNwpfyf https://t.co/YZiN2Skctr" / X</A>
									<DT><A HREF="https://research.character.ai/optimizing-inference/">Optimizing AI Inference at Character.AI</A>
									<DT><A HREF="https://x.com/RYANHINGSHING/status/2010803805269737483">(1) Ryan Leung Ê¢ÅËààÁõõ, CFA en X: "This reminds me of Huawei‚Äôs three-level KV cache storage structure for long memory context inference, which was announced 5 months ago. Since Huawei and DeepSeek have been cooperating, I suspect that DS had already tested the hierarchical concept at least half a year earlierü§î https://t.co/TUIC0sPELQ" / X</A>
								</DL><p>
								<DT><H3 FOLDED>torch-SDPA</H3>
								<DL><p>
									<DT><H3 FOLDED>sdpa-cudnn</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/4d9b5a87e4cc1e2ff81dce5123ee98a7c1b2d6a8/test/test_transformers.py#L3366">pytorch/test/test_transformers.py: torch.ops.aten._scaled_dot_product_cudnn_attention</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml#L14817C9-L14817C44">pytorch/aten/src/ATen/native/native_functions.yaml: _scaled_dot_product_cudnn_attention</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/commit/9a9a0abc2818d40d06eda6c0b6fdbc949474f12e">[SDPA-CUDNN] Make CuDNN Attention Opt in (#138522) ¬∑ pytorch/pytorch@9a9a0ab</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/nn/attention/__init__.py#L30">pytorch/torch/nn/attention/__init__.py at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/4d9b5a87e4cc1e2ff81dce5123ee98a7c1b2d6a8/torch/_meta_registrations.py#L5022">pytorch/torch/_meta_registrations.py: meta__scaled_dot_product_cudnn_attention</A>
									<DT><A HREF="https://gist.github.com/cloneofsimo/af610ff8aa11a3f57956e7d7f578409c">FlashAttention comparison</A>
									<DT><A HREF="https://docs.google.com/spreadsheets/d/18araPIxeeIGbS9BNooUCYsC4RkfnhIe4kcAqkscQGL4/edit?gid=0#gid=0">attention roofline - Google Sheets</A>
									<DT><A HREF="https://gist.github.com/drisspg/bef40a41a3f2b6faedf4a5d625616bda">sdpa.py: Torch SDPA benchmarking</A>
									<DT><A HREF="https://github.com/chengzeyi/model-deploy/blob/72bad1281b246d3ce4145671c7e0a38131bff50a/runpod/mystic_upscaler/patches/attention.py">model-deploy/runpod/mystic_upscaler/patches/attention.py: SDPBackend attention</A>
								</DL><p>
								<DT><H3 FOLDED>ChituAttention: Quantized Attention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/feifeibear/ChituAttention">feifeibear/ChituAttention: Quantized Attention on GPU</A>
								</DL><p>
								<DT><H3 FOLDED>Pyramid Attention Broadcast</H3>
								<DL><p>
									<DT><A HREF="https://oahzxl.github.io/PAB/">Real-Time Video Generation with Pyramid Attention Broadcast</A>
									<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys">NUS-HPC-AI-Lab/VideoSys: VideoSys: An easy and efficient system for video generation</A>
									<DT><A HREF="https://arxiv.org/abs/2408.12588">[2408.12588] Real-Time Video Generation with Pyramid Attention Broadcast</A>
									<DT><A HREF="https://github.com/NUS-HPC-AI-Lab/VideoSys/blob/master/docs/pab.md">VideoSys/docs/pab.md at master ¬∑ NUS-HPC-AI-Lab/VideoSys</A>
								</DL><p>
								<DT><H3 FOLDED>Stick-breaking Attention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/shawntan/stickbreaking-attention?tab=readme-ov-file">shawntan/stickbreaking-attention: Stick-breaking attention</A>
									<DT><A HREF="https://arxiv.org/abs/2403.08245">[2403.08245] Scattered Mixture-of-Experts Implementation</A>
								</DL><p>
								<DT><H3 FOLDED>Star Attention</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2411.17116">[2411.17116] Star Attention: Efficient LLM Inference over Long Sequences</A>
								</DL><p>
								<DT><H3 FOLDED>attention-language</H3>
								<DL><p>
									<DT><A HREF="https://x.com/VictorTaelin/status/1865562732457566287">turing complete attention language</A>
									<DT><A HREF="https://srush.github.io/raspy/">attention as a programming language</A>
									<DT><A HREF="https://arxiv.org/pdf/2106.06981">Thinking Like Transformers</A>
									<DT><A HREF="https://github.com/microsoft/AttentionEngine">microsoft/AttentionEngine</A>
									<DT><A HREF="https://x.com/teortaxesTex/status/1969759058157797876/photo/1">o3 chain-of-thought</A>
									<DT><A HREF="https://mp.weixin.qq.com/s/HYlU3ldZn_79GJol17s9xQ">Ë∞àË∞àÂü∫‰∫éScaleUPÁöÑÂ≠òÂÇ®Êâ©Â±ïÂíå‰∏âÁΩëËûçÂêà</A>
								</DL><p>
								<DT><H3 FOLDED>QuantumAttention</H3>
								<DL><p>
									<DT><H3 FOLDED>QuantumAttention-TK</H3>
									<DL><p>
										<DT><H3 FOLDED>exp2</H3>
										<DL><p>
											<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/blob/18e32770cc719687e869af6a7df4686dee67e041/csrc/softmax.h#L111">softmax.h#L111 This allows the compiler to use the ffma instruction instead of fadd and fmul separately.</A>
											<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/0baf4b3fd3c568964acd4f176c35e8f073c70c20/src/quantum_attn/tk/attention.py#L31">QuantumAttention/src/quantum_attn/tk/attention.py at 0baf4b3fd3c568964acd4f176c35e8f073c70c20 ¬∑ WaveSpeedAI/QuantumAttention</A>
										</DL><p>
										<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/e7b647eb86596609ea68d372c9291a2e63e16d16/src/quantum_attn/tk/attention.py">QuantumAttention/src/quantum_attn/tk/attention.py at e7b647eb86596609ea68d372c9291a2e63e16d16 ¬∑ WaveSpeedAI/QuantumAttention</A>
									</DL><p>
									<DT><A HREF="https://github.com/chengzeyi/QuantumAttention/commit/35abd08f042314e01bad999a0521faee24ca4d6a">Dev kernel (#1) ¬∑ chengzeyi/QuantumAttention@35abd08</A>
									<DT><A HREF="https://github.com/chengzeyi/QuantumAttention/blob/main/src/quantum_attn/config.py">QuantumAttention/src/quantum_attn/config.py at main env vars patch</A>
									<DT><A HREF="https://github.com/search?q=repo%3Achengzeyi%2FQuantumAttention%20attention.force_eager_fallback&type=code">config patching (e.g. attention.force_eager_fallback)</A>
									<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/commit/e7b647eb86596609ea68d372c9291a2e63e16d16">Dev fp8 attn per head (#3) ¬∑ WaveSpeedAI/QuantumAttention@e7b647e</A>
								</DL><p>
								<DT><H3 FOLDED>sparse-attention</H3>
								<DL><p>
									<DT><H3 FOLDED>MoBA</H3>
									<DL><p>
										<DT><H3 FOLDED>flash-moba</H3>
										<DL><p>
											<DT><A HREF="https://github.com/mit-han-lab/flash-moba">mit-han-lab/flash-moba</A>
											<DT><A HREF="https://arxiv.org/abs/2511.11571">[2511.11571] Optimizing Mixture of Block Attention</A>
										</DL><p>
										<DT><A HREF="https://x.com/Kimi_Moonshot/status/1891825059599352259">Introducing MoBA: Mixture of Block Attention for Long-Context LLMs release notes</A>
										<DT><A HREF="https://github.com/MoonshotAI/MoBA">MoonshotAI/MoBA: MoBA: Mixture of Block Attention for Long-Context LLMs</A>
										<DT><A HREF="https://github.com/MoonshotAI/MoBA/blob/master/MoBA_Tech_Report.pdf">MoBA/MoBA_Tech_Report.pdf at master ¬∑ MoonshotAI/MoBA</A>
										<DT><A HREF="https://arxiv.org/abs/2502.13189">[2502.13189] MoBA: Mixture of Block Attention for Long-Context LLMs</A>
									</DL><p>
									<DT><H3 FOLDED>NSA</H3>
									<DL><p>
										<DT><A HREF="https://x.com/deepseek_ai/status/1891745487071609327">(1) DeepSeek en X: "üöÄ Introducing NSA: A Hardware-Aligned and Natively Trainable Sparse Attention mechanism for ultra-fast long-context training &amp;amp; inference! Core components of NSA: ‚Ä¢ Dynamic hierarchical sparse strategy ‚Ä¢ Coarse-grained token compression ‚Ä¢ Fine-grained token selection üí° With https://t.co/zjXuBzzDCp" / X</A>
										<DT><A HREF="https://arxiv.org/abs/2502.11089">[2502.11089] Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</A>
										<DT><A HREF="https://github.com/lucidrains/native-sparse-attention-pytorch">lucidrains/native-sparse-attention-pytorch: Implementation of the sparse attention pattern proposed by the Deepseek team in their "Native Sparse Attention" paper</A>
										<DT><A HREF="https://arxiv.org/abs/2209.04881">[2209.04881] On The Computational Complexity of Self-Attention</A>
										<DT><A HREF="https://github.com/XunhaoLai/native-sparse-attention-triton">XunhaoLai/native-sparse-attention-triton: This repo provides an efficient Triton implementation of the sparse attention mechanism from the paper [Native Sparse Attention](https://arxiv.org/abs/2502.11089).</A>
										<DT><A HREF="https://github.com/mdy666/qwen-nsa">mdy666/qwen-nsa: qwen-nsa</A>
										<DT><A HREF="https://github.com/fla-org/native-sparse-attention">fla-org/native-sparse-attention: üê≥ Efficient Triton implementations for "Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention"</A>
										<DT><A HREF="https://x.com/casper_hansen_/status/1950649481617342803">DeepSeek V4 will use NSA</A>
										<DT><A HREF="https://x.com/_xjdr/status/1954946075862982890?s=12">GPT5 / Opus 4.1 NSA impl eval</A>
										<DT><A HREF="https://github.com/Noumena-Network/NSA-Test">Noumena-Network/NSA-Test: NSA Triton Kernels written with GPT5 and Opus 4.1</A>
										<DT><A HREF="https://guangxuanx.com/blog/block-sparse-attn-stats.html">Statistics behind Block Sparse Attention</A>
										<DT><A HREF="https://nathanchen.me/public/Flash-Attention-Tilelang.html">Implementing Flash Attention in TileLang (1.3x Faster Than FA-2): Part 1</A>
										<DT><A HREF="https://github.com/tilde-research/nsa-impl">tilde-research/nsa-impl: An efficient implementation of the NSA (Native Sparse Attention) kernel</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1975973344672245268">DSA vs NSA &amp; DSAÁ®ÄÁñèËÆ≠ÁªÉÁÆóÂ≠êÂÆûÁé∞(TileLang) - Áü•‰πé</A>
										<DT><A HREF="https://henryhmko.github.io/posts/nsa_tpu/nsa_tpu.html">Optimizing NSA for TPUs - Kernel Worklog</A>
										<DT><A HREF="https://www.youtube.com/watch?v=HS5FJbif5A0">ML Performance Reading Group Session 20: Native Sparse Attention - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>SpargeAttn</H3>
									<DL><p>
										<DT><A HREF="https://github.com/thu-ml/SpargeAttn">thu-ml/SpargeAttn: [ICML2025] SpargeAttention: A training-free sparse attention that accelerates any model inference.</A>
									</DL><p>
									<DT><A HREF="https://x.com/tilderesearch/status/1937929093607198998">(1) Tilde en X: "Sparse attention (MoBA/NSA) trains faster &amp;amp; beats full attention in key tasks. But we‚Äôve had no idea how they truly work...until now. üîç We reverse-engineered them to uncover: - Novel attention patterns - Hidden "attention sinks" - Better performance - And more A üßµ... ~1/8~ https://t.co/E43AAGPBi3" / X</A>
									<DT><A HREF="https://github.com/Tencent-Hunyuan/flex-block-attn">Tencent-Hunyuan/flex-block-attn: flex-block-attn: an efficient block sparse attention computation library</A>
									<DT><A HREF="https://github.com/openai/sparse_attention">openai/sparse_attention: Examples of using sparse attention, as in "Generating Long Sequences with Sparse Transformers"</A>
								</DL><p>
								<DT><H3 FOLDED>Slim-attention</H3>
								<DL><p>
									<DT><A HREF="https://x.com/TheTuringPost/status/1905205969925357934">(1) TuringPost en X: "What is Slim Attention? It's a new attention mechanism that allows models to be 2x faster and cut memory use by 32 times! ‚ñ™Ô∏è What's the secret? It uses the same math as Multi-Head Attention (MHA) but applies one clever trick: Instead of storing both keys (K) and values (V) in https://t.co/TOPoylrZrA" / X</A>
								</DL><p>
								<DT><H3 FOLDED>prefix cache</H3>
								<DL><p>
									<DT><A HREF="https://github.com/allwefantasy/auto-coder/blob/b509271626e0bc0c511dcd510f6cb6c9d28b3267/src/autocoder/rag/long_context_rag.py#L170">auto-coder/src/autocoder/rag/long_context_rag.py at b509271626e0bc0c511dcd510f6cb6c9d28b3267 ¬∑ allwefantasy/auto-coder</A>
								</DL><p>
								<DT><H3 FOLDED>local-attention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/lucidrains/local-attention">lucidrains/local-attention: An implementation of local windowed attention for language modeling</A>
									<DT><A HREF="https://x.com/nrehiew_/status/1908617547236208854">Chunked Attention: token idx 8191 and 8192 cannot interact in local attention, NoPE global attention layers</A>
								</DL><p>
								<DT><H3 FOLDED>attention-sink</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=Y8Tj9kq4iWY">Attention Sink: The Fluke That Made LLMs Actually Usable - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs/2309.17453">[2309.17453] Efficient Streaming Language Models with Attention Sinks</A>
									<DT><A HREF="https://arxiv.org/abs/2504.02732">[2504.02732] Why do LLMs attend to the first token?</A>
									<DT><A HREF="https://www.ethansmith2000.com/post/softmax-attention-is-a-fluke">Softmax Attention is a Fluke</A>
									<DT><A HREF="https://x.com/zmkzmkz/status/1917547438258450674">(1) zed en X: "EARLY PREPRINT: Softpick: No Attention Sink, No Massive Activations with Rectified Softmax Why do we use softmax in attention, even though we don‚Äôt really need non-zero probabilities that sum to one, causing attention sink and large hidden state activations? Let that sink in. https://t.co/HrVJImMe1K" / X</A>
								</DL><p>
								<DT><H3 FOLDED>attention-3d</H3>
								<DL><p>
									<DT><A HREF="https://x.com/_xjdr/status/1940972294861738016">(1) xjdr en X: "This is one of the most interesting papers ive read in a long time. not only in terms of token efficiency but also in terms of potential interesting latent interactions with the higher order trilinear representations. https://t.co/UDRkEFbVDR" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2507.02754">[2507.02754] Fast and Simplex: 2-Simplicial Attention in Triton</A>
								</DL><p>
								<DT><H3 FOLDED>MixAttention</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2409.15012">[2409.15012] Inference-Friendly Models With MixAttention</A>
									<DT><A HREF="https://www.databricks.com/blog/mixattention">Inference-Friendly Models with MixAttention | Databricks Blog</A>
								</DL><p>
								<DT><A HREF="https://kexue.fm/archives/10091">ÁºìÂ≠ò‰∏éÊïàÊûúÁöÑÊûÅÈôêÊãâÊâØÔºö‰ªéMHA„ÄÅMQA„ÄÅGQAÂà∞MLA - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
								<DT><A HREF="https://github.com/feifeibear/long-context-attention">feifeibear/long-context-attention: Sequence Parallel Attention for Long Context LLM Model Training and Inference</A>
								<DT><A HREF="https://kexue.fm/archives/9812">Scale operation of Attention from the perspective of gradient maximization</A>
								<DT><A HREF="https://kexue.fm/archives/8823">Analyzing the Scale Operation of Attention from the Perspective of Entropy</A>
								<DT><A HREF="https://www.youtube.com/watch?v=fEVyfT-gLqQ">SageAttention-blackwell</A>
								<DT><A HREF="https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/">The Transformer Family Version 2.0 | Lil'Log</A>
								<DT><A HREF="https://atcold.github.io/NYU-DLSP20/en/week12/12-3/">Attention and the Transformer ¬∑ Deep Learning</A>
								<DT><A HREF="https://twitter.com/charles_irl/status/1724110196744835193">PagedAttention, Virtual Context, Speculative Decoding, Register Tokens</A>
								<DT><A HREF="https://twitter.com/giffmana/status/1659512770100973572/photo/1">Self-Attention Does Not Need O(n^2) Memory</A>
								<DT><A HREF="https://ai.googleblog.com/2020/10/rethinking-attention-with-performers.html">Rethinking Attention with Performers ‚Äì Google Research Blog</A>
								<DT><A HREF="https://twitter.com/ZihangDai/status/1281349893873897478/photo/1">Funnel-Transformer</A>
								<DT><A HREF="https://arxiv.org/abs/2404.07143">[2404.07143] Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/advanced/gpt-attention.md">TensorRT-LLM/docs/source/advanced/gpt-attention.md</A>
								<DT><A HREF="https://www.youtube.com/watch?v=3a0_hAiFKag">TransformerFAM: Feedback attention is working memory - YouTube</A>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1764717117881094582">Based attention</A>
								<DT><A HREF="https://github.com/google/jax/blob/main/jax/experimental/pallas/ops/tpu/splash_attention/splash_attention_kernel.py">jax/jax/experimental/pallas/ops/tpu/splash_attention/splash_attention_kernel.py at main ¬∑ google/jax</A>
								<DT><A HREF="https://github.com/mit-han-lab/duo-attention/tree/main">mit-han-lab/duo-attention: DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads</A>
								<DT><A HREF="https://www.youtube.com/watch?v=qR56cyMdDXg">Every attention head explained - YouTube</A>
								<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/xfuser/model_executor/layers/attention_processor.py">xDiT/xfuser/model_executor/layers/attention_processor.py at main ¬∑ xdit-project/xDiT</A>
								<DT><A HREF="https://github.com/mit-han-lab/Block-Sparse-Attention">mit-han-lab/Block-Sparse-Attention: A sparse attention kernel supporting mix sparse patterns</A>
								<DT><A HREF="https://github.com/pytorch-labs/attention-gym">pytorch-labs/attention-gym: Helpful tools and examples for working with flex-attention</A>
								<DT><A HREF="https://arxiv.org/abs/1910.10683">[1910.10683] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer: Figure 3 Attention patterns</A>
								<DT><A HREF="https://www.youtube.com/watch?v=eMlx5fFNoYc">Attention in transformers, visually explained | DL6 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=KJtZARuO3JY">Visualizing transformers and attention | Talk for TNG Big Tech Day '24 - YouTube</A>
								<DT><A HREF="https://github.com/microsoft/AttentionEngine">microsoft/AttentionEngine</A>
								<DT><A HREF="https://sayak.dev/posts/attn-diffusion.html">Flavors of attention in modern diffusion models ‚Äì Sayak Paul</A>
								<DT><A HREF="https://supaiku.com/attention-is-logarithmic">attention is logarithmic, actually</A>
								<DT><A HREF="https://github.com/fla-org/flash-linear-attention">fla-org/flash-linear-attention: üöÄ Efficient implementations of state-of-the-art linear attention models</A>
							</DL><p>
							<DT><H3 FOLDED>MoE</H3>
							<DL><p>
								<DT><A HREF="https://github.com/microsoft/Tutel">microsoft/Tutel: Tutel MoE: An Optimized Mixture-of-Experts Implementation</A>
								<DT><A HREF="https://developer.nvidia.com/blog/demystifying-ai-inference-deployments-for-trillion-parameter-large-language-models/">Demystifying AI Inference Deployments for Trillion Parameter Large Language Models | NVIDIA Technical Blog</A>
								<DT><A HREF="https://pytorch.org/blog/training-moes/?utm_content=298456196&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Training MoEs at Scale with PyTorch | PyTorch</A>
								<DT><A HREF="https://www.artfintel.com/p/more-on-mixture-of-experts-models">More on Mixture of Experts models - by Finbarr Timbers</A>
								<DT><A HREF="https://www.artfintel.com/p/papers-ive-read-this-week-mixture">Papers I‚Äôve read this week, Mixture of Experts edition</A>
								<DT><A HREF="https://arxiv.org/html/2404.02258v1">Mixture-of-Depths: Dynamically allocating compute in transformer-based language models</A>
								<DT><A HREF="https://github.com/JerryYin777/DeepSeek-v2-MoE-MLA-DLB_and_CB-Loss-Implementation">JerryYin777/DeepSeek-v2-MoE-MLA-DLB_and_CB-Loss-Implementation: Self implementation of Device-Level Balance Loss and Communication Balance Loss of DeepSeek v2 Tech ReportÔºàNot Given in Official CodeÔºâ</A>
								<DT><A HREF="https://github.com/laekov/fastmoe">laekov/fastmoe: A fast MoE impl for PyTorch</A>
								<DT><A HREF="https://x.com/DAlistarh/status/1909568131367911843">MoE-Quant, a fast version of GPTQ for MoEs</A>
								<DT><A HREF="https://arxiv.org/pdf/2502.19811">Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</A>
							</DL><p>
							<DT><H3 FOLDED>DeltaFormer</H3>
							<DL><p>
								<DT><A HREF="https://x.com/nathancgy4/status/1970147391715287500">(1) Nathan Chen en X: "SEED's paper on associative memory and DeltaFormer is still one of my favorites üéâso I'm happy share that DeltaFormer is now supported on FLA (flash linear attention)! Learned incredibly much from @yzhang_cs and Mingyu https://t.co/1UU5U9uIBx" / X</A>
								<DT><A HREF="https://x.com/nathancgy4/status/1949303171844870326">(1) Nathan Chen en X: "Why do FFNs use ReLU instead of more precise ones like Exp? "We propose the following hypothesis: A kernel with lower retrieval precision encourages a more polysemantic key‚Äìvalue memory: multiple unrelated facts can be stored under the same key space" Great and inspiring read! https://t.co/79T2gCN7vL" / X</A>
								<DT><A HREF="https://arxiv.org/abs/2505.19488">[2505.19488] Understanding Transformer from the Perspective of Associative Memory</A>
								<DT><A HREF="https://spaces.ac.cn/archives/11320">‰∏∫‰ªÄ‰πàÁ∫øÊÄßÊ≥®ÊÑèÂäõË¶ÅÂä†Short ConvÔºü - ÁßëÂ≠¶Á©∫Èó¥|Scientific Spaces</A>
							</DL><p>
							<DT><H3 FOLDED>Adaptive Computation</H3>
							<DL><p>
								<DT><H3 FOLDED>adaptive-computation-calm</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2207.07061.pdf">Confident Adaptive Language Modeling (CALM)</A>
									<DT><A HREF="https://blog.research.google/2022/12/accelerating-text-generation-with.html?m=1">Accelerating text generation with Confident Adaptive Language Modeling (CALM) ‚Äì Google Research Blog</A>
								</DL><p>
								<DT><H3 FOLDED>speculative decoding</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/blog/hitchhikers-guide-speculative-decoding/">A Hitchhiker‚Äôs Guide to Speculative Decoding | PyTorch</A>
									<DT><A HREF="https://github.com/feifeibear/LLMSpeculativeSampling">feifeibear/LLMSpeculativeSampling: Fast inference from large lauguage models via speculative decoding</A>
									<DT><A HREF="https://arxiv.org/abs/2506.11309">[2506.11309] Bytedn SwiftSpec: Ultra-Low Latency LLM Decoding by Scaling Asynchronous Speculative Decoding</A>
									<DT><A HREF="https://lmsys.org/blog/2025-07-25-spec-forge/">SpecForge: Accelerating Speculative Decoding Training for SGLang | LMSYS Org</A>
									<DT><A HREF="https://www.together.ai/blog/adaptive-learning-speculator-system-atlas">AdapTive-LeArning Speculator System (ATLAS): A New Paradigm in LLM Inference via Runtime-Learning Accelerators</A>
									<DT><A HREF="https://x.com/cneuralnetwork/status/1987180865550725244">(1) neural nets. en X: "made a python library for spec decoding use pip install specdec you can run benchmarking of specdec v/s autoregressive for any model, for any prompt with this :) https://t.co/bitVqlPdpX" / X</A>
									<DT><A HREF="https://x.com/prajdabre/status/1986933580564713695">(1) Raj Dabre en X: "Here's your weekend challenge: Implement speculative decoding. Step 1: Read the following paper and/or blog: https://t.co/yJ7Rkb7yv9 https://t.co/8A4LWmruxM (cc @jaygala223) Step 2: Choose a family of models which come in various sizes. My choice would be the Gemma3 or Qwen https://t.co/Cgbml1nIbM" / X</A>
									<DT><A HREF="https://github.com/cneuralnetwork/SpecDec">cneuralnetwork/SpecDec</A>
								</DL><p>
								<DT><A HREF="https://github.com/hao-ai-lab/LookaheadDecoding">hao-ai-lab/LookaheadDecoding</A>
								<DT><A HREF="https://blog.research.google/2024/01/introducing-aspire-for-selective.html">Introducing ASPIRE for selective prediction in LLMs ‚Äì Google Research Blog</A>
								<DT><A HREF="https://arxiv.org/abs/2404.16710">[2404.16710] LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding</A>
								<DT><A HREF="https://lilianweng.github.io/posts/2023-01-27-the-transformer-family-v2/">The Transformer Family Version 2.0: Universal Transformer</A>
							</DL><p>
							<DT><H3 FOLDED>Elastic Inference</H3>
							<DL><p>
								<DT><A HREF="https://github.com/UKPLab/sentence-transformers/releases/tag/v2.7.0">Release v2.7.0 - CachedGISTEmbedLoss, easy Matryoshka inference &amp; evaluation, CrossEncoder, Intel Gaudi2 ¬∑ UKPLab/sentence-transformers</A>
								<DT><A HREF="https://arxiv.org/abs/2310.07707">[2310.07707] MatFormer: Nested Transformer for Elastic Inference</A>
								<DT><A HREF="https://twitter.com/adityakusupati/status/1714001115732427176">(1) Aditya Kusupati en X: "Announcing MatFormer - a nestedü™Ü(Matryoshka) Transformer that offers elasticity across deployment constraints. MatFormer is an architecture that lets us use 100s of accurate smaller models that we never actually trained for! https://t.co/wzR7To7HZu 1/9 https://t.co/mBF0ZOIjlz" / X</A>
								<DT><A HREF="https://github.com/RAIVNLab/MatFormer-OLMo">MatFormer: Nested Transformer for Elastic Inference</A>
							</DL><p>
							<DT><H3 FOLDED>Block Transformer</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2406.02657">Block Transformer: Global-to-Local Language Modeling for Fast Inference</A>
							</DL><p>
							<DT><A HREF="https://poloclub.github.io/transformer-explainer/">Transformer Explainer: LLM Transformer Model Visually Explained</A>
							<DT><A HREF="https://towardsdatascience.com/hugging-face-transformer-inference-under-1-millisecond-latency-e1be0057a51c">kernl</A>
							<DT><A HREF="https://research.google/blog/alternating-updates-for-efficient-transformers/">Alternating updates for efficient transformers</A>
							<DT><A HREF="https://arxiv.org/abs/2301.13310">[2301.13310] Alternating Updates for Efficient Transformers</A>
							<DT><A HREF="https://kexue.fm/archives/9948">(main: whole series) Transformer Upgrade Road: 16. "Review" Length Extrapolation Technology</A>
							<DT><A HREF="https://kexue.fm/archives/9844">VQ the key, and the complexity of Transformer becomes linear</A>
							<DT><A HREF="https://www.youtube.com/watch?v=PnWOeIgl3GA">Language Modeling with Reduced Densities</A>
							<DT><A HREF="https://x.com/giffmana/status/1873869654252544079">DiffTransformer</A>
							<DT><A HREF="https://www.youtube.com/watch?v=zWXxPWcfuc8">Memory Layers at Scale - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-distributed-inference</H3>
						<DL><p>
							<DT><H3 FOLDED>deepspeed-inference</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2207.00032.pdf">DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeedExamples/tree/master/inference/mii">DeepSpeedExamples/inference/mii</A>
							</DL><p>
							<DT><A HREF="https://github.com/bytedance/flux">bytedance/flux: A fast communication-overlapping library for tensor parallelism on GPUs.</A>
							<DT><A HREF="https://github.com/feifeibear/long-context-attention">feifeibear/long-context-attention: USP: Unified (a.k.a. Hybrid, 2D) Sequence Parallel Attention for Long Context Transformers Model Training and Inference</A>
							<DT><A HREF="https://www.youtube.com/watch?v=-uyXE7dY5H0">NIPS: Oral Session 4 - Ilya Sutskever - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-serving</H3>
						<DL><p>
							<DT><H3 FOLDED>reasoning-serving</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2510.18672">Reasoning Language Model Inference Serving Unveiled: An Empirical Study</A>
							</DL><p>
							<DT><H3 FOLDED>transformer-inference-prefill</H3>
							<DL><p>
								<DT><H3 FOLDED>bytedn-flexPrefill</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ByteDance-Seed/FlexPrefill">ByteDance-Seed/FlexPrefill: Code for paper: [ICLR2025 Oral] FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference</A>
									<DT><A HREF="https://arxiv.org/abs/2502.20766">[2502.20766] FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference</A>
								</DL><p>
								<DT><H3 FOLDED>Prepacking</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/siyan_zhao">Prepacking</A>
									<DT><A HREF="https://arxiv.org/abs/2404.09529">[2404.09529] Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models</A>
									<DT><A HREF="https://github.com/siyan-zhao/prepacking">siyan-zhao/prepacking: The source code of our work "Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models"</A>
									<DT><A HREF="https://twitter.com/siyan_zhao/status/1780288750624612850">(1) Siyan Zhao en X: "üö®LLM RESEARCHERSüö®Want a free boost in speed and memory efficiency for your HuggingFaceü§óLLM with ZERO degradation in generation quality? Introducing Prepacking, a simple method to obtain up to 6x speedup and 16x memory efficiency gains in prefilling prompts of varying lengths.... https://t.co/O8XsjhOLGZ" / X</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>transformer-inference-server-decode</H3>
							<DL><p>
								<DT><H3 FOLDED>speculative decoding</H3>
								<DL><p>
									<DT><H3 FOLDED>custom speculators</H3>
									<DL><p>
										<DT><A HREF="https://www.together.ai/blog/customized-speculative-decoding">Boosting DeepSeek-R1‚Äôs Speed with Customized Speculative Decoding</A>
										<DT><A HREF="https://arxiv.org/abs/2406.16758">[2406.16758] Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters</A>
										<DT><A HREF="https://www.together.ai/blog/adaptive-learning-speculator-system-atlas">AdapTive-LeArning Speculator System (ATLAS): A New Paradigm in LLM Inference via Runtime-Learning Accelerators</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2302.01318.pdf">Accelerating Large Language Model Decoding with Speculative Sampling</A>
									<DT><A HREF="https://arxiv.org/abs/2211.17192">[CRITICAL] Fast Inference from Transformers via Speculative Decoding</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM">NVIDIA/TensorRT-LLM: TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/docs/source/conceptual/speculation.md">text-generation-inference/docs/source/conceptual/speculation.md at main ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/speculative_decoding.md">TensorRT-LLM/docs/source/speculative_decoding.md</A>
									<DT><A HREF="https://github.com/lucidrains/speculative-decoding">lucidrains/speculative-decoding: Explorations into some recent techniques surrounding speculative decoding</A>
									<DT><A HREF="https://github.com/hao-ai-lab/LookaheadDecoding">hao-ai-lab/LookaheadDecoding</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>transformer-inference-server-kv-cache</H3>
							<DL><p>
								<DT><A HREF="https://twitter.com/XueFz/status/1768690833988174040">(1) Fuzhao Xue en X: "KV cache may be the most redundant memory usage, but it‚Äôs non-trivial to compress it in a lossless way. My Takeaway: 1) Adaptively append/merge the current token to KV cache. This is a simple but smart solution to achieve better trade-off between RNN and Transformer, 2) Designed..." / X</A>
								<DT><A HREF="https://github.com/SqueezeAILab/KVQuant">SqueezeAILab/KVQuant: KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization</A>
								<DT><A HREF="https://www.youtube.com/watch?v=r_UBBfTPcF0">Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>transformer-inference-continous batching</H3>
							<DL><p>
								<DT><H3 FOLDED>transformer-iteration-level scheduling</H3>
								<DL><p>
									<DT><H3 FOLDED>Orca</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/pdf/2305.05920">Fast Distributed Inference Serving for Large Language Models</A>
										<DT><A HREF="https://www.usenix.org/conference/osdi22/presentation/yu">Orca: A Distributed Serving System for Transformer-Based Generative Models | USENIX</A>
										<DT><A HREF="https://strint.notion.site/TurboTransformer-8776e615b6484f17a82ca3af81bcacfc">TurboTransformer: ÂèòÈïøËæìÂÖ•‰ªªÂä°ÁöÑ‰ºòÂåñ</A>
										<DT><A HREF="https://www.youtube.com/watch?v=z2M8gKGYws4">Understanding the LLM Inference Workload - Mark Moyou, NVIDIA - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=Ob9PPLxETYU">OSDI '22 - Orca: A Distributed Serving System for Transformer-Based Generative Models - YouTube</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/">Mastering LLM Techniques: Inference Optimization | NVIDIA Technical Blog</A>
							</DL><p>
							<DT><H3 FOLDED>FlexGen</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2303.06865">[2303.06865] High-throughput Generative Inference of Large Language Models with a Single GPU</A>
							</DL><p>
							<DT><H3 FOLDED>MuxServe</H3>
							<DL><p>
								<DT><A HREF="https://x.com/haoailab/status/1805307696297689119">(1) Hao AI Lab en X: "Multiple LLM serving has emerged as a crucial and costly demand. Want to co-serve multiple LLMs with better utilization? Introducing MuxServe - flexible spatial-temporal multiplexing - up to 1.8x higher throughput Blog: https://t.co/Pep94vUFTw Paper: https://t.co/X1Jhov3QOY https://t.co/mXrHMSLPS1" / X</A>
								<DT><A HREF="https://hao-ai-lab.github.io/blogs/muxserve/">MuxServe: Flexible Spatial-Temporal Multiplexing for Multiple LLM Serving | Hao AI Lab @ UCSD</A>
								<DT><A HREF="https://arxiv.org/abs/2404.02015">[2404.02015] MuxServe: Flexible Spatial-Temporal Multiplexing for Multiple LLM Serving</A>
								<DT><A HREF="https://github.com/hao-ai-lab/MuxServe">hao-ai-lab/MuxServe</A>
								<DT><A HREF="https://github.com/EfficientLLMSys/MuxServe-vLLM">EfficientLLMSys/MuxServe-vLLM</A>
							</DL><p>
							<DT><A HREF="https://proceedings.mlsys.org/paper_files/paper/2023/hash/523f87e9d08e6071a3bbd150e6da40fb-Abstract-mlsys2023.html">Efficiently Scaling Transformer Inference</A>
							<DT><A HREF="https://arxiv.org/pdf/2204.02311.pdf">PaLM: Scaling Language Modeling with Pathways</A>
							<DT><A HREF="https://twitter.com/aleks_madry/status/1642972175572545545">AI deployment as suppling chain problem</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-flops</H3>
						<DL><p>
							<DT><A HREF="https://twitter.com/karpathy/status/1781047292486914189">Karpathy: Llama 3 model card (flops model training taxonomy)</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-benchmarking</H3>
						<DL><p>
							<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f">LLM Inference Series: 5. Dissecting model performance (2024)</A>
							<DT><A HREF="https://arxiv.org/pdf/2011.02327.pdf">INFERBENCH: UNDERSTANDING DEEP LEARNING INFERENCE SERVING WITH AN AUTOMATIC BENCHMARKING SYSTEM</A>
							<DT><A HREF="https://kipp.ly/transformer-inference-arithmetic/">Transformer Inference Arithmetic | kipply's blog</A>
							<DT><A HREF="https://bytemlperf.ai/guide/introduction.html">Introduction - ByteMLPerf</A>
							<DT><A HREF="https://www.modular.com/blog/how-to-be-confident-in-your-performance-benchmarking">Modular: How to Be Confident in Your Performance Benchmarking</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-manifesto</H3>
						<DL><p>
							<DT><A HREF="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/#methods-overview">Large Transformer Model Inference Optimization | Lil'Log</A>
							<DT><A HREF="https://arxiv.org/abs/2211.05102">[2211.05102] Efficiently Scaling Transformer Inference</A>
							<DT><A HREF="https://www.overleaf.com/project/64399db50ab28ba5e3335352">Empirical Analysis of Compute-Optimal Large Language Model Training - Online LaTeX Editor Overleaf</A>
							<DT><A HREF="https://github.com/DataCrunch-io/inference_playbook/blob/main/manifesto.MD">inference_playbook/manifesto.MD at main ¬∑ DataCrunch-io/inference_playbook ¬∑ GitHub</A>
							<DT><A HREF="https://towardsdatascience.com/hugging-face-transformer-inference-under-1-millisecond-latency-e1be0057a51c">Hugging Face Transformer Inference Under 1 Millisecond Latency | by Micha√´l Benesty | Towards Data Science</A>
							<DT><A HREF="https://gist.github.com/lattner/31ed37682ef1576b16bca1432ea9f782#overall-vision">Swift Concurrency Manifesto</A>
							<DT><A HREF="https://www.techempower.com/benchmarks/?utm_source=pocket_mylist#section=data-r20&hw=ph&test=db">Round 20 results - TechEmpower Framework Benchmarks</A>
							<DT><A HREF="https://els-rd.github.io/transformer-deploy/compare/">Which tool to choose for your inference? - transformer-deploy by Lefebvre Dalloz</A>
							<DT><A HREF="https://github.com/ELS-RD/kernl">ELS-RD/kernl: Kernl lets you run PyTorch transformer models several times faster on GPU with a single line of code, and is designed to be easily hackable.</A>
							<DT><A HREF="https://github.com/ELS-RD/transformer-deploy">ELS-RD/transformer-deploy: Efficient, scalable and enterprise-grade CPU/GPU inference server for ü§ó Hugging Face transformer models üöÄ</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-inference-big-picture</H3>
						<DL><p>
							<DT><A HREF="https://karpathy.ai/stateofgpt.pdf">https://karpathy.ai/stateofgpt.pdf</A>
							<DT><A HREF="https://www.youtube.com/watch?v=bZQun8Y4L2A">State of GPT | BRK216HFS - YouTube</A>
							<DT><A HREF="https://excalidraw.com/#room=93d0feb81016e7e5d6c7,TYDGkAGBNB0A8Fa-5-EhDg">Excalidraw</A>
							<DT><A HREF="https://www.youtube.com/@rutgersefficientaiseminar9909">Rutgers Efficient AI Seminar - YouTube</A>
							<DT><A HREF="https://openreview.net/forum?id=wIPIhHd00i">Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time | OpenReview</A>
							<DT><A HREF="https://www.youtube.com/@neubig/videos">Graham Neubig  (CMU)</A>
						</DL><p>
						<DT><H3 FOLDED>QPS</H3>
						<DL><p>
							<DT><A HREF="https://x.com/NoamShazeer/status/1803790708358410380">(1) Noam Shazeer en X: "Character AI is serving 20,000 QPS. Here are the technologies we use to serve hyper-efficiently. [https://t.co/R14Jt9Z5yo ]" / X</A>
							<DT><A HREF="https://research.character.ai/optimizing-inference/">Optimizing AI Inference at Character.AI</A>
							<DT><A HREF="https://x.com/cis_female/status/1803816791677808964">(1) sophia en X: "&amp;gt;20k QPS MQA everywhere local attention, 1/6 layers use global attn KV cache tied between layers, cached on host memory with "95% cache rate" trained in int8 precision" / X</A>
						</DL><p>
						<DT><A HREF="https://astralord.github.io/posts/transformer-inference-optimization-toolset/">Transformers Inference Optimization Toolset | AstraBlog</A>
						<DT><A HREF="https://kipp.ly/transformer-inference-arithmetic/">Transformer Inference Arithmetic | kipply's blog</A>
						<DT><A HREF="https://kipp.ly/transformer-param-count/">LLM Parameter Counting | kipply's blog</A>
						<DT><A HREF="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">Large Transformer Model Inference Optimization | Lil'Log</A>
						<DT><A HREF="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/#methods-overview">Large Transformer Model Inference Optimization | Lil'Log</A>
						<DT><A HREF="https://arxiv.org/abs/2009.06732">[2009.06732] Efficient Transformers: A Survey</A>
						<DT><A HREF="https://arxiv.org/abs/2211.05102">[2211.05102] Efficiently Scaling Transformer Inference</A>
						<DT><A HREF="https://www.zhihu.com/people/liang-de-peng">GiantPandaCV (chinese high-proffesional discussions)</A>
						<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f">LLM Inference Series: 5. Dissecting model performance (2024)</A>
						<DT><A HREF="https://horace.io/brrr_intro.html">Making Deep Learning go Brrrr From First Principles</A>
						<DT><A HREF="https://arxiv.org/pdf/2302.14017.pdf">Full Stack Optimization of Transformer Inference: a Survey</A>
						<DT><A HREF="https://arxiv.org/abs/2303.06865">[2303.06865] High-throughput Generative Inference of Large Language Models with a Single GPU</A>
						<DT><A HREF="https://kipp.ly/transformer-inference-arithmetic/">Transformer Inference Arithmetic</A>
						<DT><A HREF="https://arxiv.org/pdf/2211.05102.pdf">Efficiently Scaling Transformer Inference</A>
						<DT><A HREF="https://huggingface.co/papers/2312.11514">Paper page - LLM in a flash: Efficient Large Language Model Inference with Limited Memory</A>
						<DT><A HREF="https://twitter.com/atiorh/status/1737912777153609918">(Apple) Atila en X: "My takeaways from Apple's ‚ÄúLLM in a flash" (1/n)" / X</A>
						<DT><A HREF="https://www.semianalysis.com/p/inference-race-to-the-bottom-make">Inference Race To The Bottom - Make It Up On Volume?</A>
						<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1773268740806705266">optimal batch size (bytes per param, flops, bytes/token, arithmetic intensity )</A>
						<DT><A HREF="https://developer.nvidia.com/blog/accelerating-hpc-applications-with-nsight-compute-roofline-analysis/">Accelerating HPC Applications with NVIDIA Nsight Compute Roofline Analysis | NVIDIA Technical Blog</A>
						<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f">LLM Inference Series: 5. Dissecting model performance (2024 main)</A>
						<DT><A HREF="https://arxiv.org/abs/2401.08092">[2401.08092] A Survey of Resource-efficient LLM and Multimodal Foundation Models</A>
						<DT><A HREF="https://research.google/blog/alternating-updates-for-efficient-transformers/">Alternating updates for efficient transformers</A>
						<DT><A HREF="https://github.com/UbiquitousLearning/Efficient_Foundation_Model_Survey?tab=readme-ov-file">UbiquitousLearning/Efficient_Foundation_Model_Survey: Survey Paper List - Efficient LLM and Foundation Models</A>
						<DT><A HREF="https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/">Mastering LLM Techniques: Inference Optimization | NVIDIA Technical Blog</A>
						<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/reference/memory.md">TensorRT-LLM/docs/source/reference/memory.md</A>
						<DT><A HREF="https://mlcommons.org/2024/03/mlperf-inference-v4/">New MLPerf Inference Benchmark Results Highlight The Rapid Growth of Generative AI Models - MLCommons</A>
						<DT><A HREF="https://arxiv.org/pdf/2405.00208">A PRIMER ON THE INNER WORKINGS OF TRANSFORMER-BASED LANGUAGE MODELS</A>
						<DT><A HREF="https://github.com/cuda-mode/awesomeMLSys">cuda-mode/awesomeMLSys: An ML Systems Onboarding list</A>
						<DT><A HREF="https://github.com/xai-org/grok-1">xai-org/grok-1: Grok open release</A>
						<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/main/workspace/blog/optimizing-mla.md">deepseekv2-profile/workspace/blog/optimizing-mla.md at main ¬∑ madsys-dev/deepseekv2-profile</A>
						<DT><A HREF="https://kexue.fm/archives/10091">The ultimate struggle between cache and effects: from MHA, MQA, GQA (by Jianlin SU (the GOD creator of ROPE)</A>
						<DT><A HREF="https://www.youtube.com/watch?v=ptGDaGUXInw">Mark Russinovich | Generative AI in the Cloud: Inside Microsoft AI Innovation - YouTube</A>
						<DT><A HREF="https://developer.nvidia.com/blog/demystifying-ai-inference-deployments-for-trillion-parameter-large-language-models/">Demystifying AI Inference Deployments for Trillion Parameter Large Language Models | NVIDIA Technical Blog</A>
						<DT><A HREF="https://github.com/xjdr-alt/mla_blog_translation">DeepSeek-V2 High-performance Inference Optimization Notes: MLA Optimization</A>
						<DT><A HREF="https://github.com/DefTruth/Awesome-LLM-Inference">DefTruth/Awesome-LLM-Inference: üìñA curated list of Awesome LLM Inference Paper with codes, TensorRT-LLM, vLLM, streaming-llm, AWQ, SmoothQuant, WINT8/4, Continuous Batching, FlashAttention, PagedAttention etc.</A>
						<DT><A HREF="https://x.com/reinerpope/status/1591150725320802304">(1) Reiner Pope en X: "1/7 Transformers allow efficient large-scale training, but inference (generating text) can be slow and suffer communication/memory bottlenecks. Our new paper proposes techniques for efficient low-latency inference on PaLM 8B‚Äî540B models: https://t.co/4npbzqRBIN https://t.co/d647YA4xxk" / X</A>
						<DT><A HREF="https://www.artfintel.com/p/where-do-llms-spend-their-flops">Where do LLMs spend their FLOPS? - by Finbarr Timbers</A>
						<DT><A HREF="https://www.artfintel.com/p/transformer-inference-tricks">Transformer inference tricks - by Finbarr Timbers</A>
						<DT><A HREF="https://www.artfintel.com/p/efficient-llm-inference">Efficient LLM inference - by Finbarr Timbers</A>
						<DT><A HREF="https://arxiv.org/pdf/2305.05920">Fast Distributed Inference Serving for Large Language Models</A>
						<DT><A HREF="https://zeux.io/2024/03/15/llm-inference-sol/">zeux.io - LLM inference speed of light</A>
						<DT><A HREF="https://x.com/arankomatsuzaki/status/1818828480366219601">Scaling Inference Compute with Repeated Sampling (efficient transformer inference batch axis)</A>
						<DT><A HREF="https://www.youtube.com/watch?v=mYRqvB1_gRk&t=835s">Exploring the Latency/Throughput &amp; Cost Space for LLM Inference // TimotheÃÅe Lacroix // CTO Mistral - YouTube</A>
						<DT><A HREF="https://www.baseten.co/blog/llm-transformer-inference-guide/">A guide to LLM inference and performance</A>
						<DT><A HREF="https://github.com/drisspg/transformer_nuggets">drisspg/transformer_nuggets: A place to store reusable transformer components of my own creation or found on the interwebs</A>
						<DT><A HREF="https://www.njkumar.com/calculating-gpt2s-inference-speedups/">Calculating GPT-2‚Äôs Inference Speedups | njkumar</A>
						<DT><A HREF="https://github.com/feifeibear/LLMRoofline">feifeibear/LLMRoofline: Compare different hardware platforms via the Roofline Model for LLM inference tasks.</A>
						<DT><A HREF="https://jax-ml.github.io/scaling-book/transformers/">All the Transformer Math You Need to Know | How To Scale Your Model</A>
						<DT><A HREF="https://www.linkedin.com/pulse/infrastructure-next-gen-llm-inference-how-does-meta-infra-yun-jin-91ofc/">How does Meta Behemothic Llama Models</A>
						<DT><A HREF="https://arxiv.org/abs/2601.05047">[2601.05047] Challenges and Research Directions for Large Language Model Inference Hardware</A>
					</DL><p>
					<DT><H3 FOLDED>Hardware</H3>
					<DL><p>
						<DT><H3 FOLDED>GPU</H3>
						<DL><p>
							<DT><H3 FOLDED>gpu-architecture</H3>
							<DL><p>
								<DT><H3 FOLDED>Instinct</H3>
								<DL><p>
									<DT><H3 FOLDED>MI300X</H3>
									<DL><p>
										<DT><A HREF="https://www.amd.com/content/dam/amd/en/documents/instinct-tech-docs/data-sheets/amd-instinct-mi300x-platform-data-sheet.pdf">DATA SHEET</A>
										<DT><A HREF="https://www.colfax-intl.com/Servers/CX8850s-EI9">Colfax CX8850s-EI9 8U Rackmount Server with 8x AMD Instinct‚Ñ¢ MI300X Accelerators</A>
										<DT><A HREF="https://www.reddit.com/r/AMD_Technology_Bets/comments/15lqkiz/no_its_not_comparable_to_the_mi300x_nvidia/">No it's not comparable to the MI300X! - "Nvidia Unveils DGX GH200 Superchip as Response to AMD‚Äôs MI300X" - chiplets of the MI300 is unique offers custom nothing nVidia's comes close! : r/AMD_Technology_Bets</A>
										<DT><A HREF="https://www.servethehome.com/amd-instinct-mi300x-gpu-and-mi300a-apus-launched-for-ai-era/amd-instinct-mi300a-vs-gh200-perf-per-watt/">AMD Instinct MI300A Vs GH200 Perf Per Watt - ServeTheHome</A>
									</DL><p>
									<DT><A HREF="https://repo.radeon.com/.hidden/cfa27af7066b8ebd5c73d75110183a62/docs/Change%20Summary_6.0.3_Known_Issues%20%281%29.pdf">AMD GPU kernel driver change summary</A>
									<DT><A HREF="https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi300x/">Testing AMD‚Äôs Giant MI300X ‚Äì Chips and Cheese</A>
									<DT><A HREF="https://x.com/ZyphraAI/status/1866562911663165565">(1) Zyphra en X: "We‚Äôve been hard at work with @AMD to optimize training for AMD GPUs. Today, we‚Äôre sharing a critical milestone towards this goal: FlashAttention-2 (FA2) and Mamba-2 backward kernels on AMD MI300X that surpass NVIDIA H100. We @ZyphraAI are the first to achieve this. https://t.co/hefQdQM568" / X</A>
								</DL><p>
								<DT><A HREF="https://x.com/RajaXg/status/1812721241985610147">GPU Architecture Impact</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/66ef1df492f7bc9c8eeb01d7e14db01838e3f0bd/tensorrt_llm/auto_parallel/cluster_info.py">TensorRT-LLM/tensorrt_llm/auto_parallel/cluster_info.py</A>
								<DT><A HREF="https://news.futunn.com/en/post/42190604/nvidia-s-next-generation-gpu-revealed-integrating-eight-hbm-4?level=1&data_ticket=1715948857342483">Nvidia's next-generation GPU revealed: integrating eight HBM 4, TSMC N3 process</A>
								<DT><A HREF="https://github.com/kuterd/nv_isa_solver?tab=readme-ov-file">kuterd/nv_isa_solver: Nvidia Instruction Set Specification Generator</A>
								<DT><A HREF="https://github.com/Jokeren/Awesome-GPU">Jokeren/Awesome-GPU: Awesome resources for GPUs</A>
								<DT><A HREF="https://www.youtube.com/watch?v=h9Z4oGN89MU">How do Graphics Cards Work? Exploring GPU Architecture - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-networking</H3>
							<DL><p>
								<DT><A HREF="https://pytorchtoatoms.substack.com/p/h100b100-analyze-of-5-different-network">H100/B100: Analyze of 5 Different Network Fabrics Types. Debate Between Infiniband and Ethernet</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-micro-benchmarking</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/1903.07486.pdf">Dissecting the NVidia Turing T4 GPU via Microbenchmarking</A>
								<DT><A HREF="https://arxiv.org/pdf/1912.03413.pdf">IPU</A>
								<DT><A HREF="https://arxiv.org/pdf/1804.06826.pdf%5B/url%5D">Volta</A>
								<DT><A HREF="https://trainy.ai/blog/gpu-utilization-misleading">GPU Utilization is a Misleading Metric</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-benchmarking</H3>
							<DL><p>
								<DT><A HREF="https://github.com/FlagOpen/FlagPerf?tab=readme-ov-file">FlagOpen/FlagPerf: FlagPerf is an open-source software platform for benchmarking AI chips.</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-intel-gaudi</H3>
							<DL><p>
								<DT><A HREF="https://habana.ai/products/gaudi2/">Intel Gaudi 2 Neural Network Deep Learning Inference Processor</A>
								<DT><A HREF="https://twitter.com/EMostaque/status/1767199048337932719">(1) Emad acc/acc en X: "The @intel Gaudi2 chips are awesome &amp;amp; run the multimodal diffusion transformer arch that powers #SD3 faster than H100s (!) in scaled training pre fp8 Way cheaper TCO &amp;amp; Gaudi3 set to be 4x faster.. We also saw 673 tok/s inference on our upcoming StableBeluga 2.5 70b model (!)" / X</A>
								<DT><A HREF="https://www.intel.com/content/www/us/en/docs/graphics-for-linux/developer-reference/1-0/alchemist-arctic-sound-m.html">2023 Intel¬Æ Processors - Alchemist/Arctic Sound-M Platform</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-amd</H3>
							<DL><p>
								<DT><A HREF="https://github.com/geohot/7900xtx">geohot/7900xtx</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-power-limited</H3>
							<DL><p>
								<DT><A HREF="https://www.thonking.ai/p/strangely-matrix-multiplications">Strangely, Matrix Multiplications on GPUs Run Faster When Given "Predictable" Data! [short]</A>
								<DT><A HREF="https://twitter.com/dwarkesh_sp/status/1780990840179187715">(1) Dwarkesh Patel en X: "Zuck on: energy-bounded AI progress"</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=jys92_j627A">Digital Design &amp; Computer Architecture -  L23: Memory Hierarchy and Caches (Spring 2022)</A>
							<DT><A HREF="https://github.com/Jokeren/Awesome-GPU">Jokeren/Awesome-GPU: Awesome resources for GPUs</A>
							<DT><A HREF="https://github.com/NVIDIA/open-gpu-doc">NVIDIA/open-gpu-doc: Documentation of NVIDIA chip/hardware interfaces</A>
							<DT><A HREF="https://nvidia.github.io/open-gpu-doc/">open-gpu-doc</A>
							<DT><A HREF="https://www.colfax-intl.com/Servers/CX8850s-EI9">Colfax CX8850s-EI9 8U Rackmount Server with 8x AMD Instinct‚Ñ¢ MI300X Accelerators</A>
							<DT><A HREF="https://twitter.com/TechPowerUp/status/1776242252974559508">RISC-V CPU, GPU, and NPU</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gofI47kfD28">Bill Dally | Directions in Deep Learning Hardware - YouTube</A>
							<DT><A HREF="https://techcommunity.microsoft.com/t5/azure-high-performance-computing/annual-roundup-of-ai-infrastructure-breakthroughs-for-2023/ba-p/4097737">Annual Roundup on AI Infrastructure Breakthroughs for 2023</A>
							<DT><A HREF="https://github.com/adam-maj/tiny-gpu">adam-maj/tiny-gpu: A minimal GPU design in Verilog to learn how GPUs work from the ground up</A>
							<DT><A HREF="https://x.com/jimkxa/status/1806105468575846509">AI on RISC-V: 10 years of mistakes</A>
							<DT><A HREF="https://github.com/moderngpu/moderngpu/wiki">Home ¬∑ moderngpu/moderngpu Wiki</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gofI47kfD28&t=2178s">Bill Dally | Directions in Deep Learning Hardware - YouTube</A>
							<DT><A HREF="https://blog.lepton.ai/the-missing-guide-to-the-h100-gpu-market-91ebfed34516">The Missing Guide to the H100 GPU Market | by Lepton AI | Medium</A>
							<DT><A HREF="https://gist.github.com/sophiawisdom/4962d844ee870d7d9d233cfdac98e903">some things i want to think about</A>
							<DT><A HREF="https://github.com/KohakuBlueleaf/HakuTPU">KohakuBlueleaf/HakuTPU: An AI accelerator implementation with Xilinx FPGA</A>
							<DT><A HREF="https://arxiv.org/html/2502.16631v1">CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads</A>
							<DT><A HREF="https://x.com/__tinygrad__/status/1984899731974471987">Before you consider a tapeout, you must master:</A>
							<DT><A HREF="https://en.algorithmica.org/hpc/cpu-cache/aos-soa/">AoS and SoA - Algorithmica</A>
						</DL><p>
						<DT><H3 FOLDED>CPU</H3>
						<DL><p>
							<DT><A HREF="https://cpu.land/">Intro | Putting the "You" in CPU</A>
							<DT><A HREF="https://github.com/hackclub/putting-the-you-in-cpu">hackclub/putting-the-you-in-cpu: A technical explainer by @kognise of how your computer runs programs, from start to finish.</A>
							<DT><A HREF="https://www.anandtech.com/show/15578/cloud-clash-amazon-graviton2-arm-against-intel-and-amd">Amazon's Arm-based Graviton2 Against AMD and Intel: Comparing Cloud Compute</A>
							<DT><A HREF="https://www.youtube.com/watch?v=GA4ONupSl8Y">Two Decades of Hardware Optimizations Down The Drain - YouTube</A>
							<DT><A HREF="https://www.modular.com/blog/understanding-simd-infinite-complexity-of-trivial-problems">Modular: Understanding SIMD: Infinite Complexity of Trivial Problems</A>
						</DL><p>
						<DT><H3 FOLDED>XPU</H3>
						<DL><p>
							<DT><H3 FOLDED>Maia</H3>
							<DL><p>
								<DT><A HREF="https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/">Maia 100</A>
								<DT><A HREF="https://twitter.com/highyieldYT/status/1724908672265150906">Maia 100 (AI accelerator) specs</A>
								<DT><A HREF="https://blogs.microsoft.com/blog/2026/01/26/maia-200-the-ai-accelerator-built-for-inference/">Maia 200: The AI accelerator built for inference - The Official Microsoft Blog</A>
							</DL><p>
							<DT><H3 FOLDED>MTIA</H3>
							<DL><p>
								<DT><A HREF="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/?utm_source=linkedin">Our next generation Meta Training and Inference Accelerator</A>
							</DL><p>
							<DT><H3 FOLDED>xpu-tesla</H3>
							<DL><p>
								<DT><A HREF="https://perspectives.mvdirona.com/2021/08/tesla-project-dojo-overview/">Tesla Project Dojo Overview ‚Äì Perspectives</A>
							</DL><p>
							<DT><H3 FOLDED>Etched</H3>
							<DL><p>
								<DT><H3 FOLDED>sohu</H3>
								<DL><p>
									<DT><A HREF="https://www.etched.com/">Etched | The World's First Transformer ASIC</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>MatX</H3>
							<DL><p>
								<DT><A HREF="https://matx.com/">MatX | MatX: high throughput chips for LLMs</A>
							</DL><p>
							<DT><H3 FOLDED>xpu-aws</H3>
							<DL><p>
								<DT><H3 FOLDED>Trainium3</H3>
								<DL><p>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/2008206863419277363">Teton3 PDS NL32x2</A>
								</DL><p>
								<DT><A HREF="https://perspectives.mvdirona.com/2018/11/aws-inferentia-machine-learning-processor/">AWS Inferentia Machine Learning Processor ‚Äì Perspectives</A>
								<DT><A HREF="https://perspectives.mvdirona.com/2022/05/graviton3-ec2-c7g-general-availability/">Graviton3 &amp; EC2 C7g General Availability ‚Äì Perspectives</A>
								<DT><A HREF="https://perspectives.mvdirona.com/2020/03/anandtech-on-aws-graviton2/">Anandtech on AWS Graviton2 ‚Äì Perspectives</A>
							</DL><p>
							<DT><H3 FOLDED>Tenstorrent</H3>
							<DL><p>
								<DT><A HREF="https://tenstorrent.com/category/research/">Category: Research - Tenstorrent</A>
								<DT><A HREF="https://github.com/geohot/tt-twitch">geohot/tt-twitch: tenstorrent kernel from twitch</A>
							</DL><p>
							<DT><A HREF="https://perspectives.mvdirona.com/2017/04/tensor-processing-unit/">Tensor Processing Unit ‚Äì Perspectives</A>
							<DT><A HREF="https://www.youtube.com/watch?v=M_BZOQLw6KU">Digital Design and Comp. Arch. - L13: MIPS Assembly II &amp; Memories (Spring 2024) - YouTube</A>
							<DT><A HREF="https://bytemlperf.ai/">ByteMLPerf</A>
							<DT><A HREF="https://x.com/CerebrasSystems/status/1822009569402613945">(1) Cerebras en X: "üöÄ Cerebras Outperforms GPUs by 95x and CPUs by 570x in Stencil Computations Researchers at Rice University and TotalEnergies have developed the StencilPy framework, which optimizes stencil computations across various hardware architectures. On the Cerebras Wafer-Scale Engine https://t.co/eyKh6usihf" / X</A>
							<DT><A HREF="https://openai.com/careers/silicon-implementation-engineer-custom-circuits/">Silicon Implementation Engineer ‚Äì Custom Circuits | OpenAI</A>
							<DT><A HREF="https://mp.weixin.qq.com/s/SAvBa0cE-O2IS1J2ks6syA">Ë∞àË∞àÈÇ£‰∏™Ë¢´NVÁúã‰∏äÂÄº20BÁöÑGroq</A>
							<DT><A HREF="https://x.com/elonmusk/status/2012492295812124978">xAI AI5 chip, training and infernce Tesla design</A>
						</DL><p>
						<DT><H3 FOLDED>hw-IPU</H3>
						<DL><p>
							<DT><H3 FOLDED>Graphcore</H3>
							<DL><p>
								<DT><A HREF="https://www.zdnet.com/article/ai-computer-maker-graphcore-unveils-3-d-chip-promises-500-trillion-parameter-ultra-intelligence-machine/">AI computer maker Graphcore unveils 3-D chip, promises 500-trillion-parameter</A>
								<DT><A HREF="https://www.graphcore.ai/apply-for-our-machine-intelligence-academy">Apply for our Machine Intelligence Academy</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>FPGA</H3>
						<DL><p>
							<DT><A HREF="http://www.clifford.at/icestorm/">Project IceStorm</A>
							<DT><A HREF="https://www.ebay.es/b/Laser-cnc-router/92150/bn_7005611421">Laser cnc router</A>
							<DT><A HREF="https://www.intel.com/content/www/us/en/products/programmable.html">Intel¬Æ FPGAs and Programmable Devices - Intel¬Æ FPGA</A>
							<DT><A HREF="https://www.xilinx.com/">Xilinx - Adaptable. Intelligent.</A>
							<DT><A HREF="https://link--springer--com.us.debiblio.com/book/10.1007/978-1-4302-6248-0">Beginning FPGA: Programming Metal</A>
							<DT><A HREF="https://link--springer--com.us.debiblio.com/book/10.1007/978-1-4757-3393-8">Functional Decomposition to FPGA Synthesis</A>
							<DT><A HREF="https://www.maxeler.com/">Maxeler Technologies</A>
							<DT><A HREF="https://taalas.com/">Taalas | The model is The Computer</A>
							<DT><A HREF="https://github.com/KohakuBlueleaf/HakuTPU">KohakuBlueleaf/HakuTPU: An AI accelerator implementation with Xilinx FPGA</A>
							<DT><A HREF="https://x.com/pavanjayasinha/status/1919037666428891392">(1) Pavan Jayasinha en X: "I implemented an LLM end-to-end in hardware, and ran it on an FPGA. Zero Python. Zero CUDA. Just pure SysVerilog. All my progress + everything I learned from 200h of LLM chip design (demo at the end)üëá https://t.co/OHcGrWuxqL" / X</A>
						</DL><p>
						<DT><H3 FOLDED>hw-Analog</H3>
						<DL><p>
							<DT><A HREF="https://escholarship.org/uc/item/5kb812qd">Stochastic Analog Computation for Machine Learning</A>
							<DT><A HREF="https://semiengineering.com/using-analog-for-ai/">Using Analog For AI</A>
						</DL><p>
						<DT><H3 FOLDED>hw-reverse-engineering</H3>
						<DL><p>
							<DT><A HREF="https://ffri.github.io/ProjectChampollion/part1/">Reverse-engineering Rosetta 2 part1: Analyzing AOT files and Rosetta 2 runtime - Project Champollion</A>
							<DT><A HREF="https://www.infoq.com/news/2020/11/rosetta-2-translation/">How x86 to arm64 Translation Works in Rosetta 2</A>
							<DT><A HREF="https://semiwiki.com/semiconductor-manufacturers/307494-the-semiconductor-ecosystem-explained/">The Semiconductor Ecosystem Explained - SemiWiki</A>
							<DT><H3 FOLDED>Ghidra</H3>
							<DL><p>
								<DT><A HREF="https://ghidra-sre.org/">Ghidra</A>
								<DT><A HREF="https://github.com/NationalSecurityAgency/ghidra">NationalSecurityAgency/ghidra: Ghidra is a software reverse engineering (SRE) framework</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Z04xTlLdZnc">George Hotz | Reverse engineering | same thing we do every weekend documenting the AMD 7900XTX Part2 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Cb2KwcnDKrk">George Hotz | Programming | tinygrad: 2.8k stars! CIFAR, ANE, speed, memory management | Part7 - YouTube</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>hw-neuromorphic</H3>
						<DL><p>
						</DL><p>
						<DT><H3 FOLDED>hw-memory</H3>
						<DL><p>
							<DT><H3 FOLDED>HBM</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=CPqdZZooS2g">HBM vs. GDDR6</A>
								<DT><A HREF="https://www.youtube.com/watch?v=k0ROr9_WNCI">SK hynix HBM3E Video - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=yAw63F1W_Us&t=658s">(Asiannometry) The Special Memory Powering the AI Revolution</A>
								<DT><A HREF="https://www.youtube.com/watch?v=JyhN_9MfPNA">HBM3 In The Data Center</A>
								<DT><A HREF="https://www.youtube.com/watch?v=oKyKAiEpOHU">Tackle Memory Bottlenecks with the Versal HBM Series - YouTube</A>
								<DT><A HREF="https://www.yolegroup.com/product/report/generative-ai-2024---deep-impacts-on-processors-memory-advanced-packaging-and-substrates/">Yole Group - Follow the latest trend news in the Semiconductor Industry</A>
								<DT><A HREF="https://investors.micron.com/news-releases/news-release-details/micron-delivers-industrys-fastest-highest-capacity-hbm-advance">Micron Delivers Industry‚Äôs Fastest, Highest-Capacity HBM to Advance Generative AI Innovation | Micron Technology</A>
								<DT><A HREF="https://x.com/rwang07/status/1930025345488494731">(1) Ray Wang en X: "üßµ‚ÄØ@MooreMorrisSemi and I just published a 4,000‚Äëword technical deep dive on HBM. A MUST READ‚ÄîI can confidently say. We break down: 1) Bonding technologies behind HBM 2) Why and how‚ÄØ SK‚ÄØ Hynix has taken the lead. 3) China‚Äôs evolved HBM capabilities. /1 Link: https://t.co/Me3btncu0x" / X</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=nZNd5FjSquk">CppCon 2017: John Lakos ‚ÄúLocal ('Arena') Memory Allocators (part 1 of 2)‚Äù - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=IRZKCBp9Q7U">Seminar in Computer Architecture - L5: Memory-Centric Computing (Spring 2024) - YouTube</A>
							<DT><A HREF="https://gwern.net/doc/ai/scaling/hardware/2021-jouppi.pdf">bandwidth-capacity pareto front of all digital memory technologies</A>
							<DT><A HREF="https://www.youtube.com/watch?v=aLttVmgYRGw">Modern Solid-State Drives (SSDs) - Lecture 2: Read/Write Operations in Modern SSDs (Spring 2024) - YouTube</A>
							<DT><A HREF="https://www.linkedin.com/pulse/tearing-down-memory-wall-sharada-yeluri/?trackingId=dn9NrSPARD2R%2BUQ9KN6CXQ%3D%3D">(1) Tearing Down the Memory Wall | LinkedIn</A>
						</DL><p>
						<DT><H3 FOLDED>hw-people</H3>
						<DL><p>
							<DT><A HREF="https://substack.com/@tanjb">@tanjb (Clive Chan reading)</A>
							<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1772472408559206798">Clive Chan</A>
						</DL><p>
						<DT><H3 FOLDED>Computational Lithography</H3>
						<DL><p>
							<DT><A HREF="https://developer.nvidia.com/culitho">cuLitho - Accelerate Computational Lithography | NVIDIA Developer</A>
							<DT><A HREF="https://www.youtube.com/watch?v=HxyM2Chu9Vc">Nvidia's Computational Lithography Breakthrough - YouTube</A>
						</DL><p>
						<DT><A HREF="https://www.youtube.com/watch?v=gofI47kfD28">Bill Dally | Directions in Deep Learning Hardware - YouTube</A>
						<DT><A HREF="https://cs217.stanford.edu/">Hardware Accelerators for Machine Learning (CS 217) by cs217</A>
						<DT><A HREF="https://rain.ai/">Rain AI</A>
						<DT><A HREF="https://datacrunchltd-my.sharepoint.com/personal/ruben_datacrunch_io/_layouts/15/onedrive.aspx?FolderCTID=0x0120003C33ADC3F352284DAB5968CA9FA1A319&id=%2Fpersonal%2Fruben%5Fdatacrunch%5Fio%2FDocuments%2FDataCrunch%5FShared%2FMisc%2FSemianalysis">Semianalysis - OneDrive</A>
						<DT><A HREF="https://eliyan.com/eliyan-news/eliyan-closes-60-million-series-b-funding-round/">Chiplet Interconnect Pioneer Eliyan Closes $60 Million Series B Funding Round, Co-led by Samsung Catalyst Fund</A>
						<DT><A HREF="https://www.youtube.com/watch?v=tQhn6Fpw5HU">Future Computing Platforms - Talk at Stanford University SystemX Seminar - 08.02.2024 - YouTube</A>
						<DT><A HREF="https://x.com/i/bookmarks?post_id=1803893996093345983">tinybox-fpga</A>
						<DT><A HREF="https://x.com/__tinygrad__/status/1803893996093345983">(1) the tiny corp en X: "We are going to. There's still a ways to go on the software before we know exactly what we are building, but it gets closer every day. We need: * Fully parameterized tensor cores to be able to search over that space. Then we can try a ton of different options in emulation and" / X</A>
						<DT><A HREF="https://github.com/SeoLabCornell/torch2chip">SeoLabCornell/torch2chip: Torch2Chip (MLSys, 2024)</A>
						<DT><A HREF="https://x.com/ogawa_tter/status/1846354116450374142">(1) OGAWA, Tadashi en X: "=&amp;gt; "NVIDIA Contributes NVIDIA GB200 NVL72 Designs to Open Compute Project", Oct 15, 2024 https://t.co/3XJVAwGDC7 Press https://t.co/liza3NL4Mq MGX Accelerated Computing Rack &amp;amp; Tray Spec, OCP Server Project Call, Sep 25, https://t.co/mQnMTbPPqU HGX Form Factor Spec, OCP, May 2022 https://t.co/M4Gh5NWJDe" / X</A>
						<DT><A HREF="https://developer.nvidia.com/blog/nvidia-contributes-nvidia-gb200-nvl72-designs-to-open-compute-project/">NVIDIA Contributes NVIDIA GB200 NVL72 Designs to Open Compute Project | NVIDIA Technical Blog</A>
						<DT><A HREF="https://github.com/fengbintu/Neural-Networks-on-Silicon">fengbintu/Neural-Networks-on-Silicon: This is originally a collection of papers on neural network accelerators. Now it's more like my selection of research on deep learning and computer architecture.</A>
						<DT><A HREF="https://irrationalanalysis.substack.com/p/hot-chips-2024-irrational-recap">Hot Chips 2024: Irrational Recap - Irrational Analysis</A>
						<DT><A HREF="https://github.com/geohot/asm2464pd-firmware">geohot/asm2464pd-firmware: vibe reversed firmware for the ASM2464PD</A>
						<DT><A HREF="https://connectorbook.com/identification.html?B=">Connector identification online - The electronic connector book</A>
						<DT><A HREF="https://www.youtube.com/watch?v=4u8iMr3iXR4">Bill Dally - Trends in Deep Learning Hardware - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>efficient-ai</H3>
					<DL><p>
						<DT><A HREF="https://www.youtube.com/watch?v=bfexfASu9h4">Scalable and Efficient AI: From Supercomputers to Smartphones (Microsoft)</A>
						<DT><H3 FOLDED>efficient-ai-i/o</H3>
						<DL><p>
							<DT><H3 FOLDED>NVMe</H3>
							<DL><p>
								<DT><H3 FOLDED>DeepNVMe</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-gds/README.md">DeepSpeed/blogs/deepspeed-gds/README.md at master ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://x.com/MSFTDeepSpeed/status/1820433545220993035">(1) DeepSpeed en X: "Introducing DeepNVMe, a suite of optimizations for fast and efficient I/O operations in DL applications. - POSIX-style APIs - Direct HBM/NVMe xfers via NVIDIA GDS - Cheap Inference scaling via NVMe-Offload Blog: https://t.co/W3SrkQQnFQ @Azure @NVIDIADC #FMS24 #GPUDirect https://t.co/c9PgXJlUD8" / X</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/releases/tag/v0.15.0">Release DeepSpeed v0.15.0 ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/pull/5852">DeepNVMe GDS by jomayeri ¬∑ Pull Request #5852 ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/compare/main...mikaylagawarecki:pytorch:gds">Comparing pytorch:main...mikaylagawarecki:gds ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/pull/5852/files#diff-c0ff3e0c2ca77226e3e4621ad72e642cb2716692ccac2171972a4afcdb9fd557">DeepNVMe GDS by jomayeri ¬∑ Pull Request #5852 ¬∑ microsoft/DeepSpeed</A>
								</DL><p>
								<DT><A HREF="https://github.com/hpcaitech/TensorNVMe">hpcaitech/TensorNVMe: A Python library transfers PyTorch tensors between CPU and NVMe</A>
							</DL><p>
							<DT><H3 FOLDED>s3</H3>
							<DL><p>
								<DT><H3 FOLDED>s3-torch</H3>
								<DL><p>
									<DT><A HREF="https://github.com/awslabs/s3-connector-for-pytorch/#distributed-checkpoints">awslabs/s3-connector-for-pytorch: The Amazon S3 Connector for PyTorch delivers high throughput for PyTorch training jobs that access and store data in Amazon S3.</A>
								</DL><p>
								<DT><A HREF="https://blog.glennklockwood.com/2025/02/llm-training-without-parallel-file.html">LLM training without a parallel file system (S3)</A>
								<DT><A HREF="https://github.com/minio/minio">minio/minio: MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.</A>
								<DT><A HREF="https://github.com/peak/s5cmd">peak/s5cmd: Parallel S3 and local filesystem execution tool.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=J1vEUTe4gi0">How AWS S3 Hit 1PB/s Using Hard Drives... This Is WILD! - YouTube</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2101.08734">[2101.08734] Clairvoyant Prefetching for Distributed Machine Learning I/O</A>
							<DT><A HREF="https://github.com/NVIDIA/aistore/blob/master/docs/overview.md">aistore/docs/overview.md at master ¬∑ NVIDIA/aistore</A>
							<DT><A HREF="https://arxiv.org/abs/2001.01858">[2001.01858] High Performance I/O For Large Scale Deep Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2101.08734">Prefetching for Distributed Machine Learning I/O (bitwise determinisn)</A>
							<DT><A HREF="https://github.com/NVIDIA/aistore/blob/master/docs/overview.md">NVIDIA/aistore</A>
							<DT><A HREF="https://arxiv.org/abs/2203.17189">Scaling Up Models and Data with t5x + seqio</A>
							<DT><A HREF="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/datasets.html">Datasets ‚Äî NVIDIA NeMo (AIStore)</A>
						</DL><p>
						<DT><H3 FOLDED>efficient-ai-compute</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2007.00072">[2007.00072] Data Movement Is All You Need: A Case Study on Optimizing Transformers</A>
							<DT><A HREF="https://github.com/spcl/dace">spcl/dace: DaCe - Data Centric Parallel Programming</A>
							<DT><A HREF="https://arxiv.org/abs/2210.17323">[2210.17323] GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</A>
							<DT><A HREF="https://research.nvidia.com/publication/2021-04_vs-quant-vector-scaled-quantization-accurate-low-precision-neural-network">VS-QUANT: Per-Vector Scaled Quantization for Accurate Low-Precision Neural Network Inference | Research</A>
							<DT><A HREF="https://arxiv.org/pdf/2102.04503.pdf">VS-QUANT: PER-VECTOR SCALED QUANTIZATION FOR ACCURATE LOW-PRECISION NEURAL NETWORK INFERENCE</A>
							<DT><A HREF="https://arxiv.org/abs/2102.00554">[2102.00554] Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks</A>
							<DT><A HREF="https://arxiv.org/abs/2306.03078">[2306.03078] SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression</A>
							<DT><A HREF="https://sparse.tamu.edu/">SuiteSparse Matrix Collection</A>
							<DT><A HREF="https://arxiv.org/abs/2304.07613">[2304.07613] STen: Productive and Efficient Sparsity in PyTorch</A>
							<DT><A HREF="https://github.com/spcl/sten">spcl/sten: Sparsity support for PyTorch</A>
							<DT><A HREF="https://sc23.supercomputing.org/presentation/?id=pap438&sess=sess178">VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores</A>
							<DT><A HREF="https://arxiv.org/abs/1712.05877">[1712.05877] Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</A>
							<DT><A HREF="https://github.com/Kobzol/hardware-effects-gpu">Kobzol/hardware-effects-gpu: Demonstration of various hardware effects on CUDA GPUs.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=q38V66bqhfU">EfficientML.ai lecture - YouTube</A>
							<DT><A HREF="https://github.com/srush/LLM-Training-Puzzles">srush/LLM-Training-Puzzles: What would you do with 1000 H100s...</A>
							<DT><A HREF="https://arxiv.org/abs/2310.07707">[2310.07707] MatFormer: Nested Transformer for Elastic Inference</A>
							<DT><A HREF="https://arxiv.org/abs/2007.00072">Data Movement Is All You Need: Case Study on Optimizing Transformers</A>
							<DT><A HREF="https://github.com/Kobzol/hardware-effects-gpu">hardware-effects-gpu: Demonstration of various hardware effects on CUDA GPUs.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=mP4BL6URdxc">EfficientML.ai Lecture 18: Distributed Training (Part II) (MIT Fall 2023)</A>
							<DT><A HREF="https://arxiv.org/abs/2306.03078">SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression</A>
							<DT><A HREF="https://research.nvidia.com/publication/2021-04_vs-quant-vector-scaled-quantization-accurate-low-precision-neural-network">VS-QUANT: Per-Vector Scaled Quantization for Accurate Low-Precision Neural Network Inference</A>
							<DT><A HREF="https://arxiv.org/abs/2102.00554">Sparsity in Deep Learning: Pruning and growth for efficient inference and training in neural networks</A>
							<DT><A HREF="https://arxiv.org/abs/1712.05877">Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</A>
							<DT><A HREF="https://twitter.com/tianle_cai/status/1770587583086764288">compute-memory bandwidth bottleneck</A>
						</DL><p>
						<DT><H3 FOLDED>efficient-ai-communication</H3>
						<DL><p>
							<DT><H3 FOLDED>juniper</H3>
							<DL><p>
								<DT><A HREF="https://community.juniper.net/blogs/sharada-yeluri/2024/01/02/gpu-fabrics-for-genai-workloads">GPU Fabrics for GenAI Workloads (Juniper)</A>
							</DL><p>
							<DT><H3 FOLDED>prime-swarm</H3>
							<DL><p>
								<DT><A HREF="https://x.com/Ar_Douillard/status/1921912345741189559">(1) Arthur Douillard en X: "this infra framework (https://t.co/8NZc37COqg) + using SWARM (https://t.co/BpD0zYWe88) on the inference node to fit ultra large models is going to be the future one step closer to the GitTheta (https://t.co/dgJuQibLAL) dream https://t.co/EhPq8bKKVM" / X</A>
								<DT><A HREF="https://www.primeintellect.ai/blog/intellect-2-release">INTELLECT-2 Release: The First Globally Trained 32B Parameter Model Reinforcement Learning Training Run</A>
								<DT><A HREF="https://arxiv.org/abs/2301.11913">[2301.11913] SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient</A>
								<DT><A HREF="https://arxiv.org/abs/2306.04529">[2306.04529] Git-Theta: A Git Extension for Collaborative Development of Machine Learning Models</A>
							</DL><p>
							<DT><A HREF="https://insujang.github.io/2022-06-11/parallelism-in-distributed-deep-learning/">Parallelism in Distributed Deep Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2201.12023">Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning</A>
							<DT><A HREF="https://arxiv.org/abs/1802.09941">Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis</A>
							<DT><A HREF="https://arxiv.org/abs/1802.08021">SparCML: High-Performance Sparse Communication for Machine Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2106.15565">[2106.15565] Flare: Flexible In-Network Allreduce</A>
							<DT><A HREF="https://arxiv.org/abs/2209.01346">[TPUv4] HammingMesh: A Network Topology for Large-Scale Deep Learning</A>
							<DT><A HREF="https://arxiv.org/abs/2302.03337">[Network Cloud Standard] Datacenter Ethernet and RDMA: Issues at scale</A>
							<DT><A HREF="https://www.youtube.com/watch?v=KYNHe_XyUBc">NVIDIA Networking: Understanding Ethernet Switches - YouTube</A>
							<DT><A HREF="https://dl.acm.org/doi/10.1145/3544216.3544265">Jupiter evolving | Proceedings of the ACM SIGCOMM 2022 Conference</A>
							<DT><A HREF="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41684.pdf">Google Omega: flexible, scalable schedulers for large compute clusters</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Collective_operation">Collective operation</A>
							<DT><A HREF="https://github.com/facebookresearch/ucc">Unified Collective Communication (UCC)</A>
							<DT><A HREF="https://network.nvidia.com/pdf/whitepapers/IB_Intro_WP_190.pdf">Introduction to InfiniBand</A>
							<DT><A HREF="https://github.com/open-mpi/ompi">open-mpi/ompi: Open MPI main development repository</A>
							<DT><A HREF="https://github.com/leandromoreira/linux-network-performance-parameters">leandromoreira/linux-network-performance-parameters</A>
							<DT><A HREF="https://arxiv.org/abs/2311.08105">[2311.08105] DiLoCo: Distributed Low-Communication Training LM</A>
							<DT><A HREF="https://arxiv.org/abs/1802.09941">Demystifying Parallel and Distributed Deep Learning: An In-Depth Analysis</A>
							<DT><A HREF="https://arxiv.org/abs/1802.08021">SparCML: High-Performance Sparse Communication for ML</A>
							<DT><A HREF="https://www.youtube.com/watch?v=KYNHe_XyUBc">NVIDIA Networking: Understanding Ethernet Switches</A>
							<DT><A HREF="https://developer.nvidia.com/blog/doubling-all2all-performance-with-nvidia-collective-communication-library-2-12/">Doubling all2all Performance with NCCL</A>
							<DT><A HREF="https://chatgpt.com/c/e57a5ce7-00de-486a-a8c2-c95db90cf417">non-blocking flat tree</A>
							<DT><A HREF="https://arxiv.org/abs/2305.06942">[2305.06942] Optimizing Distributed ML Communication with Fused Computation-Collective Operations</A>
							<DT><A HREF="https://le.qun.ch/en/blog/2024/12/25/libfabric-efa-0-intro/">Harnessing 3200 Gbps Network: A Journey with RDMA, EFA, and libfabric</A>
						</DL><p>
						<DT><H3 FOLDED>efficient-ai-supercomputing</H3>
						<DL><p>
							<DT><H3 FOLDED>supercomputing-high-performance-transaction-systems</H3>
							<DL><p>
								<DT><A HREF="https://perspectives.mvdirona.com/about-perspectives/">About Perspectives ‚Äì Perspectives</A>
							</DL><p>
							<DT><H3 FOLDED>superpod</H3>
							<DL><p>
								<DT><A HREF="https://docs.nvidia.com/https:/docs.nvidia.com/dgx-superpod-reference-architecture-dgx-h100.pdf">NVIDIA DGX SuperPOD</A>
							</DL><p>
							<DT><A HREF="https://twitter.com/tim_zaman/status/1636981863477809152?t=_WTQgylsaggk5zy5JJrlAA&s=31">Tim Zaman: Azure next-gen AI datacenter (training &amp; inference)</A>
							<DT><A HREF="https://coreweave.com/events/supercomputing-2023?utm_content=270153292&utm_medium=social&utm_source=twitter&hss_channel=tw-979803443681349632">CoreWeave @ SC23 ‚Äî Events ‚Äî CoreWeave</A>
							<DT><A HREF="https://colocatedeventsna2023.sched.com/event/1Rj1g">CNCF-Hosted Co-located Events North America 2023: How We Power the Largest AI Deployments</A>
							<DT><A HREF="https://www.youtube.com/@cncf">CNCF [Cloud Native Computing Foundation] - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=aSwfT4oRrvI">From Zero to Infinity: How AI-Powered Hedge Fund Build Cloud-Native AI</A>
							<DT><A HREF="https://www.youtube.com/watch?v=hHZxjH8u84s">Practice of Building AI Training Cluster Based on Kubernetes+RoCEv2</A>
							<DT><A HREF="https://cs217.stanford.edu/">Hardware Accelerators for Machine Learning (CS 217) by cs217</A>
							<DT><A HREF="https://blogs.nvidia.com/blog/nemo-amazon-titan/">NVIDIA Powers Training for Some of the Largest Amazon Titan Foundation Models | NVIDIA Blogs</A>
							<DT><A HREF="https://github.com/baidu-research/DeepBench">baidu-research/DeepBench: Benchmarking Deep Learning operations on different hardware (MUST)</A>
							<DT><A HREF="https://www.youtube.com/@cncf">CNCF [Cloud Native Computing Foundation]</A>
							<DT><A HREF="https://blogs.nvidia.com/blog/nemo-amazon-titan/">NVIDIA Training for Some of the Largest Amazon Fronteir Models</A>
							<DT><A HREF="https://github.com/baidu-research/DeepBench">DeepBench: Benchmarking Deep Learning operations on different hardware (MUST)</A>
							<DT><A HREF="https://gpulist.ai/">gpulist</A>
						</DL><p>
						<DT><H3 FOLDED>efficient-ai-people</H3>
						<DL><p>
							<DT><H3 FOLDED>efficient-ai-people-coreweave</H3>
							<DL><p>
								<DT><A HREF="https://github.com/anthr76">anthr76 (Anthony Rabbito)</A>
								<DT><A HREF="https://github.com/bradbeam">bradbeam (Brad Beam)</A>
								<DT><A HREF="https://github.com/ddymko">ddymko (David Dymko)</A>
								<DT><A HREF="https://github.com/dfinster">dfinster (David Finster)</A>
							</DL><p>
							<DT><A HREF="http://htor.ethz.ch/">Torsten Hoefler's Home Page</A>
							<DT><A HREF="https://arxiv.org/search/cs?searchtype=author&query=Hoefler%2C+T">Search | arXiv e-print repository</A>
							<DT><A HREF="https://github.com/suryabhupa">suryabhupa (Surya Bhupatiraju) (DeepMind)</A>
							<DT><A HREF="https://github.com/ranxian">ranxian (Ran Xian) CTO at Metabit Trading</A>
							<DT><A HREF="https://twitter.com/songhan_mit?lang=en">Instructor: Prof. Song Han</A>
						</DL><p>
						<DT><H3 FOLDED>efficient-ai-algorithms-structures</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=7WeraZ0LLlg&list=LL&index=840&t=3s">EfficientML.ai Lecture 13 - Transformer and LLM (Part II) (MIT 6.5940, Fall 2023) - YouTube</A>
							<DT><A HREF="https://hanlab.mit.edu/courses/2023-fall-65940">MIT 6.5940 Fall 2023 TinyML and Efficient Deep Learning Computing</A>
							<DT><A HREF="https://github.com/BearNinja123/data_structures/blob/main/stack.c">data_structures/stack.c at main</A>
						</DL><p>
						<DT><H3 FOLDED>efficient-ai-labs</H3>
						<DL><p>
							<DT><A HREF="https://huggingface.co/Efficient-Large-Model">Efficient-Large-Model (Efficient-Large-Model)</A>
						</DL><p>
						<DT><A HREF="https://arxiv.org/abs/2211.05102">[2211.05102] Efficiently Scaling Transformer Inference</A>
						<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1773268740806705266">optimal batch size (bytes per param, flops, bytes/token, arithmetic intensity )</A>
						<DT><A HREF="https://www.youtube.com/watch?v=gofI47kfD28">Bill Dally | Directions in Deep Learning Hardware - YouTube</A>
						<DT><A HREF="https://www.coreweave.com/blog/coreweaves-tensorizer-decrease-pytorch-model-load-times">Decrease PyTorch Model Load Times with CoreWeave‚Äôs Tensorizer</A>
						<DT><A HREF="https://www.youtube.com/watch?v=eZdOkDtYMoo">Song Han: Efficient Methods and Hardware for Deep Learning</A>
						<DT><A HREF="https://github.com/coreweave/tensorizer/#available-pre-tensorized-models-on-the-coreweave-cloud">coreweave/tensorizer: Module, Model, &amp; Tensor Serialization/Deserialization</A>
						<DT><A HREF="https://www.p99conf.io/?utm_source=google&utm_medium=cpc&utm_campaign=20420977396&utm_content=P99_Custom-Intent_P99-2023&utm_placement=youtube.com&gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdqVhRjjyo7gkpYIqZexrbTarZXUuFDYlrFHrlUkpWLbWgMlC8t1mv4aAoY2EALw_wcB">P99 CONF - The Event on All Things Performance</A>
						<DT><A HREF="https://ocw.mit.edu/courses/6-172-performance-engineering-of-software-systems-fall-2018/pages/lecture-slides/">Lecture Slides | Performance Engineering of Software Systems</A>
						<DT><A HREF="https://arxiv.org/pdf/2211.05102.pdf">Efficiently Scaling Transformer Inference</A>
						<DT><A HREF="https://www.youtube.com/watch?v=iXSfUw7VfNw">Using Pytorch 2.0 Compile in IBM's Watsonx.AI Inference</A>
						<DT><A HREF="https://www.youtube.com/watch?v=1pg1JE2CPaA">Quatization Scaling</A>
						<DT><A HREF="https://github.com/cloud-hypervisor/cloud-hypervisor">cloud-hypervisor/cloud-hypervisor: A Virtual Machine Monitor</A>
						<DT><A HREF="https://horace.io/brrr_intro.html">Making Deep Learning go Brrrr From First Principles</A>
						<DT><A HREF="https://www.youtube.com/@rutgersefficientaiseminar9909">Rutgers Efficient AI Seminar - YouTube</A>
						<DT><A HREF="https://hanlab.mit.edu/courses/2024-fall-65940">MIT 6.5940 Fall 2024 TinyML and Efficient Deep Learning Computing</A>
						<DT><A HREF="https://www.youtube.com/playlist?list=PL80kAHvQbh-pT4lCkDT53zT8DKmhE0idB">EfficientML.ai Lecture, Fall 2023, MIT 6.5940 - YouTube</A>
						<DT><A HREF="https://research.google/blog/speed-matters/">Speed Matters</A>
						<DT><A HREF="https://2024resumedropco-design.splashthat.com/">Meta Research AI and Systems Co-Design Resume Drop (PhD New Grad/Intern)</A>
						<DT><A HREF="https://x.com/PytorchToAtoms/status/1867013852279255095">(1) Pytorch To Atoms en X: "BREAKING NEWS FROM @dylan522p vs @jefrankle debate: databricks disbanded their pretraining team &amp;amp; re-org'ed it to "training efficiency team"" / X</A>
						<DT><A HREF="https://cacm.acm.org/research/metas-hyperscale-infrastructure-overview-and-insights/">(DaaC): Meta‚Äôs Hyperscale Infrastructure: Overview and Insights ‚Äì Communications of the ACM</A>
						<DT><A HREF="https://www.supercluster.blog/p/15-ai-supercluster-advanced-training">15. AI Supercluster: Advanced Training &amp; Optimization for Trillion Parameter Models</A>
						<DT><A HREF="https://x.com/JeffDean/status/1958525015722434945">(1) Jeff Dean en X: "AI efficiency is important. Today, Google is sharing a technical paper detailing our comprehensive methodology for measuring the environmental impact of Gemini inference. We estimate that the median Gemini Apps text prompt uses 0.24 watt-hours of energy (equivalent to watching an https://t.co/86v42LLkrW" / X</A>
					</DL><p>
					<DT><H3 FOLDED>papers-ai-compilers</H3>
					<DL><p>
						<DT><H3 FOLDED>papers-ai-compilers-correctness</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2306.06884">[2306.06884] A Survey of Modern Compiler Fuzzing</A>
							<DT><A HREF="https://comby.dev/blog/2022/04/11/comby-decomposer-compiler-fuzzing">Deconstructing programs for compiler fuzzing ¬∑ Comby</A>
							<DT><A HREF="https://agroce.github.io/cc22.pdf">Making No-Fuss Compiler Fuzzing Effective</A>
						</DL><p>
						<DT><H3 FOLDED>MLIR</H3>
						<DL><p>
							<DT><A HREF="https://mlir.llvm.org/docs/LangRef/">MLIR Language Reference - MLIR</A>
							<DT><A HREF="https://www.youtube.com/watch?v=5OSP5DNAozU">Building domain-specific compilers quickly with MLIR compiler infrastructure | Chris Lattner</A>
							<DT><A HREF="https://www.youtube.com/watch?v=A3qbcwasEUY">Groq Spotlight: Groq‚Ñ¢ Compiler Overview - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=3LLzHKeL2hs">MLIR-based code generation for GPU tensor cores - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=LPlRLt9w4b0&t=306s">2023 EuroLLVM - What's new in MLIR?</A>
							<DT><A HREF="https://www.youtube.com/watch?v=xNe9fPvU7-U">Open MLIR Meeting 11-16-2023: Targeting H100 with NVGPU and NVVM Dialects - YouTube</A>
							<DT><A HREF="https://github.com/llvm/llvm-project/pull/87065">[mlir][nvgpu] NVGPU Tutorials by grypp ¬∑ Pull Request #87065 ¬∑ llvm/llvm-project</A>
							<DT><A HREF="https://github.com/llvm/llvm-project/pull/87065/files">[mlir][nvgpu] NVGPU Tutorials by grypp ¬∑ Pull Request #87065 ¬∑ llvm/llvm-project</A>
							<DT><A HREF="https://grypp.github.io/papers/nvdsl.pdf">Zero to Hero: Programming Nvidia Hopper with MLIR‚Äôs NVGPU Dialect</A>
							<DT><H3 FOLDED>byteIR</H3>
							<DL><p>
								<DT><A HREF="https://github.com/bytedance/byteir">bytedance/byteir: A model compilation solution for various hardware</A>
								<DT><A HREF="https://github.com/bytedance/byteir/blob/main/talks/ChinaSoftCon-ByteIR.pdf">byteir/talks/ChinaSoftCon-ByteIR.pdf at main ¬∑ bytedance/byteir</A>
								<DT><A HREF="https://github.com/bytedance/byteir/blob/main/talks/c4ml23_poster.pdf">Linalg is All You Need to Optimize Attention</A>
							</DL><p>
							<DT><H3 FOLDED>NVGPU</H3>
							<DL><p>
								<DT><A HREF="https://mlir.llvm.org/docs/Dialects/NVGPU/">'nvgpu' Dialect - MLIR</A>
								<DT><A HREF="https://github.com/llvm/llvm-project/pull/87065">[mlir][nvgpu] NVGPU Tutorials by grypp ¬∑ Pull Request #87065 ¬∑ llvm/llvm-project</A>
								<DT><A HREF="https://github.com/llvm/llvm-project/pull/87065/files">[mlir][nvgpu] NVGPU Tutorials by grypp ¬∑ Pull Request #87065 ¬∑ llvm/llvm-project</A>
								<DT><A HREF="https://grypp.github.io/papers/nvdsl.pdf">Programming
Nvidia Hopper with MLIR‚Äôs NVGPU Dialect</A>
							</DL><p>
							<DT><A HREF="https://www.lei.chat/posts/mlir-linalg-dialect-and-patterns/">MLIR Linalg Dialect and Patterns | Lei.Chat()</A>
						</DL><p>
						<DT><H3 FOLDED>ai-compilers-lectures</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=lPX1H3jW8ZQ">AI Hardware w/ Jim Keller - YouTube</A>
							<DT><A HREF="https://ocw.mit.edu/courses/6-172-performance-engineering-of-software-systems-fall-2018/pages/lecture-slides/">Lecture Slides | Performance Engineering of Software Systems</A>
						</DL><p>
						<DT><H3 FOLDED>dtypes</H3>
						<DL><p>
							<DT><H3 FOLDED>microscaling-dtypes</H3>
							<DL><p>
								<DT><H3 FOLDED>fp8</H3>
								<DL><p>
									<DT><A HREF="https://tesla-cdn.thron.com/static/MXMU3S_tesla-dojo-technology_1WDVZN.pdf">A Guide to Tesla's Configurable Floating Point foRMATS &amp; Arithmetic</A>
									<DT><A HREF="https://arxiv.org/pdf/2209.05433.pdf">FP8 FORMATS FOR DEEP LEARNING</A>
									<DT><A HREF="https://github.com/pytorch/rfcs/blob/master/RFC-0030-native-fp8-dtype.md">rfcs/RFC-0030-native-fp8-dtype.md at master ¬∑ pytorch/rfcs</A>
									<DT><A HREF="https://arxiv.org/pdf/1710.03740.pdf">MIXED PRECISION TRAINING</A>
									<DT><A HREF="https://pytorch.org/docs/stable/quantization.html">Quantization ‚Äî PyTorch 2.0 documentation</A>
									<DT><A HREF="https://github.com/Azure/MS-AMP">Azure/MS-AMP: Microsoft Automatic Mixed Precision Library</A>
									<DT><A HREF="https://azure.github.io/MS-AMP/">MS-AMP Documentation | MS-AMP</A>
									<DT><A HREF="https://arxiv.org/abs/2309.17224">[2309.17224] Training and inference of large language models using 8-bit floating point</A>
									<DT><A HREF="https://github.com/pytorch-labs/float8_experimental">pytorch-labs/float8_experimental</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Primitive_data_type">Primitive data type - Wikipedia</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Single-precision_floating-point_format">Single-precision floating-point format - Wikipedia</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/757275f2796bb901575c633e2a32bc76ca84ffec/include/cutlass/numeric_conversion.h#L760">numeric_conversion.h</A>
									<DT><A HREF="https://research.colfax-intl.com/adding-fp8-to-flashattention/">Delivering 1 PFLOP/s of Performance with FP8 FlashAttention-2 ‚Äì Colfax Research</A>
									<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/606">FP8 Unable to achieve the expected FLOPS indicator in 4090 ¬∑ Issue #606 ¬∑ NVIDIA/TransformerEngine</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Vp1zZGBUy9o">ü§ó Hugging Cast S2E2 - Accelerating AI with NVIDIA! - YouTube</A>
									<DT><A HREF="https://github.com/P3109/Public/blob/main/Shared%20Reports/P3109%20WG%20Interim%20Report.pdf">Public/Shared Reports/P3109 WG Interim Report.pdf at main ¬∑ P3109/Public</A>
									<DT><A HREF="https://arxiv.org/pdf/2303.17951">FP8 versus INT8 for efficient deep learning inference</A>
									<DT><A HREF="https://01-ai.github.io/blog.html?post=zh/2024-07-30-%E5%A4%A7%E6%A8%A1%E5%9E%8B%20FP8%20%E4%BD%8E%E7%B2%BE%E5%BA%A6%E9%87%8F%E5%8C%96%E6%8E%A8%E7%90%86.md">Â§ßÊ®°Âûã FP8 ‰ΩéÁ≤æÂ∫¶ÈáèÂåñÊé®ÁêÜ - 01.AI Blog</A>
									<DT><A HREF="https://gist.github.com/malfet/d9aaf3faf8b62e073f963085aa7d629b">float8_mm.cu</A>
									<DT><A HREF="https://github.com/enp1s0/simple_fp8/blob/main/include/simple_fp8.hpp">simple_fp8/include/simple_fp8.hpp at main ¬∑ enp1s0/simple_fp8</A>
									<DT><A HREF="https://arxiv.org/pdf/2410.00907">ADDITION IS ALL YOU NEED FOR ENERGY-EFFICIENT LANGUAGE MODELS</A>
									<DT><A HREF="https://www.radicalnumerics.ai/blog/nvfp4-part1">NVFP4 Pretraining: From Theory to Implementation (Part 1) ¬∑ Radical Numerics</A>
								</DL><p>
								<DT><H3 FOLDED>fp6</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2401.14112">FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design</A>
									<DT><A HREF="https://github.com/usyd-fsalab/fp6_llm?tab=readme-ov-file">usyd-fsalab/fp6_llm: An efficient GPU support for LLM inference with x-bit quantization (e.g. FP6,FP5).</A>
									<DT><A HREF="https://github.com/usyd-fsalab/fp6_llm">usyd-fsalab/fp6_llm: An efficient GPU support for LLM inference with x-bit quantization (e.g. FP6,FP5).</A>
								</DL><p>
								<DT><H3 FOLDED>fp4</H3>
								<DL><p>
									<DT><H3 FOLDED>mxfp4</H3>
									<DL><p>
										<DT><A HREF="https://www.kapilsharma.dev/mxfp4/">MXFP4 Visualizer | Kapil Sharma</A>
										<DT><A HREF="https://www.kapilsharma.dev/posts/mxfp4-visualizer/">Understanding MXFP4 Quantization | Kapil Sharma</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=64">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
									<DT><A HREF="https://x.com/arankomatsuzaki/status/1884446877837582598">(Microsoft Research) Optimizing Large Language Model Training Using FP4 Quantization</A>
									<DT><A HREF="https://arxiv.org/abs/2501.17116">[2501.17116] Optimizing Large Language Model Training Using FP4 Quantization</A>
									<DT><A HREF="https://github.com/IST-DASLab/Quartet">IST-DASLab/Quartet</A>
									<DT><A HREF="https://gist.github.com/mobicham/a92d91a5d57c7c350c7763d51eb0b342">fp4_quant.py</A>
									<DT><A HREF="https://x.com/DAlistarh/status/1944643268559417443">(1) Dan Alistarh en X: "Announcing our early work on FP4 inference for LLMs! - QuTLASS: low-precision kernel support for Blackwell GPUs - FP-Quant: a flexible quantization harness for Llama/Qwen We reach 4x speedup vs BF16, with good accuracy through MXFP4 microscaling + fused Hadamard rotations. https://t.co/4WUwUSipRM" / X</A>
									<DT><A HREF="https://developer.nvidia.com/blog/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/">NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit | NVIDIA Technical Blog</A>
									<DT><A HREF="https://github.com/ModelTC/LightX2V/blob/main/lightx2v_kernel/docs/en_US/nvfp4_quantization_basics.md">LightX2V/lightx2v_kernel/docs/en_US/nvfp4_quantization_basics.md at main ¬∑ ModelTC/LightX2V</A>
									<DT><A HREF="https://arxiv.org/abs/2509.23202">[2509.23202] Bridging the Gap Between Promise and Performance for Microscaling FP4 Quantization</A>
									<DT><A HREF="https://github.com/benenzhu/learn-ptx/blob/main/nvfp4/sub1.py">learn-ptx/nvfp4/sub1.py at main ¬∑ benenzhu/learn-ptx</A>
									<DT><A HREF="https://www.radicalnumerics.ai/blog/nvfp4-part1#the-nvfp4-recipe">NVFP4 Pretraining: From Theory to Implementation (Part 1) ¬∑ Radical Numerics</A>
								</DL><p>
								<DT><A HREF="https://azure.microsoft.com/en-us/blog/fostering-ai-infrastructure-advancements-through-standardization/">Fostering AI infrastructure advancements through standardization | Microsoft Azure Blog</A>
								<DT><A HREF="https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf">OCP Microscaling Formats (MX) Specification</A>
								<DT><A HREF="https://arxiv.org/abs/2310.10537">[2310.10537] Microscaling Data Formats for Deep Learning</A>
								<DT><A HREF="https://arxiv.org/abs/2302.08007">[2302.08007] With Shared Microexponents, A Little Shifting Goes a Long Way</A>
								<DT><A HREF="https://github.com/microsoft/microxcaling">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fp6/03-05-2024">DeepSpeed/blogs/deepspeed-fp6/03-05-2024 at master ¬∑ microsoft/DeepSpeed</A>
								<DT><A HREF="https://www.opencompute.org/blog/open-compute-project-tackles-data-center-hardware-and-firmware-security">Open Compute Project Tackles Data Center Hardware and Firmware Security ¬ª Open Compute Project</A>
								<DT><A HREF="https://github.com/usyd-fsalab/fp6_llm">usyd-fsalab/fp6_llm: An efficient GPU support for LLM inference with x-bit quantization (e.g. FP6,FP5).</A>
								<DT><A HREF="https://github.com/microsoft/microxcaling?tab=readme-ov-file#Spec-Configuration">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
								<DT><A HREF="https://github.com/chengzeyi/AdaptiveFloat4">chengzeyi/AdaptiveFloat4: A novel high-precision 4bit quantization format</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=64">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>INT8</H3>
							<DL><p>
								<DT><A HREF="https://x.com/elonmusk/status/1987885633004831109">(1) Elon Musk en X: "@itsclivetime AI is moving to primarily 4 bit weights. Int4 for Tesla inference. Like a physical address, which has state, city and street. If you already know the state and city, only street need be specified. You still get the precision you need with far fewer bits." / X</A>
							</DL><p>
							<DT><H3 FOLDED>INT4</H3>
							<DL><p>
								<DT><A HREF="https://x.com/elonmusk/status/1987885633004831109">(1) Elon Musk en X: "@itsclivetime AI is moving to primarily 4 bit weights. Int4 for Tesla inference. Like a physical address, which has state, city and street. If you already know the state and city, only street need be specified. You still get the precision you need with far fewer bits." / X</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://github.com/llvm/circt">llvm/circt: Circuit IR Compilers and Tools</A>
						<DT><A HREF="https://www.youtube.com/watch?v=ZI198eFghJk">Modernizing Compiler Design for Carbon Toolchain - Chandler Carruth - CppNow 2023 - YouTube</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/FLOPS">FLOPS</A>
						<DT><A HREF="https://dl.acm.org/doi/pdf/10.1145/3620666.3651369">EVT: Accelerating Deep Learning Training with Epilogue Visitor Tree</A>
					</DL><p>
					<DT><H3 FOLDED>recommendation systems</H3>
					<DL><p>
						<DT><H3 FOLDED>generative-recommendation-systems</H3>
						<DL><p>
							<DT><H3 FOLDED>generative-recommenders</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/generative-recommenders">facebookresearch/generative-recommenders: Repository hosting code used to reproduce results in "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations" (https://arxiv.org/abs/2402.17152).</A>
								<DT><A HREF="https://github.com/facebookresearch/generative-recommenders/issues/115">How to install hammer package used in triton_ragged_hstu_attention? ¬∑ Issue #115 ¬∑ facebookresearch/generative-recommenders</A>
							</DL><p>
							<DT><H3 FOLDED>OneRec</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2506.13695">[2506.13695] OneRec Technical Report</A>
								<DT><A HREF="https://recsysml.substack.com/p/building-generative-friend-recommendations">Building Generative Friend Recommendations</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1918350919508140128">OneRec: We hope more people will research end-to-end recommendations</A>
							</DL><p>
							<DT><A HREF="https://github.com/facebookresearch/generative-recommenders">facebookresearch/generative-recommenders: Repository hosting code used to reproduce results in "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations" (https://arxiv.org/abs/2402.17152).</A>
							<DT><A HREF="https://mlfrontiers.substack.com/p/the-rise-of-generative-recommenders">The Rise of Generative Recommenders - by Samuel Flender</A>
							<DT><A HREF="https://www.linkedin.com/posts/gauravchak_recommendersystems-llm-recsys-activity-7373034499431051265-41mR/">OneRec</A>
							<DT><A HREF="https://recsysml.substack.com/p/building-generative-friend-recommendations">Building Generative Friend Recommendations</A>
							<DT><A HREF="https://arxiv.org/abs/2305.05065">[2305.05065] Recommender Systems with Generative Retrieval</A>
							<DT><A HREF="https://www.kapilsharma.dev/posts/transformers-for-recsys-1/">Transformers for Recommender Systems - Part 1 | Kapil Sharma</A>
						</DL><p>
						<DT><H3 FOLDED>torch-rec</H3>
						<DL><p>
							<DT><A HREF="https://github.com/pytorch/torchrec">pytorch/torchrec: Pytorch domain library for recommendation systems</A>
						</DL><p>
						<DT><H3 FOLDED>paddle-rec</H3>
						<DL><p>
							<DT><A HREF="https://github.com/PaddlePaddle/PaddleRec">PaddlePaddle/PaddleRec: Recommendation AlgorithmÂ§ßËßÑÊ®°Êé®ËçêÁÆóÊ≥ïÂ∫ìÔºåÂåÖÂê´Êé®ËçêÁ≥ªÁªüÁªèÂÖ∏ÂèäÊúÄÊñ∞ÁÆóÊ≥ïLR„ÄÅWide&amp;Deep„ÄÅDSSM„ÄÅTDM„ÄÅMIND„ÄÅWord2Vec„ÄÅBert4Rec„ÄÅDeepWalk„ÄÅSSR„ÄÅAITMÔºåDSINÔºåSIGNÔºåIPREC„ÄÅGRU4Rec„ÄÅYoutube_dnn„ÄÅNCF„ÄÅGNN„ÄÅFM„ÄÅFFM„ÄÅDeepFM„ÄÅDCN„ÄÅDIN„ÄÅDIEN„ÄÅDLRM„ÄÅMMOE„ÄÅPLE„ÄÅESMM„ÄÅESCMM, MAML„ÄÅxDeepFM„ÄÅDeepFEFM„ÄÅNFM„ÄÅAFM„ÄÅRALM„ÄÅDMR„ÄÅGateNet„ÄÅNAML„ÄÅDIFM„ÄÅDeep Crossing„ÄÅPNN„ÄÅBST„ÄÅAutoInt„ÄÅFGCNN„ÄÅFLEN„ÄÅFibinet„ÄÅListWise„ÄÅDeepRec„ÄÅENSFMÔºåTiSASÔºåAutoFISÁ≠âÔºåÂåÖÂê´ÁªèÂÖ∏Êé®ËçêÁ≥ªÁªüÊï∞ÊçÆÈõÜcriteo „ÄÅmovielensÁ≠â</A>
							<DT><A HREF="https://github.com/PaddleJitLab/DeepRecommender">PaddleJitLab/DeepRecommender: Deep learning for recommender systems</A>
						</DL><p>
						<DT><H3 FOLDED>bytedn-monolith</H3>
						<DL><p>
							<DT><A HREF="https://github.com/bytedance/monolith">bytedance/monolith: ByteDance's Recommendation System</A>
							<DT><A HREF="https://arxiv.org/abs/2209.07663">[2209.07663] Monolith: Real Time Recommendation System With Collisionless Embedding Table</A>
							<DT><A HREF="https://x.com/TheGregYang/status/2016041419547541662">Greg Yang en X: "bytedance was totally trolling people with the monolith paper as it was only used in a small part of tiktok</A>
						</DL><p>
						<DT><H3 FOLDED>VideoRecSys</H3>
						<DL><p>
							<DT><A HREF="https://videorecsys.com/">VideoRecSys 2024: Large-Scale Video Recommender Systems Workshop</A>
						</DL><p>
						<DT><H3 FOLDED>recommendation-systems-netflix</H3>
						<DL><p>
							<DT><A HREF="https://netflixtechblog.com/foundation-model-for-personalized-recommendation-1a0bd8e02d39">Foundation Model for Personalized Recommendation | by Netflix Technology Blog | Mar, 2025 | Netflix TechBlog</A>
						</DL><p>
						<DT><H3 FOLDED>x-algorithm</H3>
						<DL><p>
							<DT><A HREF="https://github.com/twitter/the-algorithm">twitter/the-algorithm: Source code for the X Recommendation Algorithm</A>
						</DL><p>
						<DT><H3 FOLDED>Similarity Search</H3>
						<DL><p>
							<DT><H3 FOLDED>Faiss</H3>
							<DL><p>
								<DT><A HREF="https://ai.meta.com/tools/faiss/">Faiss</A>
								<DT><A HREF="https://github.com/facebookresearch/faiss">facebookresearch/faiss: A library for efficient similarity search and clustering of dense vectors.</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://github.com/bytedance/AffineQuant">bytedance/AffineQuant: Official implementation of the ICLR 2024 paper AffineQuant</A>
						<DT><A HREF="https://arxiv.org/abs/2402.17152">[2402.17152] Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations</A>
						<DT><A HREF="https://github.com/PaddlePaddle/PaddleRec">PaddlePaddle/PaddleRec: Recommendation AlgorithmÂ§ßËßÑÊ®°Êé®ËçêÁÆóÊ≥ïÂ∫ìÔºåÂåÖÂê´Êé®ËçêÁ≥ªÁªüÁªèÂÖ∏ÂèäÊúÄÊñ∞ÁÆóÊ≥ïLR„ÄÅWide&amp;Deep„ÄÅDSSM„ÄÅTDM„ÄÅMIND„ÄÅWord2Vec„ÄÅBert4Rec„ÄÅDeepWalk„ÄÅSSR„ÄÅAITMÔºåDSINÔºåSIGNÔºåIPREC„ÄÅGRU4Rec„ÄÅYoutube_dnn„ÄÅNCF„ÄÅGNN„ÄÅFM„ÄÅFFM„ÄÅDeepFM„ÄÅDCN„ÄÅDIN„ÄÅDIEN„ÄÅDLRM„ÄÅMMOE„ÄÅPLE„ÄÅESMM„ÄÅESCMM, MAML„ÄÅxDeepFM„ÄÅDeepFEFM„ÄÅNFM„ÄÅAFM„ÄÅRALM„ÄÅDMR„ÄÅGateNet„ÄÅNAML„ÄÅDIFM„ÄÅDeep Crossing„ÄÅPNN„ÄÅBST„ÄÅAutoInt„ÄÅFGCNN„ÄÅFLEN„ÄÅFibinet„ÄÅListWise„ÄÅDeepRec„ÄÅENSFMÔºåTiSASÔºåAutoFISÁ≠âÔºåÂåÖÂê´ÁªèÂÖ∏Êé®ËçêÁ≥ªÁªüÊï∞ÊçÆÈõÜcriteo „ÄÅmovielensÁ≠â</A>
						<DT><A HREF="https://github.com/PaddleJitLab/DeepRecommender">PaddleJitLab/DeepRecommender: Deep learning for recommender systems</A>
						<DT><A HREF="https://kumo.ai/resources/blog/improving-predictions-with-large-language-models/">Improving Predictions with Large Language Models - Kumo.ai</A>
						<DT><A HREF="https://github.com/facebookresearch/generative-recommenders">facebookresearch/generative-recommenders: Repository hosting code used to reproduce results in "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations" (https://arxiv.org/abs/2402.17152).</A>
						<DT><A HREF="https://videorecsys.com/">VideoRecSys 2024: Large-Scale Video Recommender Systems Workshop</A>
						<DT><A HREF="https://github.com/bytedance/monolith">bytedance/monolith: ByteDance's Recommendation System</A>
						<DT><A HREF="https://eng.snap.com/training-models-with-tpus">Training Large-Scale Recommendation Models with TPUs</A>
						<DT><A HREF="https://pyemma.github.io/A-Random-Walk-Down-Recsys/">A Random Walk Down Recsys - Part 1 | Coding Monkey</A>
						<DT><A HREF="https://pyemma.github.io/Recommendation-Paper-2025-Review/">My 2025 Recommendation System Paper Summary | Coding Monkey</A>
						<DT><A HREF="https://x.com/_xjdr/status/2014388451542736938">(1) xjdr en X: "many many years ago, i worked on recsys and personalization systems. i finally looked at the xai algorithm and i do not understand it at all. its the normal candidate generation, pruning, reranking but without the core parts like collaborative filtering / matrix factorization and" / X</A>
					</DL><p>
					<DT><H3 FOLDED>Robotics &amp; Manufacturing</H3>
					<DL><p>
						<DT><H3 FOLDED>SLAM</H3>
						<DL><p>
							<DT><A HREF="https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping">Simultaneous localization and mapping - Wikipedia</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Particle_filter">Particle filter - Wikipedia</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Kalman_filter">Kalman filter - Wikipedia</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">Expectation‚Äìmaximization algorithm - Wikipedia</A>
							<DT><A HREF="https://docs.opencv.org/master/d8/dfe/classcv_1_1VideoCapture.html#ac4107fb146a762454a8a87715d9b7c96">OpenCV: cv::VideoCapture Class Reference</A>
							<DT><A HREF="https://www.amazon.com/Introduction-Simulation-SLAM-Alan-Pritsker/dp/0470265884">Introduction to simulation and SLAM: Pritsker, A. Alan B: 9780470265888: Amazon.com: Books</A>
							<DT><A HREF="https://fama.us.es/discovery/fulldisplay?docid=alma991000286959704987&context=L&vid=34CBUA_US:VU1&lang=es&search_scope=all_data_not_idus&adaptor=Local%20Search%20Engine&tab=all_data_not_idus&query=any,contains,Introduction%20to%20simulation%20and%20SLAM">Introduction to simulation and SLAM II</A>
							<DT><A HREF="https://pjreddie.com/darknet/">Darknet: Open Source Neural Networks in C</A>
						</DL><p>
						<DT><H3 FOLDED>Aerospace</H3>
						<DL><p>
							<DT><H3 FOLDED>Rockets</H3>
							<DL><p>
								<DT><A HREF="https://x.com/LandSpace_Tech">(1) LandSpace (@LandSpace_Tech) / X</A>
								<DT><A HREF="https://www.landspace.com/en/">LANDSPACE</A>
							</DL><p>
							<DT><H3 FOLDED>drones</H3>
							<DL><p>
								<DT><A HREF="https://fortune.com/2025/09/12/defense-spending-rise-global-conflict-brainstorm-tech/">‚ÄòBetter put some chips down‚Äô: U.S. tech is riding fears about rising global conflict | Fortune</A>
								<DT><A HREF="https://www.youtube.com/watch?v=FrAOBuskffA">Skunk Works¬Æ: Agile Drone Framework - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=bmLE9BT76Pc">I Built a $40,000 Military Drone for $120.07 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=5A3D06D97jo">We Built This to Film What‚Äôs 7,500 Light-Years Away - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=vtyYRMK_oy8">Dunking on Elon by actually tracking Stealth Fighters with cheap webcams - Q&amp;A. - YouTube</A>
								<DT><A HREF="https://x.com/grandparoy2/status/2000663100706422903">(1) Royüá®üá¶ en X: "Sources https://t.co/vsd4qE0cKj https://t.co/nlQB4xdXbc https://t.co/VaivJg4WNz" / X</A>
								<DT><A HREF="https://x.com/dim0kq/status/2012661235188113694?s=12">(1) Dimko Zhluktenko üá∫üá¶‚öîÔ∏è en X: "Ukraine did a great job reverse engineering Russian Shahed / Geran drones. You can literally go on the website and see component breakdown - made in Texas, Germany, Switzerland... I suggest you check it out. Very interesting. https://t.co/JgQmFoHghQ https://t.co/iEcbzXt0Ir" / X</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=1reS83Njcio">Actively Stabilized Model Rocket with Real-Time Telemetry - YouTube</A>
							<DT><A HREF="https://shield.ai/">Shield AI - Building The World‚Äôs Best AI Pilot</A>
							<DT><A HREF="https://vnav.mit.edu/">MIT16.485 - Visual Navigation for Autonomous Vehicles</A>
							<DT><A HREF="https://www.youtube.com/watch?v=m04G-rskO58">China‚Äôs hypersonic drone launches revealed on video for first time - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=dYFYZ-g7fzA">From the construction of the Turbo Jet engine to the flight - just one step - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=QIK6SX2wZo4">China's company successfully tests 'JINDOU' high-speed engine for near-space travel - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Humanoid</H3>
						<DL><p>
							<DT><H3 FOLDED>Sparsh</H3>
							<DL><p>
								<DT><A HREF="https://ai.meta.com/blog/fair-robotics-open-source/">Advancing embodied AI through progress in touch perception, dexterity, and human-robot interaction</A>
								<DT><A HREF="https://ai.meta.com/research/publications/sparsh-self-supervised-touch-representations-for-vision-based-tactile-sensing/">Sparsh: Self-supervised touch representations for vision-based tactile sensing | Research - AI at Meta</A>
								<DT><A HREF="https://sparsh-ssl.github.io/">Sparsh | Self-supervised touch representations for vision-based tactile sensing</A>
							</DL><p>
							<DT><H3 FOLDED>GR00T</H3>
							<DL><p>
								<DT><H3 FOLDED>Isaac Lab</H3>
								<DL><p>
									<DT><A HREF="https://isaac-sim.github.io/IsaacLab/main/index.html">Welcome to Isaac Lab! ‚Äî Isaac Lab Documentation</A>
								</DL><p>
								<DT><A HREF="https://x.com/DrJimFan/status/1869092155991773681">(1) Jim Fan en X: "I believe solving robotics = 90% engineering + 10% research vision. Project GR00T is NVIDIA's moonshot initiative to build physical AGI for humanoid robots. The GEAR Lab is assembling a crack team right now. Join us! Openings: - Sr. Research Engineer, Robotics Systems - Sr. RE, https://t.co/hrkmVqfeEn" / X</A>
								<DT><A HREF="https://developer.nvidia.com/project-gr00t">Project GR00T Robotic Foundation Model | NVIDIA Developer</A>
								<DT><A HREF="https://x.com/TheHumanoidHub/status/1876494120761577519">(1) The Humanoid Hub en X: "Jensen, at the CES 2025 stage with 14 humanoid robots standing in the background, announced NVIDIA Isaac GR00T Blueprint. It's a simulation workflow for synthetic motion generation, enabling developers to create large datasets for training humanoids using imitation learning. https://t.co/F8BOZLrktV" / X</A>
							</DL><p>
							<DT><H3 FOLDED>SAPIEN</H3>
							<DL><p>
								<DT><A HREF="https://github.com/haosulab/SAPIEN">haosulab/SAPIEN: SAPIEN Embodied AI Platform</A>
								<DT><A HREF="https://x.com/YouJiacheng/status/1929575597988036995">(1) You Jiacheng en X: "Used with RoboVerse, IsaacLab experience is shit compared to Sapien3. IsaacLab = + shit dependencies (wtf GLIBC 2.34+) + shit installation (wtf ./isaaclab.sh -i) + long start-up time + tons of warnings + incomprehensible errors Sapien3 = uv run and it works cc @Stone_Tao" / X</A>
							</DL><p>
							<DT><H3 FOLDED>ACT Lab</H3>
							<DL><p>
								<DT><A HREF="https://hekong-sustech.github.io/lab.html">Welcome to the Active Intelligent Systems Lab (ACT LAB)!</A>
							</DL><p>
							<DT><H3 FOLDED>on-device-robotics</H3>
							<DL><p>
								<DT><A HREF="https://x.com/GoogleDeepMind/status/1937511515768176966">(1) Google DeepMind en X: "We‚Äôre bringing powerful AI directly onto robots with Gemini Robotics On-Device. ü§ñ It‚Äôs our first vision-language-action model to help make robots faster, highly efficient, and adaptable to new tasks and environments - without needing a constant internet connection. üßµ https://t.co/1Y21D3cF5t" / X</A>
							</DL><p>
							<DT><A HREF="https://ai.meta.com/blog/fair-robotics-open-source/">Advancing embodied AI through progress in touch perception, dexterity, and human-robot interaction</A>
							<DT><A HREF="https://www.youtube.com/watch?v=P8WwXSnKq1g">OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation - YouTube</A>
							<DT><A HREF="https://www.figure.ai/careers#careers-listing">Careers | Figure</A>
							<DT><A HREF="https://github.com/thu-ml/RoboticsDiffusionTransformer">thu-ml/RoboticsDiffusionTransformer: RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation</A>
							<DT><A HREF="http://zlethic.com/">Lingkang Zhang</A>
							<DT><A HREF="https://x.com/DrJimFan/status/1876462220806422881/photo/1">People ask me what's next. The GOAT points the way. 
Physical AI. Embodied Agents. Robotics. That's what's next.</A>
							<DT><A HREF="https://x.com/bobmcgrewai/status/1903199829943259494">manipulation &gt;&gt; locomotion</A>
							<DT><A HREF="https://www.youtube.com/watch?v=_2NijXqBESI">The Physical Turing Test: Jim Fan on Nvidia's Roadmap for Embodied AI - YouTube</A>
							<DT><A HREF="https://x.com/lukas_m_ziegler/status/1939977771318436044">(1) Lukas Ziegler en X: "Touch used to be the final frontier for robots. Not anymore. DM-Hand1 by Hong Kong @DaimonRobotics Technology combines vision and tactile sensing, letting machines detect texture, weight shifts, and movement in real time. This changes everything. Not just what robots can https://t.co/pyNQKu6kvZ" / X</A>
							<DT><A HREF="https://x.com/rwang07/status/1974088246230737394/photo/1">Key Players on Humanoud Supply Chain by Goldman Sachs. $TSLA $NVDA $GOOGL $META</A>
							<DT><A HREF="https://www.youtube.com/watch?v=h--8XqcUuPI">Hardware Skills for the Age of AI - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Simulation</H3>
						<DL><p>
							<DT><A HREF="https://twitter.com/GoogleDeepMind/status/1714627619742683245">MuJoCO 3.0: GPU &amp; TPU acceleration through JAX</A>
							<DT><A HREF="https://www.olcf.ornl.gov/2024/02/29/planning-for-a-smooth-landing-on-mars/">Planning for a Smooth Landing on Mars ‚Äì Oak Ridge Leadership Computing Facility</A>
							<DT><A HREF="https://www.youtube.com/watch?v=M8s_cS-aH5w">NVIDIA‚Äôs New AI Just Made Real Physics Look Slow - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Additive Manufacturing</H3>
						<DL><p>
							<DT><H3 FOLDED>Hadrian</H3>
							<DL><p>
								<DT><A HREF="https://www.hadrian.co/">Hadrian ‚Ä¢ Manufacturing the future</A>
							</DL><p>
							<DT><H3 FOLDED>Relativity Space</H3>
							<DL><p>
								<DT><A HREF="https://www.relativityspace.com/additive">Relativity Space - Additive</A>
							</DL><p>
							<DT><A HREF="https://dim.etsii.upm.es/metalia/">METALIA | Divisi√≥n de Ingenier√≠a de M√°quinas</A>
						</DL><p>
						<DT><H3 FOLDED>edge-inference</H3>
						<DL><p>
							<DT><H3 FOLDED>Jetson</H3>
							<DL><p>
								<DT><H3 FOLDED>jetson-language-models</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=jSKHeYVcAB8">Gemma3 on Jetson Orin Nano: Live demo running Visual Language Models at 15 Tokens/s (with examples!) - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>jetson-thor</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=eRPSRSGiAA8">Testing VLMs and LLMs for robotics w/ the Jetson Thor devkit - YouTube</A>
									<DT><A HREF="https://x.com/TheHumanoidHub/status/1960008007540199871">(1) The Humanoid Hub en X: "NVIDIA‚Äôs new humanoid robot brain is officially on sale for $3,499. NVIDIA has announced the general availability of the Jetson AGX Thor developer kit and production modules. Powered by an NVIDIA Blackwell GPU and featuring 128GB of memory, it delivers up to 2,070 FP4 teraflops https://t.co/9ChZKjsZPG" / X</A>
								</DL><p>
								<DT><A HREF="https://www.techpowerup.com/gpu-specs/jetson-orin-nano-8-gb.c4082">NVIDIA Jetson Orin Nano 8 GB Specs | TechPowerUp GPU Database</A>
								<DT><A HREF="https://blogs.nvidia.com/blog/jetson-generative-ai-supercomputer/">NVIDIA Unveils Its Most Affordable Generative AI Supercomputer | NVIDIA Blog</A>
							</DL><p>
							<DT><A HREF="https://www.c4isrnet.com/opinion/2024/06/26/how-the-military-is-preparing-for-ai-at-the-edge/">How the military is preparing for AI at the edge</A>
							<DT><A HREF="https://www.youtube.com/watch?v=IjjZcnwkrAg">The BIG 3 Embedded Protocols - I2C, SPI, UART - YouTube</A>
							<DT><A HREF="https://research.facebook.com/publications/machine-learning-at-facebook-understanding-inference-at-the-edge/">Machine Learning at Facebook: Understanding Inference at the Edge - Meta Research</A>
							<DT><A HREF="https://github.com/kvcache-ai/ktransformers">kvcache-ai/ktransformers: A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations</A>
							<DT><A HREF="https://huggingface.co/collections/facebook/mobilellm-6722be18cb86c20ebe113e95">MobileLLM - a facebook Collection</A>
							<DT><A HREF="https://github.com/OpenBMB/MiniCPM">OpenBMB/MiniCPM: MiniCPM3-4B: An edge-side LLM that surpasses GPT-3.5-Turbo.</A>
							<DT><A HREF="https://github.com/pytorch/executorch">pytorch/executorch: On-device AI across mobile, embedded and edge for PyTorch</A>
						</DL><p>
						<DT><H3 FOLDED>neural-interfaces</H3>
						<DL><p>
							<DT><H3 FOLDED>BrainCo</H3>
							<DL><p>
								<DT><A HREF="https://brainco.tech/#/">BrainCo - Train Your Brain for Success</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>physical intelligence</H3>
						<DL><p>
							<DT><A HREF="https://www.physicalintelligence.company/">Physical Intelligence (œÄ)</A>
						</DL><p>
						<DT><H3 FOLDED>Light Robotics</H3>
						<DL><p>
							<DT><A HREF="https://www.linkedin.com/company/lightrobotics/">Light Robotics: Overview | LinkedIn</A>
						</DL><p>
						<DT><A HREF="https://www.youtube.com/watch?v=6cbayQAuvvw&t=305s">S3: They're Reimagining How to Build Anything | Hadrian</A>
						<DT><A HREF="https://twitter.com/lethic1">(1) Lethic (@lethic1) / X</A>
						<DT><A HREF="https://www.youtube.com/@lethic">Lethic Z - YouTube</A>
						<DT><A HREF="http://zlethic.com/">Lingkang Zhang</A>
						<DT><A HREF="https://github.com/zlingkang">zlingkang (Lingkang Zhang)</A>
						<DT><A HREF="https://www.anduril.com/">Anduril - Home</A>
						<DT><A HREF="https://x.com/SpaceX/status/1819772716339339664">(1) SpaceX en X: "Raptor 3 (sea level variant) Thrust: 280tf Specific impulse: 350s Engine mass: 1525kg Engine + vehicle-side commodities and hardware mass : 1720kg https://t.co/zormSroZyh" / X</A>
						<DT><A HREF="https://www.youtube.com/watch?v=2ckJt7bSqgQ">Jobs of the Future: Where Hardware Meets Software - YouTube</A>
						<DT><A HREF="https://www.youtube.com/shorts/O0qlNowndRw">3d printed robot arm, 50% speed. All joints in motion. - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=pnrhTYbOqNc">SAVA Robotics (YC X25) - Robot Operators for Sheet Metal - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=LaVioWCTISs">The Machine That Scared All Of Silicon Valley - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=h--8XqcUuPI">Hardware Skills for the Age of AI - YouTube</A>
						<DT><A HREF="https://x.com/Xaraphim/status/1986937712331342303">(1) Phoenixùïè en X: "ok so this is a little inane https://t.co/m05hOTFOaI" / X</A>
						<DT><A HREF="https://thea.energy/wp-content/uploads/2024/02/Automated-methods-for-stellarator-modelling-and-simulation_APS-DPP-23-Updated.pdf">https://thea.energy/wp-content/uploads/2024/02/Automated-methods-for-stellarator-modelling-and-simulation_APS-DPP-23-Updated.pdf</A>
					</DL><p>
					<DT><H3 FOLDED>Conferences</H3>
					<DL><p>
						<DT><A HREF="https://scie.lcc.uma.es:8443/ratingSearch.jsf">Conference Rating - Search the GGS Rating 2021</A>
						<DT><H3 FOLDED>conf-MLSys</H3>
						<DL><p>
							<DT><A HREF="https://mlsys.org/">MLSys 2026 Ninth Annual Conference on Machine Learning and Systems</A>
						</DL><p>
						<DT><H3 FOLDED>NeurIPS (A++)</H3>
						<DL><p>
							<DT><A HREF="https://nips.cc/">NeurIPS</A>
							<DT><A HREF="https://ogb.stanford.edu/neurips2022/">OGB-LSC @ NeurIPS 2022 | Open Graph Benchmark</A>
						</DL><p>
						<DT><H3 FOLDED>ASPLOS (ML SYS)</H3>
						<DL><p>
							<DT><A HREF="https://www.asplos-conference.org/">ASPLOS 2024 ‚Äì San Diego, USA ‚Äî April 27- May 1, 2024</A>
							<DT><A HREF="https://www.asplos-conference.org/asplos2024/">ASPLOS 2024 ‚Äì ASPLOS 2024</A>
						</DL><p>
						<DT><H3 FOLDED>ICLR (A++)</H3>
						<DL><p>
							<DT><A HREF="https://openreview.net/group?id=ICLR.cc/2022/Conference">ICLR 2022 Conference | OpenReview</A>
						</DL><p>
						<DT><H3 FOLDED>ICML (A++)</H3>
						<DL><p>
							<DT><A HREF="https://icml.cc/">ICML</A>
						</DL><p>
						<DT><H3 FOLDED>CVPR (A++)</H3>
						<DL><p>
							<DT><A HREF="https://cvpr2022.thecvf.com/">Home | CVPR 2022</A>
						</DL><p>
						<DT><H3 FOLDED>ICCV (A++)</H3>
						<DL><p>
						</DL><p>
						<DT><H3 FOLDED>Call For Papers (CFP)</H3>
						<DL><p>
							<DT><A HREF="https://groups.google.com/g/ml-news/c/780yWzTWR1g/m/5ho81CbCAQAJ">European Workshop on Reinforcement Learning (EWRL 2022)</A>
						</DL><p>
						<DT><H3 FOLDED>LoG: Learning on Graphs (non rated)</H3>
						<DL><p>
							<DT><A HREF="https://logconference.github.io/cfp/">Learning on Graphs Conference</A>
							<DT><A HREF="https://towardsdatascience.com/announcing-the-learning-on-graphs-conference-c63caed7347">Announcing the Learning on Graphs Conference | by Michael Bronstein | Apr, 2022</A>
							<DT><A HREF="https://docs.google.com/forms/d/e/1FAIpQLSfacoaCBxzMXPz-AisU1DV6qya6Q1Hj3idgqWwYV61B4jC8Uw/viewform">LoG 2022 Reviewer Sign-up Form</A>
						</DL><p>
						<DT><H3 FOLDED>NAACL (A+)</H3>
						<DL><p>
							<DT><A HREF="https://huggingface.co/spaces/NAACL2022/papers">NAACL 2022 Papers - a Hugging Face Space by NAACL2022</A>
						</DL><p>
						<DT><H3 FOLDED>ICSE (NIER) (A++)</H3>
						<DL><p>
							<DT><A HREF="https://conf.researchr.org/track/icse-2023/icse-2023-NIER">ICSE 2023 - NIER - New Ideas and Emerging Results - ICSE 2023</A>
							<DT><A HREF="https://www.ieee.org/conferences/publishing/templates.html">IEEE - Manuscript Templates for Conference Proceedings</A>
							<DT><A HREF="https://osl.ugr.es/CTAN/macros/latex/contrib/IEEEtran/IEEEtran_HOWTO.pdf">How to Use thE IEEEtran LaTeX Class</A>
							<DT><A HREF="https://www.connectedpapers.com/">Connected Papers | Find and explore academic papers</A>
						</DL><p>
						<DT><A HREF="https://openreview.net/group?id=ICLR.cc/2022/Conference">ICLR 2022 Conference | OpenReview</A>
						<DT><A HREF="https://towardsdatascience.com/announcing-the-learning-on-graphs-conference-c63caed7347">Announcing the Learning on Graphs Conference | by Michael Bronstein | Apr, 2022</A>
					</DL><p>
					<DT><H3 FOLDED>papers-miscelaneous</H3>
					<DL><p>
						<DT><A HREF="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold_representation_theorem">Kolmogorov‚ÄìArnold representation theorem - Wikipedia</A>
						<DT><A HREF="https://blog.ntrlab.com/why-do-neural-networks-need-an-activation-function/">Why do neural networks need an activation function?</A>
						<DT><A HREF="https://hadrien-montanelli.github.io/2019-06-25.html">Deep networks and the Kolmogorov‚ÄìArnold theorem</A>
						<DT><A HREF="https://blog.ntrlab.com/">NTRLab.Blog | Turning ideas into software</A>
						<DT><A HREF="https://math.stackexchange.com/questions/2518664/are-there-any-simple-examples-of-kolmogorov-arnold-representation">simple examples of Kolmogorov-Arnold representation?</A>
					</DL><p>
					<DT><H3 FOLDED>research</H3>
					<DL><p>
						<DT><H3 FOLDED>Requests For Research</H3>
						<DL><p>
							<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1772472408559206798">Clive Chan</A>
							<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1772370709274038694">Sholto Douglas</A>
							<DT><A HREF="https://www.youtube.com/watch?v=cPu3SecmgUU&list=LL&index=10">How They Became Leading AI Researchers in Just 1 Year ‚Äì Sholto Douglas &amp; Trenton Bricken - YouTube</A>
							<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1774583930500632917">Chip Huyen</A>
							<DT><A HREF="https://openai.com/research/requests-for-research-2">OpenAI: Requests for Research 2.0</A>
							<DT><A HREF="https://www.youtube.com/watch?v=UTuuTTnjxMQ&list=PLd7-bHaQwnthaNDpZ32TtYONGVk95-fhF">Sholto Douglas &amp; Trenton Bricken - How to Build &amp; Understand GPT-7's Mind - YouTube</A>
							<DT><A HREF="https://x.com/_sholtodouglas/status/1772370709274038694">Sholto Douglas: Language models</A>
							<DT><A HREF="https://x.com/itsclivetime/status/1772472408559206798">Clive Chan</A>
						</DL><p>
						<DT><H3 FOLDED>research-reading</H3>
						<DL><p>
							<DT><H3 FOLDED>Reading Groups</H3>
							<DL><p>
								<DT><A HREF="https://mitpress.mit.edu/9780262048439/probabilistic-machine-learning/">probabilistic-machine-learning</A>
								<DT><A HREF="https://www.youtube.com/@SanDiegoMachineLearning/videos">videos</A>
								<DT><A HREF="https://mlcollective.org/events/">ML Collective</A>
							</DL><p>
							<DT><H3 FOLDED>reading-news</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=fGF3nPClUT0">LLaMA3 400B to beat GPT4? (&amp; more) | Trends in AI - May 2024 - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>Papers With Code</H3>
							<DL><p>
								<DT><A HREF="https://paperswithcode.com/paper/the-distributed-information-bottleneck">The Distributed Information Bottleneck</A>
							</DL><p>
							<DT><H3 FOLDED>Books</H3>
							<DL><p>
								<DT><A HREF="https://mitpress.mit.edu/9780262048439/probabilistic-machine-learning/">Probabilistic Machine Learning</A>
								<DT><A HREF="https://mitpressbookstore.mit.edu/book/9780262048439">Probabilistic Machine Learning: Advanced Topics (Adaptive Computation and Machine Learning series) | mitpressbookstore</A>
								<DT><A HREF="https://www.amazon.com/dp/0262048434/">Probabilistic Machine Learning: Advanced Topics (Adaptive Computation and Machine Learning series): Murphy, Kevin P.: 9780262048439: Amazon.com: Books</A>
								<DT><A HREF="https://www.amazon.com/Obstacle-Way-Timeless-Turning-Triumph/dp/1591846358">The Obstacle Is the Way: The Timeless Art of Turning Trials into Triumph: Holiday, Ryan: 8601411257797: Amazon.com: Books</A>
								<DT><A HREF="https://www.amazon.es/Zero-Notes-Start-Build-Future/dp/0753555204/ref=asc_df_0753555204?mcid=a908809005d338c1a8666459bf630639&tag=googshopes-21&linkCode=df0&hvadid=699717042952&hvpos=&hvnetw=g&hvrand=753955044578705145&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9218601&hvtargid=pla-524041164953&psc=1&hvocijid=753955044578705145-0753555204-&hvexpln=0">Zero to One: Notes on Start Ups, or How to Build the Future : Thiel, Peter; Masters, Blake: Amazon.es: Books</A>
							</DL><p>
							<DT><H3 FOLDED>Papers implementations</H3>
							<DL><p>
								<DT><A HREF="https://nn.labml.ai/?_gl=1*v934qz*_ga*MTE0MzE1Mjg1My4xNzE5NjU5MzYx*_ga_PDCL9PHMHT*MTcxOTY1OTM2MS4xLjAuMTcxOTY1OTM2MS4wLjAuMA..">Annotated Research Paper Implementations: Transformers, StyleGAN, Stable Diffusion, DDPM/DDIM, LayerNorm, Nucleus Sampling and more</A>
								<DT><A HREF="https://github.com/kmohan321/Research_Papers">kmohan321/Research_Papers</A>
							</DL><p>
							<DT><H3 FOLDED>ai-powered-paper-reading</H3>
							<DL><p>
								<DT><H3 FOLDED>alphaxiv</H3>
								<DL><p>
									<DT><A HREF="https://www.alphaxiv.org/abs/2507.15855v2">Gemini 2.5 Pro Capable of Winning Gold at IMO 2025 | alphaXiv</A>
									<DT><A HREF="https://www.alphaxiv.org/abs/2508.02324">Qwen-Image Technical Report | alphaXiv</A>
								</DL><p>
								<DT><H3 FOLDED>aizotero</H3>
								<DL><p>
									<DT><A HREF="https://github.com/bigeagle/aizotero">bigeagle/aizotero: An AI-powered paper reading assistant for Zotero with a web interface that helps users quickly understand and manage research papers.</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://scispace.com/">SCISPACE</A>
							<DT><A HREF="https://chatdoc.com/">ChatDOC - Chat with your documents</A>
							<DT><A HREF="https://kipp.ly/sept-oct-2023/">Things Read | Sept/Oct 2023 (kipply's blog) (MUST)</A>
							<DT><A HREF="https://www.simonwenkel.com/index.html">Summary &amp; Update Papers AI/ML</A>
							<DT><A HREF="https://search.zeta-alpha.com/?similar_to=CO_3527012&sort_by=relevance&q=&retrieval_method=knn">Zeta Alpha</A>
							<DT><A HREF="https://www.youtube.com/watch?v=QQIwfpOY-qA">20 papers to master Language modeling?</A>
							<DT><A HREF="https://kipp.ly/nov-dec-2023/">Kipply's blog: nov-dec-2023</A>
							<DT><A HREF="https://nn.labml.ai/unet/index.html">U-Net</A>
							<DT><A HREF="https://twitter.com/TheGregYang/status/1680358832789155842">Greg Yang: Books to read</A>
							<DT><A HREF="https://gwern.net/complement">Laws of Tech: Commoditize Your Complement ¬∑ Gwern.net</A>
							<DT><A HREF="https://gist.github.com/matijagrcic/ae8353eb1e6be84a7c85d9fdc2f9631f">John_Carmack_Ilya_Sutskever.md</A>
							<DT><A HREF="https://papers.cool/">Cool Papers - Immersive Paper Discovery</A>
							<DT><A HREF="https://rentry.org/LocalModelsLinks">Local Models Related Links</A>
							<DT><A HREF="https://x.com/GCResearchTeam/status/1864322846777897103">(1) Graphcore Research en X: "Our November Papers of the Month is now live. This edition covers 4 papers, on "super weights", context-parallelism, scaling laws for precision and critical batch sizes. We provide our summaries and analysis of each. (üßµ1/n) https://t.co/CkQySUiNpO" / X</A>
							<DT><A HREF="https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE">Ilya 30u30</A>
							<DT><A HREF="https://github.com/adam-maj/deep-learning">adam-maj/deep-learning: A deep-dive on the entire history of deep-learning</A>
							<DT><A HREF="https://github.com/lcy-seso/LearningNotes">lcy-seso/LearningNotes: Ying's notes</A>
							<DT><A HREF="https://github.com/pageman/sutskever-30-implementations">pageman/sutskever-30-implementations: Sutskever 30 implementations inspired by https://papercode.vercel.app/</A>
						</DL><p>
						<DT><H3 FOLDED>research tools</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=hSTy_BInQs8">Obsidian: The King of Learning Tools (FULL GUIDE + SETUP) - YouTube</A>
							<DT><A HREF="https://www.connectedpapers.com/">Connected Papers | Find and explore academic papers</A>
						</DL><p>
						<DT><H3 FOLDED>research-people</H3>
						<DL><p>
							<DT><H3 FOLDED>High context people</H3>
							<DL><p>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1772472408559206798">Clive Chan</A>
								<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1772370709274038694">Sholto Douglas</A>
								<DT><A HREF="https://x.com/MajmudarAdam/status/1794190796411027791">(3) adammaj en X: "I've spent the past ~3 weeks going through the entire history of deep learning and reimplementing all the core breakthroughs. It has completely changed my beliefs about deep learning progress and where we're headed. Progress tracker in thread (all resources at the end) üëá https://t.co/BjcEA2iv3f" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=cPu3SecmgUU&list=LL&index=10">How They Became Leading AI Researchers in Just 1 Year ‚Äì Sholto Douglas &amp; Trenton Bricken - YouTube</A>
								<DT><A HREF="https://twitter.com/dwarkesh_sp">Dwarkesh Patel (main technical AI podcast)</A>
								<DT><A HREF="https://scholar.google.co.uk/citations?user=DaFHynwAAAAJ&hl=en">‚Ä™Alex Graves‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
								<DT><A HREF="https://twitter.com/kipperrii/status/1777814429838573861">Alex Graves: 8 years rule</A>
								<DT><A HREF="https://www.youtube.com/watch?v=GU2K0kiHE1Q">AI Reading List (by Ilya Sutskever) - Part 1 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=GxjEjy5UYJU">AI Reading List (by Ilya Sutskever) - Part 2 - YouTube</A>
								<DT><A HREF="https://x.com/NoamShazeer">(1) Noam Shazeer (@NoamShazeer) / X</A>
								<DT><A HREF="https://x.com/papers_anon/status/1805084174510162112">(1) PapersAnon en X: "https://t.co/CJC3YWPoB6 Various links for ML and local models (not just LLMs) that's kept fairly updated. https://t.co/5pLfM330hp ML papers I've read that I think are interesting. Also keep a text file at the top of all the abstracts for easy searching." / X</A>
								<DT><A HREF="https://rentry.org/LocalModelsLinks">Local Models Related Links</A>
								<DT><A HREF="https://www.jasonwei.net/thoughts">Thoughts ‚Äî Jason Wei</A>
								<DT><A HREF="https://x.com/ludwigABAP/status/1821107246538924407">(1) ludwig en X: ""If you constantly unpack everything for deeper understanding you never get anything done. If you don't unpack and understand it when you need to, you'll do the wrong thing" I found this quote that I wrote down (apparently from Jim Keller) and it's the best way to describe what" / X</A>
								<DT><A HREF="https://x.com/spikedoanz/status/1819435570495737988">(1) spike en X: "open sourcing said list: Joscha Bach Marvin Minsky Geohot Karpathy Paul Graham Wittgenstein Jim Keller John Carmack Aaron Swartz Robert Sapolsky Gwern Scott Alexander Nietzche Feynman Tim Rogers Jonathan Blow" / X</A>
								<DT><A HREF="https://x.com/_clashluke">(1) Lucas Nestler (@_clashluke) / X AGI</A>
								<DT><A HREF="https://ysymyth.github.io/The-Second-Half/">The Second Half ‚Äì Shunyu Yao ‚Äì ÂßöÈ°∫Èõ®</A>
								<DT><A HREF="https://www.youtube.com/watch?v=LCEmiRjPEtQ">Andrej Karpathy: Software Is Changing (Again) - YouTube</A>
								<DT><A HREF="https://www.metislist.com/">THE METIS LIST</A>
								<DT><A HREF="https://www.youtube.com/watch?v=91fmhAnECVc">Kimi Founder Yang Zhilin: K2, Agentic LLMs, Brains in Vats, and the Beginning of Infinity - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=X0PaVrpFD14">Alibaba Cloud Founder Expects Big AI Shakeup After OpenAI Hype - YouTube</A>
								<DT><A HREF="https://x.com/jaynitx/status/2012838973132189893">(1) Jaynit en X: "Elon Musk explains the mental model he uses to learn anything 10x faster: "The normal way we conduct our lives is we reason by analogy. We're doing this because it's like something else that was done, or it's like what other people are doing. 'Me too' type ideas. Slight https://t.co/BzXbo0UBd8" / X</A>
							</DL><p>
							<DT><H3 FOLDED>historical</H3>
							<DL><p>
								<DT><A HREF="https://en.wikipedia.org/wiki/Hermann_Weyl">Hermann Weyl - (Symmetry) Mathematician</A>
							</DL><p>
							<DT><A HREF="https://tacocohen.wordpress.com/">Taco Cohen-Qualcomm</A>
							<DT><A HREF="https://www.cs.ox.ac.uk/people/michael.bronstein/">Michael Bronstein-Imperial College/Twitter</A>
							<DT><A HREF="https://petar-v.com/">Petar Veliƒçkoviƒá-Deepmind</A>
							<DT><A HREF="https://arxiv.org/search/cs?searchtype=author&query=Bruna%2C+J">Joan Bruna</A>
							<DT><A HREF="https://www.stellabiderman.com/">Stella Biderman</A>
							<DT><A HREF="https://www.stellabiderman.com/">Stella Biderman (EleutherAI)</A>
							<DT><A HREF="https://people.csail.mit.edu/zhonge/index.html">Ellen D. Zhong</A>
							<DT><A HREF="https://scholar.google.com/citations?hl=en&user=7Fxbm0AAAAAJ&view_op=list_works">‚Ä™Phitchaya Mangpo Phothilimthana‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
						</DL><p>
						<DT><A HREF="https://www.youtube.com/watch?v=aR20FWCCjAs">Ilya Sutskever ‚Äì We're moving from the age of scaling to the age of research - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=c_9bxtyOd1o">Hyung Won Chung: Shaping the Future of AI from the History of Transformer - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>experiments</H3>
					<DL><p>
						<DT><H3 FOLDED>wandb</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=hmewPDNUNJs">Log Your First Run With W&amp;B - YouTube</A>
							<DT><A HREF="https://wandb.ai/antferdom/min-max-gpt?nw=nwuserantferdom">min-max-gpt Workspace ‚Äì Weights &amp; Biases</A>
						</DL><p>
						<DT><A HREF="https://wandb.ai/neuralink/exp14_mup_grid_search/reports/-Spectral-Transfer-MLP-s-Experiment-Results--Vmlldzo3NDQ0NTQw?accessToken=xe0mkunx3y8t0xzbzxu9caqcre57or5la58d9o209hinanlmzoaj7es24m4elvdj">[Spectral ¬µTransfer] MLP's Experiment Results | exp14_mup_grid_search ‚Äì Weights &amp; Biases</A>
						<DT><A HREF="https://x.com/_xjdr/status/2011904758093922549">got inspired by W&amp;B Leet . tui experiment tracking now in nmoe</A>
						<DT><A HREF="https://github.com/megvii-research/expman">megvii-research/expman</A>
					</DL><p>
					<DT><A HREF="https://www.youtube.com/@ArxivPapers/videos">Arxiv Papers - YouTube</A>
					<DT><A HREF="https://logconference.github.io/cfp/">Learning on Graphs Conference</A>
					<DT><A HREF="https://www.hotaipapers.com/papers">Hot AI Informations</A>
					<DT><A HREF="https://www.alignmentforum.org/posts/eJGptPbbFPZGLpjsp/highly-opinionated-advice-on-how-to-write-ml-papers">Highly Opinionated Advice on How to Write ML Papers ‚Äî AI Alignment Forum</A>
					<DT><A HREF="https://en.wikipedia.org/wiki/The_Metamorphosis_of_Prime_Intellect">The Metamorphosis of Prime Intellect - Wikipedia</A>
				</DL><p>
				<DT><H3 FOLDED>Software</H3>
				<DL><p>
					<DT><H3 FOLDED>AI Compilers &amp; PL</H3>
					<DL><p>
						<DT><H3 FOLDED>CUDA</H3>
						<DL><p>
							<DT><H3 FOLDED>cuda-installation</H3>
							<DL><p>
								<DT><H3 FOLDED>symlinks &amp; /etc/alternatives</H3>
								<DL><p>
									<DT><A HREF="https://chat.openai.com/c/21c4fe05-b3de-4a20-b96c-6d5c1bc7bea4">update_alternatives: multiple cuda installations</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-conda-installation</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#conda-installation">CUDA Installation Guide for Linux</A>
									<DT><A HREF="https://anaconda.org/nvidia">https://anaconda.org/nvidia</A>
									<DT><A HREF="https://anaconda.org/nvidia/repo?label=cuda-12.4.1">Package repository for nvidia :: Anaconda.org</A>
									<DT><A HREF="https://chatgpt.com/c/fc80f38a-f3a1-46a5-8a48-537e6fefe62b">LD_LIBRARY_PATH &amp; cuda lib</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-13</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/cuda-13-1-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=deb_local">CUDA Toolkit 13.1 Downloads | NVIDIA Developer</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-12.6</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/cuda-12-6-0-download-archive?target_os=Linux&target_arch=arm64-sbsa&Compilation=Native&Distribution=Ubuntu&target_version=22.04&target_type=deb_local">CUDA Toolkit 12.6 Downloads | NVIDIA Developer</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-12.4</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>cuda-arm64-sbsa</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>nv-bios-installation</H3>
								<DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/data-center/solutions/confidential-computing/secure-ai-compatibility-matrix/">combinations of NVIDIA GPUs, VBIOS versions, CUDA driver versions, and Confidential Computing modes</A>
								</DL><p>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/">CUDA Installation Guide for Linux</A>
								<DT><A HREF="https://developer.nvidia.com/cuda-12-4-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local">CUDA Toolkit 12.4 Downloads | NVIDIA Developer</A>
								<DT><A HREF="https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation">cuda - How to verify CuDNN installation</A>
								<DT><A HREF="https://nvidia.github.io/cuda-python/install.html">Installation - CUDA Python 12.1.0 documentation</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/archive/10.2/cuda-installation-guide-linux/index.html">nvcc</A>
								<DT><A HREF="https://developer.download.nvidia.com/compute/cuda/redist/">Index of /compute/cuda/redist</A>
								<DT><A HREF="https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/">Index of /compute/cuda/repos/ubuntu2204</A>
								<DT><A HREF="https://chat.openai.com/c/21c4fe05-b3de-4a20-b96c-6d5c1bc7bea4">CUDA_HOME</A>
								<DT><A HREF="https://github.com/phohenecker/switch-cuda/blob/master/switch-cuda.sh">switch-cuda/switch-cuda.sh at master ¬∑ phohenecker/switch-cuda</A>
								<DT><A HREF="https://github.com/pytorch-labs/tritonbench/blob/main/utils/cuda_utils.py">tritonbench/utils/cuda_utils.py at main ¬∑ pytorch-labs/tritonbench</A>
								<DT><A HREF="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit Archive | NVIDIA Developer</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/archive/12.6.0/cuda-installation-guide-linux/index.html#system-requirements">CUDA Installation Guide for Linux</A>
								<DT><A HREF="https://github.com/imbue-ai/cluster-health/blob/master/health_checks/health_check_fixes/reinstall_nvidia.sh">cluster-health/health_checks/health_check_fixes/reinstall_nvidia.sh at master ¬∑ imbue-ai/cluster-health</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-dev</H3>
							<DL><p>
								<DT><H3 FOLDED>cuda-debug</H3>
								<DL><p>
									<DT><H3 FOLDED>cuda-env-vars</H3>
									<DL><p>
										<DT><H3 FOLDED>CUDA_LAUNCH_BLOCKING</H3>
										<DL><p>
											<DT><A HREF="https://claude.ai/chat/483c79f7-bbc0-4cc5-bcae-24b26675cf9a">CUDA_LAUNCH_BLOCKING kernel correctness and profiling</A>
										</DL><p>
										<DT><A HREF="https://faculty.cc.gatech.edu/~hyesoon/spr09/installcuda.html">CUDA PATH, LD_LIBRARY_PATH and CUDA_INSTALL_PATH</A>
										<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/bfa2da709d619de7eb62cf58a12ecfeb24f300a0/env.src">ThunderKittens/env.src</A>
									</DL><p>
									<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/csrc/utils.cuh#L33">SageAttention/csrc/utils.cuh: CHECK_DIMS, CHECK_NUMEL, CHECK_SHAPE, CHECK_CONTIGOUS</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1938284538108293922">cuda core dump</A>
									<DT><A HREF="https://www.zhihu.com/question/10688015001/answer/1987582387396310837">How to troubleshoot and debug CUDA programs?</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-utils</H3>
								<DL><p>
									<DT><A HREF="https://github.com/perplexityai/pplx-garden/blob/main/p2p-all-to-all/a2a-kernels/src/core/device_utils.cuh">pplx-garden/p2p-all-to-all/a2a-kernels/src/core/device_utils.cuh at main ¬∑ perplexityai/pplx-garden</A>
								</DL><p>
								<DT><A HREF="https://github.com/leimao/CUTLASS-Examples/blob/f06835a42eecd52f30c8292b4b911e01fe1b02da/docker/cuda.Dockerfile">CUTLASS-Examples/docker/cuda.Dockerfile</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/Dockerfile">pytorch/Dockerfile at main ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://hub.docker.com/r/chengzeyi/ubuntu-desktop">chengzeyi/ubuntu-desktop - Docker Image | Docker Hub</A>
								<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/blob/4d272148b76130d5f15576075d067725164de35d/PyTorch/test_pytorch_customize_op/my_add_kernel.cu">DLFrameworkTest/PyTorch/test_pytorch_customize_op/my_add_kernel.cu at 4d272148b76130d5f15576075d067725164de35d ¬∑ lcy-seso/DLFrameworkTest</A>
								<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest">lcy-seso/DLFrameworkTest: My tests and experiments with some popular dl frameworks.</A>
								<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/utils/cpp/cuda_info.cuh">TiledBench/utils/cpp/cuda_info.cuh at master ¬∑ TiledTensor/TiledBench</A>
								<DT><A HREF="https://github.com/ita9naiwa/playground">ita9naiwa/playground: ..</A>
								<DT><A HREF="https://github.com/PaddleJitLab/CUDATutorial/tree/develop/docs/01_build_dev_env">CUDATutorial/docs/01_build_dev_env at develop ¬∑ PaddleJitLab/CUDATutorial</A>
								<DT><A HREF="https://www.linkedin.com/posts/emi-andere_today-were-launching-the-wafer-extension-activity-7408235262381764608-IEKv/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">wafer gpu programming extension</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-architecture</H3>
							<DL><p>
								<DT><H3 FOLDED>Ampere</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-ampere-architecture-in-depth/">NVIDIA Ampere Architecture In-Depth</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/pdf/Ampere_Tuning_Guide.pdf">Ampere Tuning Guide</A>
									<DT><A HREF="https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf">A100 Tensor Core GPU Architecture</A>
								</DL><p>
								<DT><H3 FOLDED>Ada Lovelace</H3>
								<DL><p>
									<DT><H3 FOLDED>4090-fp16</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/123558">Support FP16 accumulation for faster LLM inference on 4090 like GPUs ¬∑ Issue #123558 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://x.com/Birchlabs/status/1877537416224882770">(1) Birchlabs en X: "fp16 accumulation matmul coming to pytorch; gets around the nerf Nvidia put on the 3090/4090, allowing them to compete with datacenter-class GPUs https://t.co/nAE9UyYiuM" / X</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/144441">[CUDA][cuBLAS] Add fp16 accumulate option to cuBLAS/cuBLASLt by eqy ¬∑ Pull Request #144441 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><A HREF="https://forums.developer.nvidia.com/t/ada-geforce-rtx-4090-fp8-cublaslt-performance/250737">Ada GeForce (RTX 4090) FP8 cuBLASLt performance</A>
									<DT><A HREF="https://images.nvidia.com/aem-dam/Solutions/geforce/ada/nvidia-ada-gpu-architecture.pdf">NVIDIA ADA GPU ARCHITECTURE</A>
									<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/606">FP8 Unable to achieve the expected FLOPS indicator in 4090 ¬∑ Issue #606 ¬∑ NVIDIA/TransformerEngine</A>
								</DL><p>
								<DT><H3 FOLDED>Hopper</H3>
								<DL><p>
									<DT><H3 FOLDED>H100</H3>
									<DL><p>
										<DT><H3 FOLDED>h100-benchmarking</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>h100-tunning</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/cuda/hopper-tuning-guide/index.html">NVIDIA Hopper Tuning Guide</A>
										</DL><p>
										<DT><A HREF="https://kuterdinel.com/nv_isa/">Nvidia SM90a Instruction Set Architecture</A>
										<DT><A HREF="https://resources.nvidia.com/en-us-gpu-resources/h100-datasheet-24306">NVIDIA H100 GPU Datasheet</A>
										<DT><A HREF="https://lambdalabs.com/blog/flashattention-2-on-lambda-cloud-h100-vs-a100">NVIDIA H100 vs A100 Benchmarks for FlashAttention-2 on Lambda Cloud</A>
										<DT><A HREF="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">NVIDIA Hopper Architecture In-Depth</A>
										<DT><A HREF="https://www.youtube.com/watch?v=USMnKuyXBFM">Developing Optimal CUDA Kernels on Hopper Tensor Cores NVIDIA On Demand - YouTube</A>
										<DT><A HREF="https://mlir.llvm.org/OpenMeetings/2023-11-16-Targeting_H100_in_MLIR_ODM.pdf">Targeting H100 in MLIR</A>
									</DL><p>
									<DT><H3 FOLDED>H200</H3>
									<DL><p>
										<DT><H3 FOLDED>h200-benchmarking</H3>
										<DL><p>
											<DT><A HREF="https://lambdalabs.com/blog/partner-spotlight-evaluating-nvidia-h200-gpus-for-ai-inference-with-baseten?utm_campaign=2024-10-od-cloud-baseten&utm_content=post-a&utm_medium=social&utm_source=twitter&hss_channel=tw-708922429">Partner Spotlight: Evaluating NVIDIA H200 Tensor Core GPUs for AI Inference with Baseten</A>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/b171e879563ff0ba4eb35b94cf0e59a471e13d80/docs/source/blogs/H200launch.md">TensorRT-LLM/docs/source/blogs/H200launch.md at b171e879563ff0ba4eb35b94cf0e59a471e13d80 ¬∑ NVIDIA/TensorRT-LLM</A>
										</DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/b171e879563ff0ba4eb35b94cf0e59a471e13d80/docs/source/blogs/H200launch.md">TensorRT-LLM/docs/source/blogs/H200launch.md at b171e879563ff0ba4eb35b94cf0e59a471e13d80 ¬∑ NVIDIA/TensorRT-LLM</A>
									</DL><p>
									<DT><H3 FOLDED>GH200</H3>
									<DL><p>
										<DT><H3 FOLDED>GH200-pytorch</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/124807">[RFC] Mix and Match CUDA Allocators using Private Pools ¬∑ Issue #124807 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/125722">Uses memory pools for mixing CUDA allocators by syed-ahmed ¬∑ Pull Request #125722 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://discuss.pytorch.org/t/gh200-cuda-not-available-on-pytorch/200109">GH200 Cuda not available on pytorch - deployment - PyTorch Forums</A>
											<DT><A HREF="https://github.com/ggerganov/llama.cpp/issues/5026">Allow oversubscription of GPU memory through cudaMallocManaged on cuBLAS builds for systems like GH200 ¬∑ Issue #5026 ¬∑ ggerganov/llama.cpp</A>
										</DL><p>
										<DT><H3 FOLDED>Unified memory</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#unified-memory-programming">CUDA C++ Programming Guide</A>
											<DT><A HREF="https://homepages.dcc.ufmg.br/~sylvain.collange/gpucourse/gpu_ufmg_2015_6.pdf">GPU programming: Unified memory models and more</A>
											<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#unified-memory-programming">CUDA: 19. Unified Memory Programming</A>
											<DT><A HREF="https://www.hpcwire.com/2024/07/15/researchers-say-memory-bandwidth-and-nvlink-speeds-in-hopper-not-so-simple/">Researchers Say Memory Bandwidth and NVLink Speeds in Hopper Not So Simple</A>
											<DT><A HREF="https://arxiv.org/abs/2407.07850">[2407.07850] Harnessing Integrated CPU-GPU System Memory for HPC: a first look into Grace Hopper</A>
										</DL><p>
										<DT><A HREF="https://cf-store.widencdn.net/nvdam/6/9/4/694f8b68-0f19-4f59-af54-84cb33f1e27b.pdf?response-content-disposition=inline%3B%20filename%3D%22grace-hopper-superchip-datasheet-2705455.pdf%22&response-content-type=application%2Fpdf&Expires=1710177055&Signature=lsuy6fnxVz6h-NHXjUsDtFA~pGYyWOT5uF3CZgu8H7C9rROz4w2dvCVLHg2Z4D-TFW-aqq3Z4GmPs6MGcZ6Xqj7nfwegQDQP~~9Ew-TMxsRhiEjbbQqscqnDRysCaqJph6VxudMlh-kU-c67Thwxb1VrlkhHgBOEYIO2x4nQs0LFYs92nANSSCHe71~HWCEM35rl1Kzk2yLJbAlFNUpb-c0lTPP9HoYFAq4c5tJbWcH~nOwHAjcd~uqi3EVqJk8QuHwiVysZ-GSJL7HnbVh~5lnEkBmGFvRQT7lSBcNCCWovWqX~NAhmx7VC7tvkyX5IcC7NlyirXrGeOxdHGkFOzg__&Key-Pair-Id=APKAJD5XONOBVWWOA65A">NVIDIA GH200 GraceHopper Superchip</A>
										<DT><A HREF="https://resources.nvidia.com/en-us-grace-cpu/nvidia-grace-hopper?ncid=so-link-825427-vt25#cid=hpc012_so-link_en-us">NVIDIA Grace Hopper Superchip Architecture Whitepaper</A>
										<DT><A HREF="https://resources.nvidia.com/en-us-grace-cpu/nvidia-grace-cpu-superchip?ncid=so-link-825427-vt25">NVIDIA Grace CPU Superchip Whitepaper</A>
										<DT><A HREF="https://greennode.ai/blog/nvidia-dgx-gh200-decoding-the-language-of-massive-memory">NVIDIA DGX GH200: Decoding the Language of Massive Memory</A>
										<DT><A HREF="https://github.com/abacusai/gh200-llm/pkgs/container/gh200-llm%2Fllm-train-serve">Package gh200-llm/llm-train-serve</A>
										<DT><A HREF="https://docs.nvidia.com/gh200-superchip-benchmark-guide.pdf">NVIDIA GH200 Grace Hopper Superchip Benchmark Step-by-Step Guide</A>
										<DT><A HREF="https://arxiv.org/abs/2407.07850">[2407.07850] Harnessing Integrated CPU-GPU System Memory for HPC: a first look into Grace Hopper</A>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s61159/">Grace Hopper Superchip Architecture and Performance Optimizations for Deep Learning Applications | NVIDIA On-Demand</A>
										<DT><A HREF="https://www.fibermall.com/blog/analysis-nvidia-gh200-chip-servers.htm?srsltid=AfmBOoqZKIicWc2wawR9tGVsqsr7cSvzkul69oWeB_1XThmuna1YzNy6">Detailed Analysis of NVIDIA GH200 Chip, Servers, and Cluster Networking - fibermall.com</A>
										<DT><A HREF="https://developer.nvidia.com/blog/nvidia-grace-hopper-superchip-architecture-in-depth/">NVIDIA Grace Hopper Superchip Architecture In-Depth | NVIDIA Technical Blog</A>
									</DL><p>
									<DT><H3 FOLDED>WGMMA</H3>
									<DL><p>
										<DT><H3 FOLDED>mma.m16n8k128</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/#asynchronous-warpgroup-level-matrix-instructions">wgmma ptx</A>
										</DL><p>
										<DT><A HREF="https://research.colfax-intl.com/wp-content/uploads/2023/12/colfax-flashattention.pdf">A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on NVIDIA Hopper Architecture using the CUTLASS Library</A>
										<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">GPUs Go Brrr ¬∑ Hazy Research</A>
										<DT><A HREF="https://arxiv.org/html/2402.13499v1">Without the wgmma instruction, the older mma.sync instruction can only reach about ‚Öî the peak throughput of Hopper Tensor Cores:</A>
										<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/">PTX ISA 8.5</A>
										<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/">CUTLASS Tutorial: Fast Matrix-Multiplication with WGMMA on NVIDIA¬Æ Hopper‚Ñ¢ GPUs ‚Äì Colfax Research</A>
										<DT><A HREF="https://x.com/KuterDinel/status/1808460651494293580">(1) Kuter Dinel en X: "Investigating Warpgroup MMA (Matrix Multiply Accumulate, aka Tensor Core) instructions Nvidia added with the Hopper architecture. Wonder what `gdesc` is maybe it's global descriptor ? https://t.co/CPksrNPDgm" / X</A>
										<DT><A HREF="https://x.com/cHHillee/status/2002292457111994817">float8 accumulation on Hopper wgmma's, which were secretly done in fp22. The tf32 is a totally different case</A>
									</DL><p>
									<DT><H3 FOLDED>TMA</H3>
									<DL><p>
										<DT><A HREF="https://research.colfax-intl.com/tutorial-hopper-tma/">CUTLASS Tutorial: Mastering the NVIDIA¬Æ Tensor Memory Accelerator (TMA) ‚Äì Colfax Research</A>
										<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/pull/43/files#diff-6278ea2f3ba2c5944e0975de46068b9ef1f6451e2c54899d03172264dc3b3f6b">fix: refine and test tma copy. by lcy-seso ¬∑ Pull Request #43 ¬∑ lcy-seso/DLFrameworkTest</A>
										<DT><A HREF="https://veitner.bearblog.dev/tma-introduction/">TMA introduction | simons blog</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/721163129">„ÄêÂçöÂÆ¢ÁøªËØë„ÄëÊ∑±ÂÖ•Êé¢ËÆ® Hopper TMA ÂçïÂÖÉÂú® FP8 GEMM ËøêÁÆó‰∏≠ÁöÑÂ∫îÁî® - Áü•‰πé</A>
										<DT><A HREF="https://www.youtube.com/watch?v=MC223HlPdK0">Stanford Seminar - Nvidia‚Äôs H100 GPU - YouTube</A>
										<DT><A HREF="https://github.com/zartbot/blog/issues/2">TMA with Host memory ¬∑ Issue #2 ¬∑ zartbot/blog</A>
										<DT><A HREF="https://vjkrish.com/2026/01/19/Mma_Layouts.html">Hopper/Blackwell Tensor Core MMA layouts | vj-krish</A>
									</DL><p>
									<DT><H3 FOLDED>Distributed Shared Memory (DSM)</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>CTA Cluster (thread block cluster)</H3>
									<DL><p>
										<DT><H3 FOLDED>cluster transaction barrier</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/blob/main/docs/20250929-hopper-fp8-sparse-deep-dive.md">FlashMLA/docs/20250929-hopper-fp8-sparse-deep-dive.md at main ¬∑ deepseek-ai/FlashMLA</A>
										<DT><A HREF="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">NVIDIA Hopper Architecture In-Depth | NVIDIA Technical Blog</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2402.13499.pdf">Benchmarking and Dissecting the Nvidia Hopper GPU Architecture</A>
									<DT><A HREF="https://research.colfax-intl.com/nvidia-hopper-flashattention-2/">A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on NVIDIA Hopper Architecture using the CUTLASS Library ‚Äì Colfax Research</A>
									<DT><A HREF="https://docs.nvidia.com/grace-performance-tuning-guide.pdf">NVIDIA Grace Performance Tuning Guide</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/pdf/Hopper_Tuning_Guide.pdf">Hopper Tuning Guide</A>
									<DT><A HREF="https://gist.github.com/edecoux/a0dd3f446bb901be25f2b11be231820e">Tensor Core GPU.md</A>
									<DT><A HREF="https://github.com/kuterd/nv_isa_solver">kuterd/nv_isa_solver: Nvidia Instruction Set Specification Generator</A>
									<DT><A HREF="https://github.com/cloudcores/CuAssembler">cloudcores/CuAssembler: An unofficial cuda assembler, for all generations of SASS, hopefully ÔºöÔºâ</A>
									<DT><A HREF="https://kuterdinel.com/nv_isa/">Nvidia SM90a Instruction Set Architecture</A>
									<DT><A HREF="https://github.com/lenLRX/HopperTest">lenLRX/HopperTest</A>
									<DT><A HREF="https://github.com/lenLRX/HopperTest/blob/main/wgmma_test/power_test/test_wgmma_e4m3.cu">HopperTest/wgmma_test/power_test/test_wgmma_e4m3.cu at main ¬∑ lenLRX/HopperTest</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/30427909948">‰ªéHopperÊû∂ÊûÑÂà∞HGEMM - Áü•‰πé</A>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">NVIDIA Hopper Architecture In-Depth | NVIDIA Technical Blog</A>
									<DT><A HREF="https://github.com/zartbot/h100-features/blob/main/dense/1_m64_n8_k32.cu">h100-features/dense/1_m64_n8_k32.cu at main This code demonstrates how to use the dense wgmma instructions to perform matrix multiplication</A>
									<DT><A HREF="https://github.com/zartbot/h100-features/tree/main/examples">h100-features/examples at main ¬∑ zartbot/h100-features</A>
									<DT><A HREF="https://github.com/zartbot/fast.cu">zartbot/fast.cu: Fastest kernels written from scratch</A>
								</DL><p>
								<DT><H3 FOLDED>Blackwell</H3>
								<DL><p>
									<DT><H3 FOLDED>blackwell-notes</H3>
									<DL><p>
										<DT><A HREF="https://github.com/zartbot/blog/issues/3">Inside Nvidia GPU: Discussing Blackwell's Limitations and Predicting Rubin's Microarchitecture ¬∑ Issue #3 ¬∑ zartbot/blog</A>
										<DT><A HREF="https://www.linkedin.com/posts/activity-7391680646525657088-QPTd/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">Then, I will assume I am an architect for Vera Rubin and discuss what I would do to explore future evolutionary paths.</A>
									</DL><p>
									<DT><H3 FOLDED>NVL72</H3>
									<DL><p>
										<DT><H3 FOLDED>DPU</H3>
										<DL><p>
											<DT><A HREF="https://dl.acm.org/doi/10.1145/3731599.3767525">DoCeph: DPU-Offloaded Messaging in Ceph for Reduced Host CPU Utilization | Proceedings of the SC '25 Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis</A>
											<DT><A HREF="https://grok.com/c/d5365139-64eb-4b12-bf38-fb65680bfa02?rid=ad6f2ad9-14c1-4816-95cf-30afb3494529">CephFS with NVIDIA DPU Feasibility - Grok</A>
											<DT><A HREF="https://github.com/IBM/DPFS">IBM/DPFS: DPU-Powered File System Virtualization over virtio-fs</A>
											<DT><A HREF="https://docs.nvidia.com/doca/sdk/doca-programming-guide/index.html">DOCA Programming Guide - NVIDIA Docs</A>
										</DL><p>
										<DT><H3 FOLDED>GB200</H3>
										<DL><p>
											<DT><A HREF="https://x.com/itsclivetime/status/1910026068746289286">(1) Clive Chan en X: "Google TPUv7: - 4.6 PFLOP/s FP8 - 192 GB HBM @ 7.4 TB/s - 600 GB/s (unidi) ICI - ~1000 watts Nvidia GB200: - 5 PFLOP/s FP8 / 10 PFLOP/s FP4 - 192 GB HBM @ 8 TB/s - 900 GB/s (unidi) NVLink - ~1200 watts https://t.co/mqvQfP9YyV" / X</A>
											<DT><A HREF="https://zhangguoxian.substack.com/p/whats-difference-between-gb200-and">What's difference between GB200 and GB300 - Wukong</A>
											<DT><A HREF="https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/azure%e2%80%99s-nd-gb200-v6-delivers-record-performance-for-inference-workloads/4399253">Azure ND GB200 v6 Delivers Record Performance for Inference Workloads</A>
											<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/partition-guide-v1-2.pdf">NVIDIA GB200 NVL Partition</A>
										</DL><p>
										<DT><H3 FOLDED>GB300</H3>
										<DL><p>
											<DT><H3 FOLDED>gb300-benchmarking</H3>
											<DL><p>
												<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/11b51e9c5ad6cc71cd66cb873e34bc922d97d547/benchmark/sdpa_benchmark_training/README.md">cudnn-frontend/benchmark/sdpa_benchmark_training/README.md at 11b51e9c5ad6cc71cd66cb873e34bc922d97d547 ¬∑ NVIDIA/cudnn-frontend</A>
											</DL><p>
										</DL><p>
										<DT><H3 FOLDED>nvl72-virtualization</H3>
										<DL><p>
											<DT><A HREF="https://azure.microsoft.com/en-us/blog/microsoft-azure-delivers-the-first-large-scale-cluster-with-nvidia-gb300-nvl72-for-openai-workloads/">NVIDIA GB300 NVL72: Next-generation AI infrastructure at scale | Microsoft Azure Blog</A>
											<DT><A HREF="https://learn.microsoft.com/en-us/azure/virtual-machines/sizes/gpu-accelerated/nd-gb300-v6-series?tabs=sizebasic">ND GB300-v6 size series - Azure Virtual Machines | Microsoft Learn</A>
										</DL><p>
										<DT><A HREF="https://www.nvidia.com/en-us/data-center/gb200-nvl72/">GB200 NVL72 | NVIDIA</A>
										<DT><A HREF="https://blogs.nvidia.com/blog/blackwell-mlperf-inference/">NVIDIA Blackwell Takes Pole Position in Latest MLPerf Inference Results | NVIDIA Blog</A>
										<DT><A HREF="https://www.nvidia.com/en-us/data-center/gb300-nvl72/">Designed for AI Reasoning Performance &amp; Efficiency | NVIDIA GB300 NVL72</A>
										<DT><A HREF="https://x.com/SemiAnalysis_/status/1923142994963669245">MI450X IF128</A>
										<DT><A HREF="https://www.notion.so/datacrunchio/2025-06-19-NVL72-GB200-supermicro-21ab9e76914480d5b0d0ebe15d246668">2025.06.19 NVL72 GB200 supermicro</A>
										<DT><A HREF="https://www.coreweave.com/blog/coreweaves-nvidia-gb300-nvl72-production-ready-instances-for-enterprise-ai-featuring-nvidia-blackwell-ultra-gpus-deliver-more-than-6x-performance-gain-on-deepseek-r1">CoreWeave's NVIDIA GB300 NVL72 production-ready instances for enterprise AI, featuring NVIDIA Blackwell Ultra GPUs, deliver more than 6x performance gain on DeepSeek R1</A>
										<DT><A HREF="https://developer.nvidia.com/blog/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era/">Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era | NVIDIA Technical Blog</A>
										<DT><A HREF="https://semianalysis.com/2025/08/20/h100-vs-gb200-nvl72-training-benchmarks/">H100 vs GB200 NVL72 Training Benchmarks ‚Äì Power, TCO, and Reliability Analysis, Software Improvement Over Time ‚Äì SemiAnalysis</A>
										<DT><A HREF="https://azure.microsoft.com/en-us/blog/microsoft-azure-delivers-the-first-large-scale-cluster-with-nvidia-gb300-nvl72-for-openai-workloads/">NVIDIA GB300 NVL72: Next-generation AI infrastructure at scale | Microsoft Azure Blog</A>
										<DT><A HREF="https://x.com/SemiAnalysis_/status/1980276283297902767">(1) SemiAnalysis en X: "Next-generation backplanes have the potential to use 400G BiDi SerDes for scale-up connectivity, compared to existing backplanes that use UniDi SerDes. To explain in terms of Minecraft redstone: on GB200 NVL72 backplane each direction requires an dedicated line of redstone dust https://t.co/saQQizVGPz" / X</A>
										<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/multi-node-tuning-guide/system.html">Understanding Your Grace-Blackwell Systems ‚Äî NVIDIA GB200 NVL Multi-Node Tuning Guide</A>
										<DT><A HREF="https://pytorchtoatoms.substack.com/p/why-dgx-h100-nvl256-never-shipped">Why DGX H100 NVL256 Never Shipped? Analysis of BoM, Will GB200 NVL72 Fail too?</A>
										<DT><A HREF="https://mp.weixin.qq.com/s/HYlU3ldZn_79GJol17s9xQ">Ë∞àË∞àÂü∫‰∫éScaleUP UALink</A>
									</DL><p>
									<DT><H3 FOLDED>B300</H3>
									<DL><p>
										<DT><A HREF="https://web.archive.org/web/20250516042746/https://zhangguoxian.substack.com/p/whats-difference-between-gb200-and">What's difference between GB200 and GB300 - Wukong</A>
										<DT><A HREF="https://substack.com/@wukong535500">Wukong | Substack</A>
										<DT><A HREF="https://www.colfax-intl.com/Servers/CX8860s-X6B3">Colfax CX8860s-X6B3 Server | NVIDIA HGX‚Ñ¢ B300 8-GPU &amp; 2x Intel¬Æ Xeon¬Æ 6700 Series Processors</A>
										<DT><A HREF="https://www.glennklockwood.com/garden/processors/B300">NVIDIA B300</A>
										<DT><A HREF="https://resources.nvidia.com/en-us-blackwell-architecture/blackwell-architecture-technical-brief?ncid=no-ncid">NVIDIA Blackwell Architecture Technical Overview, Table 3. System Specifications Per GPU specs</A>
										<DT><A HREF="https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/">Introducing NVFP4 for Efficient and Accurate Low-Precision Inference | NVIDIA Technical Blog</A>
									</DL><p>
									<DT><H3 FOLDED>B200</H3>
									<DL><p>
										<DT><A HREF="https://x.com/StasBekman/status/1988338797772501499">System memory requirements per node for new bigger GPUs.</A>
									</DL><p>
									<DT><H3 FOLDED>TMEM</H3>
									<DL><p>
										<DT><H3 FOLDED>tcgen05.alloc</H3>
										<DL><p>
											<DT><A HREF="https://x.com/gaunernst/status/2002573556824354967">(1) Thien Tran en X: "Came across this by chance. tcgen05.alloc compiles to a huge chunk of SASS. Thought it was interesting... https://t.co/1CzsC5yAOg" / X</A>
										</DL><p>
										<DT><H3 FOLDED>tcgen05.mma</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-cta-pair">tcgen05 PTX ISA 8.7</A>
											<DT><A HREF="https://github.com/search?q=repo%3Atriton-lang%2Ftriton%20tcgen05&type=code">triton: tcgen05</A>
											<DT><A HREF="https://x.com/gaunernst/status/2002750211194847275">(1) Thien Tran en X: "I wrote another blogpost https://t.co/A1s4NgCI0E Thought it was gonna be a short one, but it turned into my longest blogpost yet." / X</A>
											<DT><A HREF="https://gau-nernst.github.io/tcgen05/">tcgen05 for dummies - gau-nernst's blog</A>
											<DT><A HREF="https://github.com/gau-nernst/learn-cuda/tree/3b90ac9b/02e_matmul_sm100/">learn-cuda/02e_matmul_sm100</A>
											<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-writing-gemm-kernels-using-tensor-memory-for-nvidia-blackwell-gpus/">CUTLASS Tutorial: Writing GEMM Kernels Using Tensor Memory For NVIDIA¬Æ Blackwell GPUs ‚Äì Colfax Research</A>
											<DT><A HREF="https://vjkrish.com/2026/01/19/Mma_Layouts.html">Hopper/Blackwell Tensor Core MMA layouts | vj-krish</A>
										</DL><p>
										<DT><H3 FOLDED>tcgen05.reduction</H3>
										<DL><p>
											<DT><A HREF="https://github.com/triton-lang/triton/pull/9151">tcgen05.ld.red.sync.aligned.16x32bx2.x8.u32.max {r0, r1, r2, r3, r4, r5, r6, r7},  redVal, [taddr3], 16;</A>
										</DL><p>
										<DT><H3 FOLDED>tcgen05.ld</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-instructions-tcgen05-ld">1. Introduction ‚Äî PTX ISA 9.1 documentation: tcgen05.ld</A>
											<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/#tcgen05-matrix-fragments-shape-1632b2">tcgen05{.ld,.st}.16x32bx2</A>
											<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-writing-gemm-kernels-using-tensor-memory-for-nvidia-blackwell-gpus/">CUTLASS Tutorial: Writing GEMM Kernels Using Tensor Memory For NVIDIA¬Æ Blackwell GPUs ‚Äì Colfax Research</A>
										</DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/df8a550d3917b0e97f416b2ed8c2d786f7f686a3/examples/cute/tutorial/blackwell/01_mma_sm100.cu#L86">cutlass/examples/cute/tutorial/blackwell/01_mma_sm100.cu</A>
										<DT><A HREF="https://www.together.ai/blog/thunderkittens-nvidia-blackwell-gpus#:~:text=There%E2%80%99s%20also%20a%20new%20layer,to%20227KB%20of%20shared%20memory">ThunderKittens Now Optimized for NVIDIA Blackwell GPUs</A>
										<DT><A HREF="https://chatgpt.com/c/67efb9fd-8fb4-800c-8698-9c9dae8b22ed">TMEM in NVIDIA Blackwell: A New Threadblock-Level Memory Layer</A>
										<DT><A HREF="https://x.com/SzymonOzog_/status/1975208526441324739">(1) SzymonOzog en X: "Interesting shift in GPU programming is the shift from parallel to parallel + async. Ampere was async loads Hopper was async loads + async wgmma ops Blackwell doesn't return values to registers but tensor memory When do we shrink the register file to save chip space? https://t.co/wmEdASdoTu" / X</A>
										<DT><A HREF="https://cursor.com/en-US/blog/kernels">1.5x faster MoE training with custom MXFP8 kernels ¬∑ Cursor</A>
										<DT><A HREF="https://x.com/vega_myhre/status/2015225274380734591">mma accumulation in TMEM instead of registers certainly makes for cleaner PTX instructions...  he wgmma ones with dozens of registers for outputs were a nightmare</A>
									</DL><p>
									<DT><H3 FOLDED>2CTA</H3>
									<DL><p>
										<DT><A HREF="https://www.together.ai/blog/thunderkittens-nvidia-blackwell-gpus#:~:text=There%E2%80%99s%20also%20a%20new%20layer,to%20227KB%20of%20shared%20memory">ThunderKittens Now Optimized for NVIDIA Blackwell GPUs</A>
									</DL><p>
									<DT><A HREF="https://www.together.ai/blog/thunderkittens-nvidia-blackwell-gpus#:~:text=There%E2%80%99s%20also%20a%20new%20layer,to%20227KB%20of%20shared%20memory">ThunderKittens Now Optimized for NVIDIA Blackwell GPUs</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/blackwell_functionality.md">cutlass/media/docs/blackwell_functionality.md at main ¬∑ NVIDIA/cutlass</A>
									<DT><A HREF="https://nvdam.widen.net/s/xqt56dflgh/nvidia-blackwell-architecture-technical-brief">nvidia-blackwell-architecture-technical-brief.pdf</A>
									<DT><A HREF="https://www.youtube.com/watch?v=7GV_OdqzmIU&t=430s">Cerebras Co-Founder Deconstructs Blackwell GPU Delay - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=RW2-HtWaOS0">Accelerating the Future: Triton on Blackwell Architecture - YouTube</A>
									<DT><A HREF="https://x.com/ogawa_tter/status/1843999601390678416">OGAWA: Microsoft Azure NVL72 GB200 server design</A>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-blackwell-doubles-llm-training-performance-in-mlperf-training-v4-1/">NVIDIA Blackwell Doubles LLM Training Performance in MLPerf Training v4.1 | NVIDIA Technical Blog</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/389e493055f981bfdc6d4348f823191ca7b9fddd">CUTLASS 3.8 Release (#2059) ¬∑ NVIDIA/cutlass@389e493</A>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s74639/">Enable Tensor Core Programming in Python with CUTLASS 4.0 | GTC 25 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://www.youtube.com/watch?v=gofI47kfD28">Bill Dally | Directions in Deep Learning Hardware - YouTube</A>
									<DT><A HREF="https://x.com/StasBekman/status/1942265270204260510">(1) Stas Bekman en X: "Got a chance to measure Maximum Achievable Matmul TFLOPS on NVIDIA B200. With each new NVIDIA generation the efficiency keeps on dropping: A100: 86.9% H100: 80.3% B200: 77.6% The updated table is here: https://t.co/m9qGomlrgG https://t.co/abLmKVFaty" / X</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/reference.html">Writing Mosaic GPU kernels with Pallas ‚Äî JAX documentation</A>
								</DL><p>
								<DT><H3 FOLDED>Rubin</H3>
								<DL><p>
									<DT><H3 FOLDED>rubin-notes</H3>
									<DL><p>
										<DT><A HREF="https://x.com/zephyr_z9/status/2008311460213232056">Each Vera GPU gets an extra 16TB of memory Enough to support even 10M context lengths</A>
									</DL><p>
									<DT><H3 FOLDED>rubin-CPX</H3>
									<DL><p>
										<DT><A HREF="https://x.com/msharmavikram/status/2008311158978293808">(1) Vikram en X: "Incredibly proud of the work we are doing for many months on @nvidia Context Memory architecture. (1/4) https://t.co/M5pS3X9Css" / X</A>
										<DT><A HREF="https://www.chiplog.io/p/a-deep-dive-into-nvidia-rubin-cpx">A Deep Dive into NVIDIA Rubin CPX: History, Architecture, Splitwise/DistServe, Inference Economics, and Limitations</A>
									</DL><p>
									<DT><A HREF="https://www.techspot.com/news/105852-nvidia-blackwell-ai-successor-rubin-moves-forward-six.html">Next-gen Nvidia GPU "Rubin" is ahead of schedule, uses 3nm manufacturing and HBM4 | TechSpot</A>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-rubin-cpx-accelerates-inference-performance-and-efficiency-for-1m-token-context-workloads/">NVIDIA Rubin CPX Accelerates Inference Performance and Efficiency for 1M+ Token Context Workloads | NVIDIA Technical Blog</A>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/1966656998965154212">(1) SemiAnalysis en X: "Rubin CPX Prefill Inference specialized chip does not have NVLink and only has PCIe 6.0 x16 for inter-chip communication which runs at 128GB/s unidi We used first principles analyze if this the low communication I/O will bottleneck for frontier models such as DeepSeekv3 R1. Based https://t.co/lSuSVXbxqf" / X</A>
									<DT><A HREF="https://x.com/theaustinlyons/status/1980742522340061691">(1) Austin Lyons en X: "$CRDO example setup for $NVDA Rubin NVL144. Lots of opportunity with these high-density racks. üßµ https://t.co/etyubFZI0z" / X</A>
									<DT><A HREF="https://github.com/zartbot/blog/issues/3">Inside Nvidia GPU: Discussing Blackwell's Limitations and Predicting Rubin's Microarchitecture ¬∑ Issue #3 ¬∑ zartbot/blog</A>
									<DT><A HREF="https://x.com/_xjdr/status/2015137825742876743">(1) xjdr en X: "if you thought the hopper -&amp;gt; blackwell lift was heavy (why most people still prefer hopper) you are going to be shocked by how heavy the blackwell -&amp;gt; VR lift is going to be. proximity to the pareto frontier will be directly tied to your ability to keep up and utilize the new hw" / X</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1999182124780114674">Rubin GPGPU Architecture Features Overview</A>
								</DL><p>
								<DT><H3 FOLDED>SFU (Special Function Unit)</H3>
								<DL><p>
									<DT><H3 FOLDED>exp</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>MUFU.EX2</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>sfu-blackwell-ultra</H3>
									<DL><p>
										<DT><A HREF="https://x.com/SemiAnalysis_/status/2015907663528251898">(1) SemiAnalysis en X: "IMPORTANT: Blackwell Ultra solves an attention operation performance issue found in Blackwell. As @tri_dao presented at the SemiAnalysis Hackathon, one of the biggest bottlenecks in the core attention operation is not GEMMs but the softmax (exponential)¬† part. In Hopper &amp;amp; https://t.co/x3iRUUnAlf" / X</A>
									</DL><p>
									<DT><A HREF="https://github.com/zartbot/blog/issues/3">Inside Nvidia GPU: Discussing Blackwell's Limitations and Predicting Rubin's Microarchitecture ¬∑ Issue #3 ¬∑ zartbot/blog</A>
									<DT><A HREF="https://modal.com/blog/reverse-engineer-flash-attention-4">We reverse-engineered Flash Attention 4</A>
									<DT><A HREF="https://gau-nernst.github.io/fa-5090/">Writing Speed-of-Light Flash Attention for 5090 in CUDA C++ - gau-nernst's blog</A>
								</DL><p>
								<DT><H3 FOLDED>gpu-reverse-engineer</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2503.20481">Analyzing Modern NVIDIA GPU cores</A>
									<DT><A HREF="https://www.youtube.com/watch?v=OUzm06YaUsI&t=8016s">George Hotz | how do GPUs work? (noob) + paper reading (not noob) | tinycorp.myshopify.com - YouTube</A>
								</DL><p>
								<DT><A HREF="https://github.com/ai-compiler-study/triton-kernels/blob/main/scripts/gpu_properties.cu">triton-kernels/scripts/gpu_properties.cu at gpu_properties</A>
								<DT><A HREF="https://arxiv.org/abs/2503.20481">[2503.20481] Analyzing Modern NVIDIA GPU cores</A>
								<DT><A HREF="https://x.com/RajaXg/status/1812721241985610147">GPU Architecture Impact</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/66ef1df492f7bc9c8eeb01d7e14db01838e3f0bd/tensorrt_llm/auto_parallel/cluster_info.py">TensorRT-LLM/tensorrt_llm/auto_parallel/cluster_info.py</A>
								<DT><A HREF="https://news.futunn.com/en/post/42190604/nvidia-s-next-generation-gpu-revealed-integrating-eight-hbm-4?level=1&data_ticket=1715948857342483">Nvidia's next-generation GPU revealed: integrating eight HBM 4, TSMC N3 process</A>
								<DT><A HREF="https://github.com/kuterd/nv_isa_solver?tab=readme-ov-file">kuterd/nv_isa_solver: Nvidia Instruction Set Specification Generator</A>
								<DT><A HREF="https://github.com/Jokeren/Awesome-GPU">Jokeren/Awesome-GPU: Awesome resources for GPUs</A>
								<DT><A HREF="https://www.youtube.com/watch?v=h9Z4oGN89MU">How do Graphics Cards Work? Exploring GPU Architecture - YouTube</A>
								<DT><A HREF="https://x.com/itsclivetime/status/1911543695473516689">HW-SW codesign: CSR, LLVM, two-path adder, CoWoS, DfT, STCO, SMPS</A>
								<DT><A HREF="https://www.youtube.com/watch?v=gofI47kfD28&t=1119s">Bill Dally | Directions in Deep Learning Hardware - YouTube</A>
								<DT><A HREF="https://www.zhihu.com/question/319355296/answer/1931398398445060845">How can I systematically learn about GPU architecture?</A>
								<DT><A HREF="https://www.youtube.com/watch?v=4u8iMr3iXR4">Bill Dally - Trends in Deep Learning Hardware - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-programming-model</H3>
							<DL><p>
								<DT><H3 FOLDED>cuda-memory-model</H3>
								<DL><p>
									<DT><H3 FOLDED>global-memory</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#global-memory-5-x">CUDA C++ Programming Guide ‚Äî CUDA C++ Programming Guide</A>
										<DT><A HREF="https://accelerated-computing.academy/fall24/resources/errata/l1-cache/">6.S894</A>
										<DT><A HREF="https://arxiv.org/abs/1804.06826">[1804.06826] Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</A>
										<DT><A HREF="https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9839-discovering-the-turing-t4-gpu-architecture-with-microbenchmarks.pdf#page=32">Dissecting the Turing GPU Architecture through Microbenchmarking</A>
									</DL><p>
									<DT><H3 FOLDED>shared-memory</H3>
									<DL><p>
										<DT><H3 FOLDED>shm-swizzling</H3>
										<DL><p>
											<DT><A HREF="https://leimao.github.io/blog/CUDA-Shared-Memory-Swizzling/">CUDA Shared Memory Swizzling - Lei Mao's Log Book</A>
											<DT><A HREF="https://leimao.github.io/blog/CuTe-Swizzle/">CuTe Swizzle - Lei Mao's Log Book</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/1949609885953139032">CUTLASS CuTe GEMM Details (Part 4) - Talking about some misunderstandings about B and S in Swizzle template parameters: The Swizzle principle</A>
										</DL><p>
										<DT><H3 FOLDED>bank-conflict</H3>
										<DL><p>
											<DT><A HREF="https://leimao.github.io/blog/CUDA-Shared-Memory-Bank/">CUDA Shared Memory Bank - Lei Mao's Log Book</A>
											<DT><A HREF="https://gau-nernst.github.io/bank-conflict/">Bank Conflict Visualizer</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/1942244763865707415">A more general solution for shared memory bank conflict free automatic swizzling</A>
											<DT><A HREF="https://x.com/gordic_aleksa/status/1793383927031210423">(1) Aleksa Gordiƒá (Ê∞¥Âπ≥ÈóÆÈ¢ò) en X: "back in 2018 Citadel's HPC team figured out how to modify the register mapping of V100 generated by nvcc in order to avoid bank conflicts (that forced sequential access) this improved perf from 132.05 to 152.43 GFlops/s per SMX (+15.4%) btw this was just a motivating example to https://t.co/eTCKLgxxFq" / X</A>
											<DT><A HREF="https://arxiv.org/abs/1804.06826">[1804.06826] Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</A>
											<DT><A HREF="https://x.com/mrsiipa/status/1981788425205559654">(1) maharshi en X: "https://t.co/abVfu5f1Ee" / X</A>
											<DT><A HREF="https://feldmann.nyc/blog/smem-microbenchmarks">Notes About Nvidia GPU Shared Memory Banks | Axel Feldmann</A>
											<DT><A HREF="https://aminediro.com/posts/flash_attn/">Reimplementing FlashAttention for performance and giggles | AmineDiro</A>
										</DL><p>
										<DT><A HREF="https://github.com/lcy-seso/vq-experiments/pull/8/files#diff-3105931cb25596ad015fdb28c71374aef0605adacc69fc28cd758e21ae63f5fd">feat: utility function for calculating shared memory usage. by lcy-seso ¬∑ Pull Request #8 ¬∑ lcy-seso/vq-experiments</A>
										<DT><A HREF="https://github.com/lcy-seso/vq-experiments/blob/3aef9f38da6dd19f1c9b3aa03410724a2457e0ac/shared_memory_calculator/README.md">vq-experiments/shared_memory_calculator/README.md: shared memory per block (H100 228 KB)</A>
										<DT><A HREF="https://leimao.github.io/blog/CUDA-Shared-Memory-Swizzling/">CUDA Shared Memory Swizzling - Lei Mao's Log Book</A>
										<DT><A HREF="https://grok.com/c/8f430351-dc97-4a8f-ac54-090b10c95e5e">CUDA Bank Conflicts and Swizzling - Grok</A>
										<DT><A HREF="https://feldmann.nyc/blog/smem-microbenchmarks">Notes About Nvidia GPU Shared Memory Banks | Axel Feldmann</A>
										<DT><A HREF="https://github.com/HydraQYH/NVGPUMicroBenchmark/blob/master/shared_memory_bandwidth.cu">NVGPUMicroBenchmark/shared_memory_bandwidth.cu at master ¬∑ HydraQYH/NVGPUMicroBenchmark</A>
									</DL><p>
									<DT><H3 FOLDED>cuda-indexing</H3>
									<DL><p>
										<DT><A HREF="https://veitner.bearblog.dev/indexing-in-cuda/">Indexing in CUDA | simons blog</A>
									</DL><p>
									<DT><H3 FOLDED>cuda-dsm (Distributed Shared Memory)</H3>
									<DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/blob/main/docs/20250929-hopper-fp8-sparse-deep-dive.md">FlashMLA/docs/20250929-hopper-fp8-sparse-deep-dive.md at main ¬∑ deepseek-ai/FlashMLA</A>
										<DT><A HREF="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">NVIDIA Hopper Architecture In-Depth | NVIDIA Technical Blog</A>
									</DL><p>
									<DT><H3 FOLDED>cuda-cache</H3>
									<DL><p>
										<DT><H3 FOLDED>cuda-l1</H3>
										<DL><p>
											<DT><A HREF="https://accelerated-computing.academy/fall24/resources/errata/l1-cache/">L1 Cache Behavior</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>L2 Side Aware</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ademeure/cuda-side-boost">ademeure/cuda-side-boost</A>
									</DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy">Memory Hierarchy</A>
									<DT><A HREF="https://www.youtube.com/watch?v=uHN5fpfu8As">Memory hierarchy</A>
									<DT><A HREF="https://developer.nvidia.com/gtc/2020/video/cwe21754">GTC 2020: Memory Management on Modern GPU | NVIDIA Developer</A>
									<DT><A HREF="https://developer.download.nvidia.com/video/gputechconf/gtc/2020/presentations/s21819-optimizing-applications-for-nvidia-ampere-gpu-architecture.pdf">GPU memory architecture</A>
									<DT><A HREF="https://developer.download.nvidia.com/CUDA/training/register_spilling.pdf">Local memory/register spilling</A>
									<DT><A HREF="https://lwn.net/Articles/253361/">Memory part 3: Virtual Memory [LWN.net]</A>
									<DT><A HREF="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/">Christian Mills - CUDA MODE Lecture 4: Compute and Memory Basics</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/6842963374">Some conjectures about the memory consistency model of modern GPU architecture (Part 1)</A>
									<DT><A HREF="https://modal.com/gpu-glossary/perf/memory-coalescing">What is Memory Coalescing? | GPU Glossary</A>
									<DT><A HREF="https://x.com/gaunernst/status/1978769529560822110">Thien Tran en X: "CUDA memory can be shared across processes using IPC memory handle. So we can share model weights between training and vLLM processes on the same device. No weight-syncing, always on-policy! (still need to invalidate KV cache). Multi-GPU might work too! (vLLM TP + custom FSDP?)" / X</A>
									<DT><A HREF="https://docs.unsloth.ai/get-started/reinforcement-learning-rl-guide/memory-efficient-rl">Memory Efficient RL | Unsloth Documentation</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#interprocess-communication">CUDA C++ Programming Guide ‚Äî CUDA C++ Programming Guide</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/#memory-consistency-model">1. Introduction ‚Äî PTX ISA 9.0 documentation</A>
									<DT><A HREF="https://j1129290218.substack.com/p/memory-is-the-new-bottleneck-why?utm_campaign=post&triedRedirect=true">Memory Is the New Bottleneck: Why Memory Hierarchy Optimization Will Be the Rarest Engineering Skill in the Next 3‚Äì5 Years</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-learning</H3>
								<DL><p>
									<DT><H3 FOLDED>PMPP</H3>
									<DL><p>
										<DT><H3 FOLDED>pmpp-solutions</H3>
										<DL><p>
											<DT><A HREF="https://x.com/tugot17/status/1944096782260350991">pmpp solutions</A>
											<DT><A HREF="https://github.com/tugot17/pmpp/">tugot17/pmpp: Complete solutions to the Programming Massively Parallel Processors Edition 4</A>
										</DL><p>
										<DT><A HREF="https://github.com/drisspg/simple_cuda">drisspg/simple_cuda: Learnings + Exercises from the PMPP book!</A>
										<DT><A HREF="https://github.com/olcf/cuda-training-series">olcf/cuda-training-series: Training materials associated with NVIDIA's CUDA Training Series (www.olcf.ornl.gov/cuda-training-series/)</A>
										<DT><A HREF="https://www.amazon.es/Programming-Massively-Parallel-Processors-Hands/dp/0323912311">Programming Massively Parallel Processors: A Hands-on Approach : Hwu, Wen-mei W., Kirk, David B., El Hajj, Izzat: Amazon.es: Libros</A>
										<DT><A HREF="https://shop.elsevier.com/books/programming-massively-parallel-processors/hwu/978-0-323-91231-0">Programming Massively Parallel Processors - 4th Edition | Elsevier Shop</A>
										<DT><A HREF="http://gpu.di.unimi.it/books/PMPP-3rd-Edition.pdf">‚Äégpu.di.unimi.it/books/PMPP-3rd-Edition.pdf</A>
										<DT><A HREF="https://www.cse.iitd.ac.in/~rijurekha/col730_2022/cudabook.pdf">NVIDIA version</A>
										<DT><A HREF="https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0323912311">Programming Massively Parallel Processors: A Hands-on Approach: Hwu, Wen-mei W., Kirk, David B., El Hajj, Izzat: 9780323912310: Amazon.com: Books</A>
										<DT><A HREF="https://github.com/drisspg/simple_cuda/tree/main/examples">simple_cuda/examples at main ¬∑ drisspg/simple_cuda</A>
										<DT><A HREF="https://x.com/tugot17/status/1944096782260350991">(1) Piotr Mazurek en X: "I solved every single problem in the CUDA mode book. A quick thread summarizing this experience and what I learned 1/x https://t.co/KOgppjA3ev" / X</A>
										<DT><A HREF="https://www.youtube.com/playlist?list=PLRRuQYjFhpmubuwx-w8X964ofVkW1T8O4">AUB Spring 2021 El Hajj - YouTube PMPP video lectures</A>
									</DL><p>
									<DT><H3 FOLDED>cuda-lectures</H3>
									<DL><p>
										<DT><A HREF="https://accelerated-computing.academy/fall24/">6.S894: Accelerated Computing</A>
									</DL><p>
									<DT><H3 FOLDED>cuda-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/KuangjuX/CUDAKernels">KuangjuX/CUDAKernels: üéâMy Collections of CUDA Kernels~</A>
										<DT><A HREF="https://github.com/tensor-fusion/CUDA-Transformer/blob/main/transformer_cuda.py#L37">CUDA-Transformer/transformer_cuda.py at main ¬∑ tensor-fusion/CUDA-Transformer</A>
										<DT><A HREF="https://github.com/abhisheknair10/Llama3.cu">abhisheknair10/Llama3.cu: Lightweight Llama 3-8B Inference Engine in CUDA C</A>
										<DT><A HREF="https://github.com/clu0/unet.cu">clu0/unet.cu: UNet diffusion model in pure CUDA</A>
										<DT><A HREF="https://github.com/ita9naiwa/playground">ita9naiwa/playground: ..</A>
									</DL><p>
									<DT><H3 FOLDED>cuda-hand</H3>
									<DL><p>
										<DT><A HREF="https://x.com/ProfTomYeh/status/1981730186899910734">(1) Tom Yeh en X: "How to add two arrays on a GPU by hand ‚úçÔ∏è? Join my keynote lecture next week üëâ https://t.co/ydmA0ypkvg (hosted by Together AI) https://t.co/Q0U4xCNiuH" / X</A>
										<DT><A HREF="https://www.byhand.ai/p/gpu-by-hand-together">GPU by Hand ‚úçÔ∏è Together - by Prof. Tom Yeh - AI by Hand ‚úçÔ∏è</A>
									</DL><p>
									<DT><H3 FOLDED>how-to-optim-algorithm-in-cuda</H3>
									<DL><p>
										<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda">BBuf/how-to-optim-algorithm-in-cuda: how to optimize some algorithm in cuda.</A>
										<DT><A HREF="https://leimao.github.io/tags/CUDA/">Tag: CUDA - Lei Mao's Log Book</A>
									</DL><p>
									<DT><A HREF="https://leimao.github.io/tags/CUDA/">Tag: CUDA - Lei Mao's Log Book</A>
									<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda">BBuf/how-to-optim-algorithm-in-cuda: how to optimize some algorithm in cuda.</A>
									<DT><A HREF="https://github.com/gau-nernst/learn-cuda">gau-nernst/learn-cuda: Learn CUDA with PyTorch</A>
									<DT><A HREF="https://github.com/cuda-mode">CUDA MODE</A>
									<DT><A HREF="http://giantpandacv.com/project/CUDA/%E3%80%90BBuf%E7%9A%84CUDA%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%80%EF%BC%8C%E8%A7%A3%E6%9E%90OneFlow%20Element-Wise%20%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0/">„ÄêBBufÁöÑCUDAÁ¨îËÆ∞„Äë‰∏ÄÔºåËß£ÊûêOneFlow Element-Wise ÁÆóÂ≠êÂÆûÁé∞ - GiantPandaCV</A>
									<DT><A HREF="https://github.com/NVIDIA/cuda-samples">NVIDIA/cuda-samples: Samples for CUDA Developers which demonstrates features in CUDA Toolkit</A>
									<DT><A HREF="https://github.com/cuda-mode/lectures">cuda-mode/lectures: Material for cuda-mode lectures</A>
									<DT><A HREF="https://github.com/mlecauchois/micrograd-cuda/blob/main/micrograd_cuda/operations.py">micrograd-cuda/micrograd_cuda/operations.py at main ¬∑ mlecauchois/micrograd-cuda</A>
									<DT><A HREF="https://github.com/shineyruan/CUDA-Stream-Compaction">shineyruan/CUDA-Stream-Compaction</A>
									<DT><A HREF="https://ahgamut.github.io/">Blog Needs a Name</A>
									<DT><A HREF="https://www.youtube.com/playlist?list=PL5Q2soXY2Zi_OwkTgEyA6tk3UsoPBH737">Livestream - P&amp;S Hands-on Acceleration on Heterogeneous Computing Systems (Fall 2021) - YouTube</A>
									<DT><A HREF="https://www.youtube.com/playlist?list=PL5Q2soXY2Zi-Mnk1PxjEIG32HAGILkTOF">Livestream - Computer Architecture - ETH Z√ºrich (Fall 2021) - YouTube</A>
									<DT><A HREF="https://github.com/FZJ-JSC/tutorial-multi-gpu">FZJ-JSC/tutorial-multi-gpu: Efficient Distributed GPU Programming for Exascale, an SC/ISC Tutorial</A>
									<DT><A HREF="https://homepages.dcc.ufmg.br/~sylvain.collange/gpucourse/">Index of /~sylvain.collange/gpucourse</A>
									<DT><A HREF="https://www.youtube.com/watch?v=qYqrfq452ig&list=LL&index=19&t=4582s">Hardcore CUDA Hackathon Talks at AGI House SF - YouTube</A>
									<DT><A HREF="https://github.com/PacktPublishing/Learn-CUDA-Programming">PacktPublishing/Learn-CUDA-Programming: Learn CUDA Programming, published by Packt</A>
									<DT><A HREF="https://github.com/bongwonjang/ImageNet-CUDA?tab=readme-ov-file">bongwonjang/ImageNet-CUDA</A>
									<DT><A HREF="https://github.com/PaddleJitLab/CUDATutorial/blob/develop/docs/00_prev_concept/README.md">CUDATutorial/docs/00_prev_concept/README.md at develop ¬∑ PaddleJitLab/CUDATutorial</A>
									<DT><A HREF="https://github.com/ifromeast/cuda_learning/blob/main/04_transformer/train_gpt2.cu">cuda_learning/04_transformer/train_gpt2.cu at main ¬∑ ifromeast/cuda_learning</A>
									<DT><A HREF="https://github.com/Tony-Tan/CUDA_Freshman">Tony-Tan/CUDA_Freshman</A>
									<DT><A HREF="https://github.com/cloneofsimo/torchcu/blob/main/.kernel_cache/wp___main___8109c9e/module_codegen.cu">torchcu/.kernel_cache/wp___main___8109c9e/module_codegen.cu at main ¬∑ cloneofsimo/torchcu</A>
									<DT><A HREF="https://github.com/MuGdxy/muda">MuGdxy/muda: Œº-Cuda, COVER THE LAST MILE OF CUDA. With features: intellisense-friendly, structured launch, automatic cuda graph generation and updating.</A>
									<DT><A HREF="https://github.com/moderngpu/moderngpu/wiki/Getting-started#cloning-the-source">Getting started ¬∑ moderngpu/moderngpu Wiki</A>
									<DT><A HREF="https://www.youtube.com/watch?v=eqkAaplKBc4&t=3159s">(1) A Taste of GPU Compute - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=86FAWCzIe_4">CUDA Programming Course ‚Äì High-Performance Computing with GPUs - YouTube</A>
									<DT><A HREF="https://github.com/SzymonOzog/GPU_Programming">SzymonOzog/GPU_Programming</A>
									<DT><A HREF="http://www.cudahandbook.com/">‚Äéwww.cudahandbook.com</A>
									<DT><A HREF="https://www.youtube.com/watch?v=4pkbXmE4POc&list=PLRRuQYjFhpmubuwx-w8X964ofVkW1T8O4">Lecture 01 - Introduction - YouTube</A>
									<DT><A HREF="https://mlforsystems.org/assets/papers/neurips2024/paper32.pdf">WarpDrive: An Agentic Workflow for Ninja GPU Transformations</A>
									<DT><A HREF="https://www.youtube.com/watch?v=4pkbXmE4POc&t=1s">Lecture 01 - Introduction - YouTube</A>
									<DT><A HREF="https://github.com/PaddleJitLab/CUDATutorial">PaddleJitLab/CUDATutorial: A self-learning tutorail for CUDA High Performance Programing.</A>
									<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest">lcy-seso/DLFrameworkTest: My tests and experiments with some popular dl frameworks.</A>
									<DT><A HREF="https://leimao.github.io/">Lei Mao - Lei Mao's Log Book</A>
									<DT><A HREF="https://modal.com/gpu-glossary/device-software/memory-hierarchy">What is the Memory Hierarchy? | GPU Glossary</A>
									<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2024/11/30/eleutherai-reading-group-session-1.html">An intro to GPU architecture, CUDA, NCCL, and common ML performance bottlenecks | ML Perf Notes</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Cp7g1Ll4v0M">ML Performance Reading Group Session 1: GPU Architecture, CUDA, NCCL - YouTube</A>
									<DT><A HREF="https://x.com/sadernoheart/status/1976644520835166536">(1) sadernoheart en X: "day 71/100 of GPU Programming - watched a bit of @pranjalssh's GPU Mode Lecture that lead to this technical blog explaining nvidia's hopper architecture - this prompted me to run an experiment comparing performance for my WMMA GEMM on the A100 vs H100 my observationsüßµ: https://t.co/T40UzhqDRT" / X</A>
									<DT><A HREF="https://github.com/DefTruth/CUDA-Learn-Notes">DefTruth/CUDA-Learn-Notes: üìö200+ Tensor/CUDA Cores Kernels, ‚ö°Ô∏èflash-attn-mma, ‚ö°Ô∏èhgemm with WMMA, MMA and CuTe (98%~100% TFLOPS of cuBLAS/FA2 üéâüéâ).</A>
									<DT><A HREF="https://github.com/olcf/cuda-training-series">olcf/cuda-training-series: Training materials associated with NVIDIA's CUDA Training Series (www.olcf.ornl.gov/cuda-training-series/)</A>
									<DT><A HREF="https://github.com/geohot/gpunoob">geohot/gpunoob: Noob Lessons from Stream about how GPUs work</A>
									<DT><A HREF="https://zcnrex.github.io/2025/03/08/deepgemm-1.html">DeepSeek DeepGEMM Study Note Part 1: CUDA keywords</A>
									<DT><A HREF="https://www.youtube.com/watch?app=desktop&si=K5Rpat3xfaW-QlVK&v=a-AyC6B5Ras&feature=youtu.be">How GPU Reduction Kernels Work | Threads, Blocks &amp; Shared Memory Simplified - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-thread-divergence</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=95fFNzV4sd0">Parallel C++: Thread Affinity - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-branchless-computing</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>cuda-array-interface</H3>
								<DL><p>
									<DT><A HREF="https://numba.readthedocs.io/en/stable/cuda/cuda_array_interface.html">CUDA Array Interface (Version 3) ‚Äî Numba 0+untagged.2155.g9ce83ef.dirty documentation</A>
									<DT><A HREF="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.interface.html#__array_interface__">The Array Interface ‚Äî NumPy v1.13 Manual</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-cooperative-groups</H3>
								<DL><p>
									<DT><A HREF="https://leimao.github.io/blog/CUDA-Cooperative-Groups/">CUDA Cooperative Groups - Lei Mao's Log Book</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-checks</H3>
								<DL><p>
									<DT><H3 FOLDED>CHECK_CUDA</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/morpheus/_lib/define_group__utility__error_1ga46b1154bbd80d4d46c3bca35ef60d930.html">Define CHECK_CUDA - NVIDIA Docs</A>
										<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/csrc/qattn/qk_int_sv_f8_cuda_sm90.cu">SageAttention/csrc/qattn/qk_int_sv_f8_cuda_sm90.cu at 0c8f308164b2d19025dec082520aea6084ff3626 ¬∑ thu-ml/SageAttention</A>
									</DL><p>
									<DT><A HREF="https://github.com/thu-ml/SageAttention/blob/0c8f308164b2d19025dec082520aea6084ff3626/csrc/utils.cuh#L33">SageAttention/csrc/utils.cuh: CHECK_DIMS, CHECK_NUMEL, CHECK_SHAPE, CHECK_CONTIGOUS</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-consumer-producer</H3>
								<DL><p>
									<DT><A HREF="https://veitner.bearblog.dev/consumer-producer-pattern-on-h100-in-cutedsl/">Consumer-Producer pattern on H100 in CuTeDSL | simons blog</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-multi-gpu</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/multi-gpu-programming-models">NVIDIA/multi-gpu-programming-models: Examples demonstrating available options to program multiple GPUs in a single node or a cluster</A>
								</DL><p>
								<DT><H3 FOLDED>Programmatic Dependent Launch (PDL)</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cutlass/media/docs/cpp/dependent_kernel_launch.html">Dependent kernel launches ‚Äî NVIDIA CUTLASS Documentation</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/commit/000090d02f0398e9087a8823fc1f5242becfac99">Enable PDL ¬∑ Dao-AILab/flash-attention@000090d</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-glossary</H3>
								<DL><p>
									<DT><A HREF="https://modal.com/gpu-glossary/device-hardware/tensor-memory-accelerator">What is a Tensor Memory Accelerator? | GPU Glossary</A>
									<DT><A HREF="https://sodakeyeatsmush.notion.site/Smth-Smth-GPU-Related-27bf1129214e804ba217e8d5d08fc8b5#27bf1129214e80928aeef2a9fa3c0e38">Smth Smth GPU Related</A>
									<DT><A HREF="https://modal.com/gpu-glossary">GPU Glossary</A>
								</DL><p>
								<DT><H3 FOLDED>warp-specialized-pipelines</H3>
								<DL><p>
									<DT><A HREF="https://x.com/vir_bhadeshiya/status/1992141183200723050">(1) Viral Bhadeshiya en X: "@joefioti Yeah cuBLASDx lacks hooks for warp specialization. CUTLASS handles this natively in 3.0+ for Hopper/Blackwell (e.g., via sm90_gemm_tma_warpspecialized_cooperative.hpp). You can just basically clone CUTLASS, check examples/13_two_tensor_op_fusion for fused setups, and use" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2512.18134">[2512.18134] Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs</A>
									<DT><A HREF="https://arxiv.org/abs/2510.14719">[2510.14719] Tawa: Automatic Warp Specialization for Modern GPUs with Asynchronous References</A>
								</DL><p>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/">1. Introduction ‚Äî CUDA C Programming Guide</A>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/gpus/">How to Think About GPUs | How To Scale Your Model</A>
								<DT><A HREF="https://x.com/RajaXg/status/1812721241985610147">GPU Architecture Impact</A>
								<DT><A HREF="https://github.com/IonThruster/CudaTutorials/blob/master/strategy.md">CudaTutorials/strategy.md</A>
								<DT><A HREF="https://jhui.github.io/2017/03/06/CUDA/">‚ÄúCUDA Tutorial‚Äù</A>
								<DT><A HREF="https://www.olcf.ornl.gov/calendar/cuda-shared-memory/">CUDA Shared Memory ‚Äì Oak Ridge Leadership Computing Facility</A>
								<DT><A HREF="https://www.olcf.ornl.gov/cuda-training-series/">CUDA Training Series ‚Äì Oak Ridge Leadership Computing Facility</A>
								<DT><A HREF="https://github.com/olcf/cuda-training-series">olcf/cuda-training-series: Training materials associated with NVIDIA's CUDA Training Series (www.olcf.ornl.gov/cuda-training-series/)</A>
								<DT><A HREF="https://github.com/NVIDIA/multi-gpu-programming-models">NVIDIA/multi-gpu-programming-models: Examples demonstrating available options to program multiple GPUs in a single node or a cluster</A>
								<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda">BBuf/how-to-optim-algorithm-in-cuda: how to optimize some algorithm in cuda.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=KHa-OSrZPGo">CppCon 2016: ‚ÄúBringing Clang and C++ to GPUs: An Open-Source, CUDA-Compatible GPU C++ Compiler" - YouTube</A>
								<DT><A HREF="https://tripack45.github.io/2019/10/20/intern2019/">Parallelism on Its Own Feet: 90 Days as an NVidia Intern | Patricium</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/00_quickstart.md">cutlass/media/docs/cute/00_quickstart.md at main ¬∑ NVIDIA/cutlass</A>
								<DT><A HREF="https://github.com/NVIDIA/cuda-samples">NVIDIA/cuda-samples: Samples for CUDA Developers which demonstrates features in CUDA Toolkit</A>
								<DT><A HREF="https://github.com/Tony-Tan/CUDA_Freshman">Tony-Tan/CUDA_Freshman</A>
								<DT><A HREF="https://www.youtube.com/watch?v=cXpTDKjjKZE">03 CUDA Fundamental Optimization Part 1 - YouTube</A>
								<DT><A HREF="https://github.com/cuda-mode/lecture2">cuda-mode/lecture2: lecture 2 - 2024-01-20</A>
								<DT><A HREF="https://www.youtube.com/watch?v=NQ-0D5Ti2dc">Lecture 2 Ch1-3 PMPP book</A>
								<DT><A HREF="https://www.youtube.com/watch?v=OSpy-HoR0ac">Intro to CUDA (part 5): Memory Model - YouTube</A>
								<DT><A HREF="https://github.com/torstem/demo-cuda-pybind11">demo-cuda-pybind11</A>
								<DT><A HREF="https://github.com/cuda-mode/resource-stream">cuda-mode/resource-stream: CUDA related news and material links</A>
								<DT><A HREF="https://github.com/cuda-mode/lectures">cuda-mode/lectures: Material for cuda-mode lectures</A>
								<DT><A HREF="https://www.youtube.com/watch?v=u70a9ssZnjI&list=LL&index=17">George Hotz | Programming | cherry computer: no more superscalar? the thneed lesson - YouTube</A>
								<DT><A HREF="https://blog.speechmatics.com/pointless-gpu-optimization-exercise">An Almost Pointless Exercise in GPU Optimization</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">CUDA C++ Programming Guide</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/">CUDA C++ Best Practices Guide</A>
								<DT><A HREF="https://github.com/NVIDIA/multi-gpu-programming-models">NVIDIA/multi-gpu-programming-models: Examples demonstrating available options to program multiple GPUs</A>
								<DT><A HREF="https://leimao.github.io/blog/Row-Major-VS-Column-Major/">Row-Major VS Column-Major - Lei Mao's Log Book</A>
								<DT><A HREF="https://homepages.dcc.ufmg.br/~sylvain.collange/gpucourse/">Index of /~sylvain.collange/gpucourse</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#introduction">CUDA C++ Programming Guide</A>
								<DT><A HREF="https://www.youtube.com/watch?v=c8mQYGbT310">Introduction | GPU Programming | Episode 0 - YouTube</A>
								<DT><A HREF="https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/">CUDA Refresher: The CUDA Programming Model | NVIDIA Technical Blog</A>
								<DT><A HREF="https://www.youtube.com/watch?v=0-ztm8SKq70&t=977s">Stanford CS149 I Parallel Computing I 2023 I Lecture 4 - Parallel Programming Basics - YouTube</A>
								<DT><A HREF="https://github.com/chenzomi12/AISystem/blob/main/03Compiler/04Backend/04LoopOpt.pdf">AISystem/03Compiler/04Backend/04LoopOpt.pdf at main ¬∑ chenzomi12/AISystem</A>
								<DT><A HREF="https://www.youtube.com/watch?v=31ZyYkoClT4">Lecture 05 - Memory and Tiling - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-eoUw8fTy2E&t=4s">Lecture 11 - Scan (Kogge Stone) - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=XTfH6Ll9KaA">Lecture 15 - Sort - YouTube</A>
								<DT><A HREF="https://github.com/PaddleJitLab/CUDATutorial">PaddleJitLab/CUDATutorial: A self-learning tutorail for CUDA High Performance Programing.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=OUzm06YaUsI">George Hotz | how do GPUs work? (noob) + paper reading (not noob) | tinycorp.myshopify.com - YouTube</A>
								<DT><A HREF="https://dev.to/lewis_won/demystifying-gpus-from-core-architecture-to-scalable-systems-419l">Demystifying GPUs: From Core Architecture to Scalable Systems - DEV Community</A>
								<DT><A HREF="https://cvw.cac.cornell.edu/gpu-architecture">Cornell Virtual Workshop: Understanding GPU Architecture</A>
								<DT><A HREF="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">An Even Easier Introduction to CUDA (Updated) | NVIDIA Technical Blog</A>
								<DT><A HREF="https://www.cs.cmu.edu/~dskarlat/publications/lithos_sosp25.pdf">https://www.cs.cmu.edu/~dskarlat/publications/lithos_sosp25.pdf</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-docs</H3>
							<DL><p>
								<DT><H3 FOLDED>cuda-docs-md</H3>
								<DL><p>
									<DT><A HREF="https://x.com/msharmavikram/status/2001324157808820437">CUDA documentation in Markdown format - just append .md to the documentation URL</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/programming-model.html.md">https://docs.nvidia.com/cuda/cuda-programming-guide/01-introduction/programming-model.html.md CUDA markdown docs</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>PTX-Parallel Thread Execution</H3>
							<DL><p>
								<DT><H3 FOLDED>ptx-docs</H3>
								<DL><p>
									<DT><A HREF="https://x.com/vega_myhre/status/2011296883680199000">(1) Daniel Vega-Myhre en X: "@MattJBorowski honestly the TE ptx utils have better examples than the actual docs imo: https://t.co/ObOG9mBH6W for wgmma this code has good examples: https://t.co/tpxo744gnK for tcgen05 instructions, @gaunernst has a great post covering those: https://t.co/IBpw7SdkXX" / X</A>
									<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/blob/main/transformer_engine/common/util/ptx.cuh">TransformerEngine/transformer_engine/common/util/ptx.cuh at main ¬∑ NVIDIA/TransformerEngine</A>
									<DT><A HREF="https://github.com/pranjalssh/fast.cu">pranjalssh/fast.cu: Fastest kernels written from scratch</A>
									<DT><A HREF="https://gau-nernst.github.io/tcgen05/">tcgen05 for dummies - gau-nernst's blog</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-theory</H3>
								<DL><p>
									<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/10/05/ptx-mental-model.html">PTX Mental Model - Hyunsung Lee's Blog</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/">1. Introduction ‚Äî PTX ISA 9.0 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>NVVM IR</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cuda-samples/tree/master/Samples/7_libNVVM">cuda-samples/Samples/7_libNVVM at master ¬∑ NVIDIA/cuda-samples</A>
								</DL><p>
								<DT><H3 FOLDED>CTA Cooperative Thread Array</H3>
								<DL><p>
									<DT><A HREF="https://www.together.ai/blog/thunderkittens-nvidia-blackwell-gpus#:~:text=There%E2%80%99s%20also%20a%20new%20layer,to%20227KB%20of%20shared%20memory">ThunderKittens Now Optimized for NVIDIA Blackwell GPUs</A>
								</DL><p>
								<DT><H3 FOLDED>source-in-ptx</H3>
								<DL><p>
									<DT><A HREF="https://forums.developer.nvidia.com/t/how-to-see-ptx-cu-source-code/220043">How to see PTX/CU/source code? - Developer Tools / Nsight Compute - NVIDIA Developer Forums</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/pdf/CUDA_Compiler_Driver_NVCC.pdf">NVIDIA CUDA Compiler Driver Release 12.4</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-isa-8.7</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/#warp-level-matrix-multiply-accumulate-instructions">1. Introduction ‚Äî PTX ISA 8.7 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-isa-8.5</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html">PTX ISA 8.5</A>
								</DL><p>
								<DT><H3 FOLDED>opal</H3>
								<DL><p>
									<DT><A HREF="https://github.com/kuterd/opal_ptx">kuterd/opal_ptx: Experimental GPU language with meta-programming</A>
								</DL><p>
								<DT><H3 FOLDED>inline-ptx</H3>
								<DL><p>
									<DT><A HREF="https://veitner.bearblog.dev/a-short-note-on-tensorcores-and-inline-ptx-assembly/">A short note on Tensorcores and Inline PTX Assembly | simons blog</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-matmul</H3>
								<DL><p>
									<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/10/05/ptx-mental-model.html">PTX Mental Model - Hyunsung Lee's Blog</A>
									<DT><A HREF="https://github.com/ita9naiwa/playground/tree/master/ptx-playground">playground/ptx-playground at master ¬∑ ita9naiwa/playground</A>
									<DT><A HREF="https://github.com/ita9naiwa/playground/blob/master/ptx-playground/README.md">playground/ptx-playground/README.md at master ¬∑ ita9naiwa/playground</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-mma</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#wgmma-64n8-a">Examples of mma with block scale</A>
								</DL><p>
								<DT><H3 FOLDED>ptxas-blackwell</H3>
								<DL><p>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/c186592a17299439900d712e85556e8578345821/setup.py#L551">triton/setup.py</A>
								</DL><p>
								<DT><H3 FOLDED>asm-volatile</H3>
								<DL><p>
									<DT><A HREF="https://claude.ai/chat/530844a3-aca4-4b28-bdde-ab8c646a9dac">NVIDIA PTX register initialization in compiler explorer - Claude</A>
								</DL><p>
								<DT><H3 FOLDED>mapping-kernel-ptx</H3>
								<DL><p>
									<DT><A HREF="https://patricktoulme.substack.com/p/cutile-on-blackwell-nvidias-compiler">CuTile on Blackwell: NVIDIA's Compiler Moat Is Already Built</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-to-cute</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Noumena-Network/nmoe/blob/c71e591f8675637ab5c2ad4741935a91846f4115/nmoe/blockscaled/grouped.py#L168">nmoe/nmoe/blockscaled/grouped.py Decode inv_scale from an E8M0 byte (uint8): inv_scale = 2^(127 - byte)</A>
								</DL><p>
								<DT><H3 FOLDED>ptx-load_and_store</H3>
								<DL><p>
									<DT><A HREF="https://veitner.bearblog.dev/load-and-store-matrices-efficently-with-ptx-instructions/">Load and store matrices efficently with PTX instructions: ldmatrix</A>
									<DT><A HREF="https://github.com/simveit/load_and_store">simveit/load_and_store: Learn about PTX instructions ldmatrix and stmatrix</A>
								</DL><p>
								<DT><A HREF="https://docs.nvidia.com/cuda/ptx-writers-guide-to-interoperability/index.html">PTX Writers Guide to Interoperability</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-mma">matrix-multiply-accumulate (mma)</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-ldmatrix">ldmatrix</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cp-async-bulk">cp.async.bulk</A>
								<DT><A HREF="https://github.com/openai/triton/blob/8a83b141fc832dfb83dac3f335b21f3efb888afd/python/triton/tools/compile.py#L18">triton: compile.py</A>
								<DT><A HREF="https://segmentfault.com/a/1190000041878026/en">Ê∑±Â∫¶Â≠¶‰π† - Practice torch.fx Part 1 - Pytorch-based Model Optimization Quantization Artifact - ‰∏™‰∫∫ÊñáÁ´† - SegmentFault ÊÄùÂê¶</A>
								<DT><A HREF="https://segmentfault.com/a/1190000041878026/en">Practice torch.fx Part 1 - Pytorch-based Model Optimization</A>
								<DT><A HREF="https://twitter.com/cis_female/status/1660390038226751490">microcode: ncu -k "kernel" --list-page sass --page source python3 file.py</A>
								<DT><A HREF="https://bruce-lee-ly.medium.com/nvidia-tensor-core-getting-started-with-mma-ptx-programming-508e44a6cb7d">Nvidia Tensor Core-Getting Started with MMA PTX Programming | by Bruce-Lee-LY | Medium</A>
								<DT><A HREF="https://www.tomshardware.com/tech-industry/artificial-intelligence/deepseeks-ai-breakthrough-bypasses-industry-standard-cuda-uses-assembly-like-ptx-programming-instead">DeepSeek's AI breakthrough bypasses industry-standard CUDA, uses Nvidia's assembly-like PTX programming instead | Tom's Hardware</A>
								<DT><A HREF="https://veitner.bearblog.dev/load-and-store-matrices-efficently-with-ptx-instructions/">Load and store matrices efficently with PTX instructions: ldmatrix</A>
								<DT><A HREF="https://github.com/ProjectPhysX/PTXprofiler">ProjectPhysX/PTXprofiler: A simple profiler to count Nvidia PTX assembly instructions of OpenCL/SYCL/CUDA kernels for roofline model analysis.</A>
								<DT><A HREF="https://github.com/cloneofsimo/ptx-tutorial-by-aislop/blob/main/sections/doc_main.pdf">ptx-tutorial-by-aislop/sections/doc_main.pdf at main ¬∑ cloneofsimo/ptx-tutorial-by-aislop</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/700921948">NVidia GPU Instruction Set Architecture - Integer Operations</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/695667044">NVidia GPU instruction set architecture - floating point operation</A>
								<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/02/07/wmma-matmul.html">Cuda Matmul with wmma - Hyunsung Lee's Blog</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/">1. Introduction ‚Äî PTX ISA 9.0 documentation</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html#blackwell-instruction-set">Blackwell Instruction Set</A>
							</DL><p>
							<DT><H3 FOLDED>NVCC</H3>
							<DL><p>
								<DT><H3 FOLDED>NVVM IR</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cuda-samples/tree/master/Samples/7_libNVVM">cuda-samples/Samples/7_libNVVM at master ¬∑ NVIDIA/cuda-samples</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-compilation</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/43de49e62fc0583e66d4561bf10698e640c6be21/examples/python/gemm/compile.py#L112">TiledCUDA/examples/python/gemm/compile.py at 43de49e62fc0583e66d4561bf10698e640c6be21 ¬∑ TiledTensor/TiledCUDA</A>
									<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/43de49e62fc0583e66d4561bf10698e640c6be21/examples/python/gemm/compile.py#L112">compile.py#L112</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/bdf733be55f0b323a8cf7cc6745a81c3f43cd7f0/hopper/setup.py#L163">flash-attention/hopper/setup.py at bdf733be55f0b323a8cf7cc6745a81c3f43cd7f0 ¬∑ Dao-AILab/flash-attention</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/bdf733be55f0b323a8cf7cc6745a81c3f43cd7f0/hopper/setup.py#L130">FlastAttention nvcc flags</A>
									<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/blob/master/pipeline-gemm/Makefile">cfx-article-src/pipeline-gemm/Makefile at master ¬∑ ColfaxResearch/cfx-article-src</A>
									<DT><A HREF="https://github.com/linkedin/Liger-Kernel/blob/main/src/liger_kernel/ops/utils.py">Liger-Kernel/src/liger_kernel/ops/utils.py at main ¬∑ linkedin/Liger-Kernel</A>
									<DT><A HREF="https://github.com/moderngpu/moderngpu/wiki/Getting-started#cloning-the-source">Getting started ¬∑ moderngpu/moderngpu Wiki</A>
									<DT><A HREF="https://github.com/pranjalssh/fast.cu/blob/main/logs.txt">fast.cu/logs.txt at main ¬∑ pranjalssh/fast.cu</A>
									<DT><A HREF="https://docs.cedana.ai/setup/gpu-checkpointing">Cedana</A>
									<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/master/examples/python/gemm/compile.py">TiledCUDA/examples/python/gemm/compile.py at master ¬∑ TiledTensor/TiledCUDA</A>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/cutlass/compile.py">TiledBench/benchs/python/gemm/cutlass/compile.py at master nvcc -std=c++20 -03 --use_fast_math</A>
									<DT><A HREF="https://github.com/StuartSul/gpu-experiments/commit/01965457bf998f8c314a8dab921403b399e96dc5">Add ¬∑ StuartSul/gpu-experiments@0196545 blackwell/Makefile</A>
									<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/0f16757edc065603bb19e0457c34a451c5d7c042/examples/matmul/this-sm100/test_this_perf.py#L114">MatmulTutorial/examples/matmul/this-sm100/test_this_perf.py at 0f16757edc065603bb19e0457c34a451c5d7c042 ¬∑ KnowingNothing/MatmulTutorial</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/79c1559f69972e576e1db6fffec40fe403348d31/tinygrad/runtime/support/compiler_cuda.py#L45">tinygrad/tinygrad/runtime/support/compiler_cuda.py at 79c1559f69972e576e1db6fffec40fe403348d31 ¬∑ tinygrad/tinygrad</A>
								</DL><p>
								<DT><H3 FOLDED>ninja</H3>
								<DL><p>
									<DT><A HREF="https://github.com/search?q=repo%3ATiledTensor%2FTiledCUDA+proc&type=code">make -j$(proc)</A>
								</DL><p>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">CUDA NVCC</A>
								<DT><A HREF="https://leimao.github.io/blog/CUDA-Compilation/">CUDA Compilation - Lei Mao's Log Book</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html#nvcc-command-options">NVIDIA CUDA Compiler Driver</A>
							</DL><p>
							<DT><H3 FOLDED>asm-volatile</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/sophiawisdom/88b48f7146deb0d35c09506dd3a9c09e">invocation: TORCH_CUDA_ARCH_LIST=9.0a PYTORCH_NO_CUDA_MEMORY_CACHING=1 compute-sanitizer python3 test.py</A>
								<DT><A HREF="https://triton-lang.org/main/python-api/generated/triton.language.inline_asm_elementwise.html#triton.language.inline_asm_elementwise">triton.language.inline_asm_elementwise ‚Äî Triton documentation</A>
							</DL><p>
							<DT><H3 FOLDED>cubin</H3>
							<DL><p>
								<DT><H3 FOLDED>cuobjdump</H3>
								<DL><p>
									<DT><A HREF="https://patricktoulme.substack.com/p/cutile-on-blackwell-nvidias-compiler">CuTile on Blackwell: NVIDIA's Compiler Moat Is Already Built</A>
								</DL><p>
								<DT><H3 FOLDED>CUTracer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookresearch/CUTracer">facebookresearch/CUTracer: A dynamic binary instrumentation tool for tracing and analyzing CUDA kernel instructions.</A>
								</DL><p>
								<DT><A HREF="https://github.com/facebookresearch/CUTracer">facebookresearch/CUTracer: A dynamic binary instrumentation tool for tracing and analyzing CUDA kernel instructions.</A>
								<DT><A HREF="https://twitter.com/cHHillee/status/1779141387876962469">Triton kernels can be precompiled into .cubin files</A>
								<DT><A HREF="https://github.com/VivekPanyam/cudaparsers">VivekPanyam/cudaparsers: Parsers for CUDA binary files</A>
								<DT><A HREF="https://github.com/Narsil/kernels_triton/blob/main/src/main.rs">kernels_triton/src/main.rs at main ¬∑ Narsil/kernels_triton</A>
								<DT><A HREF="https://github.com/flashinfer-ai/cubloaty">flashinfer-ai/cubloaty: a size profiler for cuda binary</A>
							</DL><p>
							<DT><H3 FOLDED>cudarc</H3>
							<DL><p>
								<DT><A HREF="https://github.com/akhildevelops/cudaz">akhildevelops/cudaz: A Zig Cuda wrapper</A>
								<DT><A HREF="https://github.com/coreylowman/cudarc/tree/main">coreylowman/cudarc: Safe rust wrapper around CUDA toolkit</A>
								<DT><A HREF="https://leimao.github.io/blog/Proper-CUDA-Error-Checking/">Proper CUDA Error Checking - Lei Mao's Log Book</A>
								<DT><A HREF="https://github.com/Narsil/axum_cudarc/blob/main/src/main.rs">axum_cudarc/src/main.rs at main ¬∑ Narsil/axum_cudarc</A>
							</DL><p>
							<DT><H3 FOLDED>sass</H3>
							<DL><p>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html">1. Overview ‚Äî cuda-binary-utilities (SaSS)</A>
								<DT><A HREF="https://github.com/openai/triton/blob/8a83b141fc832dfb83dac3f335b21f3efb888afd/python/triton/tools/disasm.py#L69">triton: disasm.py#L69</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1825109774620311700">Sass syntax highlighting and CFG visualization in browser. (Kuter Dinel)</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1821658410804506752">Python DSL to directly write ptx</A>
								<DT><A HREF="https://github.com/kuterd/sass_graph/tree/master">kuterd/sass_graph: NVIDIA Sass binary CFG graph visualization tool.</A>
								<DT><A HREF="https://kuterdinel.com/nvidia-sass-control-code-viewer.html">Nvidia SASS Control Code Viewer ‚Ä¢ Kuter Dinel's blog</A>
								<DT><A HREF="https://www.youtube.com/watch?v=we3i5VuoPWk">Lecture 37: Introduction to SASS &amp; GPU Microarchitecture - YouTube</A>
								<DT><A HREF="https://modal.com/gpu-glossary/device-hardware/tensor-core">What is a Tensor Core? | GPU Glossary</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1905661136134739622">Introduction to Nvidia GPU SASS instruction set</A>
								<DT><A HREF="https://www.youtube.com/watch?si=cVJ4PNgGkoQbFXAb&v=we3i5VuoPWk&feature=youtu.be">Lecture 37: Introduction to SASS &amp; GPU Microarchitecture - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-kernels</H3>
							<DL><p>
								<DT><H3 FOLDED>Apex</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/apex">NVIDIA/apex: A PyTorch Extension: Tools for easy mixed precision and distributed training in Pytorch</A>
									<DT><A HREF="https://nvidia.github.io/apex/">Apex (A PyTorch Extension) ‚Äî Apex 0.1.0 documentation</A>
									<DT><A HREF="https://github.com/cat-state/tinypar">cat-state/tinypar</A>
									<DT><A HREF="https://github.com/stas00/tinypar">stas00/tinypar: TP/PP/DP implementation of llama using apex blocks</A>
									<DT><A HREF="https://github.com/cat-state/tinypar/blob/main/llama.py#L130">tinypar/llama.py at main ¬∑ cat-state/tinypar</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-tensor-cores</H3>
								<DL><p>
									<DT><H3 FOLDED>tensor-cores-V100</H3>
									<DL><p>
										<DT><A HREF="https://www.olcf.ornl.gov/wp-content/uploads/2019/11/ORNL_Tensor_Core_Training_Aug2019.pdf">VOLTA TENSOR CORE TRAINING (ORNL)</A>
									</DL><p>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/discussions/4066">Tinygrad: CUDA Tensor Core Integration #2684</A>
									<DT><A HREF="https://github.com/jbaron34/torchwindow">jbaron34/torchwindow: Display tensors directly from GPU</A>
									<DT><A HREF="https://developer.nvidia.com/gtc/2020/video/s21745-vid">GTC 2020: Developing CUDA kernels to push Tensor | NVIDIA Developer</A>
									<DT><A HREF="https://ieeexplore.ieee.org/abstract/document/9139835">Demystifying Tensor Cores to Optimize Half-Precision Matrix Multiply | IEEE Conference Publication | IEEE Xplore</A>
									<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/">CUTLASS Tutorial: Fast Matrix-Multiplication with WGMMA on NVIDIA¬Æ Hopper‚Ñ¢ GPUs ‚Äì Colfax Research</A>
									<DT><A HREF="https://leimao.github.io/blog/NVIDIA-Tensor-Core-Programming/">NVIDIA Tensor Core Programming - Lei Mao's Log Book</A>
									<DT><A HREF="http://iliasmirnov.com/tensor/">Comparing CUDA and Tensor Cores for Training Neural Networks</A>
									<DT><A HREF="https://blog.sina.com.cn/s/blog_56ab14d50102yv82.html">ÁêÜËß£TensorCore_Ë±ÜÈ•≠ÁöÑÂ∞èÁ™ù_Êñ∞Êµ™ÂçöÂÆ¢</A>
									<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/blob/master/Cuda/tensor_core/README.md">DLFrameworkTest/Cuda/tensor_core/README.md at master ¬∑ lcy-seso/DLFrameworkTest</A>
									<DT><A HREF="https://semianalysis.com/2025/06/23/nvidia-tensor-core-evolution-from-volta-to-blackwell/">NVIDIA Tensor Core Evolution: From Volta To Blackwell ‚Äì SemiAnalysis</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-launch_kernel</H3>
								<DL><p>
									<DT><A HREF="https://gist.github.com/malfet/790a78754ad22fb5bcc67939e5760c69">launch_kernel.cu</A>
								</DL><p>
								<DT><A HREF="https://github.com/enp1s0/cutf">enp1s0/cutf: CUDA Template Functions</A>
								<DT><A HREF="https://jhui.github.io/2017/03/06/CUDA/">‚ÄúCUDA Tutorial‚Äù</A>
								<DT><A HREF="https://github.com/mcarilli/cuda-memory/tree/master">mcarilli/cuda-memory: Playing around with GPU memory optimization</A>
								<DT><A HREF="https://github.com/cuda-mode/triton-index">cuda-mode/triton-index: Cataloging released Triton kernels.</A>
								<DT><A HREF="https://github.com/cuda-mode/triton-index/blob/main/kernel_overview.md">triton-index/kernel_overview.md</A>
								<DT><A HREF="https://gist.github.com/malfet/cc813faf85052f4b8e11c4efeda56c85">hello.cu</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-graphs</H3>
							<DL><p>
								<DT><H3 FOLDED>cuda-graphs-debug</H3>
								<DL><p>
									<DT><A HREF="https://github.com/flashinfer-ai/debug-print?tab=readme-ov-file">flashinfer-ai/debug-print: Debug print operator for cudagraph debugging</A>
									<DT><A HREF="https://github.com/flashinfer-ai/debug-print/blob/main/example.py">debug-print/example.py at main ¬∑ flashinfer-ai/debug-print</A>
								</DL><p>
								<DT><A HREF="https://developer.nvidia.com/blog/cuda-graphs/">Getting Started with CUDA Graphs | NVIDIA Technical Blog</A>
								<DT><A HREF="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/">Accelerating PyTorch with CUDA Graphs | PyTorch</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/issues/99397">Internal errors with cuda graph (CUBLAS_STATUS_NOT_INITIALIZED and jit failure) ¬∑ Issue #99397 ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/understanding-cudagraph-trees/1967">Understanding CUDAGraph Trees - compiler - PyTorch Developer Mailing List</A>
								<DT><A HREF="https://fireworks.ai/blog/speed-python-pick-two-how-cuda-graphs-enable-fast-python-code-for-deep-learning">Speed, Python: Pick Two. How CUDA Graphs Enable Fast Python Code for Deep Learning</A>
								<DT><A HREF="https://github.com/flashinfer-ai/debug-print">flashinfer-ai/debug-print: Debug print operator for cudagraph debugging</A>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/78f87d5a0c7d82911a639c397577284868a53c42/server/text_generation_server/models/flash_causal_lm.py#L690">cuda_graph_warmup</A>
							</DL><p>
							<DT><H3 FOLDED>cccl</H3>
							<DL><p>
								<DT><H3 FOLDED>llm.cpp</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=WiB_3Csfj_Q">CUDA C++ llm.cpp - YouTube</A>
									<DT><A HREF="https://github.com/karpathy/llama2.c">karpathy/llama2.c: Inference Llama 2 in one file of pure C</A>
									<DT><A HREF="https://github.com/gevtushenko/llm.c">gevtushenko/llm.c: LLM training in simple, raw C/CUDA</A>
								</DL><p>
								<DT><H3 FOLDED>Thrust</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/thrust/index.html">Thrust</A>
									<DT><A HREF="https://thrust.github.io/">Thrust - Parallel Algorithms Library</A>
									<DT><A HREF="https://github.com/NVIDIA/thrust">NVIDIA/thrust: The C++ parallel algorithms library.</A>
									<DT><H3 FOLDED>Fancy Iterators</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/archive/12.0.0/pdf/Thrust_Quick_Start_Guide.pdf">Thrust_Quick_Start_Guide.pdf</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zlJg9mCNfkQ">Thrust and the C++ Standard Algorithms - Conor Hoekstra - GTC 2021 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=W2tWOdzgXHA">GoingNative 2013 C++ Seasoning</A>
									<DT><A HREF="https://www.youtube.com/watch?v=h4Jl1fk3MkQ">CppCon 2016: Marshall Clow ‚ÄúSTL Algorithms - why you should use them, and how to write your own" - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=2olsGf6JIkU">CppCon 2018: Jonathan Boccara ‚Äú105 STL Algorithms in Less Than an Hour‚Äù - YouTube</A>
									<DT><A HREF="https://github.com/codereport/Content/tree/main/Talks">Content/Talks at main ¬∑ codereport/Content</A>
									<DT><A HREF="https://github.com/codereport/Content/tree/main/Talks/2021-04-GTC/ThrustAndTheCppStandardAlgorithms">Content/Talks/2021-04-GTC/ThrustAndTheCppStandardAlgorithms</A>
									<DT><A HREF="https://research.nvidia.com/publication/2011-10_thrust-productivity-oriented-library-cuda">Thrust: A Productivity-Oriented Library for CUDA | Research</A>
									<DT><A HREF="https://developer.nvidia.com/blog/expressive-algorithmic-programming-thrust/">Expressive Algorithmic Programming with Thrust | NVIDIA Technical Blog</A>
									<DT><A HREF="https://github.com/nvlabs/parrot">NVlabs/parrot: Parrot is a C++ library for fused array operations using CUDA/Thrust. It provides efficient GPU-accelerated operations with lazy evaluation semantics, allowing for chaining of operations without unnecessary intermediate materializations.</A>
								</DL><p>
								<DT><H3 FOLDED>cccl-python</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/delivering-the-missing-building-blocks-for-nvidia-cuda-kernel-fusion-in-python/?linkId=100000372911291">Delivering the Missing Building Blocks for NVIDIA CUDA Kernel Fusion in Python | NVIDIA Technical Blog</A>
									<DT><A HREF="https://x.com/PyTorch/status/1945565108924538890">(1) PyTorch en X: "From @nvidia: new cuda.cccl library introduces Pythonic building blocks for CUDA kernel fusion, making it easier to implement or extend libraries like PyTorch and compose efficient GPU algorithms using PyTorch tensors. üîó https://t.co/28pXVLpBIY #PyTorch #CUDA #Python" / X</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=WiB_3Csfj_Q">CUDA C++ llm.cpp - YouTube</A>
								<DT><A HREF="https://github.com/NVIDIA/cccl">NVIDIA/cccl: CUDA C++ Core Libraries</A>
								<DT><A HREF="https://github.com/eyalroz/cuda-api-wrappers">eyalroz/cuda-api-wrappers: Thin, unified, C++-flavored wrappers for the CUDA APIs</A>
								<DT><A HREF="https://nyc2024.pydata.org/cfp/talk/TX3CBB/">Accelerating GPU Algorithms in pure Python :: PyData NYC 2024 :: pretalx</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-python</H3>
							<DL><p>
								<DT><H3 FOLDED>pycuda</H3>
								<DL><p>
									<DT><A HREF="https://github.com/inducer/pycuda">inducer/pycuda: CUDA integration for Python, plus shiny features</A>
									<DT><A HREF="https://documen.tician.de/pycuda/driver.html">Device Interface</A>
									<DT><A HREF="https://forums.developer.nvidia.com/t/pycuda-best-practice-to-keep-c-kernels-separate-from-python-code/72829/4">load_kernels</A>
								</DL><p>
								<DT><A HREF="https://github.com/NVIDIA/cuda-python">NVIDIA/cuda-python: CUDA Python Low-level Bindings</A>
								<DT><A HREF="https://github.com/inducer/pyopencl">inducer/pyopencl: OpenCL integration for Python, plus shiny features</A>
								<DT><A HREF="https://github.com/MatthieuDartiailh/pyclibrary">MatthieuDartiailh/pyclibrary: C parser and ctypes automation for python</A>
								<DT><A HREF="https://github.com/trolldbois/ctypeslib/blob/master/ctypeslib/clang2py.py">clang2py.py</A>
							</DL><p>
							<DT><H3 FOLDED>CUTLASS</H3>
							<DL><p>
								<DT><H3 FOLDED>cutlass-build</H3>
								<DL><p>
									<DT><A HREF="https://claude.ai/chat/8ff889d1-bd26-4939-94b4-7bdaa22b63c6">Troubleshooting CUTLASS Source Code Build - Claude</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-learning</H3>
								<DL><p>
									<DT><H3 FOLDED>cutlass-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/leimao/CUTLASS-Examples">leimao/CUTLASS-Examples: CUTLASS and CuTe Examples</A>
										<DT><A HREF="https://github.com/lcy-seso/cutlass-example">lcy-seso/cutlass-example</A>
									</DL><p>
									<DT><A HREF="https://www.zhihu.com/question/616201301/answer/1891185975633347028">Â¶Ç‰ΩïÂ≠¶‰π†cutlass‰ª•ËææÂà∞ÁÜüÁªÉÊéåÊè°Ôºü - Áü•‰πé</A>
									<DT><A HREF="https://www.kapilsharma.dev/posts/learn-cutlass-the-hard-way-2/">Learn CUTLASS the hard way - part 2! | Kapil Sharma</A>
									<DT><A HREF="https://github.com/zartbot/learn_cutlass/blob/main/inter_conn/cublas_with_ldst.cu">learn_cutlass/inter_conn/cublas_with_ldst.cu at main ¬∑ zartbot/learn_cutlass</A>
									<DT><A HREF="https://github.com/ArthurinRUC/cutlass-notes/tree/main/14-warp-specialization">cutlass-notes/14-warp-specialization at main ¬∑ ArthurinRUC/cutlass-notes</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-docs</H3>
								<DL><p>
									<DT><H3 FOLDED>cutlass-gemm-api</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/cutlass/media/docs/cpp/gemm_api_3x.html">CUTLASS 3.0 GEMM API ‚Äî NVIDIA CUTLASS Documentation</A>
									</DL><p>
									<DT><A HREF="https://docs.nvidia.com/cutlass/media/docs/cpp/layout.html">Layouts and Tensors ‚Äî NVIDIA CUTLASS Documentation</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-debug</H3>
								<DL><p>
									<DT><H3 FOLDED>cutlass-env-vars</H3>
									<DL><p>
										<DT><H3 FOLDED>ftemplate-backtrace-limit=0</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>use_fast_math</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>resource-usage</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>lineinfo</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>DCUTLASS_ENABLE_GDC_FOR_SM90</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>DCUTLASS_DEBUG_TRACE_LEVEL</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>gencode</H3>
										<DL><p>
										</DL><p>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>cutlass-python</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/cutlass/compile.py">TiledBench/benchs/python/gemm/cutlass/compile.py</A>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/cutlass/cutlass_gemm.cuh">TiledBench/benchs/python/gemm/cutlass/cutlass_gemm.cuh</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-dsl</H3>
								<DL><p>
									<DT><H3 FOLDED>CuTe</H3>
									<DL><p>
										<DT><H3 FOLDED>cute-learning</H3>
										<DL><p>
											<DT><A HREF="https://developer.nvidia.com/blog/cutlass-principled-abstractions-for-handling-multidimensional-data-through-tensors-and-spatial-microkernels/">CUTLASS: Principled Abstractions for Handling Multidimensional Data Through Tensors and Spatial Microkernels | NVIDIA Technical Blog</A>
											<DT><A HREF="https://github.com/DD-DuDa/Cute-Learning">DD-DuDa/Cute-Learning: Examples of CUDA implementations by Cutlass CuTe</A>
											<DT><A HREF="https://github.com/CalebDu/Awesome-Cute">CalebDu/Awesome-Cute</A>
											<DT><A HREF="https://github.com/leimao/CUTLASS-Examples/blob/f06835a42eecd52f30c8292b4b911e01fe1b02da/README.md">CUTLASS-Examples/README.md</A>
											<DT><A HREF="https://github.com/Maharshi-Pandya/cutlass-codes">Maharshi-Pandya/cutlass-codes: Dedicated repository for cutlass/cute related programs</A>
											<DT><A HREF="https://docs.nvidia.com/cutlass/latest/media/docs/cpp/cute/00_quickstart.html">Getting Started With CuTe ‚Äî NVIDIA CUTLASS Documentation</A>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/b1d6e2c9b334dfa811e4183dfbd02419249e4b52/examples/python/CuTeDSL/blackwell/tutorial_gemm/fp16_gemm_0.py">cutlass/examples/python/CuTeDSL/blackwell/tutorial_gemm/fp16_gemm_0.py at b1d6e2c9b334dfa811e4183dfbd02419249e4b52 ¬∑ NVIDIA/cutlass</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/1918927108006188667">Preliminary Practice of CuTeDSL (CUTLASS Python)</A>
										</DL><p>
										<DT><H3 FOLDED>cute-lectures</H3>
										<DL><p>
											<DT><A HREF="https://llvm.org/devmtg/2025-10/slides/technical_talks/ozen.pdf">CUTLASS Python DSL Infrastructure</A>
										</DL><p>
										<DT><H3 FOLDED>tensor-algebra</H3>
										<DL><p>
											<DT><A HREF="https://leimao.github.io/article/CuTe-Layout-Algebra/">CuTe Layout Algebra - Lei Mao's Log Book</A>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md">CuTe Layouts</A>
											<DT><A HREF="https://research.colfax-intl.com/a-note-on-the-algebra-of-cute-layouts/">A note on the algebra of CuTe Layouts ‚Äì Colfax Research</A>
											<DT><A HREF="https://github.com/leimao/CUTLASS-Examples/blob/f06835a42eecd52f30c8292b4b911e01fe1b02da/examples/cute_tiled_mma_preview/cute_tiled_mma_preview.cu">CUTLASS-Examples/examples/cute_tiled_mma_preview/cute_tiled_mma_preview.cu at f06835a42eecd52f30c8292b4b911e01fe1b02da ¬∑ leimao/CUTLASS-Examples</A>
											<DT><A HREF="https://veitner.bearblog.dev/bridging-math-and-code-cute-layout-algebra-in-cutedsl/">Bridging Math and Code: CuTe Layout Algebra in CuTeDSL | simons blog</A>
										</DL><p>
										<DT><H3 FOLDED>cute-numerics</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>cute-profiling</H3>
										<DL><p>
											<DT><H3 FOLDED>cute-intra-kernel-profiling</H3>
											<DL><p>
												<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/main/transformer_nuggets/cute/profiler/README.md">transformer_nuggets/transformer_nuggets/cute/profiler/README.md at main ¬∑ drisspg/transformer_nuggets</A>
												<DT><A HREF="https://gau-nernst.github.io/amd-a2a/#intra-kernel-profiling">gau-nernst's intra-kernel profiling for AMD MI300X</A>
												<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/main/transformer_nuggets/cute/profiler/example.py">transformer_nuggets/transformer_nuggets/cute/profiler/example.py at main ¬∑ drisspg/transformer_nuggets</A>
												<DT><A HREF="https://x.com/drisspg/status/2005035848270835808">(1) driss guessous en X: "A look inside the beast: https://t.co/gvAv8zyLi0" / X</A>
												<DT><A HREF="https://github.com/gau-nernst/learn-cuda/blob/3b90ac9b3f624bdf1f6f78d02dcd533675d36573/02e_matmul_sm100/main.py#L89">learn-cuda/02e_matmul_sm100/main.py profile</A>
											</DL><p>
											<DT><A HREF="https://github.com/Dao-AILab/quack/blob/3d0ab3ec2164749caac8f269f771e66a40efd2de/quack/gemm_sm100.py#L78">ncu python examples/blackwell/dense_gemm_persistent.py</A>
										</DL><p>
										<DT><H3 FOLDED>cute-compiler</H3>
										<DL><p>
											<DT><A HREF="https://veitner.bearblog.dev/let-the-compiler-do-the-work-in-cutedsl/">Let the compiler do the work in CuTeDSL | simons blog</A>
											<DT><A HREF="https://x.com/snowclipsed/status/2015789861165215878">what makes CuTe DSL compile times vary? getting some seriously high compile times right now. Needs to compile all possible problem shapes and there is a vairable that is causing the shape count to explode</A>
										</DL><p>
										<DT><H3 FOLDED>cute-layouts</H3>
										<DL><p>
											<DT><H3 FOLDED>cute-layouts-categorical</H3>
											<DL><p>
												<DT><A HREF="https://research.colfax-intl.com/categorical-foundations-for-cute-layouts/">Categorical Foundations for CuTe Layouts ‚Äì Colfax Research</A>
												<DT><A HREF="https://github.com/ColfaxResearch/layout-categories/tree/master">ColfaxResearch/layout-categories: This repository contains companion software for the Colfax Research paper "Categorical Foundations for CuTe Layouts".</A>
												<DT><A HREF="https://github.com/ColfaxResearch/layout-categories/blob/master/tract/examples/example_notebook.ipynb">layout-categories/tract/examples/example_notebook.ipynb at master ¬∑ ColfaxResearch/layout-categories</A>
											</DL><p>
											<DT><H3 FOLDED>cute-hierarchical-layout</H3>
											<DL><p>
												<DT><A HREF="https://veitner.bearblog.dev/intuition-behind-hierarchical-layouts/">Intuition behind Hierarchical Layouts | simons blog</A>
												<DT><A HREF="https://blog.ezyang.com/2025/08/you-could-have-invented-cute-hierarchical-layout-but-maybe-not-the-rest-of-it/">You could have invented CuTe hierarchical layout (but maybe not the rest of it?) : ezyang's blog</A>
											</DL><p>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md">CuTe Layouts</A>
											<DT><A HREF="https://x.com/ezyang/status/1962364978393981433">(1) Edward Z. Yang en X: "A Short Note About Complements of CuTe Layout</A>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/2b8dff1f90605452c378c02298dd0cacaf65753c/media/docs/cpp/layout.md?plain=1#L4">cutlass/media/docs/cpp/layout.md</A>
											<DT><A HREF="https://kuterdinel.com/cute-layout-visualizer.html">CuTe Layout Visualizer ‚Ä¢ Kuter Dinel's blog</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/661182311">cute ‰πã Layout - Áü•‰πé</A>
											<DT><A HREF="https://github.com/NTT123/cute-viz">NTT123/cute-viz: Cute layout visualization</A>
										</DL><p>
										<DT><H3 FOLDED>cute-slicing</H3>
										<DL><p>
											<DT><A HREF="https://veitner.bearblog.dev/tensors-slicing-in-cute/">Tensors Slicing in CuTe | simons blog</A>
										</DL><p>
										<DT><H3 FOLDED>cute-utils</H3>
										<DL><p>
											<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/ea8fbfdcdcbe760617b8056a4e6e021d3a096e39/transformer_nuggets/cute/utils.py">transformer_nuggets/transformer_nuggets/cute/utils.py at ea8fbfdcdcbe760617b8056a4e6e021d3a096e39 ¬∑ drisspg/transformer_nuggets</A>
											<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/blob/3e60597ad324f9e6ea261843daf1de6d2a6f5214/flashinfer/cute_dsl/utils.py#L29">flashinfer/flashinfer/cute_dsl/utils.py at 3e60597ad324f9e6ea261843daf1de6d2a6f5214 ¬∑ flashinfer-ai/flashinfer</A>
											<DT><A HREF="https://github.com/Dao-AILab/flash-attention/tree/13380067063e1861f6bd355efec2b8d369c01ecf/flash_attn/cute">flash-attention/flash_attn/cute</A>
											<DT><A HREF="https://github.com/HanGuo97/cutedsl-utilities">HanGuo97/cutedsl-utilities</A>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/b1d6e2c9b334dfa811e4183dfbd02419249e4b52/python/CuTeDSL/cutlass/utils/tmem_allocator.py">cutlass/python/CuTeDSL/cutlass/utils/tmem_allocator.py at b1d6e2c9b334dfa811e4183dfbd02419249e4b52 ¬∑ NVIDIA/cutlass</A>
										</DL><p>
										<DT><H3 FOLDED>cute-examples</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Dao-AILab/quack">Dao-AILab/quack: A Quirky Assortment of CuTe Kernels</A>
											<DT><A HREF="https://veitner.bearblog.dev/simple-reduction-in-cutedsl/">Simple reduction in CuTeDSL | simons blog</A>
											<DT><A HREF="https://github.com/aturker1/cutest/tree/main/rms_norm">cutest/rms_norm at main ¬∑ aturker1/cutest</A>
											<DT><A HREF="https://github.com/Chtholly-Boss/cute-dsl-example/blob/master/examples/hello.py">cute-dsl-example/examples/hello.py at master ¬∑ Chtholly-Boss/cute-dsl-example</A>
										</DL><p>
										<DT><H3 FOLDED>cp.async</H3>
										<DL><p>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/32486160866">Analysis of Prefetch Behavior of cp.async Based on CUTLASS CuTe</A>
											<DT><A HREF="https://x.com/SzymonOzog_/status/1975208526441324739">(2) SzymonOzog en X: "Interesting shift in GPU programming is the shift from parallel to parallel + async. Ampere was async loads Hopper was async loads + async wgmma ops Blackwell doesn't return values to registers but tensor memory When do we shrink the register file to save chip space? https://t.co/wmEdASdoTu" / X</A>
										</DL><p>
										<DT><H3 FOLDED>cute-quantization</H3>
										<DL><p>
											<DT><A HREF="https://x.com/_xjdr/status/2006473981852004451">MLIR/inline ptx is quantization, no python bindings for those atomics</A>
										</DL><p>
										<DT><H3 FOLDED>cute-internals</H3>
										<DL><p>
											<DT><A HREF="https://www.albresky.cn/cutlass-cutedsl-vs-cutecpp/">CuTe DSL V.S. CuTe C++ - Albresky's Blog</A>
										</DL><p>
										<DT><H3 FOLDED>cute-asm</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Noumena-Network/nmoe/blob/c71e591f8675637ab5c2ad4741935a91846f4115/nmoe/blockscaled/grouped.py#L125"># cvt.rn.satfinite.e4m3x2.f32 packs two f32 -&gt; one b16 (two FP8 bytes)
# PTX uses; .b16 register for packed output. Order: low byte = $2, high byte = $1.</A>
										</DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md">CuTe Layouts</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/00_quickstart.md">Getting Started With CuTe</A>
										<DT><A HREF="https://research.colfax-intl.com/a-note-on-the-algebra-of-cute-layouts/">A note on the algebra of CuTe Layouts ‚Äì Colfax Research</A>
										<DT><A HREF="https://github.com/reed-lau/cute-gemm/blob/main/gemm-simple.cu">cute-gemm/gemm-simple.cu at main ¬∑ reed-lau/cute-gemm</A>
										<DT><A HREF="https://github.com/reed-lau/cute-gemm">reed-lau/cute-gemm</A>
										<DT><A HREF="https://github.com/weishengying/cute_gemm">weishengying/cute_gemm</A>
										<DT><A HREF="https://veitner.bearblog.dev/predication-in-cutlass/">Predication in Cutlass | simons blog</A>
										<DT><A HREF="https://leimao.github.io/blog/CuTe-Tiled-MMA/">CuTe Tiled MMA - Lei Mao's Log Book</A>
										<DT><A HREF="https://github.com/leimao/CUTLASS-Examples/blob/f06835a42eecd52f30c8292b4b911e01fe1b02da/examples/cute_tiled_mma_preview/cute_tiled_mma_preview.cu">CUTLASS-Examples/examples/cute_tiled_mma_preview/cute_tiled_mma_preview.cu at f06835a42eecd52f30c8292b4b911e01fe1b02da ¬∑ leimao/CUTLASS-Examples</A>
										<DT><A HREF="https://github.com/alexarmbr/cute_kernels">alexarmbr/cute_kernels</A>
										<DT><A HREF="https://veitner.bearblog.dev/thread-value-layouts-in-cute/">Thread Value Layouts in CuTe | simons blog</A>
										<DT><A HREF="https://veitner.bearblog.dev/mma-atoms-in-cute/">MMA Atoms in CuTe | simons blog</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/examples/python/CuTeDSL/notebooks/benchmark_autotune.ipynb">cutlass/examples/python/CuTeDSL/notebooks/benchmark_autotune.ipynb at main ¬∑ NVIDIA/cutlass</A>
										<DT><A HREF="https://hc2025.hotchips.org/assets/program/tutorials/dsl_llm_kernels.pdf">https://hc2025.hotchips.org/assets/program/tutorials/dsl_llm_kernels.pdf</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1973526710105419953">CuTe Notes for Advanced Developers: The permutationMNK Parameter of tiled mma</A>
									</DL><p>
									<DT><H3 FOLDED>cutlass-4.0</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/f115c3f85467d5d9619119d1dbeb9c03c3d73864">Release v4.0.0 (#2294) ¬∑ NVIDIA/cutlass@f115c3f</A>
									</DL><p>
									<DT><H3 FOLDED>cutlass-4.1</H3>
									<DL><p>
										<DT><A HREF="https://x.com/__tensorcore__/status/1947264550790730213">CUTLASS 4.1 is now available, which adds support for ARM systems (GB200) and block scaled MMAs</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/a1aaf2300a8fc3a8106a05436e1a2abad0930443">v4.1 release ¬∑ NVIDIA/cutlass@a1aaf23</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/a1aaf2300a8fc3a8106a05436e1a2abad0930443#diff-03faf8e3761a0c4da2786a2b7a0cb15cefcc776935582eed39770d7243ae4b1a">sm_100a and sm_100f support (GB200)</A>
									</DL><p>
									<DT><H3 FOLDED>cutlass-4.2</H3>
									<DL><p>
										<DT><A HREF="https://github.com/search?q=repo%3ANVIDIA%2Fcutlass+SM103&type=discussions">Support for Blackwell SM103 kernels for B300 GPUs</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/discussions/2649">CUTLASS 4.2.0 ¬∑ NVIDIA/cutlass ¬∑ Discussion #2649</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/74825181f2fb5f2c6d9b7a735ca514dd6b6986a0/examples/89_sm103_fp4_ultra_gemm/89_sm103_fp4_ultra_gemm.cu#L33">cutlass/examples/89_sm103_fp4_ultra_gemm/89_sm103_fp4_ultra_gemm.cu at 74825181f2fb5f2c6d9b7a735ca514dd6b6986a0 ¬∑ NVIDIA/cutlass</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/8825e8be4f0ee9b55ce6198271b7a16d6b473f02/examples/python/CuTeDSL/blackwell/dense_gemm.py">cutlass/examples/python/CuTeDSL/blackwell/dense_gemm.py at 8825e8be4f0ee9b55ce6198271b7a16d6b473f02 ¬∑ NVIDIA/cutlass</A>
									</DL><p>
									<DT><H3 FOLDED>cutlass-4.3</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/b1d6e2c9b334dfa811e4183dfbd02419249e4b52">v4.3 update. (#2709) ¬∑ NVIDIA/cutlass@b1d6e2c</A>
										<DT><A HREF="https://docs.nvidia.com/cutlass/latest/overview.html">Overview ‚Äî NVIDIA CUTLASS Documentation</A>
									</DL><p>
									<DT><H3 FOLDED>cuda.bindings</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/python/CuTeDSL/cutlass/torch.py#L32">cutlass/python/CuTeDSL/cutlass/torch.py at main ¬∑ NVIDIA/cutlass</A>
										<DT><A HREF="https://nvidia.github.io/cuda-python/cuda-bindings/latest/">cuda.bindings: Low-level Python Bindings for CUDA ‚Äî cuda.bindings</A>
										<DT><A HREF="https://nvidia.github.io/cuda-python/cuda-bindings/latest/release/13.0.3-notes.html">cuda-bindings 13.0.3 Release notes ‚Äî cuda.bindings</A>
									</DL><p>
									<DT><H3 FOLDED>tilus</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/tilus">NVIDIA/tilus: Tilus is a tile-level kernel programming language with explicit control over shared memory and registers.</A>
										<DT><A HREF="https://arxiv.org/abs/2504.12984">[2504.12984] Tilus: A Virtual Machine for Arbitrary Low-Precision GPGPU Computation in LLM Serving</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/f115c3f85467d5d9619119d1dbeb9c03c3d73864">Release v4.0.0 (#2294) ¬∑ NVIDIA/cutlass@f115c3f</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/examples/python/CuTeDSL/blackwell/dense_gemm_persistent.py">cutlass/examples/python/CuTeDSL/blackwell/dense_gemm_persistent.py at main ¬∑ NVIDIA/cutlass</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/tree/main/examples/python/CuTeDSL">cutlass/examples/python/CuTeDSL at main ¬∑ NVIDIA/cutlass</A>
									<DT><A HREF="https://www.piwheels.org/project/nvidia-cutlass-dsl/">piwheels - nvidia-cutlass-dsl</A>
									<DT><A HREF="https://colab.research.google.com/github/NVIDIA/cutlass/blob/main/examples/python/03_basic_conv2d.ipynb">03_basic_conv2d.ipynb - Colab</A>
									<DT><A HREF="https://x.com/tri_dao/status/1943372635351515227?s=46">I really like Phil Tillet's framing of different tools having different tradeoffs in productivity and performance: torch compile, triton, CUDA, PTX. It's still early but CuTe-DSL and similar Python-based DSL might bend this curve. And soon we can probably get LLMs to generate these kernels</A>
									<DT><A HREF="https://semianalysis.com/wp-content/uploads/2025/03/Blackwell-Programming-for-the-Masses-With-OpenAI-Triton-Phil-Tillet.pdf">Blackwell Programming for the Masses With OpenAI Triton</A>
									<DT><A HREF="https://www.youtube.com/watch?v=UEdGJGz8Eyg&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=61&pp=iAQB0gcJCQMKAYcqIYzv">The Future Is Tiled: Using CuTile &amp; TileIR To Write Portable, High-performance GPU...- Jared Roesch - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=5NXd6MbKYNQ&t=422s">2025 US LLVM Developers' Meeting: CUTLASS Python DSL Infrastructure - YouTube</A>
									<DT><A HREF="https://veitner.bearblog.dev/blackwell-pipelining-with-cutedsl/">Blackwell Pipelining with CuTeDSL | simons blog</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-blackwell</H3>
								<DL><p>
									<DT><H3 FOLDED>cutlass-sm120</H3>
									<DL><p>
										<DT><H3 FOLDED>sm120-gemm</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/tree/5e497243f7ad13a2aa842143f9b10bbb23d98292/examples/79_blackwell_geforce_gemm">cutlass/examples/79_blackwell_geforce_gemm at 5e497243f7ad13a2aa842143f9b10bbb23d98292 ¬∑ NVIDIA/cutlass</A>
										</DL><p>
										<DT><A HREF="https://gau-nernst.github.io/fa-5090/">Writing Speed-of-Light Flash Attention for 5090 in CUDA C++ - gau-nernst's blog</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cutlass">NVIDIA/cutlass: CUTLASS 3.8 first release that supports the NVIDIA Blackwell SM100 architecture</A>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72720/">Programming Blackwell Tensor Cores with CUTLASS | GTC 25 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s74639/">Enable Tensor Core Programming in Python with CUTLASS 4.0 | GTC 25 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cpp/blackwell_functionality.md">Blackwell functionality: Blackwell SM100 GEMMs</A>
								</DL><p>
								<DT><H3 FOLDED>ctulass-tma</H3>
								<DL><p>
									<DT><A HREF="https://research.colfax-intl.com/tutorial-hopper-tma/">CUTLASS Tutorial: Mastering the NVIDIA¬Æ Tensor Memory Accelerator (TMA) ‚Äì Colfax Research</A>
									<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/tree/master/tma">cfx-article-src/tma at master ¬∑ ColfaxResearch/cfx-article-src</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-visualization</H3>
								<DL><p>
									<DT><H3 FOLDED>print_latex</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/pull/1656">feat: allow print_latex(TiledMMA) to colorize sliced thread and add print_latex(ThrMMA) by cloudhan ¬∑ Pull Request #1656 ¬∑ NVIDIA/cutlass</A>
										<DT><A HREF="https://leimao.github.io/blog/CuTe-Tiled-MMA/">CuTe Tiled MMA cute::print_latex - (Lei Mao's Log)</A>
									</DL><p>
									<DT><H3 FOLDED>cutlass-viz</H3>
									<DL><p>
										<DT><A HREF="https://github.com/flashinfer-ai/cutlass-viz">flashinfer-ai/cutlass-viz</A>
									</DL><p>
									<DT><H3 FOLDED>TV-layout</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/Chillee/e2b07157caeade8c6b0bdf463d10f833">Cutlass Thread-Value Layout Visualizer</A>
										<DT><A HREF="https://x.com/cHHillee/status/1962351828349460876">(1) Horace He en X: "@difficultyang https://t.co/99jd4lWKxC" / X</A>
										<DT><A HREF="https://x.com/SemiAnalysis_/status/1949862435160285298">(1) SemiAnalysis en X: "How do you read CUTLASS CuTe Layout? The TV layout of matrix A (image lower left) is ((4, 8), (2, 2)) : (32, 1), (16, 8)). Here we derive the TV layout step by step. https://t.co/tzH3BdxxJT" / X</A>
									</DL><p>
									<DT><A HREF="https://github.com/flashinfer-ai/cutlass-viz">flashinfer-ai/cutlass-viz</A>
									<DT><A HREF="https://github.com/NTT123/cute-viz">NTT123/cute-viz: Cute layout visualization</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-predication</H3>
								<DL><p>
									<DT><A HREF="https://veitner.bearblog.dev/predication-in-cutlass/">Predication in Cutlass | simons blog</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-tuning</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/improving-gemm-kernel-auto-tuning-efficiency-on-nvidia-gpus-with-heuristics-and-cutlass-4-2/">Improving GEMM Kernel Auto-Tuning Efficiency on NVIDIA GPUs with Heuristics and CUTLASS 4.2 | NVIDIA Technical Blog</A>
									<DT><A HREF="https://pypi.nvidia.com/nvidia-matmul-heuristics/">nvidia-matmul-heuristics</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/ec8daf642d69fc31352ac6fa6e14a0de9019604b/examples/python/CuTeDSL/notebooks/benchmark_autotune.ipynb">cutlass/examples/python/CuTeDSL/notebooks/benchmark_autotune.ipynb</A>
									<DT><A HREF="https://zcnrex.github.io/2025/12/01/nvfp4-gemv.html">Blackwell NVFP4 Kernel Hackathon Part 1: GEMV kernel | Rex‚Äôs Blog</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-fp4</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/tree/main/examples/72_blackwell_narrow_precision_gemm">cutlass/examples/72_blackwell_narrow_precision_gemm at main ¬∑ NVIDIA/cutlass</A>
								</DL><p>
								<DT><H3 FOLDED>cuTile</H3>
								<DL><p>
									<DT><H3 FOLDED>cutile-theory</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=_b4I4rKpsGA">Lecture 89: cuTile (from friends at NVIDIA) - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>cutile-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TileGym/tree/main">NVIDIA/TileGym: Helpful kernel tutorials and examples for tile-based GPU programming</A>
										<DT><A HREF="https://github.com/dsl-learn/cutile-learn">dsl-learn/cutile-learn: NVIDIA cuTile learn</A>
									</DL><p>
									<DT><H3 FOLDED>cutile-compiler</H3>
									<DL><p>
										<DT><A HREF="https://patricktoulme.substack.com/p/cutile-on-blackwell-nvidias-compiler">CuTile on Blackwell: NVIDIA's Compiler Moat Is Already Built</A>
										<DT><A HREF="https://x.com/PatrickToulme/status/2015543905031238068">(1) Patrick C Toulme en X: "CuTile is really good - so good, I question how Triton will keep up. I compiled an MoE kernel on Blackwell with CuTile. 86 lines of Python. 1,900 lines of PTX. Nanosleep backoff. Leader election before every MMA. I didn't write any of that. The compiler did. New Blog on" / X</A>
									</DL><p>
									<DT><H3 FOLDED>cutile-mlir-passes</H3>
									<DL><p>
										<DT><A HREF="https://patricktoulme.substack.com/p/cutile-on-blackwell-nvidias-compiler">CuTile on Blackwell: NVIDIA's Compiler Moat Is Already Built</A>
									</DL><p>
									<DT><A HREF="https://www.linkedin.com/pulse/copy-cuda-tile-reflection-c-x-b-yun-jin-ubvic/">(1) CUDA Tile and the Reflection of C = A X B | LinkedIn</A>
									<DT><A HREF="https://github.com/NVIDIA/cuda-tile">NVIDIA/cuda-tile: CUDA Tile IR is an MLIR-based intermediate representation and compiler infrastructure for CUDA kernel optimization, focusing on tile-based computation patterns and optimizations targeting NVIDIA tensor core units.</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/tile-ir/latest/sections/prog_model.html">2. Programming Model ‚Äî Tile IR</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cutile-python/data.html">Data Model ‚Äî cuTile Python</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/commit/b45ed93b0f1affcdd74c7f6e4fd085041807bb32">Update on "[Inductor][NV Universal Gemm] Support kernels with workspa... ¬∑ pytorch/pytorch@b45ed93</A>
									<DT><A HREF="https://github.com/NVIDIA/cutile-python">NVIDIA/cutile-python: cuTile is a programming model for writing parallel kernels for NVIDIA GPUs</A>
								</DL><p>
								<DT><H3 FOLDED>Mixed-input matrix multiplication performance optimizations</H3>
								<DL><p>
									<DT><A HREF="https://blog.research.google/2024/01/mixed-input-matrix-multiplication.html">Mixed-input matrix multiplication performance optimizations ‚Äì Google Research Blog</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/pull/1084">Support for Mixed Input TensorOp by manishucsd ¬∑ Pull Request #1084 ¬∑ NVIDIA/cutlass</A>
								</DL><p>
								<DT><A HREF="https://github.com/NVIDIA/cutlass">NVIDIA/cutlass: CUDA Templates for Linear Algebra Subroutines</A>
								<DT><A HREF="https://www.youtube.com/watch?v=PWWOGrLZtZg">CUTLASS: A CUDA C++ Template Library for Accelerating Deep Learning... Aniket Shivam &amp; Vijay Thakkar - YouTube</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/00_quickstart.md">Getting Started With CuTe</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md">CuTe Layouts</A>
								<DT><A HREF="https://www.youtube.com/watch?v=yCyZEJrlrfY&t=126s">Lightning Talk: Harnessing NVIDIA Tensor Cores: An Exploration of CUTLASS &amp; OpenAI..- Matthew Nicely - YouTube</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/python/README.md">cutlass/python/README.md</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31883/">Accelerating Convolution with Tensor Cores in CUTLASS</A>
								<DT><A HREF="https://www.nvidia.com/ko-kr/on-demand/session/gtcspring22-s41996/">Accelerating Backward Data Gradient by Increasing Tensor Core Utilization in CUTLASS</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/pull/1084">Support for Mixed Input TensorOp by manishucsd (Google PR)</A>
								<DT><A HREF="https://research.colfax-intl.com/nvidia-hopper-flashattention-2/">A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on NVIDIA Hopper Architecture using the CUTLASS Library ‚Äì Colfax Research</A>
								<DT><A HREF="https://research.colfax-intl.com/wp-content/uploads/2023/12/colfax-flashattention.pdf">A Case Study in CUDA Kernel Fusion: Implementing FlashAttention-2 on NVIDIA Hopper Architecture using the CUTLASS Library</A>
								<DT><A HREF="https://research.colfax-intl.com/nvidia-hopper-gemm-cutlass/">GEMM kernels Hopper</A>
								<DT><A HREF="https://www.youtube.com/watch?v=G6q719ck7ww">Lecture 15: CUTLASS - YouTube</A>
								<DT><A HREF="https://pypi.org/project/nvidia-cutlass/">nvidia-cutlass ¬∑ PyPI</A>
								<DT><A HREF="https://dl.acm.org/doi/pdf/10.1145/3620666.3651369">EVT: Accelerating Deep Learning Training with Epilogue Visitor Tree</A>
								<DT><A HREF="https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/">CUTLASS: Fast Linear Algebra in CUDA C++ | NVIDIA Technical Blog</A>
								<DT><A HREF="https://github.com/ericauld/cutlass-playground">ericauld/cutlass-playground</A>
								<DT><A HREF="https://research.colfax-intl.com/tutorial-matrix-transpose-in-cutlass/">Tutorial: Matrix Transpose in CUTLASS ‚Äì Colfax Research</A>
								<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/tree/master/transpose-cute">cfx-article-src/transpose-cute at master ¬∑ ColfaxResearch/cfx-article-src</A>
								<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/tree/master/cutlass_gemm">cfx-article-src/cutlass_gemm at master ¬∑ ColfaxResearch/cfx-article-src</A>
								<DT><A HREF="https://github.com/yester31/Cutlass_EX">yester31/Cutlass_EX: study of cutlass</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/issues/792">[QST] Should I use 3.x or 2.x API for gmem/smem reading/writing? ¬∑ Issue #792 ¬∑ NVIDIA/cutlass</A>
								<DT><A HREF="https://github.com/tlc-pack/cutlass_fpA_intB_gemm">tlc-pack/cutlass_fpA_intB_gemm: A standalone GEMM kernel for fp16 activation and quantized weight, extracted from FasterTransformer</A>
								<DT><A HREF="https://file.notion.so/f/f/51cb76f9-c458-4b5a-83bf-5a2d5c61edfc/894cc1c7-1dbc-4be2-85ee-2f4d76944a99/s21745-developing-cuda-kernels-to-push-tensor-cores-to-the-absolute-limit-on-nvidia-a100.pdf?table=block&id=ab3624dc-7812-40b0-8b58-15ad1afaccd2&spaceId=51cb76f9-c458-4b5a-83bf-5a2d5c61edfc&expirationTimestamp=1724169600000&signature=MpFjqZDTXGju4jogSU720ZXu1JegKfD1mu1DJX0kwnw&downloadName=s21745-developing-cuda-kernels-to-push-tensor-cores-to-the-absolute-limit-on-nvidia-a100.pdf">A100 Tensor Cores</A>
								<DT><A HREF="https://github.com/ColfaxResearch/cutlass-kernels">ColfaxResearch/cutlass-kernels</A>
								<DT><A HREF="https://github.com/weishengying/cutlass_flash_atten_fp8">weishengying/cutlass_flash_atten_fp8: ‰ΩøÁî® cutlass ‰ªìÂ∫ìÂú® ada Êû∂ÊûÑ‰∏äÂÆûÁé∞ fp8 ÁöÑ flash attention</A>
								<DT><A HREF="https://www.youtube.com/watch?v=adA9AMu4_Kc">vLLM Office Hours - Using NVIDIA CUTLASS for High-Performance Inference - September 05, 2024 - YouTube</A>
								<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/">CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining ‚Äì Colfax Research</A>
								<DT><A HREF="https://leimao.github.io/blog/Build-Develop-CUTLASS-CUDA-Kernels/">Build and Develop CUTLASS CUDA Kernels - Lei Mao's Log Book</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1911410577600942819">A little trick for reading CUTLASS source code (possibly)</A>
								<DT><A HREF="https://developer.nvidia.com/blog/cutlass-3-x-orthogonal-reusable-and-composable-abstractions-for-gemm-kernel-design/">CUTLASS 3.x: Orthogonal, Reusable, and Composable Abstractions for GEMM Kernel Design | NVIDIA Technical Blog</A>
								<DT><A HREF="https://github.com/MekkCyber/CutlassAcademy">MekkCyber/CutlassAcademy: A curated collection of resources, tutorials, and best practices for learning and mastering NVIDIA CUTLASS</A>
								<DT><A HREF="https://developer.nvidia.com/blog/cutlass-principled-abstractions-for-handling-multidimensional-data-through-tensors-and-spatial-microkernels/">CUTLASS: Principled Abstractions for Handling Multidimensional Data Through Tensors and Spatial Microkernels | NVIDIA Technical Blog</A>
							</DL><p>
							<DT><H3 FOLDED>cuDNN</H3>
							<DL><p>
								<DT><H3 FOLDED>cuDNN-9.10</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/backend/latest/release-notes.html">Fused Flash Attention fprop numerical inestabilities (lora issue)</A>
								</DL><p>
								<DT><H3 FOLDED>cuDNN-attention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/issues/52">What's the difference of flash attention implement between cudnn and Dao-AILab? ¬∑ Issue #52 ¬∑ NVIDIA/cudnn-frontend</A>
									<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/1.0/release/samples/python/test_mhas.py">cudnn-frontend/samples/python/test_mhas.py at 1.0/release ¬∑ NVIDIA/cudnn-frontend</A>
									<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/9f82dda5c029d15a5f371f0fe003dc0c74a0c987/samples/python/test_mhas.py#L431">test_mhas.py#L431: sdpa</A>
									<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-894/developer-guide/index.html">Developer Guide :: NVIDIA cuDNN Documentation</A>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/issues/41">[performance] Torch SDPA cuDNN backend vs FlashAttention v3 ¬∑ Issue #41 ¬∑ pytorch-labs/tritonbench</A>
								</DL><p>
								<DT><H3 FOLDED>cuDNN-docker</H3>
								<DL><p>
									<DT><A HREF="https://hub.docker.com/layers/nvidia/cuda/12.9.1-cudnn-devel-ubuntu22.04/images/sha256-426d35b8a3e4d806ead3878407dbbc2927a26b797c878e8e439525f635cfda5c">Image Layer Details - nvidia/cuda:12.9.1-cudnn-devel-ubuntu22.04 | Docker Hub</A>
									<DT><A HREF="https://gemini.google.com/u/3/app/52936bd97ec702c9">robust, predictable, and developer-friendly environment for both building the Docker image</A>
								</DL><p>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/installation/latest/linux.html#installing-cudnn-using-conda">Installing cuDNN Backend on Linux ‚Äî NVIDIA cuDNN Installation</A>
								<DT><A HREF="https://x.com/mike64_t/status/1981208172598874262">Looks like its possible to be approx. ~63% faster than the cuDNN LSTM implementation just by using a cutlass GEMM and an elemwise kernel &amp;amp; cuda graphs. 19 ms vs. 30 ms</A>
							</DL><p>
							<DT><H3 FOLDED>cuBLAS</H3>
							<DL><p>
								<DT><H3 FOLDED>cuBLASLt</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api">3. Using the cuBLASLt API</A>
									<DT><A HREF="https://github.com/zartbot/learn_cutlass/blob/main/inter_conn/cublas_with_ldst.cu">learn_cutlass/inter_conn/cublas_with_ldst.cu at main ¬∑ zartbot/learn_cutlass</A>
								</DL><p>
								<DT><H3 FOLDED>cublas-python</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/cuBLAS/README.md">TiledBench/benchs/python/gemm/cuBLAS/README.md cd src &amp; make &amp;&amp; cd ../ python3 test.py</A>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/cuBLAS/src/bind.cu">TiledBench/benchs/python/gemm/cuBLAS/src/bind.cu cublas_gem python bindings</A>
									<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/0f16757edc065603bb19e0457c34a451c5d7c042/examples/matmul/cublas/test_cublas_perf.py">MatmulTutorial/examples/matmul/cublas/test_cublas_perf.py at 0f16757edc065603bb19e0457c34a451c5d7c042 ¬∑ KnowingNothing/MatmulTutorial</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cublas/#cublasgemmex">cublasGemmEx</A>
								</DL><p>
								<DT><H3 FOLDED>cuBLAS-12.9</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/boosting-matrix-multiplication-speed-and-flexibility-with-nvidia-cublas-12-9/">Boosting Matrix Multiplication Speed and Flexibility with NVIDIA cuBLAS 12.9 | NVIDIA Technical Blog</A>
									<DT><A HREF="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/cuBLASLt/LtBlk128x128Fp8Matmul">CUDALibrarySamples/cuBLASLt/LtBlk128x128Fp8Matmul at master ¬∑ NVIDIA/CUDALibrarySamples</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cublas/#cublasltmatmul">1. Introduction ‚Äî cuBLAS 12.9 documentation: cublasLtMatmul()</A>
								</DL><p>
								<DT><H3 FOLDED>cublas-block_scaling</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>cublas-cmake</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/cuBLAS/src/CMakeLists.txt">TiledBench/benchs/python/gemm/cuBLAS/src/CMakeLists.txt build cublass kernel</A>
								</DL><p>
								<DT><A HREF="https://github.com/wangzyon/NVIDIA_SGEMM_PRACTICE">wangzyon/NVIDIA_SGEMM_PRACTICE: Step-by-step optimization of CUDA SGEMM</A>
								<DT><A HREF="https://github.com/Bruce-Lee-LY/cuda_hgemm">Bruce-Lee-LY/cuda_hgemm: Several optimization methods of half-precision general matrix multiplication (HGEMM) using tensor core with WMMA API and MMA PTX instruction.</A>
								<DT><A HREF="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</A>
								<DT><A HREF="https://github.com/Mozilla-Ocho/llamafile/blob/main/llamafile/tinyblas.cu">llamafile/llamafile/tinyblas.cu at main ¬∑ Mozilla-Ocho/llamafile</A>
								<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/pull/65/files">feat(hopper_gemm): Added cublas as the ground-truth. by lcy-seso ¬∑ Pull Request #65 ¬∑ lcy-seso/DLFrameworkTest</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cublas/">1. Introduction ‚Äî cuBLAS 13.0 documentation</A>
								<DT><A HREF="https://x.com/mrsiipa/status/1985728016765632530">(1) maharshi en X: "update: now using cublas instead of cutlass and i already see a big jump, it achieves 4.3 PFLOPS with quantization overhead (thanks to fast quant kernel) and 5.4 PFLOPS for the gemm alone, pretty cool. https://t.co/jRwaKsrsZi" / X</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cublas/#new-and-legacy-cublas-api">1. Introduction ‚Äî cuBLAS 13.1 documentation</A>
								<DT><A HREF="https://grok.com/c/3d4421bf-ddce-43a9-a08a-739f6b103204?rid=d4f6ab0b-0735-4ff5-9a8e-b1609ef39063">cuBLAS CUDA Deprecation and Updates - Grok</A>
							</DL><p>
							<DT><H3 FOLDED>NCCL</H3>
							<DL><p>
								<DT><H3 FOLDED>NVLINK</H3>
								<DL><p>
									<DT><H3 FOLDED>MNNVL</H3>
									<DL><p>
										<DT><H3 FOLDED>NMX-C</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/mnnvl-user-guide/index.html">Multinode NVLink User Guide ‚Äî MNNVL User Guide</A>
										</DL><p>
										<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/mnnvl-user-guide/index.html">Multinode NVLink User Guide ‚Äî MNNVL User Guide</A>
										<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/mnnvl-user-guide/deploying.html#enable-the-nvlink-cluster">Deploying ‚Äî MNNVL User Guide</A>
										<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/mnnvl-user-guide/testing.html">Multinode Testing ‚Äî MNNVL User Guide nvbandwidth</A>
									</DL><p>
									<DT><H3 FOLDED>nvidia.conf</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/mnnvl-user-guide/deploying.html#enable-the-nvlink-cluster">Deploying ‚Äî MNNVL User Guide</A>
									</DL><p>
									<DT><H3 FOLDED>nvbandwidth</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/nvbandwidth">NVIDIA/nvbandwidth: A tool for bandwidth measurements on NVIDIA GPUs.</A>
									</DL><p>
									<DT><H3 FOLDED>NVLink Networks</H3>
									<DL><p>
										<DT><H3 FOLDED>imex</H3>
										<DL><p>
											<DT><H3 FOLDED>nvidia-imex-ctl</H3>
											<DL><p>
											</DL><p>
											<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html">Overview ‚Äî NVIDIA IMEX Service for NVLink Networks</A>
										</DL><p>
										<DT><A HREF="https://docs.nvidia.com/multi-node-nvlink-systems/imex-guide/overview.html">Overview ‚Äî NVIDIA IMEX Service for NVLink Networks</A>
									</DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/data-center/nvlink/">nvlink</A>
									<DT><A HREF="https://www.zhihu.com/question/546809864/answer/3623310119">Why can NVlink achieve higher transmission bandwidth than PCIe?</A>
									<DT><A HREF="https://pytorchtoatoms.substack.com/p/benchmarking-nvlink-and-infiniband">Benchmarking Nvlink &amp; Infiniband Network Speeds</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-theory</H3>
								<DL><p>
									<DT><A HREF="https://szymonozog.github.io/posts/2025-10-26-Penny-worklog-2.html">Writing my own communications library - a worklog of creating Penny Part 2 | Szymon O≈º√≥g</A>
									<DT><A HREF="https://podcasts.apple.com/it/podcast/pytorch-developer-podcast/id1566080008?l=en-GB&i=1000664250427">Compiler collectives PT2</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-test</H3>
								<DL><p>
									<DT><H3 FOLDED>all_reduce</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/geohot/e11dc1b1058ed9e0bc6610249263b024">Test Bandwidth of all reduce</A>
										<DT><A HREF="https://dev.to/lewis_won/from-scatter-to-all-reduce-a-plain-english-guide-to-collective-operations-1695">From Scatter to All-Reduce: A Plain-English Guide to Collective Operations - DEV Community</A>
										<DT><A HREF="https://github.com/coreweave/reference-architecture/tree/main/training/slurm/torch-allreduce">reference-architecture/training/slurm/torch-allreduce at main ¬∑ coreweave/reference-architecture</A>
									</DL><p>
									<DT><H3 FOLDED>all_to_all</H3>
									<DL><p>
										<DT><A HREF="https://github.com/perplexityai/pplx-garden/blob/main/benchmarks/bench_all_to_all.py">pplx-garden/benchmarks/bench_all_to_all.py at main ¬∑ perplexityai/pplx-garden</A>
										<DT><A HREF="https://triton-distributed.readthedocs.io/en/latest/kernels/nvidia/ep_all2all_fused.html">Expert Parallelism All-to-All Fused Megakernel ‚Äî Triton-distributed documentation</A>
										<DT><A HREF="https://blog.vllm.ai/2025/12/17/large-scale-serving.html">vLLM Large Scale Serving: DeepSeek @ 2.2k tok/s/H200 with Wide-EP | vLLM Blog</A>
									</DL><p>
									<DT><H3 FOLDED>busbw</H3>
									<DL><p>
										<DT><A HREF="https://forums.developer.nvidia.com/t/what-is-the-busbw-in-nccl-tests/256858/1">What is the busBW in nccl-tests? - Accelerated Computing / GPU-Accelerated Libraries - NVIDIA Developer Forums</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/nccl-tests">NVIDIA/nccl-tests: NCCL Tests</A>
									<DT><A HREF="https://www.notion.so/datacrunchio/NCCL-Tests-218b9e76914480a7bd3fd8962022b8a6">NCCL Tests</A>
									<DT><A HREF="https://grok.com/chat/cb0541e3-524b-4dc4-bd67-b2dc2753fd39">NVIDIA GB200 NVL72: Device Count and Topology - Grok</A>
									<DT><A HREF="https://github.com/uccl-project/uccl/blob/main/rdma/run_ib.sh">uccl/rdma/run_ib.sh at main ¬∑ uccl-project/uccl</A>
									<DT><A HREF="https://www.notion.so/datacrunchio/High-Level-vs-Low-Level-Infiniband-Verbs-Benchmarking-for-GPU-Clusters-1edb9e76914480eda025c0ab8e8cabfb">High-Level vs Low-Level Infiniband Verbs Benchmarking for GPU Clusters</A>
									<DT><A HREF="https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/performance-at-scale-the-role-of-interconnects-in-azure-hpc--ai-infrastructure/4427238">Performance at Scale: The Role of Interconnects in Azure HPC &amp; AI Infrastructure</A>
									<DT><A HREF="https://github.com/coreweave/nccl-tests?tab=readme-ov-file">coreweave/nccl-tests: NVIDIA NCCL Tests for Distributed Training</A>
									<DT><A HREF="https://hub.docker.com/r/coreweave/nccl-tests">coreweave/nccl-tests - Docker Image</A>
								</DL><p>
								<DT><H3 FOLDED>nccl4py</H3>
								<DL><p>
									<DT><A HREF="https://www.linkedin.com/posts/luxiakun_im-excited-to-announce-that-the-official-activity-7415493697242361856-g7Ju/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">I'm excited to announce that the official NCCL Python binding (nccl4py) is now available.</A>
									<DT><A HREF="https://github.com/NVIDIA/nccl/tree/master/nccl4py">nccl/nccl4py pip install -e .[cu13]  # For CUDA 13.x</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-env-vars</H3>
								<DL><p>
									<DT><H3 FOLDED>NCCL_NVLS_ENABLE</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>NCCL_ALGO</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/env.html">Environment Variables ‚Äî NCCL 2.26.5 documentation</A>
									<DT><A HREF="https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/performance-at-scale-the-role-of-interconnects-in-azure-hpc--ai-infrastructure/4427238">NCCL_P2P_DISABLE, NCCL_SHM_DISABLE, NCCL_NVLS_ENABLE1, UCX_TLS</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-installation</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html">Installation Guide :: NVIDIA Deep Learning NCCL Documentation</A>
								</DL><p>
								<DT><H3 FOLDED>NCCLX</H3>
								<DL><p>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/1980840184905158712">(1) SemiAnalysis en X: "Meta has open sourced their CTran library that natively works with AMD &amp;amp; NVIDIA GPUs üöÄ. Previously, if u want multiple NVIDIA GPUs to work together on an workload, you must used the NVIDIA NCCL library. Although NCCL's source code is public, it does not have an open governance https://t.co/0g6FZoSJns" / X</A>
									<DT><A HREF="https://github.com/meta-pytorch/torchcomms/tree/main/comms/ncclx">torchcomms/comms/ncclx at main ¬∑ meta-pytorch/torchcomms</A>
									<DT><A HREF="https://www.linkedin.com/posts/hyzeng_collective-communication-for-100k-gpus-activity-7388615751034683393-8W7D/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">collective Communication for 100k+ GPUs</A>
									<DT><A HREF="https://arxiv.org/abs/2510.20171">[2510.20171] Collective Communication for 100k+ GPUs</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-multi-node</H3>
								<DL><p>
									<DT><A HREF="https://github.com/stas00/ml-engineering/blob/58bdecd9d245d4275b78f38a869631f9f08be168/network/benchmarks/all_reduce_bench.py#L49">ml-engineering/network/benchmarks/all_reduce_bench.py at 58bdecd9d245d4275b78f38a869631f9f08be168 ¬∑ stas00/ml-engineering</A>
									<DT><A HREF="https://pytorch.org/tutorials/intermediate/ddp_series_multinode.html">Multinode Training ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-profiler</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/NPKit">microsoft/NPKit: NCCL Profiling Kit</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-tuning</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/understanding-nccl-tuning-to-accelerate-gpu-to-gpu-communication/">Understanding NCCL Tuning to Accelerate GPU-to-GPU Communication | NVIDIA Technical Blog</A>
								</DL><p>
								<DT><H3 FOLDED>tccl</H3>
								<DL><p>
									<DT><A HREF="https://github.com/cchan/tccl">cchan/tccl: extensible collectives library in triton</A>
									<DT><A HREF="https://github.com/yifuwang/symm-mem-recipes">yifuwang/symm-mem-recipes</A>
									<DT><A HREF="https://github.com/cchan/tccl/blob/main/presentation.pdf">tccl/presentation.pdf at main ¬∑ cchan/tccl</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-flux</H3>
								<DL><p>
									<DT><A HREF="https://github.com/bytedance/flux">bytedance/flux: A fast communication-overlapping library for tensor parallelism on GPUs.</A>
								</DL><p>
								<DT><H3 FOLDED>collective-operation</H3>
								<DL><p>
									<DT><H3 FOLDED>all-to-all</H3>
									<DL><p>
										<DT><A HREF="https://en.wikipedia.org/wiki/All-to-all_(parallel_pattern)">All-to-all (parallel pattern) - Wikipedia</A>
										<DT><A HREF="https://developer.nvidia.com/blog/doubling-all2all-performance-with-nvidia-collective-communication-library-2-12/">Doubling all2all Performance with NVIDIA Collective Communication Library 2.12 | NVIDIA Technical Blog</A>
									</DL><p>
									<DT><A HREF="https://en.wikipedia.org/wiki/Collective_operation">Collective operation - Wikipedia</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Reduction_operator">Reduction operator - Wikipedia</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-debug</H3>
								<DL><p>
									<DT><H3 FOLDED>uccl</H3>
									<DL><p>
										<DT><A HREF="https://uccl-project.github.io/posts/about-uccl/">UCCL-Tran: An Extensible Software Transport Layer for GPU Networking</A>
										<DT><A HREF="https://github.com/uccl-project/uccl/blob/main/rdma/run_ib.sh">uccl/rdma/run_ib.sh at main ¬∑ uccl-project/uccl</A>
										<DT><A HREF="https://github.com/uccl-project/uccl">uccl-project/uccl: UCCL is an efficient communication library for GPUs, covering collectives, P2P (e.g., KV cache transfer, RL weight transfer), and EP (e.g., GPU-driven)</A>
									</DL><p>
									<DT><A HREF="https://uccl-project.github.io/posts/debug-nccl/">UCCL: How to Debug NCCL Performance Issues for ML Workloads?</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-dev</H3>
								<DL><p>
									<DT><H3 FOLDED>nccl-rust</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-pytorch/monarch/blob/main/nccl-sys/build.rs">monarch/nccl-sys/build.rs at main ¬∑ meta-pytorch/monarch</A>
									</DL><p>
									<DT><A HREF="https://szymonozog.github.io/posts/2025-09-21-Penny-worklog-1.html">Writing my own communications library - a worklog of creating Penny part 1 | Szymon O≈º√≥g</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-docker</H3>
								<DL><p>
									<DT><A HREF="https://x.com/cloneofsimo/status/1965351141522518223">NCCL_SOCKET_IFNAME=^docker0,lo</A>
								</DL><p>
								<DT><H3 FOLDED>network-fabrics</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/dgx-superpod/reference-architecture-scalable-infrastructure-b200/latest/network-fabrics.html">Network Fabrics ‚Äî NVIDIA DGX SuperPOD: Next Generation Scalable Infrastructure for AI Leadership Reference Architecture Featuring NVDIA DGX B200</A>
									<DT><A HREF="https://github.com/ai-dynamo/nixl">ai-dynamo/nixl: NVIDIA Inference Xfer Library (NIXL)</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-tk</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Shauray7/status/1971283389778100428">(1) Shauray en X: "I was writing some collective comm kernels and tried benchmarking TK for it. Ran their benchmark for all_reduce on 2xB200 with good hardware except for NUMA affinity that basically ties my GPUs to different CPU memory domain (attached below). It's same on NCCL, so regardless. 1/N https://t.co/FGlT8xVs89" / X</A>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/main/kernels/collectives/all_reduce/all_reduce.cu">ThunderKittens/kernels/collectives/all_reduce/all_reduce.cu at main ¬∑ HazyResearch/ThunderKittens</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-inspector</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/nccl/blob/59242d7c385fa91f68e19a1327b1cde0c485b291/ext-profiler/inspector/README.md">nccl/ext-profiler/inspector/README.md</A>
									<DT><A HREF="https://developer.nvidia.com/blog/enhancing-communication-observability-of-ai-workloads-with-nccl-inspector/">Enhancing Communication Observability of AI Workloads with NCCL Inspector | NVIDIA Technical Blog</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-simulate-traffic</H3>
								<DL><p>
									<DT><A HREF="https://jax-ml.github.io/scaling-book/gpus/">How to Think About GPUs | How To Scale Your Model</A>
									<DT><A HREF="https://gist.github.com/geohot/e11dc1b1058ed9e0bc6610249263b024">Test Bandwidth of all reduce</A>
								</DL><p>
								<DT><A HREF="https://le.qun.ch/en/blog/2024/12/25/libfabric-efa-0-intro/">Harnessing 3200 Gbps Network: A Journey with RDMA, EFA, and libfabric</A>
								<DT><A HREF="https://twitter.com/ProjectPhysX/status/1637789116363407362">(1) Dr. Moritz Lehmann en X: "There is a supppsed vendor-independent (but not cross-vendor) way of #GPU P2P communication in #OpenCL: have all GPUs in the same context &amp;amp; pass buffers to other devices' kernels.üí° Drivers should automatically handle P2P comm via PCIe/SLI/NVLink/CrossFire/InfFabric. üßµ1/9 https://t.co/h0DsEPPkFq" / X</A>
								<DT><A HREF="https://github.com/coreweave/nccl-tests">coreweave/nccl-tests: NVIDIA NCCL Tests for Distributed Training</A>
								<DT><A HREF="https://github.com/open-mpi/ompi">open-mpi/ompi: Open MPI main development repository</A>
								<DT><A HREF="https://github.com/horovod/horovod/blob/master/docs/concepts.rst">horovod/docs/concepts.rst at master ¬∑ horovod/horovod</A>
								<DT><A HREF="https://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/">MPI Scatter, Gather, and Allgather ¬∑ MPI Tutorial</A>
								<DT><A HREF="https://mpitutorial.com/tutorials/mpi-broadcast-and-collective-communication/">MPI Broadcast and Collective Communication ¬∑ MPI Tutorial</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/tests/onebit/test_nccl_perf.py">DeepSpeed/tests: test_nccl_perf.py</A>
								<DT><A HREF="https://www.youtube.com/watch?v=nD6PUe3d6ec">Lecture #2 - Scatter-to-Gather Transformation - YouTube</A>
								<DT><A HREF="https://github.com/cuda-mode/p2p-perf">cuda-mode/p2p-perf: measuring peer-to-peer (p2p) transfer on different cuda devices</A>
								<DT><A HREF="https://www.youtube.com/watch?v=T22e3fgit-A">Lecture 17: NCCL - YouTube</A>
								<DT><A HREF="https://github.com/NVIDIA/cuda-samples/tree/master/Samples/5_Domain_Specific/p2pBandwidthLatencyTest">cuda-samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest at master ¬∑ NVIDIA/cuda-samples</A>
								<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/network/debug">ml-engineering/network/debug</A>
								<DT><A HREF="https://github.com/microsoft/mscclpp">microsoft/mscclpp: MSCCL++: A GPU-driven communication stack for scalable AI applications</A>
								<DT><A HREF="https://github.com/microsoft/msccl">microsoft/msccl: Microsoft Collective Communication Library</A>
								<DT><A HREF="https://github.com/Azure/msccl">Azure/msccl: Microsoft Collective Communication Library</A>
								<DT><A HREF="https://en.wikipedia.org/wiki/Collective_operation">Collective operation - Wikipedia</A>
								<DT><A HREF="https://github.com/Vchitect/FasterCache/blob/main/fastercache/dsp/comm.py">FasterCache/fastercache/dsp/comm.py at main ¬∑ Vchitect/FasterCache</A>
								<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/16ab3b17c415b80bb757fe48fa6e95d0adda9430/src/para_attn/primitives.py">ParaAttention/src/para_attn/primitives.py</A>
								<DT><A HREF="https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2-4/#:~:text=We%20tested%20NCCL%202,180x%20improvement%20at%2024k%20GPUs">Massively Scale Your Deep Learning Training with NCCL 2.4 | NVIDIA Technical Blog</A>
								<DT><A HREF="https://developer.nvidia.com/blog/enabling-fast-inference-and-resilient-training-with-nccl-2-27/">Enabling Fast Inference and Resilient Training with NCCL 2.27 | NVIDIA Technical Blog</A>
								<DT><A HREF="https://www.youtube.com/watch?v=bqL1WC3AKNA">Multi-GPU programming - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=zxGVvMN6WaM">Lecture 67: NCCL and NVSHMEM - YouTube</A>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/gpus/">How to Think About GPUs | How To Scale Your Model</A>
								<DT><A HREF="https://github.com/meta-pytorch/monarch/blob/main/nccl-sys/build.rs">monarch/nccl-sys/build.rs at main ¬∑ meta-pytorch/monarch</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1952072433180848670">Sharing of MSCCL background knowledge</A>
								<DT><A HREF="https://www.zhihu.com/question/1937118606744860601/answer/1946974287522162402">Does distributed training require P2P communication more than collective communication (NCCL)?</A>
								<DT><A HREF="https://szymonozog.github.io/posts/2025-09-21-Penny-worklog-1.html">Writing my own communications library - a worklog of creating Penny part 1 | Szymon O≈º√≥g</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-09-22-pgl">One Kernel for All Your GPUs ¬∑ Hazy Research</A>
								<DT><A HREF="https://gau-nernst.github.io/amd-a2a/">My first Multi-GPU kernel: Writing All-to-all for AMD MI300X - gau-nernst's blog</A>
								<DT><A HREF="https://x.com/gaunernst/status/1984993034078179665">(1) Thien Tran en X: "https://t.co/BxK6ise8ZA" / X</A>
								<DT><A HREF="https://github.com/inclusionAI/asystem-amem">inclusionAI/asystem-amem: A NCCL extension library, designed to efficiently offload GPU memory allocated by the NCCL communication library.</A>
								<DT><A HREF="https://arxiv.org/abs/2507.04786">[2507.04786] Demystifying NCCL: An In-depth Analysis of GPU Communication Protocols and Algorithms</A>
								<DT><A HREF="https://www.youtube.com/watch?v=2xMzQ1Z2Qe0">MultiGPU + NCCL from the authors - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-performance</H3>
							<DL><p>
								<DT><H3 FOLDED>arithmetic intensity</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/cis_female/status/1771746532892586388">arithmetic intensity: easy appro min(m,n,k)</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1980454696075403417">Practical Tensor Core Tutorial: Theoretical Analysis</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=USMnKuyXBFM">Developing Optimal CUDA Kernels on Hopper Tensor Cores NVIDIA On Demand - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=OIOx3CJP2Es&t=559s">Introduction to CUDA Programming and Performance Optimization NVIDIA On Demand - YouTube</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62192/?playlistId=playList-d59c3dc3-9e5a-404d-8725-4b567f4dfe77">Advanced Performance Optimization in CUDA | NVIDIA On-Demand</A>
								<DT><A HREF="https://forums.developer.nvidia.com/t/structures-of-arrays-vs-arrays-of-structures/13581">Structures of Arrays vs Arrays of Structures? - CUDA / CUDA Programming and Performance - NVIDIA Developer Forums</A>
								<DT><A HREF="https://en.wikipedia.org/wiki/AoS_and_SoA">AoS and SoA - Wikipedia</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/#getting-started">CUDA C++ Best Practices Guide</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-profiling</H3>
							<DL><p>
								<DT><H3 FOLDED>ncu</H3>
								<DL><p>
									<DT><H3 FOLDED>ncu-scripts</H3>
									<DL><p>
										<DT><A HREF="https://github.com/lcy-seso/vq-experiments/blob/3aef9f38da6dd19f1c9b3aa03410724a2457e0ac/bench_quant_gemv/ncu.sh">vq-experiments/bench_quant_gemv/ncu.sh ncu profiling script example</A>
										<DT><A HREF="https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223">Favorite nsight systems profiling commands for Pytorch scripts</A>
										<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/15">Proper benchmarkign with CUDA synchronization NVIDIA/TransformerEngine</A>
									</DL><p>
									<DT><H3 FOLDED>ncu-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Dao-AILab/quack/blob/3d0ab3ec2164749caac8f269f771e66a40efd2de/quack/gemm_sm100.py#L78">To collect performance with NCU profiler: ncu python examples/blackwell/dense_gemm_persistent.py</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/blob/42da900e856473218e12f07e91ac176752ffa80a/tritonbench/components/ncu/analyzer.py">tritonbench/tritonbench/components/ncu/analyzer.py</A>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/blob/42da900e856473218e12f07e91ac176752ffa80a/tritonbench/utils/triton_op.py">tritonbench/tritonbench/utils/triton_op.py at 42da900e856473218e12f07e91ac176752ffa80a ¬∑ pytorch-labs/tritonbench</A>
									<DT><A HREF="https://github.com/karpathy/llm.c/discussions/331">LLM.c Speed of Light &amp; Beyond (A100 Performance Analysis) ¬∑ karpathy/llm.c ¬∑ Discussion #331</A>
									<DT><A HREF="https://github.com/Dao-AILab/quack/blob/3d0ab3ec2164749caac8f269f771e66a40efd2de/quack/gemm_sm100.py#L78">quack/quack/gemm_sm100.py at 3d0ab3ec2164749caac8f269f771e66a40efd2de ¬∑ Dao-AILab/quack</A>
									<DT><A HREF="https://github.com/gpusgobrr/explore-gemm/blob/main/cuda/py/kernel_runner.py">explore-gemm/cuda/py/kernel_runner.py at main ¬∑ gpusgobrr/explore-gemm</A>
									<DT><A HREF="https://x.com/drisspg/status/1990974698205950302">ncu trace function and commands</A>
									<DT><A HREF="https://github.com/gau-nernst/learn-cuda">ncu --set full python main.py # profile a CUDA kernel</A>
									<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/cases/test_ncu.py">ml_scripts/cases/test_ncu.py at main ¬∑ FindHao/ml_scripts</A>
								</DL><p>
								<DT><H3 FOLDED>CUPTI</H3>
								<DL><p>
									<DT><H3 FOLDED>bpftime</H3>
									<DL><p>
										<DT><A HREF="https://github.com/eunomia-bpf/eunomia.dev/blob/main/docs/bpftime/documents/gpu.md">eunomia.dev/docs/bpftime/documents/gpu.md at main ¬∑ eunomia-bpf/eunomia.dev</A>
										<DT><A HREF="https://github.com/eunomia-bpf/eunomia.dev/blob/main/docs/bpftime/documents/bpftimetool.md">eunomia.dev/docs/bpftime/documents/bpftimetool.md at main ¬∑ eunomia-bpf/eunomia.dev</A>
										<DT><A HREF="https://eunomia.dev/blog/2025/10/14/the-gpu-observability-gap-why-we-need-ebpf-on-gpu-devices/">The GPU Observability Gap: Why We Need eBPF on GPU devices - eunomia</A>
									</DL><p>
									<DT><A HREF="https://github.com/eunomia-bpf/cupti-tutorial">eunomia-bpf/cupti-tutorial: Tutorials for NVIDIA CUPTI samples</A>
								</DL><p>
								<DT><H3 FOLDED>nsys</H3>
								<DL><p>
									<DT><H3 FOLDED>nsys-videos</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=GCkdiHk6fUY">Memory Analysis with NVIDIA Nsight Compute (memory chart)</A>
										<DT><A HREF="https://www.youtube.com/watch?v=uHN5fpfu8As">Memory hierarchy</A>
										<DT><A HREF="https://www.youtube.com/watch?v=Iuy_RAvguBM">Intro to NVIDIA Nsight Compute</A>
										<DT><A HREF="https://www.youtube.com/watch?v=nhTjq0P9uc8">08 GPU Performance Analysis</A>
										<DT><A HREF="https://www.youtube.com/watch?v=fsC3QeZHM1U">Introduction to Kernel Performance Analysis with NVIDIA Nsight Compute</A>
										<DT><A HREF="https://www.youtube.com/watch?v=3DAYN-onSzY">GPU Series: Hands-On Session with NSight Systems and Compute - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=nhTjq0P9uc8">08 GPU Performance Analysis - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=fsC3QeZHM1U">Introduction to Kernel Performance Analysis with NVIDIA Nsight Compute - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>nsys-commands</H3>
									<DL><p>
										<DT><A HREF="https://github.com/yanring/Megatron-MoE-ModelZoo/blob/main/sbatch_benchmarking.sh">PROFILE_CMD="nsys profile --sample=none --cpuctxsw=none -t cuda,nvtx</A>
									</DL><p>
									<DT><H3 FOLDED>nsys-py</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/nsight-python/overview/quickstart.html">Quickstart ‚Äî nsight-python</A>
										<DT><A HREF="https://docs.nvidia.com/nsight-python/overview/core_concepts.html">Core Concepts ‚Äî nsight-python</A>
										<DT><A HREF="https://docs.nvidia.com/nsight-python/overview/architecture.html">Architecture ‚Äî nsight-python</A>
										<DT><A HREF="https://x.com/tonymongkolsmai/status/1991897063886557494">Tony Mongkolsmai en X: "Today we are releasing our first public beta of Nsight Python! The goal is to simplify the life of a Python developer by proving a pythonic way to analyze your kernel code! Check it out, provide feedback! Nsight Python ‚Äî nsight-python https://t.co/VnvpBpeucC" / X</A>
									</DL><p>
									<DT><H3 FOLDED>nanotrace</H3>
									<DL><p>
										<DT><A HREF="https://github.com/aikitoria/nanotrace">Have you ever looked at nsys and wished you could zoom in much, much further?</A>
									</DL><p>
									<DT><A HREF="https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223">Favorite nsight systems profiling commands for Pytorch scripts</A>
									<DT><A HREF="https://github.com/karpathy/llm.c/discussions/331">LLM.c Speed of Light &amp; Beyond (A100 Performance Analysis) ¬∑ karpathy/llm.c ¬∑ Discussion #331</A>
									<DT><A HREF="https://gpuhackshef.readthedocs.io/en/latest/">Sheffield GPU Hackathon ‚Äî GPUHackSheffield documentation</A>
									<DT><A HREF="https://gpuhackshef.readthedocs.io/en/latest/tools/nvidia-profiling-tools.html">NVIDIA Profiling Tools ‚Äî GPUHackSheffield documentation</A>
									<DT><A HREF="https://docs.nvidia.com/nsight-systems/UserGuide/index.html">User Guide :: Nsight Systems Documentation</A>
									<DT><A HREF="https://gist.github.com/mcarilli/213a4e698e4a0ae2234ddee56f4f3f95">Single- and multiprocess profiling workflow with nvprof and NVVP (Nsight Systems coming soon...)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=nhTjq0P9uc8">08 GPU Performance Analysis - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=fsC3QeZHM1U">Introduction to Kernel Performance Analysis with NVIDIA Nsight Compute - YouTube</A>
									<DT><A HREF="https://www.olcf.ornl.gov/wp-content/uploads/2020/02/OLCF-Webinar-Nsight-Compute.pdf">https://www.olcf.ornl.gov/wp-content/uploads/2020/02/OLCF-Webinar-Nsight-Compute.pdf</A>
									<DT><A HREF="https://blog.speechmatics.com/pointless-gpu-optimization-exercise">An Almost Pointless Exercise in GPU Optimization</A>
									<DT><A HREF="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#memory-tables">Memory tables Profiling Guide</A>
									<DT><A HREF="https://github.com/NVIDIA/nsight-training/tree/master/cuda/nsight_compute/vlog_memory_workload">nsight-training/cuda/nsight_compute/vlog_memory_workload</A>
									<DT><A HREF="https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html">2. Kernel Profiling Guide ‚Äî NsightCompute 12.4 documentation</A>
									<DT><A HREF="http://tspeterkim.github.io/posts/nsight-setup-on-ec2">How to set up Nsight Compute Locally to profile Remote GPUs | Taeksang Peter Kim</A>
									<DT><A HREF="https://www.olcf.ornl.gov/wp-content/uploads/2020/02/OLCF-Webinar-Nsight-Compute.pdf">ornl: Nsight Compute OLCF Webinar</A>
									<DT><A HREF="https://github.com/reed-lau/cute-gemm/blob/main/profile.sh">cute-gemm/profile.sh at main ¬∑ reed-lau/cute-gemm</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59">Using Nsight Systems to profile GPU workload - hardware-backends / NVIDIA CUDA - PyTorch Developer Mailing List</A>
								</DL><p>
								<DT><H3 FOLDED>NVML</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/deploy/nvml-api/group__nvmlDeviceQueries.html">NVML API Reference Guide :: GPU Deployment and Management Documentation</A>
								</DL><p>
								<DT><H3 FOLDED>High Pipe Utilization</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>Issue Slot Utilization</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>CPI Stall ‚ÄòLong Scoreboard‚Äô</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>SM saturation</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>DrGPU: A Top-Down Profiler for GPU</H3>
								<DL><p>
									<DT><A HREF="https://github.com/FindHao/drgpu">FindHao/drgpu</A>
									<DT><A HREF="https://about.findhao.net/ICPE2023.pdf">DrGPU: A Top-Down Profiler for GPU</A>
									<DT><A HREF="https://github.com/FindHao/drgpu">FindHao/drgpu (Optimization suggestions)</A>
									<DT><A HREF="https://chat.openai.com/c/74ad9a19-e6f0-4ba3-a0d7-0d7a0b6c5c61">Performance Logging &amp; Saving Kernel ASM &amp; IR</A>
									<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/de17730a993b1d2cce4fd09e3654b5f79fd23c96/kernels/triton/inference/gptq/a100_qlinear.py#L8">applied-ai/kernels/triton/inference/gptq/a100_qlinear.py (ASM &amp; IR)</A>
								</DL><p>
								<DT><H3 FOLDED>nvprof</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/cuda/profiler-users-guide/">nvprof: Profiler Users Guide</A>
								</DL><p>
								<DT><H3 FOLDED>TensorBoard</H3>
								<DL><p>
									<DT><A HREF="https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras">TensorFlow Profiler: Profile model performance ¬†|¬† TensorBoard</A>
									<DT><A HREF="https://github.com/pytorch/kineto/blob/main/tb_plugin/docs/gpu_utilization.md">pytorch gpu_utilization.md</A>
									<DT><A HREF="https://github.com/pytorch/kineto/tree/main/tb_plugin">tb_plugin</A>
									<DT><A HREF="https://pytorch.org/tutorials/intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard ‚Äî PyTorch Tutorials 2.0.1+cu117 documentation</A>
									<DT><A HREF="https://github.com/LaurentMazare/tboard-rs">LaurentMazare/tboard-rs: Read and write tensorboard data using Rust</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-power-limit</H3>
								<DL><p>
									<DT><A HREF="https://www.thonking.ai/p/strangely-matrix-multiplications">Strangely, Matrix Multiplications on GPUs Run Faster When Given "Predictable" Data! [short]</A>
									<DT><A HREF="https://github.com/stas00/ml-engineering/blob/master/compute/accelerator/README.md#maximum-achievable-flops">ml-engineering/compute/accelerator/README.md at master ¬∑ stas00/ml-engineering</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-benchmarking</H3>
								<DL><p>
									<DT><H3 FOLDED>nvbench</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/nvbench">NVIDIA/nvbench: CUDA Kernel Benchmarking Library</A>
									</DL><p>
									<DT><A HREF="https://github.com/AndreSlavescu/mHC.cu/blob/main/src/csrc/benchmarks/bench_rmsnorm_backward.cu">mHC.cu/src/csrc/benchmarks/bench_rmsnorm_backward.cu at main ¬∑ AndreSlavescu/mHC.cu</A>
								</DL><p>
								<DT><A HREF="https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223">Favorite nsight systems profiling commands for Pytorch scripts</A>
								<DT><A HREF="https://github.com/karpathy/llm.c/discussions/331">LLM.c Speed of Light &amp; Beyond (A100 Performance Analysis) ¬∑ karpathy/llm.c ¬∑ Discussion #331</A>
								<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/15">Proper benchmarkign with CUDA synchronization NVIDIA/TransformerEngine</A>
								<DT><A HREF="https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras">TensorFlow Profiler: Profile model performance ¬†|¬† TensorBoard</A>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/performance/dl-performance-gpu-background/index.html">GPU Performance Background User's Guide - NVIDIA Docs</A>
								<DT><A HREF="https://matplotlib.org/stable/gallery/lines_bars_and_markers/step_demo.html#sphx-glr-gallery-lines-bars-and-markers-step-demo-py">Step Demo ‚Äî Matplotlib 3.7.2 documentation</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/benchmarks/benchmark_latency.py">vllm/benchmarks/benchmark_latency.py at main ¬∑ vllm-project/vllm</A>
								<DT><A HREF="https://github.com/Kobzol/hardware-effects-gpu">Kobzol/hardware-effects-gpu: Demonstration of various hardware effects on CUDA GPUs.</A>
								<DT><A HREF="https://github.com/Kobzol/hardware-effects-gpu/tree/master/memory-coalescing">hardware-effects-gpu/memory-coalescing at master ¬∑ Kobzol/hardware-effects-gpu</A>
								<DT><A HREF="https://github.com/mcarilli/cuda-memory/tree/master">mcarilli/cuda-memory: Playing around with GPU memory optimization</A>
								<DT><A HREF="https://github.com/cupy/cupy/blob/5a4c7a1c461776c779afc1e614aa06db7be594fa/docs/source/user_guide/performance.rst#L10">Performance Best Practices: CuPy</A>
								<DT><A HREF="https://github.com/Lin-Mao/DrGPUM">Lin-Mao/DrGPUM: A memory profiler for NVIDIA GPUs to explore memory inefficiencies in GPU-accelerated applications.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=LuhJEEJQgUM">Lecture 1 How to profile CUDA kernels in PyTorch - YouTube</A>
								<DT><A HREF="https://docs.google.com/presentation/d/110dnMW94LX1ySWxu9La17AVUxjgSaQDLOotFC3BZZD4/edit#slide=id.p">Lecture 1 How to profile CUDA kernels in PyTorch</A>
								<DT><A HREF="https://www.speechmatics.com/company/articles-and-news/timing-operations-in-pytorch">How to Accurately Time CUDA Kernels in Pytorch</A>
								<DT><A HREF="https://developer.nvidia.com/tools-overview">NVIDIA Developer Tools Overview | NVIDIA Developer</A>
								<DT><A HREF="https://developer.nvidia.com/nsight-visual-studio-code-edition">Nsight Visual Studio Code Edition</A>
								<DT><A HREF="https://developer.nvidia.com/nsight-dl-designer">Nsight Deep Learning Designer (earlier access)</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/benchmarks/benchmark_latency.py">vllm/benchmarks/benchmark_latency.py at main</A>
								<DT><A HREF="https://github.com/Kobzol/hardware-effects-gpu/tree/master/memory-coalescing">hardware-effects-gpu/memory-coalescing at master</A>
								<DT><A HREF="https://github.com/Lin-Mao/DrGPUM">Lin-Mao/DrGPUM: A memory profiler for NVIDIA GPUs to explore memory inefficiencies in GPU</A>
								<DT><A HREF="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf">Understanding Latency Hiding on GPUs (2016)</A>
								<DT><A HREF="https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/">Using CUDA Warp-Level Primitives</A>
								<DT><A HREF="https://github.com/NVIDIA/nvbandwidth">NVIDIA/nvbandwidth: A tool for bandwidth measurements on NVIDIA GPUs.</A>
								<DT><A HREF="https://christianjmills.com/posts/cuda-mode-notes/lecture-001/">Christian Mills - CUDA MODE Lecture 1: How to profile CUDA kernels in PyTorch</A>
								<DT><A HREF="http://arthurchiao.art/blog/understanding-gpu-performance/">Understanding NVIDIA GPU Performance: Utilization vs. Saturation (2023)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=zHY7iF_2RyU">Lecture 07 - Profiling - YouTube</A>
								<DT><A HREF="https://dl.acm.org/doi/pdf/10.1145/3392717.3392752">https://dl.acm.org/doi/pdf/10.1145/3392717.3392752</A>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/gpus/">How to Think About GPUs | How To Scale Your Model</A>
								<DT><A HREF="https://grok.com/c/3b989f0f-b76b-438d-a8a4-e87fa974d3f9">Unprivileged NVIDIA Profiling Configuration Script: nsys profile --stats=true nvidia-smi</A>
								<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/commit/0f16757edc065603bb19e0457c34a451c5d7c042#diff-c4c43a43be8bf1d1236a1d324cea2240859b67d99690aed466ffe68f83e16d4d">add sm100 matmul ¬∑ KnowingNothing/MatmulTutorial@0f16757</A>
								<DT><A HREF="https://github.com/gau-nernst/learn-cuda">#profile a CUDA kernel; ncu --set full python main.py</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-microbenchmarking</H3>
							<DL><p>
								<DT><H3 FOLDED>cuda-synchronize</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HydraQYH/CUDASynchronizePrimitives/tree/master">HydraQYH/CUDASynchronizePrimitives: Benchmark sync primitives„ÄÇ</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/26116356638">Some Conjectures on the Memory Consistency Model of Modern GPU Architectures (Part 2) ‚Äî Synchronization Performance</A>
									<DT><A HREF="https://x.com/charles_irl/status/2017075226417516795">never blog the GPU, async H2D</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-memcpy</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ademeure/QuickRunCUDA">ademeure/QuickRunCUDA</A>
									<DT><A HREF="https://gist.github.com/geohot/3b23bb6be846d3097834d07806ca6563">Fast memcpy using GPUs</A>
									<DT><A HREF="https://github.com/datacrunch-research/microbenchmarking/blob/main/memcpy.py">microbenchmarking/memcpy.py at main ¬∑ datacrunch-research/microbenchmarking</A>
									<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/playground/other/test_cupy_partial_transfer.py">alpa/playground/other/test_cupy_partial_transfer.py at main ¬∑ alpa-projects/alpa</A>
									<DT><A HREF="https://github.com/shenh10/awesome-cuda/blob/master/comm/d2d/cudaMemcpy.cu">awesome-cuda/comm/d2d/cudaMemcpy.cu at master ¬∑ shenh10/awesome-cuda</A>
								</DL><p>
								<DT><H3 FOLDED>cuda-p2p-benchmark</H3>
								<DL><p>
									<DT><A HREF="https://github.com/chengyupku/benchmark_p2p/blob/main/benchmark_p2p_latency.cu">benchmark_p2p/benchmark_p2p_latency.cu at main ¬∑ chengyupku/benchmark_p2p</A>
									<DT><A HREF="https://www.youtube.com/watch?v=bqL1WC3AKNA">Multi-GPU programming - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>TF32</H3>
								<DL><p>
									<DT><A HREF="https://x.com/BenTheEgg/status/1813898551145173346">TF32 is FP32 range with FP16 accuracy (BF16 is FP32 range with reduced accuracy)</A>
								</DL><p>
								<DT><H3 FOLDED>hopper-microbenchmarking</H3>
								<DL><p>
									<DT><H3 FOLDED>hopper-transpose</H3>
									<DL><p>
										<DT><A HREF="https://veitner.bearblog.dev/making-matrix-transpose-really-fast-on-hopper-gpus/">Making matrix transpose really fast on Hopper GPUs | simons blog</A>
									</DL><p>
									<DT><A HREF="https://gist.github.com/Chillee/2ec89696db8b7ed1c24461159e325405">H100 peak matmul FLOPS</A>
									<DT><A HREF="https://github.com/ademeure/hopperian_tensor">ademeure/hopperian_tensor</A>
									<DT><A HREF="https://arxiv.org/pdf/2402.13499.pdf">Benchmarking and Dissecting the Nvidia Hopper GPU Architecture</A>
									<DT><A HREF="https://github.com/HPMLL/NVIDIA-Hopper-Benchmark?tab=readme-ov-file">HPMLL/NVIDIA-Hopper-Benchmark</A>
									<DT><A HREF="https://arxiv.org/abs/2402.13499">[2402.13499] Benchmarking and Dissecting the Nvidia Hopper GPU Architecture</A>
									<DT><A HREF="https://github.com/shen203/GPU_Microbenchmark">shen203/GPU_Microbenchmark: provides a reference for our regular unit tests.</A>
									<DT><A HREF="https://github.com/RRZE-HPC/gpu-benches">RRZE-HPC/gpu-benches: collection of benchmarks to measure basic GPU capabilities</A>
									<DT><A HREF="https://github.com/blackjack2015/NV-DVFS-Benchmark">blackjack2015/NV-DVFS-Benchmark</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2503.20481">[2503.20481] Analyzing Modern NVIDIA GPU cores</A>
								<DT><A HREF="https://arxiv.org/pdf/1903.07486.pdf">Dissecting the NVidia Turing T4 GPU via Microbenchmarking</A>
								<DT><A HREF="https://arxiv.org/pdf/1912.03413.pdf">IPU</A>
								<DT><A HREF="https://arxiv.org/pdf/1804.06826.pdf%5B/url%5D">Volta</A>
								<DT><A HREF="https://github.com/sophiawisdom/benchmarks">sophiawisdom/benchmarks</A>
								<DT><A HREF="https://github.com/Yinghan-Li/YHs_Sample/tree/master/cuda/microbenchmark">YHs_Sample/cuda/microbenchmark at master ¬∑ Yinghan-Li/YHs_Sample</A>
								<DT><A HREF="https://www.ece.lsu.edu/koppel/gp/notes/set-nv-org.pdf">slides</A>
								<DT><A HREF="https://github.com/mag-/gpu_benchmark?tab=readme-ov-file">mag-/gpu_benchmark: Gpu benchmark</A>
								<DT><A HREF="https://github.com/stas00/ml-engineering/blob/master/compute/accelerator/benchmarks/mamf-finder.py">ml-engineering/compute/accelerator/benchmarks/mamf-finder.py at master ¬∑ stas00/ml-engineering</A>
								<DT><A HREF="https://github.com/EleutherAI/cookbook/tree/main/benchmarks/sizing">cookbook/benchmarks/sizing at main ¬∑ EleutherAI/cookbook</A>
								<DT><A HREF="https://github.com/ROCm/pytorch-micro-benchmarking">ROCm/pytorch-micro-benchmarking</A>
								<DT><A HREF="https://github.com/NVIDIA/cuda-samples/blob/master/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md">cuda-samples/Samples/5_Domain_Specific/p2pBandwidthLatencyTest/README.md at master ¬∑ NVIDIA/cuda-samples</A>
								<DT><A HREF="https://x.com/cHHillee/status/1884743684928962884">(2) Horace He en X: "@PytorchToAtoms @giffmana https://t.co/yCWveA7zNp Also need to set vboost slider to 1. With this, I hit 780 TFLOPS. You also need a new-enough version of PyTorch to have this PR + have cutlass installed lol: https://t.co/Kmh6LxdNEp https://t.co/UyBoD5QgIg" / X</A>
								<DT><A HREF="https://gist.github.com/geohot/3b23bb6be846d3097834d07806ca6563">Fast memcpy using GPUs</A>
								<DT><A HREF="https://github.com/datacrunch-research/micro">datacrunch-research/micro: Miscellaneous¬†microbenchmarking playground</A>
								<DT><A HREF="https://github.com/mag-/gpu_benchmark">mag-/gpu_benchmark: Gpu benchmark</A>
								<DT><A HREF="https://fruitfly1026.github.io/static/files/p31-zhang.pdf">Understanding the GPU Microarchitecture to Achieve Bare-Metal Performance Tuning</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-reproducibility</H3>
							<DL><p>
								<DT><A HREF="https://pytorch.org/docs/stable/notes/randomness.html">Reproducibility ‚Äî PyTorch 1.13 documentation</A>
								<DT><A HREF="https://developer.nvidia.com/deep-learning-performance-training-inference">Reproducible Performance</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-error-correction-code</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>IB</H3>
							<DL><p>
								<DT><H3 FOLDED>ib-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=wecZb5lHkXk&t=2278s">InfiniBand Principles Every HPC Expert MUST Know (Part 1) - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Pgy4wAw6eEo">InfiniBand Principles Every HPC Expert MUST Know (Part 2) - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=2gidd6lLiH8">27 Aug 18: Webinar: Introduction to InfiniBand Networks - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>ib-verbs</H3>
								<DL><p>
									<DT><H3 FOLDED>libibverbs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/linux-rdma/rdma-core/blob/master/Documentation/libibverbs.md">rdma-core/Documentation/libibverbs.md at master ¬∑ linux-rdma/rdma-core</A>
									</DL><p>
									<DT><H3 FOLDED>pyverbs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/linux-rdma/rdma-core/blob/master/Documentation/pyverbs.md">rdma-core/Documentation/pyverbs.md at master ¬∑ linux-rdma/rdma-core</A>
									</DL><p>
									<DT><H3 FOLDED>rust-ibverbs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/jonhoo/rust-ibverbs">jonhoo/rust-ibverbs: Bindings for RDMA ibverbs through rdma-core</A>
									</DL><p>
									<DT><A HREF="https://github.com/jgunthorpe/python-rdma">jgunthorpe/python-rdma: Python interface to the Linux RDMA stack</A>
									<DT><A HREF="https://github.com/linux-rdma/rdma-core/blob/master/debian/ibverbs-utils.install">rdma-core/debian/ibverbs-utils.install at master ¬∑ linux-rdma/rdma-core</A>
									<DT><A HREF="https://github.com/pytorch/torchtitan/issues/708">Low multi-node performance on SLURM cluster (32x H100): pt install ibverbs-utils, NCCL_IB_DISABLE=0 NCCL_NET=IB</A>
								</DL><p>
								<DT><H3 FOLDED>ib-monitoring</H3>
								<DL><p>
									<DT><H3 FOLDED>ibtop</H3>
									<DL><p>
										<DT><H3 FOLDED>ibtop-slurm</H3>
										<DL><p>
											<DT><A HREF="https://github.com/JannikSt/ibtop/issues/6">Make ibtop SLURM friendly ¬∑ Issue #6 ¬∑ JannikSt/ibtop</A>
										</DL><p>
										<DT><A HREF="https://github.com/JannikSt/ibtop">JannikSt/ibtop: Real-time terminal monitor for InfiniBand networks - htop for high-speed interconnects</A>
										<DT><A HREF="https://x.com/jannik_stra/status/2006125292792717336">new ibtop update. quick visualization tool for debugging infiniband issues on the fly</A>
										<DT><A HREF="https://github.com/jhammond/ibtop">jhammond/ibtop: monitor InfiniBand usage by job or host</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/ib-traffic-monitor">NVIDIA/ib-traffic-monitor: A TUI-based utility for real-time monitoring of InfiniBand traffic and performance metrics on the local node</A>
								</DL><p>
								<DT><H3 FOLDED>ib-benchmarking</H3>
								<DL><p>
									<DT><A HREF="https://grok.com/chat/b10df016-a0d5-41e8-a52b-9636c4de6f80">GPU Cluster Benchmarking: PyTorch vs IB Verbs - Grok</A>
									<DT><A HREF="https://chatgpt.com/c/681c9366-b66c-800c-8a88-296a94c2161a">Torch dist vs IB Verbs</A>
								</DL><p>
								<DT><H3 FOLDED>RoCE</H3>
								<DL><p>
									<DT><A HREF="https://grok.com/c/78874756-ce3f-475a-9d27-0a2d3b1b4976?rid=a497266a-aacb-474a-b5ed-be75a00cada0">RoCE Message Semantics GPU Limitations - Grok</A>
									<DT><A HREF="https://uccl-project.github.io/posts/about-uccl/">UCCL-Tran: An Extensible Software Transport Layer for GPU Networking</A>
									<DT><A HREF="https://github.com/uccl-project/uccl">uccl-project/uccl: UCCL is an efficient communication library for GPUs, covering collectives, P2P (e.g., KV cache transfer, RL weight transfer), and EP (e.g., GPU-driven)</A>
									<DT><A HREF="https://arxiv.org/pdf/2504.17307">An Extensible Software Transport Layer for GPU Networking</A>
								</DL><p>
								<DT><A HREF="https://www.kernel.org/doc/Documentation/ABI/stable/sysfs-class-infiniband">Linux sysfs interface common for all infiniband devices</A>
								<DT><A HREF="https://enterprise-support.nvidia.com/s/article/understanding-mlx5-linux-counters-and-status-parameters">Understanding mlx5 Linux Counters and Status Parameters</A>
								<DT><A HREF="https://pytorchtoatoms.substack.com/p/nvidia-quantum-x800-next-generation">NVIDIA Quantum-X800: Next Generation Infiniband 800Gbit/s Network Topology</A>
								<DT><A HREF="https://pytorchtoatoms.substack.com/p/benchmarking-nvlink-and-infiniband">Benchmarking Nvlink &amp; Infiniband Network Speeds</A>
								<DT><A HREF="http://mvapich.cse.ohio-state.edu/benchmarks/">MVAPICH :: Benchmarks</A>
								<DT><A HREF="https://github.com/imbue-ai/cluster-health/blob/master/ufm_events/find_problematic_events.py">cluster-health/ufm_events/find_problematic_events.py at master ¬∑ imbue-ai/cluster-health</A>
								<DT><A HREF="https://github.com/imbue-ai/cluster-health/tree/master/ib_burn">cluster-health/ib_burn at master ¬∑ imbue-ai/cluster-health</A>
								<DT><A HREF="https://github.com/ppl-ai/pplx-kernels">ppl-ai/pplx-kernels: Perplexity GPU Kernels</A>
								<DT><A HREF="https://distributedhatemachine.github.io/posts/infiniband/">Infiniband | Distributed Hate Machine</A>
							</DL><p>
							<DT><H3 FOLDED>MGI</H3>
							<DL><p>
								<DT><A HREF="https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html">NVIDIA Multi-Instance GPU User Guide :: NVIDIA Tesla Documentation</A>
								<DT><A HREF="https://developer.nvidia.com/blog/getting-the-most-out-of-the-a100-gpu-with-multi-instance-gpu/">Getting the Most Out of the NVIDIA A100 GPU with Multi-Instance GPU | NVIDIA Technical Blog</A>
								<DT><A HREF="https://pytorch.org/docs/stable/cuda.html">torch.cuda ‚Äî PyTorch 1.13 documentation</A>
								<DT><A HREF="https://discuss.pytorch.org/t/access-gpu-partitions-in-mig/142272">Access GPU partitions in MIG - PyTorch Forums</A>
							</DL><p>
							<DT><H3 FOLDED>GPUDirect</H3>
							<DL><p>
								<DT><H3 FOLDED>gds-installation</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html">NVIDIA GPUDirect Storage Installation and Troubleshooting Guide - NVIDIA Docs</A>
									<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/troubleshooting-guide/index.html#mofed-req-install">NVIDIA GPUDirect Storage Installation and Troubleshooting Guide - NVIDIA Docs</A>
									<DT><A HREF="https://docs.nvidia.com/networking/display/mlnxofedv531001">NVIDIA MLNX_OFED Documentation Rev 5.3-1.0.0.1 - NVIDIA Docs</A>
									<DT><A HREF="https://docs.nvidia.com/networking/display/mlnxofedv461000/downloading+mellanox+ofed">Downloading Mellanox OFED - NVIDIA Docs</A>
									<DT><A HREF="https://docs.nvidia.com/networking/display/mlnxofedv461000/general+support+in+mlnx_ofed">General Support in MLNX_OFED - NVIDIA Docs</A>
									<DT><A HREF="https://network.nvidia.com/products/infiniband-drivers/linux/mlnx_ofed/">Linux InfiniBand Drivers</A>
									<DT><A HREF="https://ubuntu.com/server/docs/nvidia-drivers-installation">NVIDIA drivers installation | Ubuntu</A>
									<DT><A HREF="https://github.com/developer-onizuka/gpudirect_storage">developer-onizuka/gpudirect_storage (global view)</A>
								</DL><p>
								<DT><H3 FOLDED>cuFile</H3>
								<DL><p>
									<DT><H3 FOLDED>kvikio</H3>
									<DL><p>
										<DT><A HREF="https://github.com/rapidsai/kvikio/blob/branch-24.04/python/tests/test_defaults.py">kvikio/python/tests/test_defaults.py (compat_mode)</A>
										<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/topics/cufile-compatibility.html">cuFile Compatibility Mode - NVIDIA Docs</A>
										<DT><A HREF="https://docs.rapids.ai/api/libkvikio/nightly/">Compatibility Mode (KVIKIO_COMPAT_MODE)</A>
									</DL><p>
									<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html">cuFile API Reference Guide - NVIDIA Docs</A>
									<DT><A HREF="https://github.com/rapidsai/kvikio">rapidsai/kvikio</A>
									<DT><A HREF="https://github.com/rapidsai/kvikio/pull/135">Overload `numpy.fromfile()` and `cupy.fromfile()` by madsbk ¬∑ Pull Request #135 ¬∑ rapidsai/kvikio</A>
									<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py">alpa/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py at main ¬∑ alpa-projects/alpa</A>
									<DT><A HREF="https://github.com/pfnet/pytorch-pfn-extras/blob/f6b127063ec910b71788db2ae6ef96a3d89832b1/tests/pytorch_pfn_extras_tests/cuda_tests/test_allocator.py">pytorch-pfn-extras/tests/pytorch_pfn_extras_tests/cuda_tests/test_allocator.py at f6b127063ec910b71788db2ae6ef96a3d89832b1 ¬∑ pfnet/pytorch-pfn-extras</A>
									<DT><A HREF="https://pytorch-pfn-extras.readthedocs.io/en/latest/user_guide/cuda.html">CUDA (CuPy Interoperability) ‚Äî pytorch-pfn-extras documentation</A>
									<DT><A HREF="https://github.com/NVIDIA/apex/blob/810ffae374a2b9cb4b5c5e28eaeca7d7998fca0c/apex/contrib/csrc/gpu_direct_storage/gds.cpp">apex/apex/contrib/csrc/gpu_direct_storage/gds.cpp</A>
									<DT><A HREF="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_022.cc">cuFile Batch APIs</A>
									<DT><A HREF="https://chat.openai.com/c/61bb588b-35a7-42a6-90e9-c2355e5646a9">Identify Disk Storage Type</A>
								</DL><p>
								<DT><A HREF="https://github.com/NVIDIA/gds-nvidia-fs">NVIDIA/gds-nvidia-fs: NVIDIA GPUDirect Storage Driver</A>
								<DT><A HREF="https://developer.nvidia.com/blog/gpudirect-storage/">GPUDirect Storage: A Direct Path Between Storage and GPU Memory</A>
								<DT><A HREF="https://arxiv.org/pdf/2203.04910.pdf?">GPU-Initiated On-Demand High-Throughput Storage Access in the BaM System Architecture</A>
								<DT><A HREF="https://on-demand.gputechconf.com/supercomputing/2019/pdf/sc1922-gpudirect-storage-transfer-data-directly-to-gpu-memory-alleviating-io-bottlenecks.pdf">GPUDIRECT STORAGE:A DIRECT GPU-STORAGE DATA PATH</A>
								<DT><A HREF="https://www.snia-j.org/cmm/images/2022/10/3-1NVIDIA.pdf">NVIDIA GPUDirect Storage</A>
								<DT><A HREF="https://github.com/michaelbe2/write_to_gpu">michaelbe2/write_to_gpu: Using RC or DC with new post send APIs</A>
								<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py">alpa/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py at main ¬∑ alpa-projects/alpa</A>
								<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html">NVIDIA GPUDirect Storage O_DIRECT Requirements Guide - NVIDIA Docs</A>
								<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html">NVIDIA GPUDirect Storage Best Practices Guide - NVIDIA Docs</A>
								<DT><A HREF="https://medium.com/@kaiyongx2/quick-guide-to-gpudirect-storage-gds-592037bdc046">Learning Nvidia GPUDirect. Impetus of Using GPUDirect Storage | by KY | Medium</A>
								<DT><A HREF="https://chat.openai.com/c/61bb588b-35a7-42a6-90e9-c2355e5646a9">Identify Disk Storage Type</A>
								<DT><A HREF="https://man7.org/linux/man-pages/man8/lsblk.8.html">lsblk(8) - Linux manual page</A>
								<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html">NVIDIA GPUDirect Storage Overview Guide - NVIDIA Docs</A>
								<DT><A HREF="https://ieeexplore.ieee.org/document/7973709">Offloading Communication Control Logic in GPU</A>
								<DT><A HREF="https://github.com/Mellanox/gpu_direct_rdma_access">Mellanox/gpu_direct_rdma_access: example code for using DC QP for providing RDMA READ and WRITE operations to remote GPU memory</A>
								<DT><A HREF="https://github.com/NVIDIA/gdrcopy">NVIDIA/gdrcopy: A fast GPU memory copy library based on NVIDIA GPUDirect RDMA technology</A>
								<DT><A HREF="https://github.com/lw?tab=stars">lw (Luca Wehrstedt)</A>
								<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py">alpa/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/compare/main...mikaylagawarecki:pytorch:gds">Comparing pytorch:main...mikaylagawarecki:gds ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://github.com/Mellanox/nv_peer_memory">Mellanox/nv_peer_memory</A>
								<DT><A HREF="https://mkyong.com/web/how-to-pretty-print-json-output-in-curl/">How to Pretty Print JSON output with cURL - Mkyong.com</A>
							</DL><p>
							<DT><H3 FOLDED>nvidia-driver</H3>
							<DL><p>
								<DT><H3 FOLDED>cuda-driver-installation</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/cuda-12-6-0-download-archive?target_os=Linux&target_arch=arm64-sbsa&Compilation=Native&Distribution=Ubuntu&target_version=22.04&target_type=deb_local">CUDA Toolkit 12.6 Downloads | NVIDIA Developer</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#driver-installation">4. Driver Installation‚Äî Installation Guide for Linux 12.8 documentation</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/#uninstallation">8.6 Uninstallation (official docs)</A>
									<DT><A HREF="https://ubuntu.com/server/docs/nvidia-drivers-installation">NVIDIA drivers installation | Ubuntu</A>
									<DT><A HREF="https://help.ubuntu.com/community/NvidiaDriversInstallation">NvidiaDriversInstallation - Community Help Wiki</A>
									<DT><A HREF="https://gist.github.com/jhelgert/b50d2b33d59eb935d8c37cd7d5d891d1">Installing the NVIDIA driver, CUDA, cuDNN, NCCL and Tensorflow on Linux</A>
									<DT><A HREF="https://linux.die.net/man/8/modprobe">modprobe(8): add/remove modules from Kernel - Linux man page</A>
									<DT><A HREF="https://www.nvidia.com/Download/index.aspx">NVIDIA Driver Downloads</A>
									<DT><A HREF="https://fossies.org/linux/misc/">Linux: Free open source software (misc) | Fossies Archive</A>
									<DT><A HREF="https://ubuntuforums.org/showthread.php?t=2454347">[SOLVED] dpkg: error processing archive /var/cache/apt/archives/libnvidia-compute-440_440.118.</A>
									<DT><A HREF="https://github.com/imbue-ai/cluster-health/blob/master/health_checks/health_check_fixes/reinstall_nvidia.sh">cluster-health/health_checks/health_check_fixes/reinstall_nvidia.sh at master ¬∑ imbue-ai/cluster-health</A>
								</DL><p>
								<DT><H3 FOLDED>open-gpu-kernel-modules</H3>
								<DL><p>
									<DT><H3 FOLDED>nvida-driver-p2p-patch</H3>
									<DL><p>
										<DT><H3 FOLDED>p2p-patch-5090</H3>
										<DL><p>
											<DT><A HREF="https://x.com/__tinygrad__/status/1919460309066195177">(2) the tiny corp en X: "tinybox green v2 supports P2P between the 5090s using our modified driver! This means the bytes go directly between the GPUs and don't have to go to CPU RAM. Works in both tinygrad and PyTorch (anything with nccl). https://t.co/ttvwIJEpk6" / X</A>
											<DT><A HREF="https://github.com/tinygrad/open-gpu-kernel-modules/tree/570.124.06-p2p">tinygrad/open-gpu-kernel-modules at 570.124.06-p2p</A>
											<DT><A HREF="https://www.notion.so/datacrunchio/5090-p2p-kernel-patch-1e5b9e769144807db33ecdd38018bb06">(1) 5090 p2p kernel patch</A>
										</DL><p>
										<DT><A HREF="https://github.com/tinygrad/tinyos/blob/main/setup/driverinstall.sh">tinyos/setup/driverinstall.sh at main ¬∑ tinygrad/tinyos</A>
										<DT><A HREF="https://morgangiraud.medium.com/multi-gpu-tinygrad-patch-4904a75f8e16">Multi-GPU Tinygrad Patch. Unlocking Multi-GPU P2P Capabilities... | by Morgan | May, 2024 | Medium</A>
										<DT><A HREF="https://github.com/tinygrad/open-gpu-kernel-modules">tinygrad/open-gpu-kernel-modules: NVIDIA Linux open GPU with P2P support</A>
									</DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules/">NVIDIA Transitions Fully Towards Open-Source GPU Kernel Modules | NVIDIA Technical Blog</A>
									<DT><A HREF="https://stackoverflow.com/questions/30820513/what-is-the-correct-version-of-cuda-for-my-nvidia-driver/30820690#30820690">cuda driver compatiblity matrix</A>
									<DT><A HREF="https://eunomia.dev/blog/2025/10/14/nvidia-open-gpu-kernel-modules-comprehensive-source-code-analysis/">NVIDIA Open GPU Kernel Modules Comprehensive Source Code Analysis - eunomia</A>
								</DL><p>
								<DT><H3 FOLDED>nvidia-driver-570.86.15</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/datacenter/tesla/tesla-release-notes-570-86-15/index.html">Version 570.86.15(Linux)/572.13(Windows) :: NVIDIA Data Center GPU Driver Documentation</A>
								</DL><p>
								<DT><A HREF="https://docs.nvidia.com/datacenter/tesla/index.html">NVIDIA Data Center GPU Driver Documentation</A>
								<DT><A HREF="https://download.nvidia.com/XFree86/Linux-x86_64/470.223.02/README/">NVIDIA Accelerated Linux Graphics Driver README and Installation Guide</A>
								<DT><A HREF="https://github.com/tinygrad/open-gpu-kernel-modules">tinygrad/open-gpu-kernel-modules: NVIDIA Linux open GPU with P2P support</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/acc466751b2723eb913fd3148b4f054189bbf1ab/.devcontainer/README.md">pytorch/.devcontainer/README.md: NVIDIA Container Toolkit for GPU Usage</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html">CUDA 12.5 Update 1 Release Notes</A>
								<DT><A HREF="https://github.com/pytorch-labs/tritonbench/tree/main/docker/infra">tritonbench/docker/infra at main ¬∑ pytorch-labs/tritonbench</A>
								<DT><A HREF="https://github.com/facebookresearch/xformers/pull/1157">[FA3] Link to cuda library to fix the FA3 extension build by xuzhao9 ¬∑ Pull Request #1157 ¬∑ facebookresearch/xformers</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/pull/1700">Use CUDA runtime API to retrieve function pointer to driver API by shunfan-shao ¬∑ Pull Request #1700 ¬∑ NVIDIA/cutlass</A>
								<DT><A HREF="https://docs.nvidia.com/deploy/cuda-compatibility/">CUDA Compatibility</A>
								<DT><A HREF="https://docs.nvidia.com/datacenter/tesla/drivers/index.html">NVIDIA Data Center Drivers</A>
								<DT><A HREF="https://docs.nvidia.com/deploy/cuda-compatibility/why-cuda-compatibility.html">Why CUDA Compatibility ‚Äî CUDA Compatibility</A>
								<DT><A HREF="https://blog.quarkslab.com/nvidia_gpu_kernel_vmalloc_exploit.html">NVIDIA's GPU Linux drivers</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-monitoring</H3>
							<DL><p>
								<DT><H3 FOLDED>NVML</H3>
								<DL><p>
									<DT><A HREF="https://github.com/gpuopenanalytics/pynvml">gpuopenanalytics/pynvml: Provide Python access to the NVML library for GPU diagnostics</A>
									<DT><A HREF="https://pypi.org/project/pynvml/">pynvml ¬∑ PyPI</A>
									<DT><A HREF="https://docs.nvidia.com/deploy/nvml-api/group__nvmlDeviceQueries.html#group__nvmlDeviceQueries">NVML API Reference</A>
									<DT><A HREF="https://github.com/deepspeedai/DeepSpeed/blob/a01a2688b98aa90ac1dcf23012efbe13ba69ebcd/deepspeed/compile/profilers/graph_profile.py#L54">DeepSpeed/deepspeed/compile/profilers/graph_profile.py: _get_mem_usage_out_of_torch()</A>
									<DT><A HREF="https://pypi.org/project/nvidia-ml-py/">nvidia-ml-py ¬∑ PyPI</A>
								</DL><p>
								<DT><H3 FOLDED>nvidia-smi</H3>
								<DL><p>
									<DT><H3 FOLDED>nvidia-smi-kill</H3>
									<DL><p>
										<DT><A HREF="https://chatgpt.com/c/679cbf8b-5348-800c-9bc6-c99e41df17a7">Kill GPU Processes Ubuntu nvidia-smi</A>
										<DT><A HREF="https://claude.ai/chat/fcb0ea6d-a81c-4de0-a5ee-e6803c72e48e">sudo nvidia-smi --query-compute-apps=pid --format=csv,noheader | xargs -r sudo kill -9</A>
									</DL><p>
									<DT><A HREF="https://forums.developer.nvidia.com/t/nvidia-smi-drain-failed-to-parse-device-specified-at-the-command-line/180402">Nvidia-smi drain "Failed to parse device specified at the command-line" - CUDA / CUDA Programming and Performance - NVIDIA Developer Forums</A>
									<DT><A HREF="https://unix.stackexchange.com/questions/654075/how-can-i-disable-and-later-re-enable-one-of-my-nvidia-gpus">linux - How can I disable (and later re-enable) one of my NVIDIA GPUs? - Unix &amp; Linux Stack Exchange</A>
									<DT><A HREF="https://nvidia.custhelp.com/app/answers/detail/a_id/3751/~/useful-nvidia-smi-queries">Useful nvidia-smi Queries | NVIDIA</A>
									<DT><A HREF="https://x.com/pranjalssh">watch -n 0.1 nvidia-smi</A>
									<DT><A HREF="https://docs.nvidia.com/deploy/nvidia-smi/index.html">https://docs.nvidia.com/deploy/nvidia-smi/index.html</A>
									<DT><A HREF="https://github.com/gpuopenanalytics/pynvml">gpuopenanalytics/pynvml: Provide Python access to the NVML library for GPU diagnostics</A>
									<DT><A HREF="https://pypi.org/project/pynvml/">pynvml ¬∑ PyPI</A>
								</DL><p>
								<DT><H3 FOLDED>gpu-monitoring</H3>
								<DL><p>
									<DT><H3 FOLDED>nvitop</H3>
									<DL><p>
										<DT><A HREF="https://github.com/XuehaiPan/nvitop?tab=readme-ov-file#resource-metric-collector">XuehaiPan/nvitop: An interactive NVIDIA-GPU process viewer and beyond, the one-stop solution for GPU process management.</A>
										<DT><A HREF="https://github.com/XuehaiPan/nvitop">XuehaiPan/nvitop: An interactive NVIDIA-GPU process viewer and beyond, the one-stop solution for GPU process management.</A>
										<DT><A HREF="https://x.com/khoomeik/status/1958050090725134543">(1) Rohan Pandey en X: "on this episode of ml research with young infra... debugging MoE load balancer optimization by watching nvitop over the course of training https://t.co/HvsQOgSQwh" / X</A>
									</DL><p>
									<DT><H3 FOLDED>nvtop</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Syllo/nvtop">Syllo/nvtop: GPU &amp; Accelerator process monitoring for AMD, Apple, Huawei, Intel, NVIDIA and Qualcomm</A>
									</DL><p>
									<DT><A HREF="https://github.com/wookayin/gpustat">wookayin/gpustat: üìä A simple command-line utility for querying and monitoring GPU status</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>Nvidia-instruction-set-architecture</H3>
							<DL><p>
								<DT><H3 FOLDED>Nvidia SM90a Instruction Set Architecture</H3>
								<DL><p>
									<DT><A HREF="https://kuterdinel.com/nv_isa/">https://kuterdinel.com/nv_isa/</A>
									<DT><A HREF="https://x.com/KuterDinel">(1) Kuter Dinel (@KuterDinel) / X</A>
									<DT><A HREF="https://kuterdinel.com/nvidia-sass-control-code-viewer.html">Nvidia SASS Control Code Viewer ‚Ä¢ Kuter Dinel's blog</A>
									<DT><A HREF="https://kuterdinel.com/python-bytecode-and-ast-explorer.html">Python Bytecode and AST Explorer ‚Ä¢ Kuter Dinel's blog</A>
									<DT><A HREF="https://github.com/kuterd/nv_isa_solver">kuterd/nv_isa_solver: Nvidia Instruction Set Specification Generator</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>cupy</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cupy/cupy/blob/cf9b4a517725b803fba4828ed0b1c93a231cc5da/cupyx/distributed/_nccl_comm.py#L56">cupy/cupyx/distributed/_nccl_comm.py</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-sharing</H3>
							<DL><p>
								<DT><H3 FOLDED>Multi-Process Service (MPS)</H3>
								<DL><p>
									<DT><A HREF="https://www.olcf.ornl.gov/wp-content/uploads/2021/06/MPS_ORNL_20210817.pdf">Introduction (slides)</A>
									<DT><A HREF="https://docs.nvidia.com/deploy/mps/index.html">Multi-Process Service :: GPU Deployment and Management Documentation</A>
								</DL><p>
								<DT><H3 FOLDED>Time-Slicing</H3>
								<DL><p>
									<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html">Time-Slicing GPUs in Kubernetes ‚Äî NVIDIA GPU Operator 23.9.2 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>NVIDIA Multi-Instance GPU</H3>
								<DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/technologies/multi-instance-gpu/">Multi-Instance GPU (MIG) | NVIDIA</A>
								</DL><p>
								<DT><A HREF="https://research.colfax-intl.com/sharing-nvidia-gpus-at-the-system-level-time-sliced-and-mig-backed-vgpus/">Sharing NVIDIA¬Æ GPUs at the System Level: Time-Sliced and MIG-Backed vGPUs ‚Äì Colfax Research</A>
								<DT><A HREF="https://www.youtube.com/watch?v=8VQHwNwX-BU">NSDI '23 - Transparent GPU Sharing in Container Clouds for Deep Learning Workloads - YouTube</A>
								<DT><A HREF="https://github.com/pkusys/TGS">pkusys/TGS: Artifacts for our NSDI'23 paper TGS</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-people</H3>
							<DL><p>
								<DT><A HREF="https://github.com/wangzyon">wangzyon (Wang Zhiyong)</A>
								<DT><A HREF="https://www.youtube.com/@OnurMutluLectures/videos">Onur Mutlu Lectures - YouTube</A>
								<DT><A HREF="https://siboehm.com/">siboehm</A>
								<DT><A HREF="https://leimao.github.io/tags/CUDA/">Tag: CUDA - Lei Mao's Log Book</A>
								<DT><A HREF="https://github.com/depaulmillz">dePaul Miller (@depaulmillz)</A>
								<DT><A HREF="https://github.com/Sam3077">Sam3077 (Samantha)</A>
								<DT><A HREF="https://github.com/yzhaiustc">yzhaiustc (Yujia Zhai)</A>
								<DT><A HREF="https://github.com/shangz-ai">shangz-ai (Shang Zhang)</A>
								<DT><A HREF="https://github.com/IonThruster">IonThruster (Pradeep Ramani)</A>
								<DT><A HREF="https://github.com/mbrookhart">mbrookhart (Matthew Brookhart)</A>
								<DT><A HREF="https://github.com/masahi">masahi</A>
								<DT><A HREF="https://github.com/binarybana">binarybana (Jason Knight)</A>
								<DT><A HREF="https://github.com/CliveUnger">CliveUnger (Clive Unger)</A>
							</DL><p>
							<DT><H3 FOLDED>compute-capability</H3>
							<DL><p>
								<DT><A HREF="https://github.com/pytorch/pytorch/pull/109168/files#diff-6eceb58c0b35f53fc6d289165f9ff56fa419155920dfdef45a82296f171c96fa">Basic fp8 support in Inductor by ipiszy ¬∑ Pull Request #109168 ¬∑ pytorch/pytorch: isSM90orLaterDevice</A>
								<DT><A HREF="https://github.com/ai-compiler-study/triton-kernels/blob/main/scripts/gpu_properties.cu">triton-kernels/scripts/gpu_properties.cu at gpu_properties</A>
							</DL><p>
							<DT><H3 FOLDED>nvshmem</H3>
							<DL><p>
								<DT><H3 FOLDED>nvshmem-learning</H3>
								<DL><p>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1962089463871144000">NVSHMEM Learning</A>
									<DT><A HREF="https://github.com/KuangjuX/NVSHMEM-Tutorial">KuangjuX/NVSHMEM-Tutorial: NVSHMEM‚ÄëTutorial: Build a DeepEP‚Äëlike GPU Buffer</A>
								</DL><p>
								<DT><H3 FOLDED>NVSHMEM4Py</H3>
								<DL><p>
									<DT><A HREF="https://www.linkedin.com/posts/jeffhammond_nvshmem4py-cu12-activity-7344061638259441664-deL1/">Post | LinkedIn</A>
									<DT><A HREF="https://pypi.org/project/nvshmem4py-cu12/">nvshmem4py-cu12¬∑PyPI</A>
									<DT><A HREF="https://github.com/mpi4py/shmem4py">mpi4py/shmem4py: Python bindings for OpenSHMEM</A>
									<DT><A HREF="https://shmem4py.readthedocs.io/en/latest/">OpenSHMEM for Python (shmem4py) ‚Äî shmem4py 1.0.0 documentation</A>
									<DT><A HREF="https://shmem4py.readthedocs.io/en/latest/examples.html#hello-world">Usage examples ‚Äî shmem4py 1.0.0 documentation</A>
									<DT><A HREF="https://github.com/openshmem-org/osss-ucx/blob/main/example/hello.c">osss-ucx/example/hello.c at main ¬∑ openshmem-org/osss-ucx</A>
									<DT><A HREF="https://github.com/muriloboratto/NVSHEMEM">muriloboratto/NVSHEMEM: Sample Codes using NVSHMEM on Multi-GPU</A>
									<DT><A HREF="https://github.com/NVIDIA/NVSHMEM/tree/main/nvshmem4py">NVSHMEM/nvshmem4py at main ¬∑ NVIDIA/NVSHMEM</A>
									<DT><A HREF="https://github.com/KuangjuX/NVSHMEM-Tutorial">KuangjuX/NVSHMEM-Tutorial: NVSHMEM‚ÄëTutorial: Build a DeepEP‚Äëlike GPU Buffer</A>
									<DT><A HREF="https://github.com/KuangjuX/AttnLink">KuangjuX/AttnLink: :construction: An experimental communicating attention kernel based on DeepEP.</A>
								</DL><p>
								<DT><H3 FOLDED>nvshmem-multi-node</H3>
								<DL><p>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/1984722871848223158">(1) SemiAnalysis en X: "PyTorch symmetrical memory now supports multinode too üöÄexclusively on CUDA through NVSHMEM. We explain why this is important belowüëá This feature is crucial because it enables easy authoring of multi-GPU, multi-node compute-communication overlapping kernels using Triton or C++. https://t.co/ZHfhNEHCwF" / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/NVIDIA/NVSHMEM">NVIDIA/NVSHMEM: NVIDIA NVSHMEM is a parallel programming interface for NVIDIA GPUs based on OpenSHMEM. NVSHMEM can significantly reduce multi-process communication and coordination overheads by allowing programmers to perform one-sided communication from within CUDA kernels and on CUDA streams.</A>
								<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/1160">feat: nvshmem python bindings by yzh119 ¬∑ Pull Request #1160 ¬∑ flashinfer-ai/flashinfer</A>
								<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/1160/files">feat: nvshmem python bindings by yzh119 ¬∑ Pull Request #1160 ¬∑ flashinfer-ai/flashinfer</A>
								<DT><A HREF="https://www.youtube.com/watch?v=zxGVvMN6WaM">Lecture 67: NCCL and NVSHMEM - YouTube</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1952325639211315297">nvshmem source code learning (I) the overall process from the perspective of ibgda</A>
							</DL><p>
							<DT><H3 FOLDED>cudaRT</H3>
							<DL><p>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/a1c1ebe9357418ae8cf8ffdf66e3eaec066170e8/python/sglang/srt/distributed/device_communicators/cuda_wrapper.py#L64">sglang/python/sglang/srt/distributed/device_communicators/cuda_wrapper.py at a1c1ebe9357418ae8cf8ffdf66e3eaec066170e8 ¬∑ sgl-project/sglang</A>
							</DL><p>
							<DT><H3 FOLDED>opencl</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/geohot/0cad05378fcbaeb0dceec3e89e0d4d7b">A 1024x1024x1024 matmul with a 2x2x2 core in OpenCL</A>
							</DL><p>
							<DT><H3 FOLDED>cuda-checkpointing</H3>
							<DL><p>
								<DT><H3 FOLDED>CRIUgpu</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/html/2502.16631v1">CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads</A>
								</DL><p>
								<DT><H3 FOLDED>GPU Memory Snapshots</H3>
								<DL><p>
									<DT><A HREF="https://modal.com/blog/gpu-mem-snapshots">GPU Memory Snapshots: Supercharging Sub-second Startup</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>cuDeviceGetAttribute</H3>
							<DL><p>
								<DT><A HREF="https://developer.download.nvidia.com/compute/DevZone/docs/html/C/doc/html/group__CUDA__DEVICE_g9c3e1414f0ad901d3278a4d6645fc266.html">NVIDIA CUDA Library: cuDeviceGetAttribute: CLOCK_RATE</A>
							</DL><p>
							<DT><H3 FOLDED>confidential computing</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/nvtrust">NVIDIA/nvtrust: Ancillary open source software to support confidential computing on NVIDIA GPUs</A>
								<DT><A HREF="https://learn.microsoft.com/en-us/azure/confidential-computing/confidential-computing-deployment-models">Choose Between Deployment Models | Microsoft Learn</A>
							</DL><p>
							<DT><A HREF="https://github.com/geohot/cuda_ioctl_sniffer">geohot/cuda_ioctl_sniffer: Sniff CUDA ioctls</A>
							<DT><A HREF="https://jhui.github.io/2017/03/06/CUDA/">‚ÄúCUDA Tutorial‚Äù</A>
							<DT><A HREF="https://developer.nvidia.com/deep-learning-performance-training-inference">Reproducible Performance</A>
							<DT><A HREF="https://catalog.ngc.nvidia.com/collections">Collections - Use-Case Based AI Software Packages | NVIDIA NGC</A>
							<DT><A HREF="https://forums.fast.ai/t/clearing-gpu-memory-pytorch/14637">Clearing GPU Memory - PyTorch - Part 1 (2018) / Beginner (2018) - Deep Learning Course Forums</A>
							<DT><A HREF="https://discuss.pytorch.org/t/why-moving-model-and-tensors-to-gpu/41498">Moving memory from CPU-RAM to GPU VRAM</A>
							<DT><A HREF="https://www.programcreek.com/python/?CodeExample=clear+memory">Python clear memory</A>
							<DT><A HREF="https://groups.google.com/a/anaconda.com/g/numba-users/c/7jkf-X_U7B8">Best way to clean up GPU memory</A>
							<DT><A HREF="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__MEMORY.html#group__CUDART__MEMORY_1ga042655cbbf3408f01061652a075e094">CUDA Runtime API :: CUDA Toolkit Documentation</A>
							<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/developer-guide/index.html">cuDNN Documentation</A>
							<DT><A HREF="https://stackoverflow.com/questions/31326015/how-to-verify-cudnn-installation">cuda - How to verify CuDNN installation</A>
							<DT><A HREF="https://nvidia.github.io/cuda-python/install.html">Installation - CUDA Python 12.1.0 documentation</A>
							<DT><A HREF="https://twitter.com/marius/status/1657530968801181696/photo/1">GPU Computing</A>
							<DT><A HREF="https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics">CUDA semantics ‚Äî PyTorch 2.0 documentation</A>
							<DT><A HREF="https://www.youtube.com/watch?v=QQceTDjA4f4">GTC 2022 - How CUDA Programming Works - Stephen Jones, CUDA Architect, NVIDIA - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=-J8YyfrSwTk">Effective ML - YouTube</A>
							<DT><A HREF="https://github.com/enp1s0/cutf">enp1s0/cutf: CUDA Template Functions</A>
							<DT><A HREF="https://arxiv.org/pdf/1903.07486.pdf">https://arxiv.org/pdf/1903.07486.pdf</A>
							<DT><A HREF="https://arxiv.org/abs/1903.07486">[1903.07486] Dissecting the NVidia Turing T4 GPU via Microbenchmarking</A>
							<DT><A HREF="https://gist.github.com/mcarilli">mcarilli‚Äôs gists</A>
							<DT><A HREF="https://futhark-lang.org/">Why Futhark?</A>
							<DT><A HREF="https://www.youtube.com/watch?v=q38V66bqhfU">EfficientML.ai lecture - YouTube</A>
							<DT><A HREF="https://github.com/coreylowman/cudarc">coreylowman/cudarc: Safe rust wrapper around CUDA toolkit</A>
							<DT><A HREF="https://research.colfax-intl.com/adding-fp8-to-flashattention/">Delivering 1 PFLOP/s of Performance with FP8 FlashAttention-2 ‚Äì Colfax Research</A>
							<DT><A HREF="https://forums.fast.ai/t/clearing-gpu-memory-pytorch/14637">Clearing GPU Memory</A>
							<DT><A HREF="https://github.com/microsoft/onnxruntime/tree/main/onnxruntime/core/providers/cuda">onnxruntime/onnxruntime/core/providers/cuda at main</A>
							<DT><A HREF="https://github.com/NVIDIA/FasterTransformer/blob/df4a7534860137e060e18d2ebf019906120ea204/src/fastertransformer/kernels/matrix_transpose_kernels.cu#L4">FasterTransformer/src/fastertransformer/kernels/matrix_transpose_kernels.cu at df4a7534860137e060e18d2ebf019906120ea204 ¬∑ NVIDIA/FasterTransformer</A>
							<DT><A HREF="https://github.com/HigherOrderCO/HVM/blob/5de3e7ed8f1fcee6f267841a24119ffd569c714d/src/hvm.cu#L4">HVM/src/hvm.cu</A>
							<DT><A HREF="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">NVIDIA CUDA Compiler Driver</A>
							<DT><A HREF="https://github.com/Rust-GPU/Rust-CUDA">Rust-GPU/Rust-CUDA: Ecosystem of libraries and tools for writing and executing fast GPU code fully in Rust.</A>
						</DL><p>
						<DT><H3 FOLDED>rocm</H3>
						<DL><p>
							<DT><H3 FOLDED>HIP</H3>
							<DL><p>
								<DT><A HREF="https://github.com/geohot/tinygrad/pull/750">HIP backend by nanamiwang ¬∑ Pull Request #750 ¬∑ geohot/tinygrad</A>
								<DT><A HREF="https://www.semianalysis.com/p/nvidiaopenaitritonpytorch">TorchInductor &amp; Triton</A>
								<DT><A HREF="https://github.com/openai/triton/issues/46">Support for HIP backend / AMD GPUs ¬∑ Issue #46 ¬∑ openai/triton</A>
								<DT><A HREF="https://github.com/openai/triton/blob/a2433f3135c312c05fbbcd98083896c93bf0c504/python/triton/runtime/driver.py#L111">triton/driver.py</A>
								<DT><A HREF="https://nv-adlr.github.io/MegatronLM">MegatronLM: NCCL</A>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/mpi.html">NCCL and MPI ‚Äî NCCL 2.18.1 documentation</A>
								<DT><A HREF="https://pytorch.org/docs/stable/notes/hip.html">HIP (ROCm) semantics ‚Äî PyTorch 2.0 documentation</A>
								<DT><A HREF="https://github.com/ROCm-Developer-Tools/HIP">ROCm-Developer-Tools/HIP: HIP: C++ Heterogeneous-Compute Interface for Portability</A>
								<DT><A HREF="https://github.com/ROCm-Developer-Tools/HIPIFY">HIPIFY</A>
								<DT><A HREF="https://docs.python.org/3/library/ctypes.html">ctypes ‚Äî A foreign function library for Python ‚Äî Python 3.11.3 documentation</A>
								<DT><A HREF="https://www.youtube.com/playlist?list=PLB1fSi1mbw6IKbZSPz9a2r2DbnHWnLbF-">AMD HIP Tutorial - YouTube</A>
								<DT><A HREF="https://gist.github.com/geohot/6232fb00527de161a5c8ce8a635dd4f3">Wrapper for HIP</A>
							</DL><p>
							<DT><H3 FOLDED>RDNA3</H3>
							<DL><p>
								<DT><A HREF="https://www.amd.com/system/files/TechDocs/rdna3-shader-instruction-set-architecture-feb-2023_0.pdf">Instruction Set Architecture</A>
								<DT><A HREF="https://github.com/geohot/tinygrad/blob/ed038ba12906bb1980956b1e31e02e77ec0524ee/extra/rocm/rdna3/asm.py">tinygrad/asm.py</A>
							</DL><p>
							<DT><H3 FOLDED>rocm-llvm</H3>
							<DL><p>
								<DT><A HREF="https://llvm.org/docs/CommandGuide/llvm-mc.html">llvm-mc - LLVM Machine Code Playground ‚Äî LLVM 17.0.0git documentation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=avRWPe1MXPk">LLVM Isn't Always The Best Choice For Compilers. - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>rocm-lumi</H3>
							<DL><p>
								<DT><H3 FOLDED>user information</H3>
								<DL><p>
									<DT><A HREF="https://docs.csc.fi/accounts/how-to-manage-user-information/#how-to-link-your-csc-user-account-to-external-authentication-sources">Managing user information - Docs CSC</A>
									<DT><A HREF="https://my.csc.fi/profile">My CSC</A>
									<DT><A HREF="https://mms.myaccessid.org/fed-apps/profile/#settings_sshkeys">Perun - User profile</A>
									<DT><A HREF="https://puhuri-portal.neic.no/login/">Puhuri Portal |</A>
									<DT><A HREF="https://md.sigma2.no/lumi-general-course-oct23?both#DAY-1-%E2%80%93-Tuesday-3102023">LUMI General Course - HedgeDoc</A>
									<DT><A HREF="https://lumi-supercomputer.github.io/LUMI-training-materials/4day-20230530/extra_1_05_Compilers_and_Parallel_Programming_Models/">Compilers and Parallel Programming Models - LUMI training materials</A>
								</DL><p>
								<DT><A HREF="https://openfam.github.io/">OpenFAM: A library for programming Fabric-Attached Memory</A>
								<DT><A HREF="https://cpe.ext.hpe.com/docs/performance-tools/perftools-lite.html#description">perftools-lite ‚Äî HPE Cray Programming Environment 10.1.0 documentation</A>
							</DL><p>
							<DT><H3 FOLDED>rocm-instinct</H3>
							<DL><p>
								<DT><H3 FOLDED>rocm-amd-mi300x</H3>
								<DL><p>
									<DT><A HREF="https://www.semianalysis.com/p/amd-mi300-taming-the-hype-ai-performance">AMD MI300 ‚Äì Taming The Hype ‚Äì AI Performance, Volume Ramp, Customers, Cost, IO, Networking, Software</A>
								</DL><p>
								<DT><H3 FOLDED>rocm-mi250x</H3>
								<DL><p>
									<DT><A HREF="https://www.lumi-supercomputer.eu/lumis-full-system-architecture-revealed/">LUMI‚Äôs full system architecture revealed - LUMI</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://rocm.github.io/rocncloc.html">ROCm, A New Era in Open GPU Computing</A>
							<DT><A HREF="https://github.com/ROCm-Developer-Tools/rocprofiler">ROCm-Developer-Tools/rocprofiler: ROC profiler library. Profiling with perf-counters and derived metrics.</A>
							<DT><A HREF="https://github.com/ROCmSoftwarePlatform/hip-python">ROCmSoftwarePlatform/hip-python: HIP Python Low-level Bindings</A>
							<DT><A HREF="https://www.youtube.com/watch?v=lnVQsJJFcdg&list=LL&index=296&t=1336s">George Hotz | Programming | writing a Qualcomm GPU driver | Freedreno | Mesa for compute | part 2 - YouTube</A>
							<DT><A HREF="https://github.com/tinygrad/remu?tab=readme-ov-file">tinygrad/remu: RDNA3 emulator</A>
							<DT><A HREF="https://docs.amd.com/">AMD Documentation - Portal</A>
							<DT><A HREF="https://pytorch.org/docs/stable/elastic/run.html#launcher-api">torchrun (Elastic Launch) ‚Äî PyTorch 2.0 documentation</A>
							<DT><A HREF="https://www.youtube.com/watch?v=LG9G4aA28rU">GPU Programming Concepts (Part 1) - YouTube</A>
							<DT><A HREF="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide#distributed-pytorch-underthehood">(MPI): Multi node PyTorch Distributed Training</A>
							<DT><A HREF="https://github.com/openai/triton/pull/1983">[ROCM] Core Functionality for AMD by micmelesse ¬∑ Pull Request #1983 ¬∑ openai/triton</A>
							<DT><A HREF="https://www.mosaicml.com/blog/amd-mi250">Training LLMs with AMD MI250 GPUs and MosaicML</A>
							<DT><A HREF="https://tenstorrent.com/category/research/">Category: Research - Tenstorrent</A>
							<DT><A HREF="https://github.com/ROCm/rocm-blogs">ROCm/rocm-blogs</A>
							<DT><A HREF="https://gau-nernst.github.io/amd-a2a/">My first Multi-GPU kernel: Writing All-to-all for AMD MI300X - gau-nernst's blog</A>
						</DL><p>
						<DT><H3 FOLDED>Kernels</H3>
						<DL><p>
							<DT><H3 FOLDED>kernels-theory</H3>
							<DL><p>
								<DT><H3 FOLDED>kernels-performance</H3>
								<DL><p>
									<DT><A HREF="https://horace.io/brrr_intro.html">Making Deep Learning go Brrrr From First Principles</A>
									<DT><A HREF="https://x.com/tenderizzation/status/1941191643731984758">understanding performance from first principles</A>
								</DL><p>
								<DT><H3 FOLDED>kernel-grid</H3>
								<DL><p>
									<DT><H3 FOLDED>dynamic grid</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=liKrhX2gm44">High Performance LLMs in Jax 2024</A>
									</DL><p>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/pallas/grid_blockspec.html#pallas-grid">Grids and BlockSpecs ‚Äî JAX documentation</A>
									<DT><A HREF="https://indico.fysik.su.se/event/6537/contributions/9386/attachments/4028/4627/2.CUDA-FromLoops2Grids-Markidis.pdf">CUDA ‚Äì From Loops to Grids</A>
									<DT><A HREF="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/">CUDA Pro Tip: Write Flexible Kernels with Grid-Stride Loops | NVIDIA Technical Blog</A>
									<DT><A HREF="https://erangad.medium.com/1d-2d-and-3d-thread-allocation-for-loops-in-cuda-e0f908537a52">1D, 2D and 3D thread allocation for loops in CUDA | by Eranga Dulshan | Medium</A>
									<DT><A HREF="https://www.youtube.com/watch?v=sRpWrTBOXCc">Kernel Grid | GPU Programming | Episode 2 - YouTube</A>
									<DT><A HREF="https://github.com/SzymonOzog/GPU_Programming">SzymonOzog/GPU_Programming</A>
								</DL><p>
								<DT><H3 FOLDED>softmax-kernel</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=IpHjDoW4ffw">How to write a fast Softmax kernel - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=p-6wUOXaVqs">Why Do Neural Networks Love the Softmax? - YouTube</A>
									<DT><A HREF="https://x.com/cHHillee/status/1941180893844078605">Horace He: Softmax memory bandwidth</A>
									<DT><A HREF="https://x.com/zmkzmkz/status/1917547438258450674">(1) zed en X: "EARLY PREPRINT: Softpick: No Attention Sink, No Massive Activations with Rectified Softmax Why do we use softmax in attention, even though we don‚Äôt really need non-zero probabilities that sum to one, causing attention sink and large hidden state activations? Let that sink in. https://t.co/HrVJImMe1K" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=pUCWwGR5WmQ">Beyond Softmax: The Future of Attention Mechanisms - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>tiling</H3>
								<DL><p>
									<DT><A HREF="https://github.com/lcy-seso/VPTQ/pull/5">feat: use more warps to improve instruction latency hiding. by lcy-seso ¬∑ Pull Request #5 ¬∑ lcy-seso/VPTQ</A>
									<DT><A HREF="https://github.com/jax-ml/scaling-book/blob/ae5cc16da630a8f15743c9646b2997c9c40f1b2a/assets/img/tiling.png">scaling-book/assets/img/tiling.png at ae5cc16da630a8f15743c9646b2997c9c40f1b2a ¬∑ jax-ml/scaling-book</A>
								</DL><p>
								<DT><H3 FOLDED>kernels-leaderboards</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=mdDVkBeFy9A">GPU MODE kernels leaderboards</A>
									<DT><A HREF="https://x.com/GPU_MODE/status/1986119785705607672">(1) GPU MODE en X: "Congrats again to the winners of the GPU MODE IRL #2 hackathon held in the beautiful @Accel office A giant thank you to the only neocloud that could pull off a Blackwell hackathon for us @nebiusai 1st Place ‚Äì Symmetric Minds: Enabled multi-GPU expert-parallel MoE inference in https://t.co/Wwmvvo97cn" / X</A>
									<DT><A HREF="https://arseniivanov.github.io/blog.html#nvidia-gemm">NVIDIA GB200 GPU Programming Challenge</A>
								</DL><p>
								<DT><A HREF="https://x.com/RajaXg/status/1812721241985610147">GPU Architecture Impact</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-05-12-quick-tk">ThunderKittens: A Simple Embedded DSL for AI kernels ¬∑ Hazy Research</A>
								<DT><A HREF="https://twitter.com/karpathy/status/1789666350878601581">(1) Andrej Karpathy en X: "@Kartikayb77 I read this book and then I was surprised that I still understood so little of the kernels that started to appear as llm.c contributions, beating mine. It's a pretty good 101 intro. Learning CUDA is like that horse meme, all the learning resources you can find on the left, then... https://t.co/C0k1WZqkQM" / X</A>
								<DT><A HREF="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</A>
								<DT><A HREF="https://github.com/cuda-mode/triton-index">cuda-mode/triton-index: Cataloging released Triton kernels.</A>
								<DT><A HREF="https://github.com/cuda-mode/triton-index/blob/main/kernel_overview.md">triton-index/kernel_overview.md</A>
								<DT><A HREF="https://github.com/mgmalek/efficient_cross_entropy/blob/main/modules.py#L67">efficient_cross_entropy/modules.py at main ¬∑ mgmalek/efficient_cross_entropy</A>
								<DT><A HREF="https://mp.weixin.qq.com/s/G_XvnB4CeEBWTLNefi0Riw">„ÄêBBufÁöÑCUDAÁ¨îËÆ∞„ÄëÂçÅ‰∫åÔºåLayerNorm/RMSNormÁöÑÈáçËÆ°ÁÆóÂÆûÁé∞</A>
								<DT><A HREF="http://giantpandacv.com/project/CUDA/%E3%80%90BBuf%E7%9A%84CUDA%E7%AC%94%E8%AE%B0%E3%80%91%E4%B8%80%EF%BC%8C%E8%A7%A3%E6%9E%90OneFlow%20Element-Wise%20%E7%AE%97%E5%AD%90%E5%AE%9E%E7%8E%B0/">„ÄêBBufÁöÑCUDAÁ¨îËÆ∞„Äë‰∏ÄÔºåËß£ÊûêOneFlow Element-Wise ÁÆóÂ≠êÂÆûÁé∞ - GiantPandaCV</A>
								<DT><A HREF="https://www.youtube.com/watch?v=qYqrfq452ig&list=LL&index=19&t=4582s">Hardcore CUDA Hackathon Talks at AGI House SF (Tri Dao)</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">GPUs Go Brrr ¬∑ Hazy Research</A>
								<DT><A HREF="https://github.com/microsoft/microxcaling">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
								<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/">CUTLASS Tutorial: Fast Matrix-Multiplication with WGMMA on NVIDIA¬Æ Hopper‚Ñ¢ GPUs ‚Äì Colfax Research</A>
								<DT><A HREF="https://github.com/lw/kernels/tree/main">lw/kernels</A>
								<DT><A HREF="https://github.com/triton-lang/kernels">triton-lang/kernels</A>
								<DT><A HREF="https://gist.github.com/nadavrot/5b35d44e8ba3dd718e595e40184d03f0">Efficient matrix multiplication</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/6c4ddd62601cfb6d839cdc50cae27881f7a2d106/tinygrad/codegen/kernel.py#L388">tinygrad/tinygrad/codegen/kernel.py at 6c4ddd62601cfb6d839cdc50cae27881f7a2d106 ¬∑ tinygrad/tinygrad</A>
								<DT><A HREF="https://github.com/Tony-Tan/CUDA_Freshman">Tony-Tan/CUDA_Freshman</A>
								<DT><A HREF="https://github.com/KuangjuX/CUDAKernels">KuangjuX/CUDAKernels: üéâMy Collections of CUDA Kernels~</A>
								<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/">CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining ‚Äì Colfax Research</A>
								<DT><A HREF="https://www.youtube.com/watch?v=RW2-HtWaOS0">Accelerating the Future: Triton on Blackwell Architecture - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=NZz5sczZ_30&t=16s">Triton Conference 2024: Morning Session - YouTube</A>
								<DT><A HREF="https://docs.nersc.gov/tools/performance/roofline/#:~:text=The%20Roofline%20performance%20model%20offers,software%20implementations%20and%20architecture%20designs.">Roofline Performance Model - NERSC Documentation</A>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html">Linear/Fully-Connected Layers User's Guide - NVIDIA Docs</A>
								<DT><A HREF="https://x.com/zealandic1/status/1856110612084076752">Extract fast Torch kernels (geohot)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=zy8ChVd_oTM">Flash Attention derived and coded from first principles with Triton (Python) - YouTube</A>
								<DT><A HREF="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention</A>
								<DT><A HREF="https://pytorch.org/blog/hadacore/?utm_content=318142989&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">HadaCore: Tensor Core Accelerated Hadamard Transform Kernel | PyTorch</A>
								<DT><A HREF="https://x.com/vtabbott_/status/1949105225698357688">kernelization: Category-theoretic notion of a CUDA kernel as a parallelised function</A>
								<DT><A HREF="https://research.colfax-intl.com/mission-statement/">Mission Statement ‚Äì Colfax Research</A>
								<DT><A HREF="https://gpu.camp/">https://gpu.camp</A>
								<DT><A HREF="https://arxiv.org/abs/2512.18134">[2512.18134] Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs</A>
							</DL><p>
							<DT><H3 FOLDED>kernel-fusion</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM">NVIDIA/TensorRT-LLM: TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines.</A>
								<DT><A HREF="https://nvidia.github.io/TensorRT-LLM/overview.html#about-tensorrt-llm">Overview ‚Äî tensorrt_llm documentation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=m6BSREnQ84U">Fusing Kernels - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-benchmarking</H3>
							<DL><p>
								<DT><H3 FOLDED>kernels-tests</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/bench.py#L109">TiledBench/benchs/python/gemm/bench.py at master run_cublas_unittest all_close</A>
									<DT><A HREF="https://chat.deepseek.com/a/chat/s/dafccf53-9f22-4965-9fc4-a0478e5a0a4f">FP8 Attention Kernel Implementation Plan - DeepSeek</A>
								</DL><p>
								<DT><H3 FOLDED>Tritonbench</H3>
								<DL><p>
									<DT><H3 FOLDED>tritonbench-proton</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch-labs/tritonbench/commit/794bc77d2c960c6317091c5dfa4b5d701a789d30">Support flops metric in proton profiling (#111) ¬∑ pytorch-labs/tritonbench@794bc77</A>
										<DT><A HREF="https://github.com/pytorch-labs/tritonbench/issues/41">$ python run.py --op flash_attention --batch 1 --n-heads 24 --seq-len 4608 --d-head 128 --only cudnn,sdpa,flash_v3 --metrics proton --native-sdpa --pt2-sdpa</A>
									</DL><p>
									<DT><H3 FOLDED>nvtx</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch-labs/tritonbench/commit/e985049aa6e80429845a2b560252a53b7cf64937">Use nvtx.range_start (#116) ¬∑ pytorch-labs/tritonbench@e985049</A>
										<DT><A HREF="https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223">Favorite nsight systems profiling commands for Pytorch scripts</A>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59">Using Nsight Systems to profile GPU workload - hardware-backends / NVIDIA CUDA - PyTorch Developer Mailing List</A>
										<DT><A HREF="https://github.com/Noumena-Network/nmoe/blob/c71e591f8675637ab5c2ad4741935a91846f4115/nmoe/attention/mla.py#L24">_nvtx(tag: str): torch.cuda.nvtx.range(tag)</A>
									</DL><p>
									<DT><H3 FOLDED>tritonbench:run</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/commit/ff0d56d03592aa03f3ced8359241d21df1783393">`TORCH_AUTOTUNE_REP=1000 CUDA_VISIBLE_DEVICES=2 ENABLE_MMA_V5_ATT_PIPELINE=1 TORCHINDUCTOR_MAX_AUTOTUNE=1 TORCHINDUCTOR_FORCE_DISABLE_CACHES=1 buck2 run mode/opt  //pytorch/tritonbench:run -c fbcode.nvcc_arch=b200a -c fbcode.enable_gpu_sections=true -c fbcode.platform010_cuda_version=12.8 -- --op gemm --iter $NUM_ITERS --input-loader /home/njriasan/parsed_shapes.json --only pt2_matmul_maxautotune`</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/tree/main">pytorch-labs/tritonbench: Tritonbench is a collection of PyTorch custom operators with example inputs to measure their performance.</A>
									<DT><A HREF="https://github.com/meta-pytorch/tritonbench">meta-pytorch/tritonbench: Tritonbench is a collection of PyTorch custom operators with example inputs to measure their performance.</A>
									<DT><A HREF="https://github.com/pytorch/fbgemm">pytorch/FBGEMM: FB (Facebook) + GEMM (General Matrix-Matrix Multiplication) - https://code.fb.com/ml-applications/fbgemm/</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/issues/136168">OperatorBench Plan ¬∑ Issue #136168 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/397a2e6eb6cff0d956b22c46f63e109694695391/test/test_speed_v_torch.py#L4">tinygrad/test/test_speed_v_torch.py at 397a2e6eb6cff0d956b22c46f63e109694695391 ¬∑ tinygrad/tinygrad</A>
									<DT><A HREF="https://github.com/AI-Hypercomputer/accelerator-microbenchmarks/blob/main/src/benchmark_attention.py">accelerator-microbenchmarks/src/benchmark_attention.py at main ¬∑ AI-Hypercomputer/accelerator-microbenchmarks</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/issues/165785">TORCHINDUCTOR_FORCE_DISABLE_CACHES=1 TRITON_ALWAYS_COMPILE=1 TRITON_PRINT_AUTOTUNING=1 TORCH_LOGS=+inductor CUDA_VISIBLE_DEVICES=7 python run.py --op gemm --only aten_matmul,pt2_triton_matmul,pt2_nv_universal_gemm_matmul --metrics tflops,accuracy --force --cudagraph --num-inputs 1</A>
									<DT><A HREF="https://github.com/meta-pytorch/tritonbench/pull/764">Migrate FBGEMM GenAI calls to MSLK by cthi ¬∑ Pull Request #764 ¬∑ meta-pytorch/tritonbench</A>
								</DL><p>
								<DT><H3 FOLDED>roofline</H3>
								<DL><p>
									<DT><A HREF="https://en.wikipedia.org/wiki/Roofline_model">Roofline model - Wikipedia</A>
									<DT><A HREF="https://tullo.ch/articles/pytorch-gpu-inference-performance/">Improving PyTorch inference performance on GPUs with a few simple tricks ‚ÄîAndrew Tulloch</A>
									<DT><A HREF="https://x.com/__tinygrad__/status/1963698909026652276">Sure, you can fit the model, but it would be stupidly slow! If you are filling up the 96GB of RAM, you can only access all of it 20 times per second. That's 20 tok/s max for a dense model</A>
									<DT><A HREF="https://docs.nersc.gov/tools/performance/roofline/">Roofline Performance Model - NERSC Documentation</A>
									<DT><A HREF="https://github.com/mreso/ao/blob/5ff272612e2e1d596501e229c3e55781c8e045e9/torchao/testing/float8/roofline_utils.py#L26C10-L26C31">ao/torchao/testing/float8/roofline_utils.py at pct_achievable_mem_bw</A>
								</DL><p>
								<DT><A HREF="https://github.com/oadirt/quant-matmul">oadirt/quant-matmul</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/pull/138536">[Prototype] Adding lowering to persistent-tma device kernel for _scaled_mm by drisspg FP8Kernel ScalingStrategy ExperimentConfig</A>
								<DT><A HREF="https://github.com/oadirt/quant-matmul/blob/main/tests/test_quant_matmul.py">quant-matmul/tests/test_quant_matmul.py at main ¬∑ oadirt/quant-matmul</A>
								<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/tests/test_flash_attn.py">flash-attention/tests/test_flash_attn.py at main ¬∑ Dao-AILab/flash-attention</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/7eb2a99585b683e5486bfbf2e78c8165f08c392b/benchmarks/dynamo/microbenchmarks/bench_mm_fusion.py#L92">pytorch/benchmarks/dynamo/microbenchmarks/bench_mm_fusion.py</A>
								<DT><A HREF="https://github.com/drisspg/driss_torch/blob/main/test/test_amax.py">driss_torch/test/test_amax.py at main ¬∑ drisspg/driss_torch</A>
								<DT><A HREF="https://github.com/tgale96/grouped_gemm/pull/14#issuecomment-2211362572">Use CUTLASS for both `trans_a` and `trans_b` on Ampere by dfyz ¬∑ Pull Request #14 ¬∑ tgale96/grouped_gemm</A>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/main/benchmark/benchmark_dynamic_quant.py">FLASHNN/benchmark/benchmark_dynamic_quant.py at main ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/main/benchmark/benchmark_flash_attn.py">FLASHNN/benchmark/benchmark_flash_attn.py at main ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/main/benchmark/benchmark_gemm_a8w8.py">FLASHNN/benchmark/benchmark_gemm_a8w8.py at main ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/main/benchmark/benchmark_paged_attn.py">FLASHNN/benchmark/benchmark_paged_attn.py at main ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://github.com/FlagOpen/FlagGems/blob/master/benchmark/performance_utils.py#L15">FlagGems/benchmark/performance_utils.py at master ¬∑ FlagOpen/FlagGems</A>
								<DT><A HREF="https://github.com/triton-lang/kernels/tree/main/benchmarking">kernels/benchmarking at main ¬∑ triton-lang/kernels</A>
								<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/699857ab8940ff704f6c087f971dfde6f7172af9/demos/based_demo/benchmark_kernel.py#L48">ThunderKittens/demos/based_demo/benchmark_kernel.py at 699857ab8940ff704f6c087f971dfde6f7172af9 ¬∑ HazyResearch/ThunderKittens</A>
								<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/utils/benchmark.py#L60">benchmark_torch_function_in_microseconds</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/f3c54ccf8f6139807f4623037c0174964a286652/torch/_inductor/utils.py#L121">do_bench_using_profiling</A>
								<DT><A HREF="https://docs.nersc.gov/tools/performance/roofline/#:~:text=The%20Roofline%20performance%20model%20offers,software%20implementations%20and%20architecture%20designs.">Roofline Performance Model - NERSC Documentation</A>
								<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/needs_perf_help/fp8_gemm_bench.py">applied-ai/kernels/needs_perf_help/fp8_gemm_bench.py at main ¬∑ pytorch-labs/applied-ai</A>
								<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/01965457bf998f8c314a8dab921403b399e96dc5/blackwell/79-triton-matmul.py">gpu-experiments/blackwell/79-triton-matmul.py at 01965457bf998f8c314a8dab921403b399e96dc5 ¬∑ StuartSul/gpu-experiments</A>
							</DL><p>
							<DT><H3 FOLDED>vector addition</H3>
							<DL><p>
								<DT><A HREF="https://chloechiaw.github.io/vec-add/">Vector Addition Worklog on a B200 | Chloe Chia</A>
								<DT><A HREF="https://github.com/gau-nernst/learn-cuda/tree/main/01_vector_addition">learn-cuda/01_vector_addition at main ¬∑ gau-nernst/learn-cuda</A>
								<DT><A HREF="https://gau-nernst.github.io/nvrtc-matmul/">Use NVRTC to explore MMA instruction variants - gau-nernst's blog</A>
							</DL><p>
							<DT><H3 FOLDED>matmul</H3>
							<DL><p>
								<DT><H3 FOLDED>matmul-theory</H3>
								<DL><p>
									<DT><H3 FOLDED>tiled-matmul</H3>
									<DL><p>
										<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/01/27/matmul-basics.html">Tiled Matmul 101 - Hyunsung Lee's Blog</A>
									</DL><p>
									<DT><A HREF="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</A>
									<DT><A HREF="https://github.com/spikedoanz/matmul">spikedoanz/matmul: can you multiply two matrices?</A>
									<DT><A HREF="https://en.algorithmica.org/hpc/algorithms/matmul/">Matrix Multiplication - Algorithmica</A>
									<DT><A HREF="https://www.youtube.com/watch?v=VgSQ1GOC86s">George Hotz | Programming | can you multiply a matrix? (noob lesson) | geohot/tinygrad/tree/gemm - YouTube</A>
									<DT><A HREF="https://salykova.github.io/matmul-cpu">Beating OpenBLAS and MKL in 150 lines of C Code: A Tutorial on High-Performance Matrix Multiplication</A>
									<DT><A HREF="https://www.cs.utexas.edu/~flame/pubs/GotoTOMS_revision.pdf">Anatomy of High-Performance Matrix Multiplication</A>
									<DT><A HREF="https://www.youtube.com/watch?v=aVp3FnNw_VA">How do matmuls even work - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-blackwell</H3>
								<DL><p>
									<DT><A HREF="https://www.modular.com/blog/matrix-multiplication-on-nvidias-blackwell-part-2-using-hardware-features-to-optimize-matmul">Modular: Matrix Multiplication on Blackwell: Part 2 - Using Hardware Features to Optimize Matmul</A>
									<DT><A HREF="https://github.com/alexarmbr/cute_kernels/blob/main/sm100_persistent_matmul.py">cute_kernels/sm100_persistent_matmul.py at main ¬∑ alexarmbr/cute_kernels</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/blackwell_matmul.html">Writing high-performance matrix multiplication kernels for Blackwell ‚Äî JAX documentation</A>
									<DT><A HREF="https://github.com/jax-ml/jax/blob/d2391fcc0e08361d6387935270746967ac1c7f69/docs/pallas/gpu/blackwell_matmul.md">jax/docs/pallas/gpu/blackwell_matmul.md</A>
								</DL><p>
								<DT><H3 FOLDED>cute-matmul</H3>
								<DL><p>
									<DT><A HREF="https://github.com/alexarmbr/cute_kernels/blob/main/sm100_persistent_matmul.py">cute_kernels/sm100_persistent_matmul.py at main ¬∑ alexarmbr/cute_kernels</A>
								</DL><p>
								<DT><H3 FOLDED>torch-matmul</H3>
								<DL><p>
									<DT><H3 FOLDED>_inductor/kernel/mm_scaled</H3>
									<DL><p>
										<DT><H3 FOLDED>torch._scaled_mm</H3>
										<DL><p>
											<DT><A HREF="https://x.com/mrsiipa/status/1985689614544470385">Check torch._scaled_mm, which hooks up to cublas...</A>
											<DT><A HREF="https://gist.github.com/malfet/7874d96b99670c3da83cbb779ab770c6">scale_mm_example.py</A>
											<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247495506&idx=1&sn=385c2b750379214ea1deefaf7587837b&scene=21&poc_token=HJmkd2mjNoN3CIT1c2XNEQFchJwHawJS1wRFa0OZ">RoCE's message semantics are not GPU-friendly</A>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/354fe48db9ef94c69db6d03d997a374048824f83/torch/_inductor/kernel/mm_scaled.py#L504">pytorch/torch/_inductor/kernel/mm_scaled.py at 354fe48db9ef94c69db6d03d997a374048824f83 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://gist.github.com/drisspg/783616821043ab4594b9784f556c6714">Scaled MM API: This doc servers as a quick reference for the _scaled_mm API and how it has changed overtime for each major version of PyTorch.</A>
										<DT><A HREF="https://research.colfax-intl.com/deepseek-r1-and-fp8-mixed-precision-training/">DeepSeek-R1 and FP8 Mixed-Precision Training ‚Äì Colfax Research</A>
										<DT><A HREF="https://github.com/pytorch/ao/blob/4d1c7741842a1dfbd479b3481fcdc93c64db703e/torchao/dtypes/floatx/float8_layout.py#L279">ao/torchao/dtypes/floatx/float8_layout.py preprocess_data row-major and colum-major</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/4c1dd13ba33d0fcd1f039ea67b026979a09ae00a/benchmarks/dynamo/microbenchmarks/bench_mm_fusion.py#L8">pytorch/benchmarks/dynamo/microbenchmarks/bench_mm_fusion.py at 4c1dd13ba33d0fcd1f039ea67b026979a09ae00a ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/c2ff9fe042ffe39a2684aecc6c6062a066489f54/torch/_inductor/kernel/mm_scaled.py#L190">pytorch/torch/_inductor/kernel/mm_scaled.py at c2ff9fe042ffe39a2684aecc6c6062a066489f54 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://gist.github.com/Chillee/f86675147366a7a0c6e244eaa78660f7#file-4-matmul-bench-py">PT 2.0 Benchmarks</A>
									<DT><A HREF="https://gist.github.com/Chillee/2ec89696db8b7ed1c24461159e325405">H100 peak matmul FLOPS</A>
									<DT><A HREF="https://huggingface.co/spaces/not-lain/Pytorch-Matrix-Multiplication">Pytorch Matrix Multiplication - a Hugging Face Space by not-lain</A>
									<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/kernels/blackwell/cute_gemm_01/driver.py">applied-ai/kernels/blackwell/cute_gemm_01/driver.py at main ¬∑ meta-pytorch/applied-ai</A>
								</DL><p>
								<DT><H3 FOLDED>cuBLAS-matmul</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Mozilla-Ocho/llamafile/blob/main/llamafile/tinyblas.cu">llamafile/llamafile/tinyblas.cu at main ¬∑ Mozilla-Ocho/llamafile</A>
									<DT><A HREF="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-quant</H3>
								<DL><p>
									<DT><A HREF="https://github.com/oadirt/quant-matmul">oadirt/quant-matmul</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-sm90</H3>
								<DL><p>
									<DT><H3 FOLDED>triton-matmul-sm90</H3>
									<DL><p>
										<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/main/examples/matmul/triton/triton_matmul_sm90.py">MatmulTutorial/examples/matmul/triton/triton_matmul_sm90.py at main ¬∑ KnowingNothing/MatmulTutorial</A>
										<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/main/examples/matmul/triton/complex_matmul.py">MatmulTutorial/examples/matmul/triton/complex_matmul.py at main ¬∑ KnowingNothing/MatmulTutorial</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/extra/gemm/triton_nv_matmul.py#L4">tinygrad/extra/gemm/triton_nv_matmul.py at master ¬∑ tinygrad/tinygrad</A>
										<DT><A HREF="https://github.com/pytorch-labs/applied-ai/commit/4d6a670431f1af8c25e8d1f1745a8e4981c6130f#diff-e1dc3f6561669f4e7d7cf69bb2ef4fb3bcd0ab1cce84e553cb4c779d50e7dc91">add triton tma gemm and cutlass pingpong gemm ¬∑ pytorch-labs/applied-ai@4d6a670</A>
										<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/_triton/tiled_matmul_kernels.py#L152">xformers/xformers/ops/_triton/tiled_matmul_kernels.py at 0004c67c7e9ec3c9e7b3907db0e0b2957430b35b ¬∑ facebookresearch/xformers</A>
										<DT><A HREF="https://github.com/stanford-futuredata/stk/blob/main/stk/backend/triton_kernels.py#L222">stk/stk/backend/triton_kernels.py at main</A>
										<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/01965457bf998f8c314a8dab921403b399e96dc5/blackwell/79-triton-matmul.py">gpu-experiments/blackwell/79-triton-matmul.py at 01965457bf998f8c314a8dab921403b399e96dc5 ¬∑ StuartSul/gpu-experiments</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/e1976daacc7b030ba672217eb5d96f5a663df4ab/media/docs/efficient_gemm.md">cutlass/media/docs/efficient_gemm.md</A>
									<DT><A HREF="https://github.com/c3sr/tcu_scope/blob/master/src/gemm/wmma.cu">tcu_scope/src/gemm/wmma.cu at master ¬∑ c3sr/tcu_scope</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">CUDA C++ Programming Guide: wmma::mma_sync</A>
									<DT><A HREF="https://github.com/wmmae/wmma_extension">wmmae/wmma_extension: An extension library of WMMA API (Tensor Core API)</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-tiling</H3>
								<DL><p>
									<DT><A HREF="https://x.com/cHHillee/status/1630274862345490432">(2) Horace He en X: "Let's say I have a [M x K] @ [K x N] matmul. Which one of these configurations will have the best perf? Think about the actual ramifications of tiling! A: M=2047, K=N=2048 B: K=2047, M=N=2048 C: N=2047, M=K=2048 19/19" / X</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-benchmarking</H3>
								<DL><p>
									<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/main/examples/matmul/triton/triton_matmul_sm90.py">MatmulTutorial/examples/matmul/triton/triton_matmul_sm90.py at main ¬∑ KnowingNothing/MatmulTutorial</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-data-movement</H3>
								<DL><p>
									<DT><A HREF="https://reiner.org/strassen">Would Strassen matmuls be useful in AI if data movement were free?</A>
								</DL><p>
								<DT><H3 FOLDED>SIMD</H3>
								<DL><p>
									<DT><H3 FOLDED>AVX</H3>
									<DL><p>
										<DT><A HREF="https://github.com/HydraQYH/AVX_Practice/blob/master/permute1.cpp">AVX_Practice/permute1.cpp at master ¬∑ HydraQYH/AVX_Practice</A>
										<DT><A HREF="https://github.com/HydraQYH/AVX_Practice/blob/master/hello_avx.c">AVX_Practice/hello_avx.c at master ¬∑ HydraQYH/AVX_Practice</A>
									</DL><p>
									<DT><A HREF="https://parallelprogrammer.substack.com/p/why-we-need-simd-the-real-reason?r=4xff6v&utm_medium=ios&triedRedirect=true">Why We Need SIMD (The Real Reason) - by Nicholas Wilt</A>
									<DT><A HREF="https://x.com/xXshaurizardXx/status/1974948675324456967">(1) shaur en X: "For those wondering what is AVX? Your CPU normally, on each core, applies one operation on one piece of data. This gets quite slow for bigger data :( So why not use the GPU? That adds latency and overhead. What if we want parallel operations, but it isn‚Äôt worth offloading? https://t.co/4b8BUvDKMk" / X</A>
									<DT><A HREF="https://en.algorithmica.org/hpc/">Algorithms for Modern Hardware - Algorithmica</A>
									<DT><A HREF="https://sbaziotis.com/performance/a-beginners-guide-to-vectorization-by-hand-part-2.html">A Beginner's Guide to Vectorization By Hand: Part 2</A>
								</DL><p>
								<DT><H3 FOLDED>matmul-sparsity</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/cHHillee/status/1785021827871596581">(1) Horace He en X: "Many don't know that GPUs automatically leverage ternary and fine-grained sparsity to accelerate your matmuls! e.g. A matmul with ternary + 90% sparsity results in 33% more FLOPs in my benchmark. (not joking) I explore this "optimization" here: https://t.co/YD3CTq1i7J (1/3) https://t.co/QQ7x8fmbfZ" / X</A>
									<DT><A HREF="https://www.thonking.ai/p/strangely-matrix-multiplications">Strangely, Matrix Multiplications on GPUs Run Faster When Given "Predictable" Data! [short]</A>
									<DT><A HREF="https://gist.github.com/Chillee/42e4635c59760a74cb3b4ba7ea5ad9f8#file-mm_weird-py">Strangely, Matrix Multiplications Run Faster When Given "Predictable" Data!</A>
								</DL><p>
								<DT><A HREF="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</A>
								<DT><A HREF="https://gist.github.com/nadavrot/5b35d44e8ba3dd718e595e40184d03f0">Efficient matrix multiplication</A>
								<DT><A HREF="https://www.aleksagordic.com/blog/matmul">Inside NVIDIA GPUs: Anatomy of high performance matmul kernels - Aleksa Gordiƒá</A>
								<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial">KnowingNothing/MatmulTutorial: A Easy-to-understand TensorOp Matmul Tutorial</A>
								<DT><A HREF="https://jax.readthedocs.io/en/latest/pallas/tpu/matmul.html">Matrix Multiplication ‚Äî JAX documentation</A>
								<DT><A HREF="https://github.com/openai/openai-gemm">openai/openai-gemm: Open single and half precision gemm implementations</A>
								<DT><A HREF="https://blog.research.google/2024/01/mixed-input-matrix-multiplication.html">Mixed-input matrix multiplication performance optimizations ‚Äì Google Research Blog</A>
								<DT><A HREF="https://arxiv.org/pdf/2006.16668.pdf">GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-mma">matrix-multiply-accumulate (mma)</A>
								<DT><A HREF="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications?utm_source=post-email-title&publication_id=1781836&post_id=142904770&utm_campaign=email-post-title&isFreemail=true&r=1mqy6n&triedRedirect=true&utm_medium=email">What Shapes Do Matrix Multiplications Like? [medium]</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Sk35MKtCXfQ&t=4743s">tinygrad: matrix multiplication, a@b, cube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=VgSQ1GOC86s&t=19510s">George Hotz | Programming | can you multiply a matrix? (noob lesson) | geohot/tinygrad/tree/gemm - YouTube</A>
								<DT><A HREF="https://github.com/matiaslindgren/cuda-memory-access-recorder/tree/master/examples">cuda-memory-access-recorder/examples at master ¬∑ matiaslindgren/cuda-memory-access-recorder</A>
								<DT><A HREF="https://github.com/BearNinja123/matmul">BearNinja123/matmul: A collection of matrix multiplication techniques in C, from naive to BLAS</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/examples/llm.c/ubench/matmul.c">tinygrad/examples/llm.c/ubench/matmul.c</A>
								<DT><A HREF="https://gist.github.com/geohot/0cad05378fcbaeb0dceec3e89e0d4d7b">A 1024x1024x1024 matmul with a 2x2x2 core in OpenCL</A>
								<DT><A HREF="https://twitter.com/cis_female/status/1771746532892586388">arithmetic intensity: easy appro min(m,n,k)</A>
								<DT><A HREF="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications">What Shapes Do Matrix Multiplications Like? [medium]</A>
								<DT><A HREF="https://gist.github.com/Chillee/abc38703f88fcb64683b6ccb0ae9d8ba">What Shapes Do Matrix Multiplications Like?</A>
								<DT><A HREF="https://www.youtube.com/watch?v=VgSQ1GOC86s&t=19510s">George Hotz | Programming | can you multiply a matrix? (noob lesson)</A>
								<DT><A HREF="https://pytorch.org/blog/inside-the-matrix/">Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond | PyTorch</A>
								<DT><A HREF="https://github.com/ridgerchu/matmulfreellm">ridgerchu/matmulfreellm: Implementation for MatMul-free LM.</A>
								<DT><A HREF="https://github.com/tspeterkim/cuda-matmult">tspeterkim/cuda-matmult</A>
								<DT><A HREF="https://github.com/yester31/Matrix_Multiplication">yester31/Matrix_Multiplication: Diverse Matrix multiplication algorithms</A>
								<DT><A HREF="https://www.youtube.com/watch?v=oQT7IC0x254">2678x Faster with CUDA C: How GPUs enabled Deep Learning Revolution - YouTube</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/14108c1677e5a2f93a822a41cb579b572977d0d3/torch/_inductor/kernel/mm.py#L585">pytorch/torch/_inductor/kernel/mm.py at 14108c1677e5a2f93a822a41cb579b572977d0d3 ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://gist.github.com/malfet/029aadee65629bcfcc7285c608a3bd79">Swift example that runs matrix multiplicaiton on MPS</A>
								<DT><A HREF="https://github.com/nadavrot/bistra">nadavrot/bistra: Bistra is a domain-specific language designed to generate high-performance kernels (such as GEMMs, convolutions, etc). The program is designed to allow powerful compiler optimizations and code generation that are not possible in C. The tool can auto-tune GEMM kernels to around 90% of peak performance (on X86/AVX2) within seconds.</A>
								<DT><A HREF="https://medium.com/@nevinbaiju_77488/optimizing-llama-2-faster-matmul-using-avx-8ca0b02258d5">Optimizing Llama 2: Faster matmul using AVX | by Nevin Baiju | Medium</A>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/tiled_matmul.py">xformers/xformers/ops/tiled_matmul.py at 0004c67c7e9ec3c9e7b3907db0e0b2957430b35b ¬∑ facebookresearch/xformers</A>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/_triton/tiled_matmul_kernels.py#L152">xformers/xformers/ops/_triton/tiled_matmul_kernels.py at 0004c67c7e9ec3c9e7b3907db0e0b2957430b35b ¬∑ facebookresearch/xformers</A>
								<DT><A HREF="https://github.com/mobiusml/gemlite/blob/master/examples/cuda_example.py">gemlite/examples/cuda_example.py at master ¬∑ mobiusml/gemlite</A>
								<DT><A HREF="https://www.thonking.ai/p/answer-key-what-shapes-do-matrix">Solutions: What Shapes Do Matrix Multiplications Like?</A>
								<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/01/27/matmul-basics.html">Tiled Matmul 101 - Hyunsung Lee's Blog</A>
								<DT><A HREF="https://alexarmbr.github.io/2024/08/10/How-To-Write-A-Fast-Matrix-Multiplication-From-Scratch-With-Tensor-Cores.html">How To Write A Fast Matrix Multiplication From Scratch With Tensor Cores | Alex Armbruster</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1924011555437155686">Analyzing the Triton compiler's MatMul optimization (Part 3) ‚Äì TMA</A>
							</DL><p>
							<DT><H3 FOLDED>GEMM</H3>
							<DL><p>
								<DT><H3 FOLDED>HGEMM</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Bruce-Lee-LY/cuda_hgemm">Bruce-Lee-LY/cuda_hgemm: Several optimization methods of half-precision general matrix multiplication (HGEMM) using tensor core with WMMA API and MMA PTX instruction.</A>
								</DL><p>
								<DT><H3 FOLDED>SGEMM</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NervanaSystems/maxas/wiki/SGEMM">SGEMM ¬∑ NervanaSystems/maxas Wiki</A>
									<DT><A HREF="https://github.com/siboehm/SGEMM_CUDA">siboehm/SGEMM_CUDA: Fast CUDA matrix multiplication from scratch</A>
									<DT><A HREF="https://github.com/wangzyon/NVIDIA_SGEMM_PRACTICE">wangzyon/NVIDIA_SGEMM_PRACTICE: Step-by-step optimization of CUDA SGEMM</A>
									<DT><A HREF="https://github.com/Mozilla-Ocho/llamafile/blob/main/llamafile/sgemm.cpp">llamafile/llamafile/sgemm.cpp at main ¬∑ Mozilla-Ocho/llamafile</A>
									<DT><A HREF="https://github.com/yzhaiustc/Optimizing-SGEMM-on-NVIDIA-Turing-GPUs">yzhaiustc/Optimizing-SGEMM-on-NVIDIA-Turing-GPUs: Optimizing SGEMM kernel functions on NVIDIA GPUs to a close-to-cuBLAS performance.</A>
								</DL><p>
								<DT><H3 FOLDED>Grouped-gemm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tgale96/grouped_gemm">tgale96/grouped_gemm: PyTorch bindings for CUTLASS grouped GEMM.</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu">cutlass/examples/57_hopper_grouped_gemm/57_hopper_grouped_gemm.cu at main ¬∑ NVIDIA/cutlass</A>
									<DT><A HREF="https://github.com/google/jax/pull/20462/">Add MegaBlox grouped matrix multiplication kernels for TPU. by copybara-service[bot] ¬∑ Pull Request #20462 ¬∑ google/jax</A>
								</DL><p>
								<DT><H3 FOLDED>scaled-gemm</H3>
								<DL><p>
									<DT><H3 FOLDED>FBGEMM</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/docs/transformers/quantization/fbgemm_fp8">FBGEMM FP8</A>
										<DT><A HREF="https://github.com/pytorch/FBGEMM">pytorch/FBGEMM: FB (Facebook) + GEMM (General Matrix-Matrix Multiplication)</A>
										<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/main/fbgemm_gpu/experimental/gen_ai/bench/quantize_bench.py">FBGEMM/fbgemm_gpu/experimental/gen_ai/bench/quantize_bench.py at main ¬∑ pytorch/FBGEMM</A>
									</DL><p>
									<DT><H3 FOLDED>scaled-mm-api</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/test/test_scaled_matmul_cuda.py#L1798">pytorch/test/test_scaled_matmul_cuda.py at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://x.com/mrsiipa/status/1985689614544470385">cutlass fp4</A>
										<DT><A HREF="https://github.com/pytorch/ao/blob/7b0d2ce50baaa2a137eb9d438a076544c43096a3/torchao/float8/inference.py#L35">ao/torchao/float8/inference.py: preprocess_data</A>
										<DT><A HREF="https://gist.github.com/drisspg/783616821043ab4594b9784f556c6714">weight = weight.t().contiguous().t() column-major matrix</A>
									</DL><p>
									<DT><H3 FOLDED>cute-scaled_gemm</H3>
									<DL><p>
										<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/blob/3e60597ad324f9e6ea261843daf1de6d2a6f5214/flashinfer/cute_dsl/blockscaled_gemm.py#L2558">flashinfer/flashinfer/cute_dsl/blockscaled_gemm.py</A>
										<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/blob/3e60597ad324f9e6ea261843daf1de6d2a6f5214/flashinfer/cute_dsl/blockscaled_gemm.py#L462">Sm100BlockScaledPersistentDenseGemmKernel</A>
										<DT><A HREF="https://github.com/datacrunch-research/cortex/blob/main/csrc/cortex/cutlass/int8_gemm_sm100a_impl.cu">cortex/csrc/cortex/cutlass/int8_gemm_sm100a_impl.cu at main ¬∑ datacrunch-research/cortex</A>
										<DT><A HREF="https://gist.github.com/drisspg/783616821043ab4594b9784f556c6714">Scaled MM API</A>
									</DL><p>
									<DT><H3 FOLDED>gemm-fp8</H3>
									<DL><p>
										<DT><H3 FOLDED>GridQuant</H3>
										<DL><p>
											<DT><A HREF="https://pytorch.org/blog/hadacore/?utm_content=318142990&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">HadaCore: Tensor Core Accelerated Hadamard Transform Kernel | PyTorch</A>
											<DT><A HREF="https://pytorch.org/blog/accelerating-gemms-triton/?utm_content=318580331&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Accelerating 2D Dynamic Block Quantized Float8 GEMMs in Triton | PyTorch</A>
										</DL><p>
										<DT><A HREF="https://gist.github.com/wkcn/232d2cf8d50e15cdb38be3e577cc4e3a">FP8GEMM</A>
										<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/669b6c7167f7ea21eb049c621b5408cb03240e44/fbgemm_gpu/experimental/gemm/triton_gemm/fp8_gemm.py#L1448">FBGEMM/fbgemm_gpu/experimental/gemm/triton_gemm/fp8_gemm.py at 669b6c7167f7ea21eb049c621b5408cb03240e44 ¬∑ pytorch/FBGEMM</A>
										<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/53b48f35ad87603df882d036c1a2e3f7d88f2bd8/kernels/needs_perf_help/fp8_gemm_bench.py#L102">applied-ai/kernels/needs_perf_help/fp8_gemm_bench.py at 53b48f35ad87603df882d036c1a2e3f7d88f2bd8 ¬∑ pytorch-labs/applied-ai</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/c2ff9fe042ffe39a2684aecc6c6062a066489f54/torch/_inductor/kernel/mm_scaled.py#L190">pytorch/torch/_inductor/kernel/mm_scaled.py at c2ff9fe042ffe39a2684aecc6c6062a066489f54 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://research.colfax-intl.com/adding-fp8-to-flashattention/">Delivering 1 PFLOP/s of Performance with FP8 FlashAttention-2 ‚Äì Colfax Research</A>
										<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/needs_perf_help/fp8_rowwise_tma_persistent.py">applied-ai/kernels/needs_perf_help/fp8_rowwise_tma_persistent.py</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1975964435991527542">This article discusses how to achieve a high-performance memory bounding kernel on the B200, based on an MXFP8 quantized kernel.</A>
										<DT><A HREF="https://blog.fal.ai/chasing-6-tb-s-an-mxfp8-quantizer-on-blackwell/">Chasing 6+ TB/s: an MXFP8 quantizer on Blackwell</A>
									</DL><p>
									<DT><H3 FOLDED>gemm-fp4</H3>
									<DL><p>
										<DT><H3 FOLDED>fbgemm-fp4</H3>
										<DL><p>
											<DT><A HREF="https://github.com/meta-llama/llama-models/blob/main/models/quantize_impls.py#L50">llama-models/models/quantize_impls.py: Int4ScaledWeights</A>
											<DT><A HREF="https://gist.github.com/drisspg/783616821043ab4594b9784f556c6714">Scaled MM API</A>
										</DL><p>
										<DT><H3 FOLDED>gemm-fp4-triton</H3>
										<DL><p>
											<DT><A HREF="https://triton-lang.org/main/getting-started/tutorials/10-block-scaled-matmul.html">Block Scaled Matrix Multiplication ‚Äî Triton documentation: nvfp4, mxfp4</A>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/32b42821c75bcb17d0f58ddabc479b95df8dbcbf/python/tutorials/10-block-scaled-matmul.py#L311">triton/python/tutorials/10-block-scaled-matmul.py</A>
										</DL><p>
										<DT><H3 FOLDED>cutlass-gemm-fp4</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/5e497243f7ad13a2aa842143f9b10bbb23d98292/examples/72_blackwell_narrow_precision_gemm/72b_blackwell_nvfp4_nvfp4_gemm.cu#L35">cutlass/examples/72b_blackwell_nvfp4_nvfp4_gemm.cu</A>
										</DL><p>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/commit/79fc51f4b853d031babb0c7229b4efa99190f14f">v3.9 update (#2213) ¬∑ NVIDIA/cutlass@79fc51f</A>
										<DT><A HREF="https://github.com/search?q=repo%3Atriton-lang%2Ftriton%20nvfp4&type=code">Triton nvfp4 block_scaled_mma</A>
										<DT><A HREF="https://zcnrex.github.io/2025/12/23/nvfp4-gemm.html">Blackwell NVFP4 Kernel Hackathon Part 2: GEMM kernel | Rex‚Äôs Blog</A>
										<DT><A HREF="https://zcnrex.github.io/2025/12/01/nvfp4-gemv.html">Blackwell NVFP4 Kernel Hackathon Part 1: GEMV kernel | Rex‚Äôs Blog</A>
										<DT><A HREF="https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/">Introducing NVFP4 for Efficient and Accurate Low-Precision Inference | NVIDIA Technical Blog</A>
									</DL><p>
									<DT><A HREF="https://github.com/drisspg/driss_torch/tree/c5177a390ca405330c60463a0ecd202ec3d20d2b/src/scaled_mm_kernels">driss_torch/src/scaled_mm_kernels</A>
									<DT><A HREF="https://docs.nvidia.com/cuda/cublas/">1D Block Scaling for FP8 and FP4 Data Types</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=61">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=9_v-HBLHfFk&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=114&pp=iAQB">Sponsor Session: Low-Precision Inference without Quality Loss... - Pankaj Gupta &amp; Philip Kiely - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-distributed</H3>
								<DL><p>
									<DT><A HREF="https://blog.shi-labs.com/distributed-gemm-88be6a481e2b">Distributed GEMM: CUTLASS-native Tensor Parallelism | SHI Labs</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/tree/main/examples/65_distributed_gemm">cutlass/examples/65_distributed_gemm at main ¬∑ NVIDIA/cutlass</A>
								</DL><p>
								<DT><H3 FOLDED>mix-precission-gemm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Bruce-Lee-LY/cuda_hgemm">Bruce-Lee-LY/cuda_hgemm: Several optimization methods of half-precision general matrix multiplication (HGEMM) using tensor core with WMMA API and MMA PTX instruction.</A>
									<DT><A HREF="https://www.spatters.ca/two-stage-fp16-mma">Improving FP16/16 matmul accuracy with two-stage accumulation | spatters.ca</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-benchmark</H3>
								<DL><p>
									<DT><H3 FOLDED>mmapeak</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ReinForce-II/mmapeak">ReinForce-II/mmapeak</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/extra/mmapeak/mmapeak.py">tinygrad/extra/mmapeak/mmapeak.py at master ¬∑ tinygrad/tinygrad</A>
									</DL><p>
									<DT><H3 FOLDED>gpu-burn</H3>
									<DL><p>
										<DT><A HREF="https://github.com/wilicc/gpu-burn/commit/671f4be92477ce01cd9b536bc534a006dbee058f">Support CUDA 13+ (#135) ¬∑ wilicc/gpu-burn@671f4be</A>
										<DT><A HREF="https://github.com/wilicc/gpu-burn/compare/master...commaai:gpu-burn:master">Comparing wilicc:master...commaai:master ¬∑ wilicc/gpu-burn</A>
									</DL><p>
									<DT><A HREF="https://github.com/EleutherAI/cookbook/tree/main/benchmarks/sizing">cookbook/benchmarks/sizing at main ¬∑ EleutherAI/cookbook</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/benchmarks/benchmark_gemm.py">flash-attention/benchmarks/benchmark_gemm.py at main ¬∑ Dao-AILab/flash-attention</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/138555">[WIP] Prototype Triton kernel for torch.bmm(NJT, T) by cpuhrsch ¬∑ Pull Request #138555 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/mag-/gpu_benchmark">mag-/gpu_benchmark: Gpu benchmark</A>
								</DL><p>
								<DT><H3 FOLDED>openai-gemm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/openai/openai-gemm">openai/openai-gemm: Open single and half precision gemm implementations</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-gemm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/tree/c4fdb9c725924fd1bc8a89ca07a1f405953b4d54/extra/gemm">tinygrad/extra/gemm</A>
								</DL><p>
								<DT><H3 FOLDED>cutlass-gemm</H3>
								<DL><p>
									<DT><H3 FOLDED>cute-gemm</H3>
									<DL><p>
										<DT><H3 FOLDED>cute-gemm-blackwell</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/examples/python/CuTeDSL/blackwell/tutorial_gemm/fp16_gemm_0.py">cutlass/examples/python/CuTeDSL/blackwell/tutorial_gemm/fp16_gemm_0.py at main ¬∑ NVIDIA/cutlass</A>
											<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/b1d6e2c9b334dfa811e4183dfbd02419249e4b52/examples/python/CuTeDSL/blackwell/tutorial_gemm/fp16_gemm_0.py">cutlass/examples/python/CuTeDSL/blackwell/tutorial_gemm/fp16_gemm_0.py</A>
											<DT><A HREF="https://github.com/Dao-AILab/quack/blob/3d0ab3ec2164749caac8f269f771e66a40efd2de/quack/gemm_sm100.py#L78">quack/quack/gemm_sm100.py</A>
										</DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1949609885953139032">CUTLASS CuTe GEMM Details (Part 4) - Talking about some misunderstandings about B and S in Swizzle template parameters</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/713713957">CUTLASS CuTe GEMM Details (Part 3) - Swizzle&lt;B, M, S&gt; Template Parameter Values</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/703560147">CUTLASS CuTe GEMM Details (Part 2) ‚Äî TiledCopy and cp.async</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/702818267">Detailed Analysis of CUTLASS CuTe GEMM (I) - Selection of ldmatrix</A>
										<DT><A HREF="https://github.com/Dao-AILab/quack/blob/3d0ab3ec2164749caac8f269f771e66a40efd2de/quack/gemm_sm100.py#L78">quack/quack/gemm_sm100.py at 3d0ab3ec2164749caac8f269f771e66a40efd2de ¬∑ Dao-AILab/quack</A>
									</DL><p>
									<DT><H3 FOLDED>ping-pong-gemm</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/blog/cutlass-ping-pong-gemm-kernel/">Deep Dive on Cutlass Ping-Pong GEMM Kernel | PyTorch</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1935338652726204054">Pingpong Schedule is not a panacea</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1922067252909434076">Some intuitive understanding of Pingpong and Cooperative</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/5c447dd84f8ae0e1d48ff9a2eae26ce8c4958101/python/cutlass/op/gemm.py#L137">cutlass/python/cutlass/op/gemm.py</A>
									<DT><A HREF="https://www.kapilsharma.dev/posts/learn-cutlass-the-hard-way/">Learn CUTLASS the hard way! | Kapil Sharma</A>
									<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/">CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining ‚Äì Colfax Research</A>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/pipeline.md">cutlass/media/docs/pipeline.md at main ¬∑ NVIDIA/cutlass</A>
									<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/tree/master/pipeline-gemm">cfx-article-src/pipeline-gemm at master ¬∑ ColfaxResearch/cfx-article-src</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1899404237374494486">Analysis of the Alignment Parameter in CUTLASS Grouped GEMM</A>
									<DT><A HREF="https://github.com/gpusgobrr/explore-gemm">gpusgobrr/explore-gemm: Exploring how optimizations for GEMMs work</A>
									<DT><A HREF="https://www.kapilsharma.dev/posts/learn-cutlass-the-hard-way-2/">Learn CUTLASS the hard way - part 2! | Kapil Sharma</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/issues/170476">[inductor] cutlass GEMM backend SM103 runtime error ¬∑ Issue #170476 ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>Threadblock Rasterization</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/media/docs/efficient_gemm.md#threadblock-rasterization">cutlass/media/docs/efficient_gemm.md at main ¬∑ NVIDIA/cutlass</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Cache_prefetching">Cache prefetching - Wikipedia</A>
								</DL><p>
								<DT><H3 FOLDED>TiledCuda</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/master/src/kernels/gemm.cu">TiledCUDA/src/kernels/gemm.cu at master ¬∑ TiledTensor/TiledCUDA</A>
									<DT><A HREF="https://github.com/TiledTensor/benchmarks">TiledTensor/benchmarks: Benchmark tests supporting the TiledCUDA library.</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-hopper</H3>
								<DL><p>
									<DT><H3 FOLDED>gemm-hopper-benchmark</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/Chillee/2ec89696db8b7ed1c24461159e325405">H100 peak matmul FLOPS</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/144829/files#diff-90b954bddfc0db29441328610022aa85c98d3e2647875f7982a6b42acdf2b183">Added swizzle searching, disabled fp16 accum, and enabled ping-pong for cutlass by masnesral ¬∑ Pull Request #144829 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://x.com/cHHillee/status/1884743684928962884">Horace He Hopper GEMM microbenchmarking cutlass</A>
									</DL><p>
									<DT><H3 FOLDED>DeepGEMM</H3>
									<DL><p>
										<DT><H3 FOLDED>DeepGEMM-templating</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ademeure/DeeperGEMM/blob/6ee8079e7f2a24cc31fe075fcd90900892f7d462/deep_gemm/jit_kernels/gemm.py">DeeperGEMM/deep_gemm/jit_kernels/gemm.py C++ code templates</A>
										</DL><p>
										<DT><H3 FOLDED>DeepGEMM-tuning</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ademeure/DeeperGEMM/blob/6ee8079e7f2a24cc31fe075fcd90900892f7d462/deep_gemm/jit_kernels/tuner.py">DeeperGEMM/deep_gemm/jit_kernels/tuner.py at 6ee8079e7f2a24cc31fe075fcd90900892f7d462 ¬∑ ademeure/DeeperGEMM</A>
										</DL><p>
										<DT><H3 FOLDED>DeeperGEMM</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ademeure/DeeperGEMM">ademeure/DeeperGEMM: DeeperGEMM: crazy optimized version</A>
											<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/compare/main...ademeure:DeeperGEMM:main#diff-d07651f3d119035344e6b5ca25f1e6825d2a4029b3b5f843e2986269da2db2a9">DeeperGEMM source code addition</A>
										</DL><p>
										<DT><H3 FOLDED>DeepGEMM-tests</H3>
										<DL><p>
											<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/tree/main/tests">DeepGEMM/tests tests</A>
										</DL><p>
										<DT><H3 FOLDED>DeepGEMM-mhc</H3>
										<DL><p>
											<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/pull/280">Multiple updates and refactorings by zheanxu ¬∑ Pull Request #280 ¬∑ deepseek-ai/DeepGEMM mHC</A>
											<DT><A HREF="https://x.com/YouJiacheng/status/2012097999414157422">DeepGEMM added coded for HyperConnection</A>
										</DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM">deepseek-ai/DeepGEMM: DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling</A>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72876/">Blackwell Programming for the Masses With OpenAI Triton | GTC 25 2025 | NVIDIA On-Demand</A>
										<DT><A HREF="https://github.com/cat538/DeepGEMM">cat538/DeepGEMM: DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling (MoE training kernel)</A>
										<DT><A HREF="https://zcnrex.github.io/2025/03/08/deepgemm-1.html">DeepSeek DeepGEMM Study Note Part 1: The Kernel | Rex‚Äôs Blog</A>
									</DL><p>
									<DT><A HREF="https://github.com/pranjalssh/fast.cu">pranjalssh/fast.cu: Fastest kernels written from scratch</A>
									<DT><A HREF="https://cudaforfun.substack.com/p/outperforming-cublas-on-h100-a-worklog">Outperforming cuBLAS on H100: a Worklog</A>
									<DT><A HREF="https://github.com/weishengying/cute_gemm">weishengying/cute_gemm</A>
									<DT><A HREF="https://github.com/lcy-seso/hopper-gemm-101">lcy-seso/hopper-gemm-101</A>
									<DT><A HREF="https://vjkrish.com/2026/01/19/Mma_Layouts.html">Hopper/Blackwell Tensor Core MMA layouts | vj-krish</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-blackwell</H3>
								<DL><p>
									<DT><H3 FOLDED>gemm-blackwell-cublas</H3>
									<DL><p>
										<DT><A HREF="https://github.com/gau-nernst/learn-cuda/tree/3b90ac9b/02e_matmul_sm100/">learn-cuda/02e_matmul_sm100</A>
										<DT><A HREF="https://x.com/gaunernst/status/2002750211194847275">(2) Thien Tran en X: "I wrote another blogpost https://t.co/A1s4NgCI0E Thought it was gonna be a short one, but it turned into my longest blogpost yet." / X</A>
									</DL><p>
									<DT><H3 FOLDED>DeepGEMM-blackwell</H3>
									<DL><p>
										<DT><A HREF="https://github.com/search?q=repo%3Adeepseek-ai%2FDeepGEMM%20sm100&type=code">sm100_fp8_gemm_1d1d</A>
										<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/pull/112">Add more GPU architectures support by RayWang96 ¬∑ Pull Request #112 ¬∑ deepseek-ai/DeepGEMM</A>
										<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/pull/274">docs: add comprehensive API reference documentation by yurekami ¬∑ Pull Request #274 ¬∑ deepseek-ai/DeepGEMM</A>
										<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/pull/164">BF16 support by RayWang96 ¬∑ Pull Request #164 ¬∑ deepseek-ai/DeepGEMM</A>
										<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/pull/174">support compile with cuda 13.0 by rainj-me: This PR make DeepGemm successfully compile on cuda 13.0 and 12.8</A>
										<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/commit/0f16757edc065603bb19e0457c34a451c5d7c042#diff-c4c43a43be8bf1d1236a1d324cea2240859b67d99690aed466ffe68f83e16d4d">add sm100 matmul ¬∑ KnowingNothing/MatmulTutorial@0f16757</A>
									</DL><p>
									<DT><H3 FOLDED>gemm-blackwell-cute</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/b517a592049ed81a4cf9ad3aa4b4a7372e9d9a56/flash_attn/cute/blackwell_helpers.py">flash-attention/flash_attn/cute/blackwell_helpers.py: ptx gemm SM100</A>
										<DT><A HREF="https://github.com/Dao-AILab/quack/blob/main/quack/gemm_sm100.py">quack/quack/gemm_sm100.py at main ¬∑ Dao-AILab/quack</A>
										<DT><A HREF="https://github.com/alexarmbr/cute_kernels/blob/main/sm100_persistent_matmul.py">cute_kernels/sm100_persistent_matmul.py at main ¬∑ alexarmbr/cute_kernels</A>
									</DL><p>
									<DT><H3 FOLDED>gemm-blackwell-pallas</H3>
									<DL><p>
										<DT><A HREF="https://github.com/jax-ml/jax/blob/d2391fcc0e08361d6387935270746967ac1c7f69/docs/pallas/gpu/blackwell_matmul.md">jax/docs/pallas/gpu/blackwell_matmul.md</A>
										<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/collective_matmul.html">Collective matrix multiplication ‚Äî JAX documentation</A>
										<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/blackwell_matmul.html">Writing high-performance matrix multiplication kernels for Blackwell ‚Äî JAX documentation</A>
									</DL><p>
									<DT><H3 FOLDED>gemm-nvfp4</H3>
									<DL><p>
										<DT><A HREF="https://www.gpumode.com/v2/leaderboard/597?tab=rankings">Thien Tran submission, inline ptx</A>
										<DT><A HREF="https://gist.github.com/gradjitta/96900466463308be2600f635d285de56">Implementing the NVFP4 Recipe From Scratch: A Developer's Tutorial</A>
										<DT><A HREF="https://arseniivanov.github.io/blog.html#nvidia-gemm">NVIDIA GB200 GPU Programming Challenge</A>
										<DT><A HREF="https://x.com/gaunernst/status/2008183108999487627?s=12">(1) Thien Tran en X: "Trying to implement 2-SM nvfp4 kernel, thought I was going crazy. The layout for SFA and SFB in smem/tmem are DIFFERENT! Although A, B, and SFA are sharded across 2 CTAs, SFB must be duplicated. This is not documented in PTX doc (similar to many .cta_group::2 details) https://t.co/RJAmVaorCc" / X</A>
									</DL><p>
									<DT><H3 FOLDED>gemm-blackwell-fp8</H3>
									<DL><p>
										<DT><A HREF="https://blog.fal.ai/chasing-6-tb-s-an-mxfp8-quantizer-on-blackwell/">Chasing 6+ TB/s: an MXFP8 quantizer on Blackwell</A>
									</DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72876/">Blackwell Programming for the Masses With OpenAI Triton | GTC 25 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72720/">Programming Blackwell Tensor Cores with CUTLASS | GTC 25 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-gemm-with-thread-block-clusters-on-nvidia-blackwell-gpus/">CUTLASS Tutorial: GEMM with Thread Block Clusters on NVIDIA¬Æ Blackwell GPUs ‚Äì Colfax Research</A>
									<DT><A HREF="https://www.modular.com/blog/matrix-multiplication-on-nvidias-blackwell-part-2-using-hardware-features-to-optimize-matmul">Modular: Matrix Multiplication on Blackwell: Part 2 - Using Hardware Features to Optimize Matmul</A>
									<DT><A HREF="https://www.modular.com/blog/matrix-multiplication-on-nvidias-blackwell-part-1-introduction">Modular: Matrix Multiplication on Blackwell: Part 1 - Introduction</A>
									<DT><A HREF="https://github.com/alexarmbr/cute_kernels/blob/main/sm100_persistent_matmul.py">cute_kernels/sm100_persistent_matmul.py at main ¬∑ alexarmbr/cute_kernels</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/blackwell_matmul.html">Writing high-performance matrix multiplication kernels for Blackwell ‚Äî JAX documentation</A>
									<DT><A HREF="https://www.modular.com/blog/matrix-multiplication-on-blackwell-part-4---breaking-sota">Modular: Matrix Multiplication on Blackwell: Part 4 - Breaking SOTA</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1975964435991527542">This article discusses how to achieve a high-performance memory bounding kernel on the B200, based on an MXFP8 quantized kernel.</A>
									<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/commit/0f16757edc065603bb19e0457c34a451c5d7c042">add sm100 matmul ¬∑ KnowingNothing/MatmulTutorial@0f16757</A>
									<DT><A HREF="https://github.com/meta-pytorch/applied-ai/tree/main/kernels/blackwell/cute_gemm_01">applied-ai/kernels/blackwell/cute_gemm_01 at main ¬∑ meta-pytorch/applied-ai</A>
									<DT><A HREF="https://www.modular.com/matrix-multiplication-on-blackwell">Modular: Matrix Multiplication on Blackwell</A>
									<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-writing-gemm-kernels-using-tensor-memory-for-nvidia-blackwell-gpus/">CUTLASS Tutorial: Writing GEMM Kernels Using Tensor Memory For NVIDIA¬Æ Blackwell GPUs ‚Äì Colfax Research</A>
									<DT><A HREF="https://vjkrish.com/2026/01/19/Mma_Layouts.html">Hopper/Blackwell Tensor Core MMA layouts | vj-krish</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-cublas</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Dao-AILab/gemm-cublas">Dao-AILab/gemm-cublas</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-cutile</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/how-to-write-high-performance-matrix-multiply-in-nvidia-cuda-tile/">How to Write High-Performance Matrix Multiply in NVIDIA CUDA Tile | NVIDIA Technical Blog</A>
								</DL><p>
								<DT><H3 FOLDED>torch-gemm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/kernels/blackwell/cute_gemm_01/driver.py">applied-ai/kernels/blackwell/cute_gemm_01/driver.py at main ¬∑ meta-pytorch/applied-ai</A>
									<DT><A HREF="https://github.com/MARD1NO/SimpleBenchMark/blob/main/bench_scaled_mm/test.py">SimpleBenchMark/bench_scaled_mm/test.py at main ¬∑ MARD1NO/SimpleBenchMark</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/issues/170476">[inductor] cutlass GEMM backend SM103 runtime error ¬∑ Issue #170476 ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>gemm-tests</H3>
								<DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/DeepGEMM/blob/3ccf40c53a979df8c2f5edf87a166beac0d7b42c/tests/generators.py#L3">DeepGEMM/tests/generators.py</A>
									<DT><A HREF="https://github.com/sgl-project/DeepGEMM/blob/main/tests/generators.py#L63">DeepGEMM/tests/generators.py at main ¬∑ sgl-project/DeepGEMM</A>
									<DT><A HREF="https://github.com/sgl-project/DeepGEMM/blob/1392a4d054b7db5ddee89bf9b261645edf6f5464/tests/test_bf16.py">DeepGEMM/tests/test_bf16.py</A>
								</DL><p>
								<DT><A HREF="https://cudaforfun.substack.com/p/outperforming-cublas-on-h100-a-worklog">Outperforming cuBLAS on H100: a Worklog</A>
								<DT><A HREF="https://x.com/pranjalssh/status/1862657709994385694">Pranjal en X: "I implemented H100 cuda matmul kernel from scratch</A>
								<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/">CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining ‚Äì Colfax Research</A>
								<DT><A HREF="https://siboehm.com/articles/22/CUDA-MMM">How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog</A>
								<DT><A HREF="https://www.kapilsharma.dev/posts/learn-cutlass-the-hard-way/">Learn CUTLASS the hard way! | Kapil Sharma</A>
								<DT><A HREF="https://leimao.github.io/article/CUDA-Matrix-Multiplication-Optimization/">CUDA Matrix Multiplication Optimization - Lei Mao's Log Book</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/e1976daacc7b030ba672217eb5d96f5a663df4ab/media/docs/efficient_gemm.md">cutlass/media/docs/efficient_gemm.md</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/tree/c4fdb9c725924fd1bc8a89ca07a1f405953b4d54/extra/gemm">tinygrad/extra/gemm</A>
								<DT><A HREF="https://github.com/mobiusml/gemlite/">mobiusml/gemlite: Simple and fast low-bit matmul kernels in CUDA / Triton</A>
								<DT><A HREF="http://giantpandacv.com/project/CUDA/%E5%8F%AF%E8%83%BD%E6%98%AF%E8%AE%B2%E5%BE%97%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84WeightOnlyGEMM/">ÂèØËÉΩÊòØËÆ≤ÂæóÊúÄÊ∏ÖÊ•öÁöÑWeightOnlyGEMM - GiantPandaCV</A>
								<DT><A HREF="https://engineering.fb.com/2018/11/07/ml-applications/fbgemm/">Open-sourcing FBGEMM for server-side inference - Engineering at Meta</A>
								<DT><A HREF="https://github.com/pytorch/FBGEMM">pytorch/FBGEMM: FB (Facebook) + GEMM (General Matrix-Matrix Multiplication) - https://code.fb.com/ml-applications/fbgemm/</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/3930f709ce01ada61b7d7a57935b5503ab72f1ed/media/docs/cute/0x_gemm_tutorial.md">cutlass/media/docs/cute/0x_gemm_tutorial.md</A>
								<DT><A HREF="https://arxiv.org/abs/1804.06826">[1804.06826] Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</A>
								<DT><A HREF="https://scholar.google.com/citations?hl=en&user=8d0x03EAAAAJ&view_op=list_works&sortby=pubdate">‚Ä™Zhe Jia‚Ä¨ - ‚Ä™Google Scholar‚Ä¨</A>
								<DT><A HREF="https://arxiv.org/pdf/1912.03413.pdf">Dissecting the Graphcore IPUArchitecture via Microbenchmarking</A>
								<DT><A HREF="https://github.com/vdumoulin/conv_arithmetic">vdumoulin/conv_arithmetic: A technical report on convolution arithmetic in the context of deep learning</A>
								<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/main/fbgemm_gpu/fbgemm_gpu/enums.py">FBGEMM/fbgemm_gpu/fbgemm_gpu/enums.py at main ¬∑ pytorch/FBGEMM</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/tree/main/aten/src/ATen/native/cuda">pytorch/aten/src/ATen/native/cuda at main ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://github.com/sjfeng1999/gpu-arch-microbenchmark">sjfeng1999/gpu-arch-microbenchmark: Dissecting NVIDIA GPU Architecture</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/extra/gemm/torch_gemm.py">tinygrad/extra/gemm/torch_gemm.py at master ¬∑ tinygrad/tinygrad</A>
								<DT><A HREF="https://github.com/LaurentMazare/gemm">LaurentMazare/gemm</A>
								<DT><A HREF="https://research.colfax-intl.com/nvidia-hopper-gemm-cutlass/">GEMM kernels Hopper</A>
								<DT><A HREF="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications?utm_source=post-email-title&publication_id=1781836&post_id=142904770&utm_campaign=email-post-title&isFreemail=true&r=1mqy6n&triedRedirect=true&utm_medium=email">What Shapes Do Matrix Multiplications Like? [medium]</A>
								<DT><A HREF="https://twitter.com/Si_Boehm/status/1610335205767933952">Iterative CUDA matrix multiply optimization (80% cuBLAS perf)</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/examples/00_basic_gemm/basic_gemm.cu">cutlass/examples/00_basic_gemm/basic_gemm.cu</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/66ef1df492f7bc9c8eeb01d7e14db01838e3f0bd/cpp/tensorrt_llm/kernels/cutlass_kernels/python/generate_kernels.py#L69">generate_kernels.py#L69</A>
								<DT><A HREF="https://github.com/microsoft/microxcaling">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
								<DT><A HREF="https://github.com/flame/how-to-optimize-gemm">flame/how-to-optimize-gemm</A>
								<DT><A HREF="https://github.com/flame/how-to-optimize-gemm/wiki#step-by-step-optimizations">Approach to Optimizing Matrix-Matrix Multiplication - Step-by-Step</A>
								<DT><A HREF="https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/">CUTLASS: Fast Linear Algebra in CUDA C++ | NVIDIA Technical Blog</A>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/5c447dd84f8ae0e1d48ff9a2eae26ce8c4958101/python/cutlass/op/gemm.py#L137">cutlass/python/cutlass/op/gemm.py</A>
								<DT><A HREF="https://gist.github.com/Chillee/abc38703f88fcb64683b6ccb0ae9d8ba">What Shapes Do Matrix Multiplications Like?</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Sk35MKtCXfQ&t=4743s">matrix multiplication, a@b, cube</A>
								<DT><A HREF="https://pytorch.org/blog/inside-the-matrix/">Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond | PyTorch</A>
								<DT><A HREF="https://github.com/pytorch/ao/blob/cb3bd8c674f2123af232a0231b5e38ddafa756a8/torchao/dtypes/aqt.py#L526">ao/torchao/dtypes/aqt.py</A>
								<DT><A HREF="https://github.com/openai/openai-gemm">openai/openai-gemm: Open single and half precision gemm implementations</A>
								<DT><A HREF="https://github.com/Yinghan-Li/YHs_Sample/tree/master/cuda/gemm">YHs_Sample/cuda/gemm</A>
								<DT><A HREF="https://github.com/leimao/CUDA-GEMM-Optimization">leimao/CUDA-GEMM-Optimization: CUDA Matrix Multiplication Optimization</A>
								<DT><A HREF="https://github.com/tlc-pack/cutlass_fpA_intB_gemm">tlc-pack/cutlass_fpA_intB_gemm: A standalone GEMM kernel for fp16 activation and quantized weight, extracted from FasterTransformer</A>
								<DT><A HREF="https://github.com/sarah-ek/small-gemm/blob/main/src/lib.rs">small-gemm/src/lib.rs at main ¬∑ sarah-ek/small-gemm</A>
								<DT><A HREF="https://github.com/LaurentMazare/gemm-metal">LaurentMazare/gemm-metal</A>
								<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/master/src/kernels/gemm.cu">TiledCUDA/src/kernels/gemm.cu at master ¬∑ TiledTensor/TiledCUDA</A>
								<DT><A HREF="https://github.com/reed-lau/cute-gemm">reed-lau/cute-gemm</A>
								<DT><A HREF="https://github.com/weishengying/cute_gemm">weishengying/cute_gemm</A>
								<DT><A HREF="https://github.com/TiledTensor/benchmarks/blob/62e50b7597fe6fe1c4775bc9e83dde9df0b4f050/gemm/cutlass/gemm.py#L5">benchmarks/gemm/cutlass/gemm.py</A>
								<DT><A HREF="https://alexarmbr.github.io/2024/08/10/How-To-Write-A-Fast-Matrix-Multiplication-From-Scratch-With-Tensor-Cores.html">How To Write A Fast Matrix Multiplication From Scratch With Tensor Cores | Alex Armbruster</A>
								<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/blob/master/pipeline-gemm/README.md">cfx-article-src/pipeline-gemm/README.md at master ¬∑ ColfaxResearch/cfx-article-src</A>
								<DT><A HREF="https://github.com/LeiWang1999/Stream-k.tvm?tab=readme-ov-file">LeiWang1999/Stream-k.tvm</A>
								<DT><A HREF="https://github.com/pranjalssh/fast.cu">pranjalssh/fast.cu: Fastest kernels written from scratch</A>
								<DT><A HREF="https://www.youtube.com/watch?v=XAr_iVE8uUk">Matmul | Triton GPU Kernels 101 Lesson #6 - YouTube</A>
								<DT><A HREF="https://github.com/bertmaher/simplegemm">bertmaher/simplegemm</A>
								<DT><A HREF="https://andrewkchan.dev/posts/yalm.html">‚≠êÔ∏è Fast LLM Inference From Scratch</A>
								<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial">KnowingNothing/MatmulTutorial: A Easy-to-understand TensorOp Matmul Tutorial</A>
								<DT><A HREF="https://www.aleksagordic.com/blog/matmul">Inside NVIDIA GPUs: Anatomy of high performance matmul kernels - Aleksa Gordiƒá</A>
								<DT><A HREF="https://x.com/cHHillee/status/1972782935859401155">(1) Horace He en X: "I quite enjoyed this and it covers a bunch of topics without good introductory resources! 1. A bunch of GPU hardware details in one place (warp schedulers, shared memory, etc.) 2. A breakdown/walkthrough of reading PTX and SASS. 3. Some details/walkthroughs of a number of other" / X</A>
								<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/blackwell_matmul.html">Writing high-performance matrix multiplication kernels for Blackwell ‚Äî JAX documentation</A>
								<DT><A HREF="https://nathanchen.me/public/Triton-Matrix-Multiplication.html">Implementing Matrix Multiplication in Triton with L2 Cache Optimization: A Tutorial</A>
							</DL><p>
							<DT><H3 FOLDED>Flash-Attention</H3>
							<DL><p>
								<DT><H3 FOLDED>flashattention-theory</H3>
								<DL><p>
									<DT><H3 FOLDED>fa-derivation</H3>
									<DL><p>
										<DT><A HREF="https://lcy-seso.github.io/Deriving-the-Online-Update-Formula-for-Attention-(1)/">Deriving The Online Update Formula For Attention (1)</A>
									</DL><p>
									<DT><A HREF="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/668888063">Principles: From Online-Softmax to FlashAttention V1/V2/V3</A>
									<DT><A HREF="https://lcy-seso.github.io/Deriving-the-Online-Update-Formula-for-Attention-(1)/">Deriving The Online Update Formula For Attention (1)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zy8ChVd_oTM&list=LL&index=9&t=2s">Flash Attention derived and coded from first principles with Triton (Python) - YouTube</A>
									<DT><A HREF="https://kuterdinel.com/online-softmax.html">Online Softmax for dummies ‚Ä¢ Kuter Dinel's blog</A>
									<DT><A HREF="https://github.com/tspeterkim/flash-attention-minimal">tspeterkim/flash-attention-minimal: Flash Attention in ~100 lines of CUDA (forward pass only)</A>
									<DT><A HREF="https://research.colfax-intl.com/gpu-mode-cutlass-and-flashattention-3/">GPU Mode: CUTLASS and FlashAttention-3 ‚Äì Colfax Research</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zy8ChVd_oTM">Flash Attention derived and coded from first principles with Triton (Python) - YouTube</A>
									<DT><A HREF="https://colab.research.google.com/drive/1X-x6PCRydNY9LZBPLA0DZh3Tj2Dyz60M?usp=sharing">naive_flash.ipynb - Colab</A>
									<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2024/12/14/eleutherai-reading-group-session-2.html">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness | ML Perf Notes</A>
									<DT><A HREF="https://lcy-seso.github.io/Ensuring-Numerical-Stability-in-Online-Attention-Updates-(2)/">Ensuring Numerical Stability In Online Attention Updates (2)</A>
									<DT><A HREF="https://tridao.me/blog/2024/flash3/">FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision | Tri Dao</A>
									<DT><A HREF="https://github.com/tzadouri?tab=stars">tzadouri (Ted Zadouri) / Starred</A>
									<DT><A HREF="https://x.com/vtabbott_/status/1977911153498976329/photo/1">(1) vickieGPT (@yyw2000) / X</A>
									<DT><A HREF="https://jax-ml.github.io/scaling-book/transformers/">All the Transformer Math You Need to Know | How To Scale Your Model</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/696075602">FlashDecoding</A>
									<DT><A HREF="https://llmsystem.github.io/llmsystem2025spring/assets/files/llmsys-20-FlashAttention_tridao-cac5b634b4ad77cb027451422b07ae75.pdf">Optimizing Attention for Modern Hardware</A>
									<DT><A HREF="https://aminediro.com/posts/flash_attn/">Reimplementing FlashAttention for performance and giggles | AmineDiro</A>
									<DT><A HREF="https://pytorch.org/blog/flashattention-3/">FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision ‚Äì PyTorch</A>
								</DL><p>
								<DT><H3 FOLDED>flash-attention-issues</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HazyResearch/flash-attention/issues/253">ModuleNotFoundError: No module named 'torch' ¬∑ Issue #253 ¬∑ HazyResearch/flash-attention</A>
									<DT><A HREF="https://github.com/HazyResearch/flash-attention/issues/246">No Module Named 'torch' ¬∑ Issue #246 ¬∑ HazyResearch/flash-attention</A>
									<DT><A HREF="https://github.com/HazyResearch/flash-attention/issues/131">installing dropout_layer_norm ¬∑ Issue #131 ¬∑ HazyResearch/flash-attention</A>
									<DT><A HREF="https://github.com/HazyResearch/flash-attention/issues/250">ModuleNotFoundError: No module named 'dropout_layer_norm' when trying to import flash_attn.ops.layer_norm ¬∑ Issue #250 ¬∑ HazyResearch/flash-attention</A>
									<DT><A HREF="https://x.com/taha_yssne/status/1966753338650726834">Taha Yassine üçâ en X: "Wait stop hold on, did uv finally solve the flash-attn setup madness?? Now you just need this in your config and then `uv sync` and it works every single time?? Nah @charliermarsh and the team cooked so hard https://t.co/mcB8tubkU4" / X</A>
								</DL><p>
								<DT><H3 FOLDED>flash-attention-mosaic</H3>
								<DL><p>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1812897008031617493">FA3 mosaic</A>
									<DT><A HREF="https://github.com/google/jax/blob/main/jax/experimental/mosaic/gpu/examples/flash_attention.py#L146-L354">jax/jax/experimental/mosaic/gpu/examples/flash_attention.py at main ¬∑ google/jax</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-2</H3>
								<DL><p>
									<DT><A HREF="https://mp.weixin.qq.com/s/5K6yNj23NmNLcAQofHcT4Q">Flash Attention v2</A>
									<DT><A HREF="http://giantpandacv.com/project/CUDA/%E3%80%90BBuf%E7%9A%84CUDA%E7%AC%94%E8%AE%B0%E3%80%91%E5%8D%81%E4%BA%94%EF%BC%8COpenAI%20Triton%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%E4%B8%89%20FusedAttention/">FlashAttention V2 (chinese blog)</A>
									<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/cuda/tutorials/flash2.cu">applied-ai/kernels/cuda/tutorials/flash2.cu</A>
									<DT><A HREF="https://princeton-nlp.github.io/flash-atttention-2/">FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning | Princeton NLP Group</A>
									<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/master/src/kernels/flash_attn.cu">TiledCUDA/src/kernels/flash_attn.cu at master ¬∑ TiledTensor/TiledCUDA</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-3</H3>
								<DL><p>
									<DT><H3 FOLDED>FA3-flops</H3>
									<DL><p>
										<DT><A HREF="https://github.com/facebookresearch/xformers/commit/536363ecc38809cec9c6227e6ceef88255538fea">Provide FLOPs formula for FlashAttention3 ¬∑ facebookresearch/xformers@536363e</A>
									</DL><p>
									<DT><H3 FOLDED>FA3-inductor</H3>
									<DL><p>
										<DT><H3 FOLDED>FA3-xformers</H3>
										<DL><p>
											<DT><A HREF="https://github.com/facebookresearch/xformers/blob/main/xformers/ops/fmha/flash3.py">xformers/xformers/ops/fmha/flash3.py at main ¬∑ facebookresearch/xformers</A>
										</DL><p>
										<DT><A HREF="https://gist.github.com/antferdom/f7874ab68f4c1183d2b8196d2ace3ffc">FlashAttention v3 within torch.compile compatible</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/pull/1590">feat: fa3 custom ops for compatibility with PT Compile by zhangheng408 ¬∑ Pull Request #1590 ¬∑ Dao-AILab/flash-attention</A>
										<DT><A HREF="https://github.com/huggingface/diffusers/blob/2c669e84808f40ac5b5026fa44e948cfbc325119/src/diffusers/models/attention_dispatch.py#L628">diffusers/src/diffusers/models/attention_dispatch.py @_custom_op("_diffusers_flash_attn_3::_flash_attn_forward", mutates_args=(), device_types="cuda")</A>
									</DL><p>
									<DT><A HREF="https://www.together.ai/blog/flashattention-3">FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</A>
									<DT><A HREF="https://github.com/LaurentMazare/jax-flash-attn3">LaurentMazare/jax-flash-attn3: JAX bindings for the flash-attention3 kernels</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/3ae95a858eac26088102075500e3860864432106/python/test/unit/hopper/test_flashattention.py#L294">triton/python/test/unit/hopper/test_flashattention.py: torch.autograd.Function</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/pull/1112">Add how to import FA3 to documentation. by AdamLouly ¬∑ Pull Request #1112 ¬∑ Dao-AILab/flash-attention</A>
									<DT><A HREF="https://research.character.ai/optimizing-ai-inference-at-character-ai-part-deux/">Optimizing AI Inference at Character.AI (Part Deux)</A>
									<DT><A HREF="https://research.colfax-intl.com/gpu-mode-cutlass-and-flashattention-3/">GPU Mode: CUTLASS and FlashAttention-3 ‚Äì Colfax Research</A>
									<DT><A HREF="https://gist.github.com/sophiawisdom/88b48f7146deb0d35c09506dd3a9c09e">invocation: TORCH_CUDA_ARCH_LIST=9.0a PYTORCH_NO_CUDA_MEMORY_CACHING=1 compute-sanitizer python3 test.py</A>
									<DT><A HREF="https://pytorch.org/blog/flashattention-3/">FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision ‚Äì PyTorch</A>
									<DT><A HREF="https://tridao.me/publications/flash3/flash3.pdf">FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-4</H3>
								<DL><p>
									<DT><H3 FOLDED>FA4-cuDNN</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>FA4-cute</H3>
									<DL><p>
										<DT><H3 FOLDED>flash_bwd_sm100</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/cute/flash_bwd_sm100.py">flash-attention/flash_attn/cute/flash_bwd_sm100.py at main ¬∑ Dao-AILab/flash-attention</A>
										</DL><p>
										<DT><H3 FOLDED>FA4-fp8</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Dao-AILab/flash-attention/pull/2109">[Cute,Fwd,Sm100] fp8 e4m3 and e5m2 support by dcw02 ¬∑ Pull Request #2109 ¬∑ Dao-AILab/flash-attention</A>
											<DT><A HREF="https://github.com/Dao-AILab/flash-attention/pull/2109/files#diff-f6e1736114a1fdce71e61da4bf8fb5f6bb433c53fed416f58bcb3689fa060feb">[Cute,Fwd,Sm100] fp8 e4m3 and e5m2 support by dcw02 ¬∑ Pull Request #2109 ¬∑ Dao-AILab/flash-attention</A>
										</DL><p>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/b517a592049ed81a4cf9ad3aa4b4a7372e9d9a56/flash_attn/cute/flash_fwd_sm100.py">flash-attention/flash_attn/cute/flash_fwd_sm100.py: FlashAttention CuTe</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/commits?author=tridao">Commits ¬∑ Dao-AILab/flash-attention</A>
										<DT><A HREF="https://github.com/Dao-AILab/quack">Dao-AILab/quack: A Quirky Assortment of CuTe Kernels</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/python/CuTeDSL/base_dsl/typing.py#L850">cutlass/python/CuTeDSL/base_dsl/typing.py Numeric quantization</A>
										<DT><A HREF="https://x.com/elonmusk/status/1950251710141567110?s=12">‚Äúfastest time to make a fun, shareable video‚Äù, rather than visual/auditory perfection.</A>
										<DT><A HREF="https://x.com/elonmusk/status/1950590957424111902?s=12">Grok Imagine is super fun üòé</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/0256114fe2381ab293503219bdd9078de3cd26b3/flash_attn/cute/interface.py#L800">flash-attention/flash_attn/cute/interface.py</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/tests/cute/test_flash_attn.py">flash-attention/tests/cute/test_flash_attn.py at main ¬∑ Dao-AILab/flash-attention</A>
										<DT><A HREF="https://research.colfax-intl.com/a-users-guide-to-flexattention-in-flash-attention-cute-dsl/">A User‚Äôs Guide to FlexAttention in FlashAttention CuTe DSL ‚Äì Colfax Research</A>
									</DL><p>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/b517a592049ed81a4cf9ad3aa4b4a7372e9d9a56/flash_attn/cute/blackwell_helpers.py">flash-attention/flash_attn/cute/blackwell_helpers.py</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/9428">FA4 by hyhieu ¬∑ Pull Request #9428 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/10368/files">Fix FA4 import cause moe_fused_gate output be illegal memory by fzyzcjy ¬∑ Pull Request #10368 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/facebookresearch/xformers/commit/115df95feecf99f2a7d85ee64650921e0b9207ec#diff-e4bf91c33d2a05a5a457623f0f07026957aabae60831e3a7f3fe7e15c93d4538">Enable Cutlass Blackwell attention (#1332) ¬∑ facebookresearch/xformers@115df95</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/tree/main/fbgemm_gpu/experimental/gen_ai">FBGEMM/fbgemm_gpu/experimental/gen_ai at main ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/tree/main/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha">FBGEMM/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha at main ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/main/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha/cutlass_blackwell_fmha_custom_op.py">FBGEMM/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha/cutlass_blackwell_fmha_custom_op.py at main ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/f9ccd0126207c149bf99877c5e863d8018208858/fbgemm_gpu/experimental/gen_ai/test/attention/blackwell_fmha_custom_op_check.py#L12">FBGEMM/fbgemm_gpu/experimental/gen_ai/test/attention/blackwell_fmha_custom_op_check.py at f9ccd0126207c149bf99877c5e863d8018208858 ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/f9ccd0126207c149bf99877c5e863d8018208858/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha/__init__.py">FBGEMM/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha/__init__.py at f9ccd0126207c149bf99877c5e863d8018208858 ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/f9ccd0126207c149bf99877c5e863d8018208858/fbgemm_gpu/experimental/gen_ai/src/attention/cuda/cutlass_blackwell_fmha/README.md">FBGEMM/fbgemm_gpu/experimental/gen_ai/src/attention/cuda/cutlass_blackwell_fmha/README.md at f9ccd0126207c149bf99877c5e863d8018208858 ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/f9ccd0126207c149bf99877c5e863d8018208858/fbgemm_gpu/experimental/gen_ai/src/attention/cuda/cutlass_blackwell_fmha/gen_example.cu#L4">FBGEMM/fbgemm_gpu/experimental/gen_ai/src/attention/cuda/cutlass_blackwell_fmha/gen_example.cu at f9ccd0126207c149bf99877c5e863d8018208858 ¬∑ pytorch/FBGEMM</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/d51243e946b25e437ba02e2c9d1aaad08da17c93/benchmarks/fav4.py">transformer_nuggets/benchmarks/fav4.py</A>
									<DT><A HREF="https://modal.com/blog/reverse-engineer-flash-attention-4">We reverse-engineered Flash Attention 4 | Modal Blog</A>
									<DT><A HREF="https://github.com/facebookexperimental/triton/commit/cc65c1b6b555ea5bc30f002aa56b0f3d21be2006">Code refactoring to Blackwell FA kernels (#402) ¬∑ facebookexperimental/triton@cc65c1b</A>
									<DT><A HREF="https://www.youtube.com/watch?v=ZIEq-WTquy4">How FlashAttention 4 Works - YouTube</A>
									<DT><A HREF="https://gau-nernst.github.io/fa-5090/">Writing Speed-of-Light Flash Attention for 5090 in CUDA C++ - gau-nernst's blog</A>
								</DL><p>
								<DT><H3 FOLDED>torch-scaled-dot-product-attention</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/tutorials/intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA) ‚Äî PyTorch Tutorials 2.1.0+cu121 documentation</A>
									<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html">torch.nn.functional.scaled_dot_product_attention ‚Äî PyTorch 2.4 documentation</A>
									<DT><A HREF="https://github.com/thecharlieblake/lovely-llama/blob/08b8b068dbf2e8e9aea3328328f3910cd954a596/lovely_llama.py#L68">lovely_llama.py#L68</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/3b5e2689a1b8a3137e65b0c0bc8bfb96260c9bfe/torch/nn/functional.py">pytorch/torch/nn/functional.py at 3b5e2689a1b8a3137e65b0c0bc8bfb96260c9bfe ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-cuda</H3>
								<DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1910574691284300167">(1) the tiny corp en X: ".fuse() is now supported on Tensors. Automatic fusing puts one reduce in a kernel, but if you want more, you can fuse back to the nearest contiguous with fuse. Try it, it's fun! Single kernel softmax works, and with a few tweaks, this is flash attention ($500 bounty). https://t.co/9iI4csuBKI" / X</A>
									<DT><A HREF="https://gist.github.com/sophiawisdom/88b48f7146deb0d35c09506dd3a9c09e">invocation: TORCH_CUDA_ARCH_LIST=9.0a PYTORCH_NO_CUDA_MEMORY_CACHING=1 compute-sanitizer python3 test.py</A>
									<DT><A HREF="https://github.com/ita9naiwa/attention-impl">ita9naiwa/attention-impl: attention implemenation</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-triton</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/5e6c32657e384b023faf03d79e06f7727feedb7c/python/sglang/srt/layers/attention/triton_backend.py#L17">sglang/python/sglang/srt/layers/attention/triton_backend.py</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/text_generation_server/layers/attention/flash_attn_triton.py">text-generation-inference/server/text_generation_server/layers/attention/flash_attn_triton.py at main ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://www.youtube.com/watch?v=6ap2QVWKFH0">Flash-attention forward pass | Triton GPU Kernels 101 Lesson #9 - YouTube</A>
									<DT><A HREF="https://arxiv.org/abs/2507.02754">[2507.02754] Fast and Simplex: 2-Simplicial Attention in Triton</A>
									<DT><A HREF="https://nathanchen.me/public/Triton-Flash-Attention-Kernel-Walkthrough.html">Triton Flash Attention Kernel Walkthrough: The Forward Pass</A>
									<DT><A HREF="https://www.arxiv.org/abs/2511.11581">[2511.11581] The Anatomy of a Triton Attention Kernel</A>
								</DL><p>
								<DT><H3 FOLDED>cudnn-flashattention</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/issues/52">What's the difference of flash attention implement between cudnn and Dao-AILab? ¬∑ Issue #52 ¬∑ NVIDIA/cudnn-frontend</A>
									<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/1.0/release/samples/python/test_mhas.py#L431">cudnn-frontend/samples/python/test_mhas.py at 1.0/release ¬∑ NVIDIA/cudnn-frontend</A>
								</DL><p>
								<DT><H3 FOLDED>flexAttention</H3>
								<DL><p>
									<DT><H3 FOLDED>flexAttention-benchmark</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ai-compiler-study/test_attn/blob/main/benchmark_attention.py#L211">test_attn/benchmark_attention.py at main ¬∑ ai-compiler-study/test_attn</A>
									</DL><p>
									<DT><H3 FOLDED>flexAttention-examples</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/Chillee/2e270fc5413dbbce58c779f8c4eac66c">flex_attention_tutorial.py</A>
									</DL><p>
									<DT><H3 FOLDED>flexAttention-backward</H3>
									<DL><p>
										<DT><A HREF="https://x.com/giffmana/status/1940503880539722169">triton_tem_fused_zeros big fat profiling</A>
									</DL><p>
									<DT><H3 FOLDED>flexAttention-cute</H3>
									<DL><p>
										<DT><A HREF="https://research.colfax-intl.com/a-users-guide-to-flexattention-in-flash-attention-cute-dsl/">A User‚Äôs Guide to FlexAttention in FlashAttention CuTe DSL ‚Äì Colfax Research</A>
									</DL><p>
									<DT><H3 FOLDED>flexAttention-compile</H3>
									<DL><p>
										<DT><A HREF="https://x.com/kalomaze/status/2003665976848711777">torch._inductor.config.unsafe_marked_cacheable_functions['torch.ops.higher_order.flex_attention_backward'] = True</A>
									</DL><p>
									<DT><A HREF="https://gist.github.com/Chillee/2e270fc5413dbbce58c779f8c4eac66c">flex_attention_tutorial.py</A>
									<DT><A HREF="https://github.com/drisspg/attention-gym">drisspg/attention-gym: Helpful tools and examples for working with flex-attention</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/14108c1677e5a2f93a822a41cb579b572977d0d3/torch/_inductor/kernel/flex_decoding.py#L3">pytorch/torch/_inductor/kernel/flex_decoding.py at 14108c1677e5a2f93a822a41cb579b572977d0d3 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/14108c1677e5a2f93a822a41cb579b572977d0d3/torch/_inductor/kernel/flex_attention.py">pytorch/torch/_inductor/kernel/flex_attention.py at 14108c1677e5a2f93a822a41cb579b572977d0d3 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://x.com/drisspg/status/1821949403302637667">option for specifying backend (e.g. cuDNN)</A>
									<DT><A HREF="https://x.com/cHHillee/status/1821253769147118004">Introducing FlexAttention, a new PyTorch API allowing for many attention variants to enjoy fused kernels in a few lines of PyTorch.</A>
									<DT><A HREF="https://pytorch.org/blog/flexattention/?utm_content=303215489&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention | PyTorch</A>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1833131508564914295">Longformer: On long sequence lengths, the speedup is even more significant. Added visualizations and repo link in the replies</A>
									<DT><A HREF="https://github.com/cccntu/t5-flex-attention">cccntu/t5-flex-attention: T5 model optimized with FlexAttention</A>
									<DT><A HREF="https://arxiv.org/abs/2412.05496">[2412.05496] Flex Attention: A Programming Model for Generating Optimized Attention Kernels</A>
									<DT><A HREF="https://pytorch.org/blog/flexattention/">FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention | PyTorch</A>
									<DT><A HREF="https://x.com/ye_combinator/status/1869826615146053904">(1) Zihao Ye en X: "@tri_dao @__tensorcore__ (3/n) Inspired by the awesome FlexAttention (from @cHHillee @JoyChew_d etc), we added JIT support in FlashInfer to allow user to customize their own attention variants, using user-defined Query/Logits/... Transform functors, and generate code to the CUDA/Cutlass template for LLM https://t.co/5oiBbLjLga" / X</A>
									<DT><A HREF="https://github.com/shreyansh26/Attention-Mask-Patterns">shreyansh26/Attention-Mask-Patterns: Using FlexAttention to compute attention with different masking patterns</A>
									<DT><A HREF="https://x.com/cHHillee/status/1887015958033908080">(1) Horace He en X: "Did you know that you can merge two separate attention calls in FlexAttention... and then differentiate through it? Thanks to @tri_dao and @typedfemale for guidance on how to implement this! https://t.co/xzfedL1Glf" / X</A>
									<DT><A HREF="https://gist.github.com/Chillee/afc7eda51be08c2d40f44f15e4df1161">Merge Attention</A>
									<DT><A HREF="https://github.com/meta-pytorch/attention-gym/blob/main/examples/flex_flash_attention.py">attention-gym/examples/flex_flash_attention.py at main ¬∑ meta-pytorch/attention-gym</A>
									<DT><A HREF="https://x.com/kimbochen/status/2014610059830124822">(1) Kimbo en X: "Jonathan's blog post: https://t.co/FFitVSwS8D PyTorch: https://t.co/DyvTthqEya I'll be studying schedulers next!" / X</A>
									<DT><A HREF="https://jonathanc.net/blog/vllm-flex-attention-from-scratch">vLLM from scratch with FlexAttention ‚Äì Jonathan Chang‚Äôs Blog</A>
									<DT><A HREF="https://github.com/Tencent-Hunyuan/flex-block-attn">Tencent-Hunyuan/flex-block-attn: flex-block-attn: an efficient block sparse attention computation library</A>
								</DL><p>
								<DT><H3 FOLDED>libflash</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tlc-pack/libflash_attn/tree/master">tlc-pack/libflash_attn: Standalone Flash Attention v2 kernel without libtorch dependency</A>
								</DL><p>
								<DT><H3 FOLDED>AttentionEngine</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tile-ai/AttentionEngine">tile-ai/AttentionEngine</A>
									<DT><A HREF="https://github.com/microsoft/AttentionEngine">microsoft/AttentionEngine</A>
								</DL><p>
								<DT><H3 FOLDED>attention-quantized</H3>
								<DL><p>
									<DT><H3 FOLDED>QuantumAttention</H3>
									<DL><p>
										<DT><H3 FOLDED>QuantumAttention-TK</H3>
										<DL><p>
											<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/e7b647eb86596609ea68d372c9291a2e63e16d16/src/quantum_attn/tk/attention.py">QuantumAttention/src/quantum_attn/tk/attention.py at e7b647eb86596609ea68d372c9291a2e63e16d16 ¬∑ WaveSpeedAI/QuantumAttention</A>
										</DL><p>
										<DT><A HREF="https://github.com/chengzeyi/QuantumAttention/commit/35abd08f042314e01bad999a0521faee24ca4d6a">Dev kernel (#1) ¬∑ chengzeyi/QuantumAttention@35abd08</A>
										<DT><A HREF="https://github.com/chengzeyi/QuantumAttention/blob/main/src/quantum_attn/config.py">QuantumAttention/src/quantum_attn/config.py at main env vars patch</A>
										<DT><A HREF="https://github.com/search?q=repo%3Achengzeyi%2FQuantumAttention%20attention.force_eager_fallback&type=code">config patching (e.g. attention.force_eager_fallback)</A>
										<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/commit/e7b647eb86596609ea68d372c9291a2e63e16d16">Dev fp8 attn per head (#3) ¬∑ WaveSpeedAI/QuantumAttention@e7b647e</A>
									</DL><p>
									<DT><A HREF="https://matx.com/research/leaky_quantization">Future leakage in block-quantized attention | MatX</A>
								</DL><p>
								<DT><H3 FOLDED>FlashMLA</H3>
								<DL><p>
									<DT><H3 FOLDED>FlashMLA-b200</H3>
									<DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/commit/fd249aacce56327affecd16f89e035b12691974f">Add Sparse Decoding Kernel and Sparse Prefill Kernel for Blackwell</A>
									</DL><p>
									<DT><H3 FOLDED>FlashMLA-model1</H3>
									<DL><p>
										<DT><A HREF="https://github.com/search?q=repo%3Adeepseek-ai%2FFlashMLA%20MODEL1&type=code">FlashMLA MODEL1 instantiations</A>
										<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/commit/082094b793fcc7452977d0a71a00e266a2e3061e">Multiple updates and refactorings (#150) ¬∑ deepseek-ai/FlashMLA@082094b</A>
										<DT><A HREF="https://x.com/teortaxestex/status/2013531668150202816?s=12">k_cache.stride(0) must be a multiple of 656B (for V32) or 576B (for **MODEL1**)</A>
									</DL><p>
									<DT><A HREF="https://github.com/deepseek-ai/FlashMLA">deepseek-ai/FlashMLA</A>
									<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/commit/4da4dbd303eabbcdb5806051d82430ded46625d6">feat: add benchmark for flash_infer vs flash_mla ¬∑ deepseek-ai/FlashMLA@4da4dbd</A>
									<DT><A HREF="https://github.com/deepseek-ai/open-infra-index?tab=readme-ov-file">deepseek-ai/open-infra-index</A>
									<DT><A HREF="https://github.com/Dao-AILab/grouped-latent-attention">Dao-AILab/grouped-latent-attention</A>
									<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/blob/main/docs/20250422-new-kernel-deep-dive.md">FlashMLA/docs/20250422-new-kernel-deep-dive.md at main ¬∑ deepseek-ai/FlashMLA</A>
									<DT><A HREF="https://github.com/deepseek-ai/FlashMLA/blob/main/docs/20250929-hopper-fp8-sparse-deep-dive.md">FlashMLA/docs/20250929-hopper-fp8-sparse-deep-dive.md at main ¬∑ deepseek-ai/FlashMLA</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-metal</H3>
								<DL><p>
									<DT><A HREF="https://github.com/philipturner/metal-flash-attention">philipturner/metal-flash-attention: FlashAttention (Metal Port)</A>
								</DL><p>
								<DT><H3 FOLDED>flashAttention-hand</H3>
								<DL><p>
									<DT><A HREF="https://dev.to/lewis_won/flashattention-by-hand-34im">FlashAttention by hand - DEV Community</A>
								</DL><p>
								<DT><H3 FOLDED>FlashAttention-flops</H3>
								<DL><p>
									<DT><H3 FOLDED>test_attn</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ai-compiler-study/test_attn">ai-compiler-study/test_attn: Testing and benchmarking¬†different attention implementations¬†and backends</A>
										<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/d51243e946b25e437ba02e2c9d1aaad08da17c93/benchmarks/fav4.py#L102">transformer_nuggets/benchmarks/fav4.py at d51243e946b25e437ba02e2c9d1aaad08da17c93 ¬∑ drisspg/transformer_nuggets</A>
										<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/main/tests/test_interface.py">QuantumAttention/tests/test_interface.py at main ¬∑ WaveSpeedAI/QuantumAttention</A>
									</DL><p>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/5059fd53e602bcc00336bb5cc8a85e50940485cb/hopper/benchmark_attn.py#L73">benchmark_attn.py#L73: batch * nheads * 2 * seqlen_q * avg_seqlen * (headdim + headdim_v)</A>
								</DL><p>
								<DT><H3 FOLDED>fa-bwd</H3>
								<DL><p>
									<DT><A HREF="https://github.com/daniel-geon-park/triton_bwd/blob/main/tests/test_triton_bwd_flashattn.py">triton_bwd/tests/test_triton_bwd_flashattn.py at main ¬∑ daniel-geon-park/triton_bwd</A>
								</DL><p>
								<DT><H3 FOLDED>fa-sfu</H3>
								<DL><p>
									<DT><A HREF="https://x.com/SemiAnalysis_/status/2015907663528251898">(1) SemiAnalysis en X: "IMPORTANT: Blackwell Ultra solves an attention operation performance issue found in Blackwell. As @tri_dao presented at the SemiAnalysis Hackathon, one of the biggest bottlenecks in the core attention operation is not GEMMs but the softmax (exponential)¬† part. In Hopper &amp;amp; https://t.co/x3iRUUnAlf" / X</A>
									<DT><A HREF="https://github.com/zartbot/blog/issues/3">Blackwell ultra attention acceleration (SFU EX2) 10.7 TeraExponentials/s</A>
									<DT><A HREF="https://x.com/_alyxya/status/2015919339648799046">use 2 as the base instead of e as the base for exponentials. 2^k</A>
								</DL><p>
								<DT><A HREF="https://courses.cs.washington.edu/courses/cse599m/23sp/notes/flashattn.pdf">From Online Softmax to FlashAttention</A>
								<DT><A HREF="https://github.com/NVIDIA/online-softmax">NVIDIA/online-softmax: Benchmark code for the "Online normalizer calculation for softmax" paper</A>
								<DT><A HREF="https://github.com/HazyResearch/flash-attention">HazyResearch/flash-attention: Fast and memory-efficient exact attention</A>
								<DT><A HREF="https://pytorch.org/tutorials/intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA) ‚Äî PyTorch Tutorials 2.1.0+cu121 documentation</A>
								<DT><A HREF="https://gist.github.com/Chillee/41baf11aac8036d25d637321c48dad20">You Could Have Invented Flash-Attention!</A>
								<DT><A HREF="https://github.com/tspeterkim/flash-attention-minimal">tspeterkim/flash-attention-minimal: Flash Attention in ~100 lines of CUDA (forward pass only)</A>
								<DT><A HREF="https://github.com/lucidrains/flash-cosine-sim-attention">lucidrains/flash-cosine-sim-attention: Implementation of fused cosine similarity attention in the same style as Flash Attention</A>
								<DT><A HREF="https://github.com/jundaf2/INT8-Flash-Attention-FMHA-Quantization">jundaf2/INT8-Flash-Attention-FMHA-Quantization</A>
								<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/main/src/turbomind/kernels/flash_attention/flash_attention.h">lmdeploy/src/turbomind/kernels/flash_attention/flash_attention.h at main ¬∑ InternLM/lmdeploy</A>
								<DT><A HREF="https://mp.weixin.qq.com/s?__biz=Mzg2NjcwNjcxNQ==&mid=2247485453&idx=1&sn=beb642f06f3501bd235a8f42973e39fb&chksm=ce47fc79f930756f991d93f69cad36409e3dcb58e517f41f583d29609b360e9b46f6777a42b4&scene=21#wechat_redirect">ÂõæËß£Â§ßÊ®°ÂûãËÆ°ÁÆóÂä†ÈÄüÁ≥ªÂàóÔºöFlash Attention V1Ôºå‰ªéÁ°¨‰ª∂Âà∞ËÆ°ÁÆóÈÄªËæë</A>
								<DT><A HREF="https://arxiv.org/abs/1805.02867">[1805.02867] Online normalizer calculation for softmax</A>
								<DT><A HREF="https://gist.github.com/wkcn/65bbf94037222a38af78169f7f2c206b">test_flash_attn.py</A>
								<DT><A HREF="https://www.thonking.ai/p/pytorch-blog-flexattention-the-flexibility?utm_source=post-email-title&publication_id=1781836&post_id=147464468&utm_campaign=email-post-title&isFreemail=false&r=1tutvb&triedRedirect=true&utm_medium=email">[PyTorch Blog] FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention</A>
								<DT><A HREF="https://x.com/cHHillee/status/1821253769147118004">FlexAttention</A>
								<DT><A HREF="https://github.com/pytorch-labs/attention-gym/">pytorch-labs/attention-gym: Helpful tools and examples for working with flex-attention</A>
								<DT><A HREF="https://arxiv.org/pdf/1805.02867">Online normalizer calculation for softmax</A>
								<DT><A HREF="https://github.com/lancerts/Algo-ML-Kernels/blob/main/flash_attn/naive_flash.ipynb">Algo-ML-Kernels/flash_attn/naive_flash.ipynb at main ¬∑ lancerts/Algo-ML-Kernels</A>
								<DT><A HREF="https://github.com/zhuzilin/ring-flash-attention">zhuzilin/ring-flash-attention: Ring attention implementation with flash attention</A>
								<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/main/examples/attention/triton/fused_linear_attention_complex.py">MatmulTutorial/examples/attention/triton/fused_linear_attention_complex.py</A>
								<DT><A HREF="https://github.com/weishengying/cutlass_flash_atten_fp8">weishengying/cutlass_flash_atten_fp8: ‰ΩøÁî® cutlass ‰ªìÂ∫ìÂú® ada Êû∂ÊûÑ‰∏äÂÆûÁé∞ fp8 ÁöÑ flash attention</A>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/7efcb5e0ed6403f08965b999626c5807680b46ed/server/text_generation_server/layers/attention/flash_attn_triton.py#L811">text-generation-inference/server/text_generation_server/layers/attention/flash_attn_triton.py at 7efcb5e0ed6403f08965b999626c5807680b46ed ¬∑ huggingface/text-generation-inference</A>
								<DT><A HREF="https://gist.github.com/cloneofsimo/af610ff8aa11a3f57956e7d7f578409c">FlashAttention comparison</A>
								<DT><A HREF="https://github.com/INT-FlashAttention2024/INT-FlashAttention/blob/main/flash_atten_fp.py">INT-FlashAttention/flash_atten_fp.py at main ¬∑ INT-FlashAttention2024/INT-FlashAttention</A>
								<DT><A HREF="https://github.com/KuangjuX/PyKernelCollection/blob/main/src/pytorch/flashattention/flashattention.py">PyKernelCollection/src/pytorch/flashattention/flashattention.py at main ¬∑ KuangjuX/PyKernelCollection</A>
								<DT><A HREF="https://www.youtube.com/watch?v=zy8ChVd_oTM">Flash Attention derived and coded from first principles with Triton (Python) - YouTube</A>
								<DT><A HREF="https://x.com/papers_anon/status/1857271245349490945">Computes the cross-entropy loss without materializing the logis for all tokens into global memory</A>
								<DT><A HREF="https://x.com/ogawa_tter/status/1858431835560460684">OGAWA, Tadashi en X: "=&amp;gt; "CUTLASS and Flash Attention 3", Jay Shah, Colfax Research, GPU Mode, Nov 17, 2024 (1:49:15) https://t.co/dKVCsw7RGx https://t.co/Wl3LCuydFp BF16: up to 850 TFLOPS FP8: up to 1.3 PFLOPS FlashAttention-3, Jul 12 https://t.co/PttAXd4rzt CUTLASS, Jun 7 https://t.co/j32ViFdKt7 https://t.co/vkaYgvPXR1" / X</A>
								<DT><A HREF="https://github.com/FlagOpen/FlagAttention">FlagOpen/FlagAttention: A collection of memory efficient attention operators implemented in the Triton language.</A>
								<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/blob/master/fused_mha/README.md">DLFrameworkTest/fused_mha/README.md at master ¬∑ lcy-seso/DLFrameworkTest</A>
								<DT><A HREF="https://x.com/__tinygrad__/status/1910574691284300167?s=12">Tinygrad automatic searched softmax optimized kenrel with fusion</A>
								<DT><A HREF="https://gau-nernst.github.io/fa-5090/">Writing Speed-of-Light Flash Attention for 5090 in CUDA C++ - gau-nernst's blog</A>
							</DL><p>
							<DT><H3 FOLDED>BMM</H3>
							<DL><p>
								<DT><A HREF="https://github.com/EleutherAI/cookbook/tree/main/benchmarks/sizing">cookbook/benchmarks/sizing at main ¬∑ EleutherAI/cookbook</A>
								<DT><A HREF="https://github.com/EleutherAI/cookbook/blob/main/benchmarks/sizing/bmm_flops.py">cookbook/benchmarks/sizing/bmm_flops.py at main ¬∑ EleutherAI/cookbook</A>
							</DL><p>
							<DT><H3 FOLDED>linalg: standard Linear Algebra</H3>
							<DL><p>
								<DT><H3 FOLDED>BLAS</H3>
								<DL><p>
									<DT><H3 FOLDED>colmajor-rowmajor</H3>
									<DL><p>
										<DT><A HREF="https://www.netlib.org/blas/blast-forum/blas-report.pdf">Conventional Storage</A>
										<DT><A HREF="https://leimao.github.io/blog/Row-Major-VS-Column-Major/">Row-Major VS Column-Major - Lei Mao's Log Book</A>
										<DT><A HREF="https://www.youtube.com/watch?v=USMnKuyXBFM">Developing Optimal CUDA Kernels on Hopper Tensor Cores NVIDIA On Demand - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>row-major</H3>
									<DL><p>
										<DT><A HREF="https://scicomp.stackexchange.com/questions/4796/row-major-versus-column-major-layout-of-matrices">matrix - Row major versus Column major layout of matrices - Computational Science Stack Exchange</A>
									</DL><p>
									<DT><H3 FOLDED>BLAS-level-1</H3>
									<DL><p>
										<DT><A HREF="https://www.netlib.org/blas/snrm2.f90">SNRM2</A>
										<DT><A HREF="https://netlib.org/lapack/explore-html/d6/d12/snrm2_8f90_source.html">LAPACK: BLAS/SRC/snrm2.f90 Source File</A>
									</DL><p>
									<DT><A HREF="https://www.netlib.org/blas/">BLAS (Basic Linear Algebra Subprograms)</A>
									<DT><A HREF="https://www.netlib.org/blas/blast-forum/blas-report.pdf">Basic Linear Algebra Subprograms Technial (BLAST)</A>
									<DT><A HREF="https://github.com/flame/blis/">flame/blis: BLAS-like Library Instantiation Software Framework (main)</A>
									<DT><A HREF="https://github.com/flame">flame</A>
									<DT><A HREF="https://github.com/flame/blislab?tab=readme-ov-file">flame/blislab: BLISlab: A Sandbox for Optimizing GEMM</A>
									<DT><A HREF="https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/">CUTLASS: Fast Linear Algebra in CUDA C++ | NVIDIA Technical Blog</A>
									<DT><A HREF="https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html">Matrix Multiplication Background User's Guide - NVIDIA Docs</A>
									<DT><A HREF="https://github.com/NVIDIA/FasterTransformer/blob/df4a7534860137e060e18d2ebf019906120ea204/src/fastertransformer/kernels/matrix_transpose_kernels.cu#L4">FasterTransformer/src/fastertransformer/kernels/matrix_transpose_kernels.cu</A>
									<DT><A HREF="https://github.com/microsoft/BitBLAS">microsoft/BitBLAS: BitBLAS is a library to support mixed-precision matrix multiplications, especially for quantized LLM deployment.</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/fd27f19e9231160939da8a3a23434b4ae8ce51ee/docs/tensor/ops.md?plain=1">tinygrad/docs/tensor/ops.md</A>
								</DL><p>
								<DT><A HREF="https://www.netlib.org/blas/blast-forum/blas-report.pdf">Basic Linear Algebra Subprograms Technial (BLAST)</A>
								<DT><A HREF="https://en.cppreference.com/w/cpp/numeric/linalg">Basic linear algebra algorithms (since C++26) - cppreference.com</A>
								<DT><A HREF="https://numpy.org/doc/stable/reference/routines.linalg.html">Linear algebra (numpy.linalg) ‚Äî NumPy v1.26 Manual</A>
								<DT><A HREF="https://github.com/bytedance/byteir/blob/main/talks/c4ml23_poster.pdf">Linalg is All You Need to Optimize Attention</A>
								<DT><A HREF="https://www.openblas.net/">OpenBLAS : An optimized BLAS library</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cublas/">cuBLAS</A>
								<DT><A HREF="https://github.com/flame/blislab?tab=readme-ov-file">flame/blislab: BLISlab: A Sandbox for Optimizing GEMM</A>
								<DT><A HREF="https://developer.nvidia.com/blog/cutlass-linear-algebra-cuda/">CUTLASS: Fast Linear Algebra in CUDA C++ | NVIDIA Technical Blog</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/c4fdb9c725924fd1bc8a89ca07a1f405953b4d54/docs/tensor/ops.md?plain=1#L2">tinygrad/docs/tensor/ops.md</A>
							</DL><p>
							<DT><H3 FOLDED>tilelang</H3>
							<DL><p>
								<DT><H3 FOLDED>tilelang-examples</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tile-ai/tilelang-puzzles">tile-ai/tilelang-puzzles: Learning TileLang with 10 puzzles!</A>
									<DT><A HREF="https://api-docs.deepseek.com/news/news250929">Key GPU kernels in TileLang &amp; CUDA (use TileLang for rapid research prototyping!)</A>
									<DT><A HREF="https://github.com/tile-ai/tilelang/tree/main/examples/minference">tilelang/examples/minference at main ¬∑ tile-ai/tilelang</A>
									<DT><A HREF="https://github.com/SiriusNEO/Triton-Puzzles-Lite">SiriusNEO/Triton-Puzzles-Lite: Puzzles for learning Triton, play it with minimal environment configuration!</A>
								</DL><p>
								<DT><H3 FOLDED>tilelang-tcgen5.mma</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tile-ai/tilelang/issues/931">B200 gemm_tcgen5mma example does not work ¬∑ Issue #931 ¬∑ tile-ai/tilelang</A>
								</DL><p>
								<DT><H3 FOLDED>tilelang-compiler</H3>
								<DL><p>
									<DT><H3 FOLDED>tilelang-lowering</H3>
									<DL><p>
										<DT><A HREF="https://www.albresky.cn/tilelang-insight/">tilelang lowering compiler flow</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>tilelang-backends</H3>
								<DL><p>
									<DT><H3 FOLDED>Tilecute</H3>
									<DL><p>
										<DT><A HREF="https://github.com/cherichy/tilecute">cherichy/tilecute</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>tilelang-ffi</H3>
								<DL><p>
									<DT><A HREF="https://x.com/Lei_Wang_1999/status/1990812613077578100">tilelang supports tvm-ffi</A>
								</DL><p>
								<DT><A HREF="https://github.com/tile-ai/tilelang">tile-ai/tilelang: Domain-specific language designed to streamline the development of high-performance GPU/CPU/Accelerators kernels</A>
								<DT><A HREF="https://github.com/LeiWang1999/tilelang/blob/6574ac58fd5b9ee964a9479d61bc56af5235068a/tilelang/jit/adapter/libgen.py">tilelang/tilelang/jit/adapter/libgen.py CUTLASS_INCLUDE_DIR</A>
								<DT><A HREF="https://x.com/Lei_Wang_1999/status/1907752700952908228">tilelang analyzer</A>
								<DT><A HREF="https://github.com/tile-ai/tilelang/tree/main/examples/analyze">TVM IR Performance Analyzer</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1959411304675665848">‰ªéDeepSeek V3.2 DSAÁÆóÂ≠êÁúãTileLangÁºñËØëÂô®ÁöÑÁªÜËäÇ - Áü•‰πé</A>
							</DL><p>
							<DT><H3 FOLDED>persistent-kernels</H3>
							<DL><p>
								<DT><H3 FOLDED>wave quantization</H3>
								<DL><p>
									<DT><A HREF="https://www.kapilsharma.dev/posts/learn-cutlass-the-hard-way-2/">Learn CUTLASS the hard way - part 2! | Kapil Sharma</A>
									<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-persistent-kernels-and-stream-k/">CUTLASS Tutorial: Persistent Kernels and Stream-K ‚Äì Colfax Research</A>
								</DL><p>
								<DT><H3 FOLDED>Stream-K</H3>
								<DL><p>
									<DT><A HREF="https://www.kapilsharma.dev/posts/learn-cutlass-the-hard-way-2/">Learn CUTLASS the hard way - part 2! | Kapil Sharma</A>
									<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-persistent-kernels-and-stream-k/">CUTLASS Tutorial: Persistent Kernels and Stream-K ‚Äì Colfax Research</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/config.py">TORCHINDUCTOR_MULTI_KERNEL (i.e. no loops kernels)</A>
								<DT><A HREF="https://x.com/cHHillee/status/1943416186412449946">persistent reductions kernels (i.e. no loops)</A>
								<DT><A HREF="https://gist.github.com/Chillee/6f1a8995dc25c08b11494485d4a53460">Random Kernel Microbenchmarks</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-05-27-no-bubbles">Look Ma, No Bubbles! Designing a Low-Latency Megakernel for Llama-1B ¬∑ Hazy Research</A>
								<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops/blob/9bfcaf6c29c5d1413971c8fb16da325fa1602d7d/batch_invariant_ops/batch_invariant_ops.py#L483">batch_invariant_ops/batch_invariant_ops/batch_invariant_ops.py at 9bfcaf6c29c5d1413971c8fb16da325fa1602d7d ¬∑ thinking-machines-lab/batch_invariant_ops</A>
								<DT><A HREF="https://x.com/bfspector/status/1972384521149718541">(1) Benjamin F Spector en X: "(1/8) We‚Äôre releasing an 8-GPU Llama-70B inference engine megakernel! Our megakernel supports arbitrary batch sizes, mixed prefill+decode, a paged KV cache, instruction pipelining, dynamic scheduling, interleaved communication, and more! On ShareGPT it‚Äôs 22% faster than SGLang. https://t.co/nRUfEiCubk" / X</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-09-28-tp-llama-main">We Bought the Whole GPU, So We're Damn Well Going to Use the Whole GPU ¬∑ Hazy Research</A>
								<DT><A HREF="https://www.youtube.com/watch?v=PAsL680eWUw">Triton Pipelining Persistent Kernels - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?app=desktop&si=1ahzuf6QmO-ItbZ6&v=kCNsdqgKuO8&feature=youtu.be">Persistent Kernels ‚Äì Dynamic GPU Work Distribution Explained - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=kCNsdqgKuO8">Persistent Kernels ‚Äì Dynamic GPU Work Distribution Explained - YouTube</A>
								<DT><A HREF="https://github.com/alexarmbr/cute_kernels/blob/main/sm100_persistent_matmul.py">cute_kernels/sm100_persistent_matmul.py at main ¬∑ alexarmbr/cute_kernels</A>
								<DT><A HREF="https://github.com/simveit/cute_persistent_kernels">simveit/cute_persistent_kernels</A>
							</DL><p>
							<DT><H3 FOLDED>flashinfer</H3>
							<DL><p>
								<DT><H3 FOLDED>flashinfer-bench</H3>
								<DL><p>
									<DT><A HREF="https://flashinfer.ai/2025/10/21/flashinfer-bench.html">FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems | FlashInfer</A>
								</DL><p>
								<DT><H3 FOLDED>flashinfer-sm103-nvfp4</H3>
								<DL><p>
									<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/2303">[Perf][Feature] Add SM103-specific schedulers for NVFP4 CUTLASS kernels by LopezCastroRoberto ¬∑ Pull Request #2303 ¬∑ flashinfer-ai/flashinfer</A>
								</DL><p>
								<DT><H3 FOLDED>flashinfer-nvfp4_quantize</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Overworldai/world_engine/blob/main/src/quantize.py">world_engine/src/quantize.py nvfp4_quantize fp4_linear</A>
								</DL><p>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/layers/activation.py#L26">sglang/python/sglang/srt/layers/activation.py: gelu_and_mul</A>
								<DT><A HREF="https://github.com/yzh119/flashinfer-dev">yzh119/flashinfer-dev: FlashInfer: Kernel Library for LLM Serving</A>
								<DT><A HREF="https://x.com/cHHillee/status/1869839444179816588">(1) Horace He en X: "Although FlexAttention required custom kernel work, in our view the "main" contribution of FlexAttention is introducing an API that is both: 1. Flexible enough to support a wide variety of attention variants, and 2. easy to codegen into an efficient kernel. FlashInfer is one of" / X</A>
								<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/1372">ci: add blackwell unittest scripts by yzh119 ¬∑ Pull Request #1372 ¬∑ flashinfer-ai/flashinfer</A>
								<DT><A HREF="https://github.com/flashinfer-ai/flashinfer">flashinfer-ai/flashinfer: FlashInfer: Kernel Library for LLM Serving</A>
								<DT><A HREF="https://ydnyshhh.github.io/posts/flash_infer/">Dissecting FlashInfer - A Systems Perspective on High-Performance LLM Inference | yadnyesh's blog</A>
							</DL><p>
							<DT><H3 FOLDED>MSLK</H3>
							<DL><p>
								<DT><A HREF="https://github.com/meta-pytorch/MSLK">meta-pytorch/MSLK: MSLK (Meta Superintelligence Labs Kernels) is a collection of PyTorch GPU operator libraries that are designed and optimized for GenAI training and inference, such as FP8 row-wise quantization and collective communications.</A>
								<DT><A HREF="https://github.com/meta-pytorch/MSLK/blob/main/test/gemm/gemm_test.py">MSLK/test/gemm/gemm_test.py at main ¬∑ meta-pytorch/MSLK</A>
								<DT><A HREF="https://x.com/tetsuo_cpp/status/2009238107309461782">(1) tetsuo.cpp (no slop) en X: "Oh, you're writing CUDA kernels? Everyone's on Triton now. Just kidding, we're all on Mojo. We're using cuTile. We're using ROCm. We have an in-house DSL compiler targeting the NVGPU MLIR dialect but wait, Tile IR just dropped so we're going to target that instead. Our PM is on" / X</A>
								<DT><A HREF="https://github.com/meta-pytorch/tritonbench/pull/764">Migrate FBGEMM GenAI calls to MSLK by cthi ¬∑ Pull Request #764 ¬∑ meta-pytorch/tritonbench</A>
							</DL><p>
							<DT><H3 FOLDED>quack</H3>
							<DL><p>
								<DT><H3 FOLDED>quack-benchmark</H3>
								<DL><p>
									<DT><A HREF="https://gist.github.com/Chillee/6f1a8995dc25c08b11494485d4a53460">Random Kernel Microbenchmarks: softmax_quack.py</A>
									<DT><A HREF="https://github.com/Dao-AILab/quack/blob/main/benchmarks/benchmark_gemm_sm90.py#L430">quack/benchmarks/benchmark_gemm_sm90.py at main ¬∑ Dao-AILab/quack</A>
								</DL><p>
								<DT><H3 FOLDED>quack-gemm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Dao-AILab/quack/blob/main/benchmarks/benchmark_gemm_sm90.py#L430">quack/benchmarks/benchmark_gemm_sm90.py at main ¬∑ Dao-AILab/quack</A>
								</DL><p>
								<DT><A HREF="https://github.com/Dao-AILab/quack">Dao-AILab/quack: A Quirky Assortment of CuTe Kernels</A>
								<DT><A HREF="https://x.com/cHHillee/status/1943416186412449946">torch.compile auto-tuning vs quack mem-bound</A>
								<DT><A HREF="https://x.com/WentaoGuo7/status/1943369417078821279">new SOL mem-bound kernel library without a single line of CUDA C++ all straight in Python thanks to CuTe-DSL</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1927016529330943911">Flash Attention author's new work becomes a hit, accelerating H100 by 33%-50% without CUDA code</A>
							</DL><p>
							<DT><H3 FOLDED>Marlin</H3>
							<DL><p>
								<DT><A HREF="https://github.com/IST-DASLab/marlin">IST-DASLab/marlin: FP16xINT4 LLM inference kernel that can achieve near-ideal ~4x speedups up to medium batchsizes of 16-32 tokens.</A>
								<DT><A HREF="https://github.com/flashinfer-ai/flashinfer">flashinfer-ai/flashinfer: FlashInfer: Kernel Library for LLM Serving</A>
								<DT><A HREF="https://github.com/IST-DASLab/Sparse-Marlin">IST-DASLab/Sparse-Marlin</A>
								<DT><A HREF="https://x.com/Tim_Dettmers/status/1967552946172027057">(1) Tim Dettmers en X: "I do not get why Dan's group does not get more attention: best quantization methods, best quantization kernels, and they even put everything into open-source libraries. Meanwhile, we see slop papers/software explode. If frontier labs ask me who's students to hire, I go like üëá" / X</A>
								<DT><A HREF="https://github.com/IST-DASLab/gptq-gguf-toolkit">IST-DASLab/gptq-gguf-toolkit: GPTQ and efficient search for GGUF</A>
								<DT><A HREF="https://research-explorer.ista.ac.at/groups/DaAl">ISTA Research Explorer</A>
								<DT><A HREF="https://github.com/IST-DASLab/llmq/">IST-DASLab/llmq: Quantized LLM training in pure CUDA/C++.</A>
							</DL><p>
							<DT><H3 FOLDED>XQA-kernel</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/XQA-kernel.md">TensorRT-LLM/docs/source/blogs/XQA-kernel.md</A>
							</DL><p>
							<DT><H3 FOLDED>split-k-gemm</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/main/examples/06_splitK_gemm/splitk_gemm.cu">cutlass/examples/06_splitK_gemm/splitk_gemm.cu</A>
								<DT><A HREF="https://arxiv.org/abs/2402.00025">[2402.00025] Accelerating a Triton Fused Kernel for W4A16 Quantized Inference with SplitK work decomposition</A>
								<DT><A HREF="https://pytorch.org/blog/accelerating-moe-model//#30-work-decomposition---splitk">Accelerating MoE model inference with Locality-Aware Kernel Design | PyTorch</A>
								<DT><A HREF="https://github.com/pytorch-labs/applied-ai/tree/main/kernels/triton/inference/col_major_moe_gemm">applied-ai/kernels/triton/inference/col_major_moe_gemm at main ¬∑ pytorch-labs/applied-ai</A>
							</DL><p>
							<DT><H3 FOLDED>deterministic-attention</H3>
							<DL><p>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-894/developer-guide/index.html">Developer Guide :: NVIDIA cuDNN Documentation</A>
								<DT><A HREF="https://github.com/NVIDIA/cudnn-frontend/blob/de355c7094af70467f2b264f531ab5c5f4401c42/test/python_fe/test_mhas.py#L1198">test_mhas.py#L1198: use_deterministic_algorithm=is_deterministic</A>
							</DL><p>
							<DT><H3 FOLDED>FlashFFTConv</H3>
							<DL><p>
								<DT><A HREF="https://twitter.com/realDanFu/status/1724127071902011611">FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-dit</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ai-compiler-study/sd3-triton-kernels">ai-compiler-study/sd3-triton-kernels: Triton kernels for Stable Diffusion 3</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-quantization</H3>
							<DL><p>
								<DT><H3 FOLDED>mx</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/microxcaling">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fp6/03-05-2024">deepspeed-fp6</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=64">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>gptq</H3>
								<DL><p>
									<DT><A HREF="https://github.com/IST-DASLab/gptq">IST-DASLab/gptq: Code for the ICLR 2023 paper "GPTQ: Accurate Post-training Quantization of Generative Pretrained Transformers".</A>
								</DL><p>
								<DT><H3 FOLDED>awq</H3>
								<DL><p>
									<DT><A HREF="https://github.com/mit-han-lab/llm-awq">mit-han-lab/llm-awq: [MLSys 2024 Best Paper Award] AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</A>
								</DL><p>
								<DT><A HREF="https://github.com/hahnyuan/RPTQ4LLM">hahnyuan/RPTQ4LLM: Reorder-based post-training quantization for large language model</A>
								<DT><A HREF="https://github.com/IST-DASLab/QUIK">IST-DASLab/QUIK: Repository for the QUIK project, enabling the use of 4bit kernels for generative inference</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-sparsity</H3>
							<DL><p>
								<DT><H3 FOLDED>dynamic sparse training</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/blog/accelerating-neural-network-training/?utm_content=297933946&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Accelerating Neural Network Training with Semi-Structured (2:4) Sparsity | PyTorch</A>
									<DT><A HREF="https://arxiv.org/pdf/1903.05662">UNDERSTANDING STRAIGHT-THROUGH ESTIMATOR IN TRAINING ACTIVATION QUANTIZED NEURAL NETS</A>
									<DT><A HREF="https://arxiv.org/pdf/2310.06927">Sparse Fine-tuning for Inference Acceleration of Large Language Models</A>
								</DL><p>
								<DT><H3 FOLDED>V:N:M</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/pdf/2310.02065">VENOM: A Vectorized N:M Format for Unleashing the Power of Sparse Tensor Cores</A>
								</DL><p>
								<DT><A HREF="https://pytorch.org/blog/accelerating-neural-network-training/?utm_content=297933946&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Accelerating Neural Network Training with Semi-Structured (2:4) Sparsity | PyTorch</A>
								<DT><A HREF="https://github.com/pytorch/ao/tree/main/torchao/sparsity/training#benchmarking">ao/torchao/sparsity/training at main ¬∑ pytorch/ao</A>
								<DT><A HREF="https://developer.nvidia.com/blog/structured-sparsity-in-the-nvidia-ampere-architecture-and-applications-in-search-engines/">Structured Sparsity in the NVIDIA Ampere Architecture and Applications in Search Engines | NVIDIA Technical Blog</A>
								<DT><A HREF="https://docs.nvidia.com/cuda/cusparselt/index.html">cuSPARSELt: A High-Performance CUDA Library for Sparse Matrix-Matrix Multiplication ‚Äî NVIDIA cuSPARSELt 0.6.1 documentation</A>
								<DT><A HREF="https://arxiv.org/pdf/2104.08378">Accelerating Sparse Deep Neural Networks</A>
								<DT><A HREF="https://pytorch.org/tutorials/advanced/semi_structured_sparse.html?highlight=beta">(beta) Accelerating BERT with semi-structured (2:4) sparsity ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/pull/122350">[sparse] Add fast semi-structured spasification kernels by jcaip ¬∑ Pull Request #122350 ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://github.com/pytorch/ao/commit/d97ae74f46bb92bc26d01b2b5aed11197c275dd9">training acceleration via runtime semi-structured sparsity (#184) ¬∑ pytorch/ao@d97ae74</A>
								<DT><A HREF="https://github.com/IST-DASLab/Sparse-Marlin">IST-DASLab/Sparse-Marlin</A>
								<DT><A HREF="https://github.com/AlibabaResearch/flash-llm">AlibabaResearch/flash-llm: Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity</A>
							</DL><p>
							<DT><H3 FOLDED>Warp Divergence</H3>
							<DL><p>
								<DT><A HREF="https://www.reddit.com/r/CUDA/comments/gkpjxe/what_is_warp_divergence/#">What is Warp Divergence ? : r/CUDA</A>
								<DT><A HREF="https://pytorch.org/blog/accelerating-neural-network-training/?utm_content=297933946&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Accelerating Neural Network Training with Semi-Structured (2:4) Sparsity | PyTorch</A>
							</DL><p>
							<DT><H3 FOLDED>arithmetic-intensity</H3>
							<DL><p>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/638468472">LLMÔºàÂçÅ‰∏ÉÔºâÔºö‰ªé FlashAttention Âà∞ PagedAttention, Â¶Ç‰ΩïËøõ‰∏ÄÊ≠•‰ºòÂåñ Attention ÊÄßËÉΩ - Áü•‰πé</A>
								<DT><A HREF="https://www.youtube.com/watch?v=qYqrfq452ig&t=4548s">Hardcore CUDA Hackathon Talks at AGI House SF - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-tma</H3>
							<DL><p>
								<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/triton/inference/fp8/tma_gemm.py">applied-ai/kernels/triton/inference/fp8/tma_gemm.py at main ¬∑ pytorch-labs/applied-ai</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-tuning</H3>
							<DL><p>
								<DT><H3 FOLDED>KPerfIR</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2505.21661">[2505.21661] KPerfIR: Towards an Open and Compiler-centric Ecosystem for GPU Kernel Performance Tooling on Modern AI Workloads</A>
									<DT><A HREF="https://github.com/triton-lang/triton/tree/main/third_party/proton/dialect">triton/third_party/proton/dialect at main ¬∑ triton-lang/triton</A>
								</DL><p>
								<DT><A HREF="https://github.com/KernelTuner/kernel_tuner">KernelTuner/kernel_tuner: Kernel Tuner</A>
								<DT><A HREF="https://github.com/KernelTuner/kernel_tuner_tutorial/blob/master/hands-on/cuda/03_Kernel_Tuner_Advanced.ipynb">kernel_tuner_tutorial/hands-on/cuda/03_Kernel_Tuner_Advanced.ipynb at master ¬∑ KernelTuner/kernel_tuner_tutorial</A>
								<DT><A HREF="https://github.com/ademeure/DeeperGEMM/blob/6ee8079e7f2a24cc31fe075fcd90900892f7d462/deep_gemm/jit_kernels/tuner.py">DeeperGEMM/deep_gemm/jit_kernels/tuner.py at 6ee8079e7f2a24cc31fe075fcd90900892f7d462 ¬∑ ademeure/DeeperGEMM</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/0f75b907c6bf6273dbb813b9e983757dab20751f/benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton.py">sglang/benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton.py at 0f75b907c6bf6273dbb813b9e983757dab20751f ¬∑ sgl-project/sglang</A>
								<DT><A HREF="https://github.com/pytorch/torchtitan/blob/main/torchtitan/experiments/kernels/triton_mg_group_gemm/torchao_pr/tma_autotuning.py#L146">torchtitan/torchtitan/experiments/kernels/triton_mg_group_gemm/torchao_pr/tma_autotuning.py at main ¬∑ pytorch/torchtitan</A>
								<DT><A HREF="https://developer.nvidia.com/blog/improving-gemm-kernel-auto-tuning-efficiency-on-nvidia-gpus-with-heuristics-and-cutlass-4-2/">Improving GEMM Kernel Auto-Tuning Efficiency on NVIDIA GPUs with Heuristics and CUTLASS 4.2 | NVIDIA Technical Blog</A>
							</DL><p>
							<DT><H3 FOLDED>scan</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/Chillee/e3089e7a11419c6b85f68de170e0ba0c">Higher Order Kernel - associative scan</A>
							</DL><p>
							<DT><H3 FOLDED>ThunderKittens</H3>
							<DL><p>
								<DT><H3 FOLDED>ThunderKittens-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=xcpEl0cGCC4">CUDA + ThunderKittens, but increasingly drunk. - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=IAwLzkldxUk">ThunderKittens goes live: AMA and library walkthrough - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>ThunderKittens-benchmark</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/699857ab8940ff704f6c087f971dfde6f7172af9/demos/based_demo/README.md">ThunderKittens/demos/based_demo/README.md at 699857ab8940ff704f6c087f971dfde6f7172af9 ¬∑ HazyResearch/ThunderKittens</A>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/699857ab8940ff704f6c087f971dfde6f7172af9/demos/based_demo/benchmark_kernel.py">ThunderKittens/demos/based_demo/benchmark_kernel.py at 699857ab8940ff704f6c087f971dfde6f7172af9 ¬∑ HazyResearch/ThunderKittens</A>
								</DL><p>
								<DT><H3 FOLDED>ThunderKittens-cubinding</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/blob/main/kernels/example_bind/example_bind.cu">ThunderKittens/kernels/example_bind/example_bind.cu at main ¬∑ HazyResearch/ThunderKittens</A>
								</DL><p>
								<DT><H3 FOLDED>ThunderKittens-blackwell</H3>
								<DL><p>
									<DT><H3 FOLDED>ThunderKittens-blackwell-attention</H3>
									<DL><p>
										<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/blackwell/kernels/attn/b200">ThunderKittens/kernels/attn/b200 at blackwell ¬∑ HazyResearch/ThunderKittens</A>
									</DL><p>
									<DT><H3 FOLDED>ThunderKittens-blackwell-gemm</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://x.com/bfspector/status/1883051606369001873">(1) Benjamin F Spector en X: "We got early access to some of the very first Nvidia B200‚Äôs. We share initial benchmark results and wrote the fastest (public) attention kernel with 925+ BF16 TFLOPs: Since the PTX instruction set released yesterday, @aaryan04 and I have been hard at work at @HazyResearch https://t.co/ZhlsBMvRl1" / X</A>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/blackwell">HazyResearch/ThunderKittens at blackwell</A>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/blackwell_tuning">HazyResearch/ThunderKittens at blackwell_tuning</A>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/blackwell_shapes">HazyResearch/ThunderKittens at blackwell_shapes</A>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/blackwell_fp4">HazyResearch/ThunderKittens at blackwell_fp4</A>
									<DT><A HREF="https://www.together.ai/blog/nvidia-hgx-b200-with-together-kernel-collection">Together AI Achieves 90% Faster BF16 Training with NVIDIA Blackwell Platform and Together Kernel Collection</A>
									<DT><A HREF="https://www.together.ai/blog/thunderkittens-nvidia-blackwell-gpus#:~:text=There%E2%80%99s%20also%20a%20new%20layer,to%20227KB%20of%20shared%20memory">ThunderKittens Now Optimized for NVIDIA Blackwell GPUs</A>
									<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-03-15-tk-blackwell">ThunderKittens Now on Blackwells! ¬∑ Hazy Research</A>
								</DL><p>
								<DT><H3 FOLDED>TK-fp8</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/commit/1719fb72641b965d26155a0515d413b007f9dc72">[wip] fp8 bindings ¬∑ HazyResearch/ThunderKittens@1719fb7</A>
								</DL><p>
								<DT><H3 FOLDED>TK-collectives</H3>
								<DL><p>
									<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-09-22-pgl">One Kernel for All Your GPUs ¬∑ Hazy Research</A>
									<DT><A HREF="https://x.com/stuart_sul/status/1970239956624011556">(1) Stuart Sul en X: "(1/6) We‚Äôre happy to share that ThunderKittens now supports writing multi-GPU kernels, with the same programming model and full compatibility with PyTorch + torchrun. We‚Äôre also releasing collective ops and fused multi-GPU GEMM kernels, up to 2.6x faster than PyTorch + NCCL. https://t.co/hvnNe2RBXp" / X</A>
								</DL><p>
								<DT><H3 FOLDED>TK-MLA</H3>
								<DL><p>
									<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-03-04-thundermla">ThunderMLA: FlashMLA, Faster and Fused-er! ¬∑ Hazy Research</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/abs/2410.20399">[2410.20399] ThunderKittens: Simple, Fast, and Adorable AI Kernels</A>
								<DT><A HREF="https://twitter.com/bfspector/status/1789749117104894179">(1) Benjamin F Spector en X: "(1/7) Happy mother‚Äôs day! We think what the mothers of America really want is a Flash Attention implementation that‚Äôs just 100 lines of code and 30% faster, and we‚Äôre happy to provide. We're excited to introduce ThunderKittens (TK), a simple DSL embedded within CUDA that makes... https://t.co/7Nupt8B4hq" / X</A>
								<DT><A HREF="https://github.com/HazyResearch/ThunderKittens">HazyResearch/ThunderKittens: Tile primitives for speedy kernels</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-05-12-quick-tk">ThunderKittens: A Simple Embedded DSL for AI kernels ¬∑ Hazy Research</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-05-12-tk">GPUs Go Brrr ¬∑ Hazy Research</A>
								<DT><A HREF="https://github.com/Narsil/zandle/tree/main/src">zandle/src at main ¬∑ Narsil/zandle</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-10-29-tk2">Easier, Better, Faster, Cuter ¬∑ Hazy Research</A>
								<DT><A HREF="https://hazyresearch.stanford.edu/blog/2024-11-27-tk-fp8">ThunderKittens: Bringing fp8 to theaters near you ¬∑ Hazy Research</A>
								<DT><A HREF="https://github.com/tile-ai/tilelang">tile-ai/tilelang: Domain-specific language designed to streamline the development of high-performance GPU/CPU kernels</A>
								<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/pull/28/files">[feat] add simple half gemm example by luliyucoordinate ¬∑ Pull Request #28 ¬∑ HazyResearch/ThunderKittens</A>
								<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/blackwell">HazyResearch/ThunderKittens at blackwell</A>
								<DT><A HREF="https://github.com/fla-org/ThunderKittens">fla-org/ThunderKittens: Tile primitives for speedy kernels</A>
								<DT><A HREF="https://x.com/__tinygrad__/status/1976084605141909845">(1) the tiny corp en X: "Shout out to ThunderKittens for writing simple yet very performant GPU code. We're working on "tinykittens" which uses the same insight but in tinygrad's language. The insight is that GPU "registers" are the wrong primitive and TK's "register tile" is a lot more sensible. https://t.co/gDKwmBBLL0" / X</A>
								<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/main/blackwell/02-fp8-mm.cu">gpu-experiments/blackwell/02-fp8-mm.cu at main ¬∑ StuartSul/gpu-experiments</A>
								<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/main/src/quantum_attn/tk/attention.py">QuantumAttention/src/quantum_attn/tk/attention.py load_tk_attention_module</A>
							</DL><p>
							<DT><H3 FOLDED>TiledCuda</H3>
							<DL><p>
								<DT><H3 FOLDED>TileFusion</H3>
								<DL><p>
									<DT><H3 FOLDED>tilefusion-shared-memory</H3>
									<DL><p>
										<DT><A HREF="https://github.com/lcy-seso/vq-experiments/blob/3aef9f38da6dd19f1c9b3aa03410724a2457e0ac/shared_memory_calculator/README.md">vq-experiments/shared_memory_calculator/README.md at 3aef9f38da6dd19f1c9b3aa03410724a2457e0ac ¬∑ lcy-seso/vq-experiments</A>
										<DT><A HREF="https://github.com/lcy-seso/vq-experiments/pull/8/files#diff-d90aac6207a1bb13e0c2b012acae231b944bf643e570f1afc35f33f6f542ad2f">feat: utility function for calculating shared memory usage. by lcy-seso ¬∑ Pull Request #8 ¬∑ lcy-seso/vq-experiments</A>
									</DL><p>
									<DT><A HREF="https://github.com/lcy-seso/vq-experiments/blob/3aef9f38da6dd19f1c9b3aa03410724a2457e0ac/bench_quant_gemv/ncu.sh">vq-experiments/bench_quant_gemv/ncu.sh ncu profiling script example</A>
									<DT><A HREF="https://github.com/VPTQ/benchmarks">VPTQ/benchmarks: Benchmark tests for VPTQ.</A>
									<DT><A HREF="https://github.com/microsoft/TileFusion">microsoft/TileFusion: TileFusion is an experimental C++ macro kernel template library that elevates the abstraction level in CUDA C for tile processing.</A>
								</DL><p>
								<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/tree/master">TiledTensor/TiledCUDA: TiledCUDA is a highly efficient kernel template library designed to elevate CUDA C‚Äôs level of abstraction for processing tiles.</A>
								<DT><A HREF="https://github.com/microsoft/TileFusion">microsoft/TileFusion</A>
							</DL><p>
							<DT><H3 FOLDED>mirage</H3>
							<DL><p>
								<DT><A HREF="https://mirage-project.readthedocs.io/en/latest/tutorials/index.html">Tutorials ‚Äî Mirage documentation</A>
								<DT><A HREF="https://mirage-project.readthedocs.io/en/latest/index.html">Welcome to Mirage‚Äôs documentation! ‚Äî Mirage documentation</A>
								<DT><A HREF="https://arxiv.org/abs/2405.05751">[2405.05751] A Multi-Level Superoptimizer for Tensor Programs</A>
								<DT><A HREF="https://www.youtube.com/watch?app=desktop&v=_EbQwE5mDFY">Mirage (MPK): Compiling LLMs into Mega Kernels - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>helion</H3>
							<DL><p>
								<DT><H3 FOLDED>torch.fx.experimental.proxy_tensor.make_fx</H3>
								<DL><p>
									<DT><A HREF="https://docs.pytorch.org/docs/stable/generated/torch.fx.experimental.proxy_tensor.make_fx.html">torch.fx.experimental.proxy_tensor.make_fx ‚Äî PyTorch 2.7 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>helion-fx</H3>
								<DL><p>
									<DT><A HREF="https://docs.pytorch.org/docs/stable/generated/torch.fx.experimental.proxy_tensor.make_fx.html">torch.fx.experimental.proxy_tensor.make_fx ‚Äî PyTorch 2.7 documentation</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch-labs/helion">pytorch-labs/helion: A Python-embedded DSL that makes it easy to write fast, scalable ML kernels with minimal boilerplate.</A>
								<DT><A HREF="https://github.com/jax-ml/jax/blob/579a1573cc82265c2b3245f2ee9ffd33f55fcd63/jax/experimental/pallas/ops/tpu/example_kernel.py#L16">jax/jax/experimental/pallas/ops/tpu/example_kernel.py at 579a1573cc82265c2b3245f2ee9ffd33f55fcd63 ¬∑ jax-ml/jax</A>
								<DT><A HREF="https://www.youtube.com/watch?v=N4Vn2l1JX5c">Helion: A high-level DSL for ML kernels - Jason Ansel | ASAP 32 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=BW-Ht-5IxgM&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=122">Helion: A High-level DSL for Kernel Authoring - Jason Ansel, Meta - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>gpu-experiments</H3>
							<DL><p>
								<DT><H3 FOLDED>fma</H3>
								<DL><p>
									<DT><A HREF="https://siboehm.com/articles/23/Inlining-FMA-FP-consistency">Can Function Inlining Affect Floating Point Outputs? Exploring FMA and Other Consistency Issues</A>
								</DL><p>
								<DT><A HREF="https://github.com/StuartSul/gpu-experiments/tree/main">StuartSul/gpu-experiments: A collection of GPU tests and benchmarks for my own research.</A>
								<DT><A HREF="https://github.com/ita9naiwa/playground/blob/master/setup.py">playground/setup.py at master ¬∑ ita9naiwa/playground</A>
								<DT><A HREF="https://github.com/ita9naiwa/playground">ita9naiwa/playground: ..</A>
								<DT><A HREF="https://github.com/ita9naiwa/playground/tree/master/ptx-playground">playground/ptx-playground at master ¬∑ ita9naiwa/playground</A>
								<DT><A HREF="https://github.com/StuartSul/gpu-experiments">StuartSul/gpu-experiments: A collection of GPU tests and benchmarks for my own research.</A>
								<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/kernels/blackwell/cute_gemm_01/setup.py">applied-ai/kernels/blackwell/cute_gemm_01/setup.py at main ¬∑ meta-pytorch/applied-ai</A>
							</DL><p>
							<DT><H3 FOLDED>kernels-multi-node</H3>
							<DL><p>
								<DT><H3 FOLDED>intra-kernel-profiling</H3>
								<DL><p>
									<DT><A HREF="https://gau-nernst.github.io/amd-a2a/">My first Multi-GPU kernel: Writing All-to-all for AMD MI300X - gau-nernst's blog</A>
									<DT><A HREF="https://x.com/gaunernst/status/2002750211194847275">(2) Thien Tran en X: "I wrote another blogpost https://t.co/A1s4NgCI0E Thought it was gonna be a short one, but it turned into my longest blogpost yet." / X</A>
									<DT><A HREF="https://github.com/gau-nernst/learn-cuda/blob/3b90ac9b/02e_matmul_sm100/profiler.h">learn-cuda/02e_matmul_sm100/profiler.h</A>
									<DT><A HREF="https://github.com/gau-nernst/learn-cuda/blob/3b90ac9b3f624bdf1f6f78d02dcd533675d36573/02e_matmul_sm100/trace_v5.json.gz">learn-cuda/02e_matmul_sm100/trace_v5.json.gz matmul_sm100</A>
									<DT><A HREF="https://x.com/gaunernst/status/1984993038704541969/photo/1">no merge of torch.profile, manual timestamps inside the kernel</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>kernels-numa</H3>
							<DL><p>
								<DT><H3 FOLDED>bindpcie</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/mlperf-common/blob/main/client/bindpcie">mlperf-common/client/bindpcie at main ¬∑ NVIDIA/mlperf-common</A>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/dev/docs/discussions/deepseek-v3-gb200-optimization/deepseek-v3-gb200-optimization.md">Megatron-LM/docs/discussions/deepseek-v3-gb200-optimization/deepseek-v3-gb200-optimization.md at dev ¬∑ NVIDIA/Megatron-LM</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>kernels-build</H3>
							<DL><p>
								<DT><H3 FOLDED>cmake</H3>
								<DL><p>
									<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/scripts/cmake/generic.cmake">TiledBench/scripts/cmake/generic.cmake</A>
								</DL><p>
								<DT><A HREF="https://github.com/StuartSul/gpu-experiments/commit/01965457bf998f8c314a8dab921403b399e96dc5">Add ¬∑ StuartSul/gpu-experiments@0196545</A>
							</DL><p>
							<DT><A HREF="https://github.com/cuda-mode/triton-index">cuda-mode/triton-index: Cataloging released Triton kernels.</A>
							<DT><A HREF="https://openai.com/research/block-sparse-gpu-kernels">OpenAI: Block-sparse GPU kernels</A>
							<DT><A HREF="https://github.com/IST-DASLab/marlin">IST-DASLab/marlin: FP16xINT4 LLM inference kernel that can achieve near-ideal ~4x speedups up to medium batchsizes of 16-32 tokens.</A>
							<DT><A HREF="https://hta.readthedocs.io/en/latest/source/features/kernel_breakdown.html">Kernel Breakdown ‚Äî Holistic Trace Analysis 0.2.0 documentation</A>
							<DT><A HREF="https://github.com/efeslab/Atom">efeslab/Atom: [MLSys'24] Atom: Low-bit Quantization for Efficient and Accurate LLM Serving</A>
							<DT><A HREF="https://github.com/huggingface/candle-paged-attention">huggingface/candle-paged-attention</A>
							<DT><A HREF="https://github.com/microsoft/onnxscript">microsoft/onnxscript: ONNX Script enables developers to naturally author ONNX functions and models using a subset of Python.</A>
							<DT><A HREF="https://github.com/flashinfer-ai/flashinfer">flashinfer-ai/flashinfer: FlashInfer: Kernel Library for LLM Serving</A>
							<DT><A HREF="https://github.com/microsoft/onnxscript">microsoft/onnxscript: programm ONNX functions and models using a subset of Python.</A>
							<DT><A HREF="https://ai.meta.com/research/publications/accelerating-a-triton-fused-kernel-for-w4a16-quantized-inference-with-splitk-work-decomposition/">Accelerating a Triton Fused Kernel for W4A16 Quantized Inference with SplitK Work Decomposition</A>
							<DT><A HREF="https://github.com/turboderp/exllama">turboderp/exllama: A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.</A>
							<DT><A HREF="https://github.com/turboderp/exllamav2">turboderp/exllamav2: LLMs locally on modern consumer-class GPUs</A>
							<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/de17730a993b1d2cce4fd09e3654b5f79fd23c96/kernels/triton/inference/gptq/a100_qlinear.py#L109">applied-ai: Triton GPTQ a100_qlinear.py (print perf stats)</A>
							<DT><A HREF="https://github.com/BearNinja123/channels-last-groupnorm">BearNinja123/channels-last-groupnorm: A CUDA kernel for NHWC GroupNorm for PyTorch</A>
							<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/66ef1df492f7bc9c8eeb01d7e14db01838e3f0bd/cpp/tensorrt_llm/kernels">TensorRT-LLM/cpp/tensorrt_llm/kernels</A>
							<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/66ef1df492f7bc9c8eeb01d7e14db01838e3f0bd/cpp/tensorrt_llm/kernels/cutlass_kernels">TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels</A>
							<DT><A HREF="https://pytorch.org/blog/accelerating-llama3/">Accelerating Llama3 FP8 Inference with Triton Kernels | PyTorch</A>
							<DT><A HREF="https://pytorch.org/blog/accelerating-moe-model/#30-work-decomposition---splitk">Accelerating MoE model inference with Locality-Aware Kernel Design | PyTorch</A>
							<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/triton/inference/gptq/splitk_dequant_gemm.py">applied-ai/kernels/triton/inference/gptq/splitk_dequant_gemm.py at main ¬∑ pytorch-labs/applied-ai</A>
							<DT><A HREF="https://github.com/vedantroy/gpu_kernels/">vedantroy/gpu_kernels</A>
							<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda">BBuf/how-to-optim-algorithm-in-cuda: how to optimize some algorithm in cuda.</A>
							<DT><A HREF="https://github.com/mgmalek/efficient_cross_entropy">mgmalek/efficient_cross_entropy</A>
							<DT><A HREF="https://github.com/openai/openai-gemm">openai/openai-gemm: Open single and half precision gemm implementations</A>
							<DT><A HREF="https://github.com/RulinShao/LightSeq/blob/main/lightseq/lightseq_async_attn.py#L436">LightSeq/lightseq/lightseq_async_attn.py at main ¬∑ RulinShao/LightSeq</A>
							<DT><A HREF="https://github.com/pytorch/ao/blob/main/torchao/kernel/intmm_triton.py">ao/torchao/kernel/intmm_triton.py at main ¬∑ pytorch/ao</A>
							<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN">AlibabaPAI/FLASHNN</A>
							<DT><A HREF="https://github.com/FlagOpen/FlagGems">FlagOpen/FlagGems: FlagGems is an operator library for large language models implemented in Triton Language.</A>
							<DT><A HREF="https://github.com/microsoft/DeepSpeed-Kernels/tree/main/dskernels/ft_gemm/gemm_variants">DeepSpeed-Kernels/dskernels/ft_gemm/gemm_variants at main ¬∑ microsoft/DeepSpeed-Kernels</A>
							<DT><A HREF="https://gist.github.com/msaroufim/087c2a358c505e287a926e6a27b3e3b0">Project Popcorn: Generate SOTA kernels with LLMs in public</A>
							<DT><A HREF="https://github.com/ai-compiler-study/triton-kernels/blob/main/scripts/gpu_properties.cu">triton-kernels/scripts/gpu_properties.cu at gpu_properties</A>
							<DT><A HREF="https://github.com/perplexityai/pplx-kernels">perplexityai/pplx-kernels: Perplexity GPU Kernels</A>
							<DT><A HREF="https://github.com/Tencent/hpc-ops">Tencent/hpc-ops: High Performance LLM Inference Operator Library</A>
						</DL><p>
						<DT><H3 FOLDED>computational graph explorer</H3>
						<DL><p>
							<DT><H3 FOLDED>flashinfer-bench-architecture</H3>
							<DL><p>
							</DL><p>
							<DT><A HREF="https://research.google/blog/model-explorer/">Model Explorer: Graph visualization for large model development</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/45e7400e3c86bc147cd1ab7b1b068068bdfe0cb2/docs-legacy/env_vars.md">tinygrad: env var GRAPH create a graph of all operations</A>
							<DT><A HREF="https://github.com/ezyang/torchdbg">ezyang/torchdbg: PyTorch centric eager mode debugger</A>
							<DT><A HREF="https://bbycroft.net/llm">LLM Visualization</A>
							<DT><A HREF="https://pytorch.org/blog/inside-the-matrix/">Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond | PyTorch</A>
							<DT><A HREF="https://ai.google.dev/edge/model-explorer#two_ways_to_use_model_explorer">Model Explorer ¬†|¬† Edge ¬†|¬† Google for Developers</A>
							<DT><A HREF="https://github.com/google-ai-edge/model-explorer">google-ai-edge/model-explorer: A modern model graph visualizer and debugger</A>
							<DT><A HREF="https://ieeexplore.ieee.org/document/8019861">Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow | IEEE Journals &amp; Magazine | IEEE Xplore</A>
							<DT><A HREF="https://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf">Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow</A>
							<DT><A HREF="https://github.com/google-ai-edge/model-explorer/tree/main">google-ai-edge/model-explorer: A modern model graph visualizer and debugger</A>
						</DL><p>
						<DT><H3 FOLDED>PyTorch</H3>
						<DL><p>
							<DT><H3 FOLDED>torch-installation</H3>
							<DL><p>
								<DT><H3 FOLDED>pytorch-from-source</H3>
								<DL><p>
									<DT><H3 FOLDED>cmake</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/main/python/requirements.txt">triton/python/requirements.txt at main ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><A HREF="https://gist.github.com/mhubii/1c1049fb5043b8be262259efac4b89d5">A guide to install and use the PyTorch C++ API with Anaconda.md</A>
									<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/compile_torch.sh">ml_scripts/compile_torch.sh</A>
								</DL><p>
								<DT><H3 FOLDED>torch-nightly</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-nightly-list</H3>
									<DL><p>
										<DT><A HREF="https://github.com/youkaichao/list_pytorch_nightly">youkaichao/list_pytorch_nightly: List recently available pytorch nightly version, for every day</A>
									</DL><p>
									<DT><A HREF="https://twitter.com/karpathy/status/1779354343013269929">"compound" F.sdpa (scaled dot product attention)</A>
									<DT><A HREF="https://github.com/Chillee/llm.c?tab=readme-ov-file#some-benchmark-numbers-with-newer-version-of-pytorch">PyTorch nightly + F.sdpa + coordinate descent tuning vs llm.c</A>
									<DT><A HREF="https://github.com/triton-lang/triton/issues/4310">torch pip nighly wheels binaries release</A>
									<DT><A HREF="https://x.com/_xjdr/status/1976332809397731600/photo/2">(1) xjdr en X RUN uv pip install --pre torch --index-url https://download.pytorch.org/whl/nightly/cu128</A>
									<DT><A HREF="https://pytorch.org/get-started/locally/">pip3 install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu130</A>
									<DT><A HREF="https://gist.github.com/malfet/4e1c42a2eb982cd2723db82a12f1136f">install_nightly.py</A>
								</DL><p>
								<DT><A HREF="https://pytorch.org/get-started/locally/">Start Locally | PyTorch</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-release-2-6-0-final-rc-is-available/2748">PyTorch Release 2.6.0 - Final RC is available - Release Announcements - PyTorch Developer Mailing List</A>
								<DT><A HREF="https://chrisdare.medium.com/running-pytorch-on-apple-silicon-m1-gpus-a8bb6f680b02">Installing and running pytorch on M1 GPUs (Apple metal/MPS)</A>
								<DT><A HREF="https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/">Introducing Accelerated PyTorch Training on Mac | PyTorch</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/tree/main/.devcontainer">pytorch/.devcontainer at main ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/89ba1b1a67d570e41b03da87e5518eaff0d31fbf/docker/common/install_pytorch.sh">TensorRT-LLM/docker/common/install_pytorch.sh at 89ba1b1a67d570e41b03da87e5518eaff0d31fbf ¬∑ NVIDIA/TensorRT-LLM</A>
								<DT><A HREF="https://github.com/pytorch-labs/tritonbench/tree/main/utils">tritonbench/utils at main ¬∑ pytorch-labs/tritonbench</A>
								<DT><A HREF="https://github.com/pytorch-labs/tritonbench/blob/main/utils/cuda_utils.py">tritonbench/utils/cuda_utils.py at main ¬∑ pytorch-labs/tritonbench</A>
								<DT><A HREF="https://github.com/pytorch-labs/tritonbench/pull/163/files">[install] install pytorch nightly if does not exist by xuzhao9 ¬∑ Pull Request #163 ¬∑ pytorch-labs/tritonbench</A>
								<DT><A HREF="https://github.com/meta-pytorch/tritonbench/blob/a404ea7aeb4699555a3139c83851c34c8f32c22a/install.py#L24">tritonbench/install.py</A>
								<DT><A HREF="https://github.com/tinygrad/tinyos/blob/main/build/in-chroot-post.d/05install-torch__user.sh">tinyos/build/in-chroot-post.d/05install-torch__user.sh at main ¬∑ tinygrad/tinyos</A>
							</DL><p>
							<DT><H3 FOLDED>torch-release-notes</H3>
							<DL><p>
								<DT><H3 FOLDED>PyTorch 2.0</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>PyTorch 2.1</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-2-1-automatic-dynamic-shape-compilation-torch-distributed-checkpoint-torch-compile-numpy-torch-export-prototype-and-more/1548">PyTorch 2.1: automatic dynamic shape compilation, torch.distributed.checkpoint, torch.compile + NumPy, torch.export prototype, and more! - Release Announcements - PyTorch Dev Discussions</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/releases/tag/v2.1.0">Release PyTorch 2.1: automatic dynamic shape compilation, distributed checkpointing ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>PyTorch 2.2</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/releases/tag/v2.2.0">PyTorch 2.2: FlashAttention-v2, AOTInductor</A>
								</DL><p>
								<DT><H3 FOLDED>PyTorch 2.3</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/blog/pytorch2-3/">PyTorch 2.3 Release Blog | PyTorch</A>
									<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with torch.compile ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
									<DT><A HREF="https://cloud.google.com/blog/products/ai-machine-learning/introducing-pytorch-xla-2-3">Introducing PyTorch/XLA 2.3 | Google Cloud Blog</A>
								</DL><p>
								<DT><H3 FOLDED>PyTorch 2.4</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>PyTorch 2.5</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/releases/tag/v2.5.0">Release PyTorch 2.5.0 Release, SDPA CuDNN backend, Flex Attention ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>PyTorch 2.6</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-release-2-6-0-final-rc-is-available/2748">PyTorch Release 2.6.0 - Final RC is available - Release Announcements - PyTorch Developer Mailing List</A>
								</DL><p>
								<DT><H3 FOLDED>torch 2.7</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-2-7-rc1-produced-for-pytorch-audio-vision/2855">PyTorch 2.7 RC1 produced for pytorch, audio, vision - Release Announcements - PyTorch Developer Mailing List</A>
								</DL><p>
								<DT><H3 FOLDED>torch 2.8</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-2-8-final-rc-available/3144">pip3 install torch==2.8.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/test/cu129</A>
									<DT><A HREF="https://pytorch.org/blog/pytorch-2-8/">PyTorch 2.8 Release Blog ‚Äì PyTorch</A>
								</DL><p>
								<DT><H3 FOLDED>torch 2.9</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/blog/pytorch-2-9/?utm_campaign=25624466-25Q4_PyTorch_2.9&utm_content=351844714&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">PyTorch 2.9 Release Blog ‚Äì PyTorch</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/pull/1791">ABI stable fa3 by mikaylagawarecki ¬∑ Pull Request #1791 ¬∑ Dao-AILab/flash-attention</A>
								</DL><p>
								<DT><H3 FOLDED>torch 2.10</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-2-10-rc1-produced-for-pytorch-torchvision-torchaudio/3281">PyTorch 2.10 RC1 produced for pytorch, torchvision &amp; torchaudio - Release Announcements - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://x.com/gaunernst/status/2015242181049745607">(2) Thien Tran en X: "one of the cool new changes in PyTorch 2.10 is that it's now much easier to use the NVRTC wrapper in PyTorch. C++ template works out-of-the-box! just pass the templated kernel name thanks to @marksaroufim for started this efforts https://t.co/8EHFrM5gCE" / X</A>
								</DL><p>
								<DT><H3 FOLDED>torch-roadmap</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/meta-pytorch-team-2024-h2-roadmaps/2226">Meta PyTorch Team 2024 H2 Roadmaps - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/meta-pytorch-team-2025-h1-roadmaps/2794">Meta PyTorch Team 2025 H1 Roadmaps - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://drive.google.com/file/d/1vTy9e5Vwk4xOb8tmhlICapT4x2KGbPQ7/view">[PUBLIC] Triton v-team OKRs H1 2025.pdf - Google Drive</A>
								</DL><p>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-2-1-automatic-dynamic-shape-compilation-torch-distributed-checkpoint-torch-compile-numpy-torch-export-prototype-and-more/1548">PyTorch 2.1: automatic dynamic shape compilation, torch.distributed.checkpoint, torch.compile + NumPy, torch.export prototype, and more! - Release Announcements - PyTorch Dev Discussions</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/releases/tag/v2.1.0">Release PyTorch 2.1: automatic dynamic shape compilation, distributed checkpointing ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/releases/tag/v2.2.0">PyTorch 2.2: FlashAttention-v2, AOTInductor</A>
								<DT><A HREF="https://pytorch.org/blog/pytorch2-5/">PyTorch 2.5 Release Blog | PyTorch</A>
							</DL><p>
							<DT><H3 FOLDED>torch-docs</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-composability-meeting-notes</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/document/d/1QTR3t3KdRu5JT1lvAuJLsPd3LruCfv0LecpsgR8eWhg/edit#heading=h.8y2jwyieg2yh">Composability meeting notes - Google Docs</A>
									<DT><A HREF="https://www.youtube.com/watch?v=YmCbrQDan8Q&t=8s">Composability Sync - Inductor Compiled Code HOP - YouTube</A>
								</DL><p>
								<DT><A HREF="https://pytorch.org/blog/accelerating-llama3/">Accelerating Llama3 FP8 Inference with Triton Kernels | PyTorch</A>
								<DT><A HREF="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py">Tensors ‚Äî PyTorch Tutorials 1.11.0+cu102 documentation</A>
								<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">CrossEntropyLoss ‚Äî PyTorch 1.11.0 documentation</A>
								<DT><A HREF="https://pytorch.org/docs/stable/optim.html">torch.optim ‚Äî PyTorch 1.11.0 documentation</A>
								<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.Tensor.to.html">torch.Tensor.to ‚Äî PyTorch 1.12 documentation</A>
								<DT><A HREF="https://github.com/BBuf/how-to-learn-deep-learning-framework?tab=readme-ov-file">BBuf/how-to-learn-deep-learning-framework: how to learn PyTorch and OneFlow</A>
								<DT><A HREF="https://github.com/pytorch/workshops/blob/master/ASPLOS_2024/README.md">workshops/ASPLOS_2024/README.md at master ¬∑ pytorch/workshops</A>
								<DT><A HREF="https://github.com/pytorch/workshops/blob/master/ASPLOS_2024/inductor.pdf">workshops/ASPLOS_2024/inductor.pdf at master ¬∑ pytorch/workshops</A>
								<DT><A HREF="https://colab.research.google.com/drive/1XQwio7DsqB5LP2D574f_uIb8G7KhirNa?usp=sharing#scrollTo=fMsppme9eqnl">PT2-Benchmark - Colab</A>
								<DT><A HREF="https://hanfang.info/posts/2025/08/pytorch-comprehensive-tutorial/">PyTorch Basics &amp; Tutorial - Han Fang</A>
							</DL><p>
							<DT><H3 FOLDED>torch-dev</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-composability</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/document/d/1QTR3t3KdRu5JT1lvAuJLsPd3LruCfv0LecpsgR8eWhg/edit">Composability meeting notes - Google Docs</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/pytorch/tree/main/.devcontainer">pytorch/.devcontainer at main ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://github.com/albanD/pytorch_dev_env_setup">albanD/pytorch_dev_env_setup</A>
								<DT><A HREF="https://direnv.net/">direnv ‚Äì unclutter your .profile | direnv</A>
								<DT><A HREF="http://giantpandacv.com/project/PyTorch/%E3%80%8APytorchConference2023%20%E7%BF%BB%E8%AF%91%E7%B3%BB%E5%88%97%E3%80%8B2-PyTorch%E5%BC%80%E5%8F%91%E8%80%85%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/">PyTorch 2.0 SW infra</A>
								<DT><A HREF="https://docs.google.com/document/d/1QTR3t3KdRu5JT1lvAuJLsPd3LruCfv0LecpsgR8eWhg/edit">Composability meeting notes - Google Docs</A>
								<DT><A HREF="https://github.com/pytorch/builder">pytorch/builder: Continuous builder and binary build scripts for pytorch</A>
								<DT><A HREF="https://github.com/alihassanijr/PyTorch-CUDA12">alihassanijr/PyTorch-CUDA12: Nightly PyTorch + CUDA 12 Dockerfile</A>
								<DT><A HREF="https://fkong.tech/posts/2023-05-24-torch-source/">Some thoughts on reading PyTorch source code</A>
								<DT><A HREF="https://x.com/drisspg/status/1990974698205950302">(1) driss guessous en X: "My zshfuncs who has some other good ones? https://t.co/1xPaAxTmos" / X</A>
								<DT><A HREF="https://m.twitch.tv/videos/2655611921">Live vibe coding - Twitch</A>
							</DL><p>
							<DT><H3 FOLDED>torch-lightning</H3>
							<DL><p>
								<DT><A HREF="https://github.com/Lightning-AI/pytorch-lightning">Lightning-AI/pytorch-lightning: Pretrain, finetune and deploy AI models on multiple GPUs, TPUs with zero code changes.</A>
								<DT><A HREF="https://github.com/Lightning-AI/litgpt">Lightning-AI/litgpt: Load, pretrain, finetune, deploy 20+ LLMs on your own data. Uses state-of-the-art techniques: flash attention, FSDP, 4-bit, LoRA, and more.</A>
								<DT><A HREF="https://github.com/Lightning-AI/LitServe">Lightning-AI/LitServe: Deploy AI models at scale. High-throughput serving engine for AI/ML models that uses the latest state-of-the-art model deployment techniques.</A>
								<DT><A HREF="https://x.com/_willfalcon/status/1859964670129422391">(1) William Falcon ‚ö°Ô∏è en X: "Yesterday we announced our $50M new funding. Don‚Äôt know why our users love Lightning? check out these 3 products: I swear these 3 products will EASILY 10x your iteration speed. 1. PyTorch Lightning: EASILY train and finetune ANY model of ANY size. With over 160 million https://t.co/IMGknJnO0k" / X</A>
							</DL><p>
							<DT><H3 FOLDED>torch-compiler</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-compiler-docs</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/document/d/1y5CRfMLdwEoF1nTk9q8qEu1mgMUuUtvhklPKJ2emLU8/edit#heading=h.ivdr7fmrbeab">torch.compile, the missing manual - Google Docs</A>
									<DT><A HREF="http://blog.ezyang.com/2024/11/ways-to-use-torch-compile/">Ways to use torch.compile : ezyang‚Äôs blog</A>
									<DT><A HREF="https://github.com/pytorch/workshops/tree/master/ASPLOS_2024">workshops/ASPLOS_2024 at master ¬∑ pytorch/workshops</A>
									<DT><A HREF="https://fkong.tech/posts/2024-09-01-torch-compile-stack/">torch.compile ÈáçË¶ÅÊ≠•È™§ÂáΩÊï∞Ë∞ÉÁî®Ê†à ¬∑ fkong' tech blog</A>
									<DT><A HREF="https://x.com/ezyang/status/1809766173849821669">what to expect from the compiler</A>
									<DT><A HREF="https://www.slideshare.net/slideshow/pytorch-2-internals/264537964">PyTorch 2 Internals | PPT</A>
									<DT><A HREF="https://strint.notion.site/torch-compile-backend-9f80a637dc0c4025abc207829bece666">torch.compile Ëá™ÂÆö‰πâ backend Ë∞ÉÁ†î</A>
									<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler.html">torch.compiler ‚Äî PyTorch 2.4 documentation</A>
									<DT><A HREF="https://github.com/apuaaChen/EVT_AE/blob/main/benchmark/ops/gemm.py">EVT_AE/benchmark/ops/gemm.py at main ¬∑ apuaaChen/EVT_AE</A>
									<DT><A HREF="https://gist.github.com/gradjitta/aa84759af89223e0baae1f9afaeea8e0">torch.compile Troubleshooting Guide</A>
									<DT><A HREF="https://www.youtube.com/watch?v=CVVbFlnP0m0&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=13">torch.compile Practice and Optimization in Different Scenarios - Yichen Yan, Alibaba Cloud - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=JE6kTSFkf-U&t=3826s">Compile and export Zonos - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>Inductor</H3>
								<DL><p>
									<DT><H3 FOLDED>inductor-config</H3>
									<DL><p>
										<DT><H3 FOLDED>inductor-mode</H3>
										<DL><p>
											<DT><A HREF="https://pytorch.org/get-started/pytorch-2.0/">max-autotune</A>
											<DT><A HREF="https://twitter.com/jxmnop/status/1778835034079691008">max-autotune description</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/31c0467594c7c41c8e8ff1828bf01fa31fc4454f/torch/_inductor/__init__.py#L179">torch/_inductor/__init__.py: list_mode_options</A>
										</DL><p>
										<DT><H3 FOLDED>TORCHINDUCTOR_COMPILE_THREADS</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/eb65b36914d039f37e24c2e0372f9e7c022f20ed/torch/_inductor/config.py#L1051">User can override it by TORCHINDUCTOR_COMPILE_THREADS.  One may want to disable async compiling by setting this to 1 to make pdb happy. Solved SM103 compilation issue</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/eb65b36914d039f37e24c2e0372f9e7c022f20ed/torch/_inductor/select_algorithm.py#L2625">pytorch/torch/_inductor/select_algorithm.py get_num_workers()</A>
										</DL><p>
										<DT><H3 FOLDED>inductor.config.patch</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/87fb258cd122a6cb2704e3992d768bce3683d1d1/test/inductor/test_custom_op_autotune.py#L43">test_custom_op_autotune.py#L43 with inductor.config.patch(.. ..)</A>
										</DL><p>
										<DT><A HREF="https://twitter.com/cHHillee/status/1777825367954432114/photo/1">TORCH_LOGS="output_code" python t.py</A>
										<DT><A HREF="https://twitter.com/karpathy/status/1779354343013269929">TORCHINDUCTOR_COORDINATE_DESCENT_TUNING=1</A>
										<DT><A HREF="https://github.com/Chillee/llm.c">Chillee/llm.c: LLM training in simple, raw C/CUDA</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/f3c54ccf8f6139807f4623037c0174964a286652/torch/_inductor/config.py#L682">TORCHINDUCTOR_PROFILE_WITH_DO_BENCH_USING_PROFILING</A>
										<DT><A HREF="https://github.com/discus0434/faster-flux/blob/main/src/faster_flux/pipeline_wrapper.py">triton.cudagraphs</A>
										<DT><A HREF="https://pytorch.org/docs/stable/generated/torch._logging.set_logs.html">torch._logging.set_logs ‚Äî PyTorch 2.5 documentation</A>
										<DT><A HREF="https://github.com/ROCm/pytorch-micro-benchmarking">ROCm/pytorch-micro-benchmarking</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/config.py">TORCHINDUCTOR_MULTI_KERNEL (i.e. no loops kernels)</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/blob/main/src/cache_dit/compile/utils.py">cache-dit/src/cache_dit/compile/utils.py at main ¬∑ vipshop/cache-dit</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-codegen</H3>
									<DL><p>
										<DT><H3 FOLDED>inductor-codegen-debug</H3>
										<DL><p>
											<DT><H3 FOLDED>cudalive</H3>
											<DL><p>
												<DT><A HREF="https://x.com/traviscline/status/1812342671026852071">Live-rendering of pytorch torch.compile optimizations</A>
												<DT><A HREF="https://github.com/tmc/cudalive">tmc/cudalive</A>
												<DT><A HREF="https://www.youtube.com/watch?v=KE7qXPY1j28&t=915s">Hardcore CUDA Hackathon Demos at AGI House - YouTube</A>
											</DL><p>
											<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173">Getting Triton to generate all kernels - torch.compile / torch._inductor - PyTorch Forums</A>
											<DT><A HREF="https://www.youtube.com/watch?v=qYqrfq452ig&t=4548s">Hardcore CUDA Hackathon Talks at AGI House SF - YouTube</A>
											<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_inductor_profiling.html#benchmark-individual-triton-kernel">TORCHINDUCTOR_UNIQUE_KERNEL_NAMES=1 TORCHINDUCTOR_BENCHMARK_KERNEL=1 TorchInductor GPU profiling</A>
											<DT><A HREF="https://colab.research.google.com/drive/1XQwio7DsqB5LP2D574f_uIb8G7KhirNa?usp=sharing#scrollTo=P5sS86KpdaTI">PT2-Benchmark - Colab: TORCHINDUCTOR_UNIQUE_KERNEL_NAMES</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-codegen-triton</H3>
										<DL><p>
											<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173">Getting Triton to generate all kernels - torch.compile / torch._inductor - PyTorch Forums</A>
										</DL><p>
										<DT><H3 FOLDED>_inductor-codegen-cuda</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/ac87388e61e6af38e978458af0bcb03e605d1928/torch/_inductor/codegen/cuda/cuda_template.py#L23">pytorch/torch/_inductor/codegen/cuda/cuda_template.py at ac87388e61e6af38e978458af0bcb03e605d1928 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>torch.library</H3>
										<DL><p>
											<DT><H3 FOLDED>torch.library.register_fake</H3>
											<DL><p>
											</DL><p>
											<DT><H3 FOLDED>torch.library.register_autograd</H3>
											<DL><p>
											</DL><p>
											<DT><H3 FOLDED>torch.library.custom_op</H3>
											<DL><p>
												<DT><H3 FOLDED>torch-custom_op-examples</H3>
												<DL><p>
													<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/tiled_matmul.py#L201">tiled_matmul.py#L201 xformers</A>
													<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/fmha/flash3.py">xformers_flash3::flash_fwd</A>
													<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/tree/master/cutlass_gemm">cfx-article-src/cutlass_gemm at master ¬∑ ColfaxResearch/cfx-article-src</A>
													<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/blob/master/PyTorch/test_pytorch_customize_op/setup.py">DLFrameworkTest/PyTorch/test_pytorch_customize_op/setup.py at master ¬∑ lcy-seso/DLFrameworkTest</A>
												</DL><p>
												<DT><H3 FOLDED>cortex-extra_layers</H3>
												<DL><p>
													<DT><A HREF="https://github.com/drisspg/transformer_nuggets/commit/ffcba037e8c0987df360593ebb9c62456f681bc5">Extract layer_idx from fully qualified name</A>
												</DL><p>
												<DT><H3 FOLDED>torch-fa4</H3>
												<DL><p>
													<DT><H3 FOLDED>install_flash_attn_cute</H3>
													<DL><p>
														<DT><A HREF="https://github.com/pytorch/pytorch/pull/167392/files">ci/pytorch/common_utils.sh</A>
													</DL><p>
													<DT><A HREF="https://github.com/pytorch/pytorch/pull/167348">Add FA4 to sdpa by drisspg ¬∑ Pull Request #167348 ¬∑ pytorch/pytorch</A>
													<DT><A HREF="https://github.com/pytorch/pytorch/blob/01baeb672e93675d901d50fd40828dca01588728/torch/nn/attention/_fa4.py#L75">pytorch/torch/nn/attention/_fa4.py: _fa4_import_module</A>
													<DT><A HREF="https://github.com/pytorch/pytorch/blob/a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a/.github/workflows/test-b200.yml">pytorch/.github/workflows/test-b200.yml at a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a ¬∑ pytorch/pytorch</A>
													<DT><A HREF="https://github.com/pytorch/pytorch/blob/a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a/test/nn/attention/test_fa4.py">pytorch/test/nn/attention/test_fa4.py</A>
													<DT><A HREF="https://github.com/pytorch/pytorch/pull/167392/files">Add Tests by drisspg: install_flash_attention_cute</A>
												</DL><p>
												<DT><H3 FOLDED>cortex.custom_op</H3>
												<DL><p>
													<DT><H3 FOLDED>cortex-fa4</H3>
													<DL><p>
													</DL><p>
													<DT><A HREF="https://github.com/datacrunch-research/cortex/blob/main/src/cortex/utils/custom_op.py">cortex/src/cortex/utils/custom_op.py</A>
													<DT><A HREF="https://github.com/datacrunch-research/cortex/blob/main/src/cortex/backends/cuda/op_registry.py">cortex/src/cortex/backends/cuda/op_registry.py at main ¬∑ datacrunch-research/cortex</A>
													<DT><A HREF="https://github.com/datacrunch-research/cortex/blob/ea8cea8b9c54ae119950e784a479e63bbf017a86/src/cortex/backends/inductor/op_registry/placeholder_ops.py#L66C5-L66C83">placeholder_ops.py: @torch.library.impl("cortex_inductor::linear_group_wise", ["default", "Meta"])</A>
													<DT><A HREF="https://github.com/pytorch/pytorch/pull/164212">[Inductor] Enable Custom op Autotune Decompositions and Parameter Tuning by tianrengao ¬∑ Pull Request #164212 ¬∑ pytorch/pytorch</A>
												</DL><p>
												<DT><A HREF="https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit#heading=h.ptttacy8y1u9">The Custom Operators Manual - Google Docs</A>
												<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/tiled_matmul.py#L201">xformers_python::tiled_matmul_fwd</A>
												<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/fmha/flash3.py">xformers_flash3::flash_fwd</A>
												<DT><A HREF="https://github.com/triton-lang/triton/blob/3ae95a858eac26088102075500e3860864432106/python/test/unit/hopper/test_flashattention.py#L294">triton/python/test/unit/hopper/test_flashattention.py: torch.autograd.Function (only works on post-Ampere GPUs right now)</A>
												<DT><A HREF="https://pytorch.org/tutorials/advanced/custom_ops_landing_page.html">PyTorch Custom Operators ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
												<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
												<DT><A HREF="https://github.com/triton-lang/triton/issues/34">Custom operation tutorial: module 'triton' has no attribute 'Function' ¬∑ Issue #34 ¬∑ triton-lang/triton</A>
												<DT><A HREF="http://152.67.113.27/articles/PyTorch+%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%8812%EF%BC%89+%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BF%90%E7%AE%97%E7%AC%A6_10977905_csdn.html">PyTorch Basic Learning (12) - Custom Operators</A>
												<DT><A HREF="https://static.sched.com/hosted_files/pytorch2024/36/PTC%202024_%20Extending%20PyTorch%20with%20Custom%20Operators.pdf">PyTorch conf 2024:  Extending PyTorch with Custom Operators</A>
												<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/flash/flash_attention.py">transformer_nuggets/transformer_nuggets/flash/flash_attention.py</A>
												<DT><A HREF="https://github.com/drisspg/driss_torch">drisspg/driss_torch: Cuda extensions for PyTorch</A>
												<DT><A HREF="https://github.com/triton-lang/triton/blob/3ae95a858eac26088102075500e3860864432106/python/tutorials/05-layer-norm.py#L226">triton/python/tutorials/05-layer-norm.py: torch.autograd.Function</A>
												<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/9cafd4ae140b52dc2c95be1a1c6aeb24925a883d/hopper/flash_attn_interface.py#L165">flash-attention/hopper/flash_attn_interface.py: FlashAttnFunc(torch.autograd.Function)</A>
												<DT><A HREF="https://www.youtube.com/watch?v=ACR1WnRScCc">Composability Sync - User defined Triton vs custom ops / C++ FX - YouTube</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/pull/111434">[Inductor] Support user defined triton kernels in inductor by oulgen ¬∑ Pull Request #111434 ¬∑ pytorch/pytorch</A>
												<DT><A HREF="https://github.com/BobMcDear/attorch/blob/main/attorch/glu_layer.py">attorch/attorch/glu_layer.py: GLUAutoGrad.apply</A>
												<DT><A HREF="https://github.com/chengzeyi/stable-fast/blob/fffe290680ec2ddc01f511e8e7fc62357ed901d8/src/sfast/triton/torch_ops.py">sfast: register_custom_python_operator</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/issues/136550">torch.compiled custom Triton kernels can output incorrect results ¬∑ Issue #136550 ¬∑ pytorch/pytorch</A>
												<DT><A HREF="https://pytorch.org/tutorials/advanced/cpp_custom_ops.html#testing-an-operator">Custom C++ and CUDA Operators ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
												<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/master/pytiledcuda/__init__.py">TiledCUDA/pytiledcuda/__init__.py at master ¬∑ TiledTensor/TiledCUDA</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/20af56d4359c3f5fed2e8f94e111a8502f2ebeb3/test/test_flop_counter.py#L801">pytorch/test/test_flop_counter.py: registration example</A>
												<DT><A HREF="https://github.com/pytorch/tutorials/blob/main/advanced_source/cpp_custom_ops.rst">tutorials/advanced_source/cpp_custom_ops.rst at main ¬∑ pytorch/tutorials</A>
												<DT><A HREF="https://docs.google.com/document/d/1ZcxkW1FRNVm9AvDuTthRHvM09XnbkXOQzOE0yqSVMQI/edit?tab=t.0">torch_custom_operators - Google Docs</A>
												<DT><A HREF="https://github.com/chengzeyi/piflux/blob/main/src/piflux/ops/context_ops.py">piflux/src/piflux/ops/context_ops.py at main ¬∑ chengzeyi/piflux</A>
												<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/tree/master/PyTorch/test_pytorch_customize_op">DLFrameworkTest/PyTorch/test_pytorch_customize_op at master ¬∑ lcy-seso/DLFrameworkTest</A>
												<DT><A HREF="https://docs.pytorch.org/docs/stable/library.html">torch.library ‚Äî PyTorch 2.7 documentation</A>
												<DT><A HREF="https://github.com/sgl-project/sglang/blob/f96413c444a4ce16c6b01770e28a636350df24bf/python/sglang/srt/patch_torch.py">sglang/python/sglang/srt/patch_torch.py</A>
												<DT><A HREF="https://docs.pytorch.org/tutorials/advanced/custom_ops_landing_page.html">PyTorch Custom Operators ‚Äî PyTorch Tutorials 2.8.0+cu128 documentation</A>
											</DL><p>
											<DT><H3 FOLDED>batch_invariant_ops</H3>
											<DL><p>
												<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops/tree/9bfcaf6c29c5d1413971c8fb16da325fa1602d7d">thinking-machines-lab/batch_invariant_ops</A>
												<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops/blob/9bfcaf6c29c5d1413971c8fb16da325fa1602d7d/batch_invariant_ops/batch_invariant_ops.py#L483">_batch_invariant_LIB.impl("aten::mm", mm_batch_invariant, "CUDA")</A>
												<DT><A HREF="https://x.com/HeMuyu0327/status/1966709535101387109">(1) Muyu He en X: "Yep @thinkymachines called it: the chunk size of prefill strategy does cause the LLM outputs to be non-deterministic. When I partition the attention reduction into 1, 2, 4 and 16 chunks, the logits drift significantly, across all three dtypes. So there are at least two https://t.co/31MYCJXXG8" / X</A>
												<DT><A HREF="https://x.com/HeMuyu0327/status/1972476311492006293">FA2 deterministic</A>
												<DT><A HREF="https://x.com/HeMuyu0327/status/1975038313175322930">(1) Muyu He en X: "For the past week I've been fighting with the flash attention bug that causes indeterministic outputs even with temp=0. Update: it is still there, despite fixing everything that @thinkymachines suggests. Strange observations: - I now have implemented both identical split sizes https://t.co/9YMMCW19Cx" / X</A>
												<DT><A HREF="https://github.com/sgl-project/sglang/issues/10278">[Feature] Support deterministic inference with Batch Invariant Ops ¬∑ Issue #10278 ¬∑ sgl-project/sglang</A>
												<DT><A HREF="https://x.com/vllm_project/status/1981088861506982041">(1) vLLM en X: "üöÄ Excited to share our work on batch-invariant inference in vLLM! Now you can get identical results regardless of batch size with just one flag: VLLM_BATCH_INVARIANT=1 No more subtle differences between bs=1 and bs=N (including prefill!). Let's dive into how we built this üßµüëá https://t.co/NkDPVc1vTb" / X</A>
												<DT><A HREF="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Defeating Nondeterminism in LLM Inference - Thinking Machines Lab</A>
											</DL><p>
											<DT><H3 FOLDED>torch.ops</H3>
											<DL><p>
												<DT><A HREF="https://github.com/drisspg/driss_torch/blob/c5177a390ca405330c60463a0ecd202ec3d20d2b/driss_torch/__init__.py">driss_torch/driss_torch/__init__.py</A>
											</DL><p>
											<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops/tree/9bfcaf6c29c5d1413971c8fb16da325fa1602d7d">thinking-machines-lab/batch_invariant_ops</A>
											<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops/blob/9bfcaf6c29c5d1413971c8fb16da325fa1602d7d/batch_invariant_ops/batch_invariant_ops.py#L483">_batch_invariant_LIB.impl("aten::mm", mm_batch_invariant, "CUDA")</A>
											<DT><A HREF="https://docs.pytorch.org/docs/stable/library.html">torch.library.register_fake</A>
											<DT><A HREF="https://chatgpt.com/c/68c2ae45-0524-8327-9b38-cbd1444fa118">Torch library kernel override</A>
											<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/main/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha/cutlass_blackwell_fmha_custom_op.py">FBGEMM/fbgemm_gpu/experimental/gen_ai/gen_ai/attention/cutlass_blackwell_fmha/cutlass_blackwell_fmha_custom_op.py at main ¬∑ pytorch/FBGEMM</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-kernels</H3>
										<DL><p>
											<DT><H3 FOLDED>torch-cutlass</H3>
											<DL><p>
												<DT><A HREF="https://www.youtube.com/watch?v=USMnKuyXBFM">Developing Optimal CUDA Kernels on Hopper Tensor Cores NVIDIA On Demand - YouTube</A>
												<DT><A HREF="https://x.com/cHHillee/status/1884743684928962884">Horace: vboost slider 780 TFLOPS cutlass GEMM backend warpspecialized</A>
											</DL><p>
											<DT><H3 FOLDED>inductor-kernels-profiling</H3>
											<DL><p>
												<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_inductor_profiling.html">TorchInductor GPU Profiling ‚Äî PyTorch 2.4 documentation</A>
												<DT><A HREF="https://colab.research.google.com/drive/1XQwio7DsqB5LP2D574f_uIb8G7KhirNa?usp=sharing#scrollTo=5qmmcFxtePrz">PT2-Benchmark - Colab</A>
												<DT><A HREF="https://gist.github.com/chenyang78/703498efed5de6161fcf1514c2bc6531">parse_kernel_metadata_csv.py</A>
												<DT><A HREF="https://github.com/pytorch/workshops/blob/master/ASPLOS_2024/profiling.pdf">workshops/ASPLOS_2024/profiling.pdf at master ¬∑ pytorch/workshops</A>
												<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/utils/benchmark.py#L60">transformer_nuggets/transformer_nuggets/utils/benchmark.py</A>
												<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_inductor_profiling.html#benchmark-individual-triton-kernel">TORCHINDUCTOR_BENCHMARK_KERNEL</A>
												<DT><A HREF="https://gist.github.com/shunting314/96a0afef9dce53d6357bf1633094f358">cjk2vm3446xrk7rth7hr6pun7xxo3dnzubwcn6ydrpifal4eykrz.py</A>
												<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_profiling_torch_compile.html">Profiling to understand torch.compile performance ‚Äî PyTorch 2.4 documentation</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/issues/120423">Inefficient triton kernels generated by inductor ¬∑ Issue #120423 ¬∑ pytorch/pytorch</A>
											</DL><p>
											<DT><H3 FOLDED>inductor.kernel.custom_op</H3>
											<DL><p>
												<DT><H3 FOLDED>CustomOpConfig</H3>
												<DL><p>
													<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/kernel/custom_op.py">pytorch/torch/_inductor/kernel/custom_op.py at main ¬∑ pytorch/pytorch</A>
													<DT><A HREF="https://github.com/pytorch/pytorch/blob/87fb258cd122a6cb2704e3992d768bce3683d1d1/test/inductor/test_custom_op_autotune.py">pytorch/test/inductor/test_custom_op_autotune.py at 87fb258cd122a6cb2704e3992d768bce3683d1d1 ¬∑ pytorch/pytorch</A>
												</DL><p>
												<DT><A HREF="https://github.com/pytorch/pytorch/pull/164212">[Inductor] Enable Custom op Autotune Decompositions and Parameter Tuning by tianrengao ¬∑ Pull Request #164212 ¬∑ pytorch/pytorch</A>
											</DL><p>
											<DT><H3 FOLDED>TritonTemplate</H3>
											<DL><p>
												<DT><A HREF="https://github.com/triton-lang/triton/issues/4310">Latest nightly triton causes my custom fused attention kernel to output incorrect results. ¬∑ Issue #4310 ¬∑ triton-lang/triton</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/419a7e197d2579e699c2e730902d197a27df8deb/torch/_inductor/select_algorithm.py#L675">pytorch/torch/_inductor/select_algorithm.py</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/419a7e197d2579e699c2e730902d197a27df8deb/test/inductor/test_max_autotune.py#L880">pytorch/test/inductor/test_max_autotune.py</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/419a7e197d2579e699c2e730902d197a27df8deb/torch/_inductor/kernel/conv.py#L140">pytorch/torch/_inductor/kernel/conv.py</A>
												<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173/4">Getting Triton to generate all kernels - torch.compile / torch._inductor - PyTorch Forums</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/issues/152032">RFC: The State of Custom CUDA extensions in PyTorch ¬∑ Issue #152032 ¬∑ pytorch/pytorch</A>
											</DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/tree/14108c1677e5a2f93a822a41cb579b572977d0d3/torch/_inductor/kernel">pytorch/torch/_inductor/kernel</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/14108c1677e5a2f93a822a41cb579b572977d0d3/torch/_inductor/kernel/flex_attention.py">pytorch/torch/_inductor/kernel/flex_attention.py at 14108c1677e5a2f93a822a41cb579b572977d0d3 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/14108c1677e5a2f93a822a41cb579b572977d0d3/torch/_inductor/kernel/mm.py#L585">pytorch/torch/_inductor/kernel/mm.py at 14108c1677e5a2f93a822a41cb579b572977d0d3 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with torch.compile ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
											<DT><A HREF="https://dev-discuss.pytorch.org/t/user-defined-kernels-vs-torch-library-custom-op/2113">User-defined Kernels vs. `torch.library` custom op - compiler - PyTorch Developer Mailing List</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/121367">`torch.compile` makes triton kernel slower in some cases ¬∑ Issue #121367 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/drisspg/driss_torch">drisspg/driss_torch: Cuda extensions for PyTorch</A>
											<DT><A HREF="https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit#heading=h.ptttacy8y1u9">The Custom Operators Manual - Google Docs</A>
											<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
											<DT><A HREF="https://gist.github.com/chenyang78/703498efed5de6161fcf1514c2bc6531">parse_kernel_metadata_csv.py</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-lowering</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch-labs/attention-gym/blob/bbf437e9ea7d802c0ee71d067787f7b57605f9ff/attn_gym/mods/softcapping.py#L23">register_lowering example: softcapping.py#L23</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/8dd380803c0e25786cba12801088c420a2ca071b/torch/_inductor/lowering.py#L2450">pytorch/torch/_inductor/lowering.py at 8dd380803c0e25786cba12801088c420a2ca071b ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>cudagraph-custom_op</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/releases/tag/v2.9.0">Release 2.9 Release Notes ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/159450">[Graph Partition] add graph partition doc by BoyuanFeng ¬∑ Pull Request #159450 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/9cad651a508bd35aef8245173958e3d376240f1f/docs/source/torch.compiler_cudagraph_trees.md">pytorch/docs/source/torch.compiler_cudagraph_trees.md at 9cad651a508bd35aef8245173958e3d376240f1f ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://pytorch.org/blog/accelerating-pytorch-with-cuda-graphs/">Accelerating PyTorch with CUDA Graphs ‚Äì PyTorch</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-cutlass</H3>
										<DL><p>
											<DT><H3 FOLDED>inductor-cutlass-sm103</H3>
											<DL><p>
												<DT><A HREF="https://github.com/pytorch/pytorch/issues/170476">[inductor] cutlass GEMM backend SM103 runtime error ¬∑ Issue #170476 ¬∑ pytorch/pytorch</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/pull/172263">Add b300 to cpp codegen by drisspg ¬∑ Pull Request #172263 ¬∑ pytorch/pytorch</A>
												<DT><A HREF="https://github.com/NVIDIA/cutlass/blob/8c524595040d0fa2a6ed2852e3fa823cd796c989/python/cutlass_cppgen/backend/evt/passes/util.py#L45">We do have an internal remapping of 103 -&gt; 100 in the cppgen here</A>
											</DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=2dY8vPQ349Q">CUTLASS backend for Inductor: PyTorch Compiler Series - YouTube</A>
											<DT><A HREF="https://www.youtube.com/watch?utm_content=336888394&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024&v=2dY8vPQ349Q&feature=youtu.be">CUTLASS backend for Inductor: PyTorch Compiler Series - YouTube</A>
											<DT><A HREF="https://gist.github.com/Chillee/2ec89696db8b7ed1c24461159e325405">H100 peak matmul FLOPS</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-cute</H3>
										<DL><p>
											<DT><H3 FOLDED>CuteDSLTemplate</H3>
											<DL><p>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/3ecc137077021fe89f0f88399b2e0ce8f7373bbc/torch/_inductor/codegen/cutedsl/README.md?plain=1#L11">pytorch/torch/_inductor/codegen/cutedsl/README.md at 3ecc137077021fe89f0f88399b2e0ce8f7373bbc ¬∑ pytorch/pytorch</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/3ecc137077021fe89f0f88399b2e0ce8f7373bbc/test/inductor/test_cutedsl_template.py">pytorch/test/inductor/test_cutedsl_template.py</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/tree/47f048afa57d90eba0717741e4309443767e4e8e/torch/_inductor/codegen/cutedsl">pytorch/torch/_inductor/codegen/cutedsl</A>
											</DL><p>
											<DT><A HREF="https://x.com/SemiAnalysis_/status/1990997414832906562/photo/1">(1) SemiAnalysis en X: "BREAKING: The CUDA moat has just expanded again! PyTorch Compile/Inductor can now target NVIDIA Python CuTeDSL in addition to Triton. This enables 2x faster FlexAttention compared to Triton implementations. We explain below üëá As we explained in our April 2025 AMD 2.0 piece, https://t.co/sJMLTzylo3" / X</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/3ecc137077021fe89f0f88399b2e0ce8f7373bbc/torch/_inductor/codegen/cutedsl/cutedsl_kernel.py#L63">pytorch/torch/_inductor/codegen/cutedsl/cutedsl_kernel.py at 3ecc137077021fe89f0f88399b2e0ce8f7373bbc ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/3ecc137077021fe89f0f88399b2e0ce8f7373bbc/torch/_inductor/kernel/flex/flex_flash_attention.py#L46">pytorch/torch/_inductor/kernel/flex/flex_flash_attention.py at 3ecc137077021fe89f0f88399b2e0ce8f7373bbc ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/3ecc137077021fe89f0f88399b2e0ce8f7373bbc/test/inductor/test_cutedsl_template.py">pytorch/test/inductor/test_cutedsl_template.py</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-gluon</H3>
										<DL><p>
											<DT><H3 FOLDED>GluonTemplate</H3>
											<DL><p>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/3a29dd4346a1c60a64430a227bf1be6efee3776d/torch/_inductor/codegen/gluon/gluon_template.py#L164">pytorch/torch/_inductor/codegen/gluon/gluon_template.py uses TritonTemplate infra but Gluon's ASTSource and extended IR builder</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/blob/3a29dd4346a1c60a64430a227bf1be6efee3776d/test/test_matmul_cuda.py">pytorch/test/test_matmul_cuda.py F.grouped_mm GLUON backend</A>
											</DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/166063">Add Gluon based grouped MM kernel for Blackwell into Inductor by alexsamardzic ¬∑ Pull Request #166063 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/169336">[Inductor][Grouped Gemm] Add Improved Blackwell CuTeDSL Kernel by NikhilAPatel ¬∑ Pull Request #169336 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-cutile</H3>
										<DL><p>
											<DT><A HREF="https://patricktoulme.substack.com/p/cutile-on-blackwell-nvidias-compiler">CuTile on Blackwell: NVIDIA's Compiler Moat Is Already Built</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/165785">Currently in the process of adding a full Inductor backend consisting of CuTeDSL kernels (and eventually CuTile kernels) based on NVIDIA‚Äôs new Python universal GEMM template.</A>
											<DT><A HREF="https://github.com/search?q=repo%3Apytorch%2Fpytorch%20NVGEMM&type=code">max_autotune_gemm_backends = NVGEMM</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/152032">RFC: The State of Custom CUDA extensions in PyTorch ¬∑ Issue #152032 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-reductions</H3>
										<DL><p>
											<DT><A HREF="https://karthick.ai/blog/2025/Learn-By-Doing-Torchinductor-Reduction/">Learn by doing: TorchInductor Reduction Kernels | Karthick Panner Selvam</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-sm103</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/170623">[Inductor] Add Nvidia Universal Gemm Backend to Inductor by NikhilAPatel ¬∑ Pull Request #170623 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><A HREF="https://twitter.com/cHHillee/status/1777825367954432114/photo/1">TORCH_LOGS="output_code" python t.py</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/wiki/Codegen-and-Structured-Kernels">Codegen and Structured Kernels ¬∑ pytorch/pytorch Wiki</A>
										<DT><A HREF="https://towardsdatascience.com/how-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26">How Pytorch 2.0 Accelerates Deep Learning with Operator Fusion and CPU/GPU Code-Generation</A>
										<DT><A HREF="https://twitter.com/marksaroufim/status/1746307482904076374">torch.utils.cpp_extension import load_inline</A>
										<DT><A HREF="https://twitter.com/johnowhitaker/status/1746275479806742664/photo/1">IR Triton code</A>
										<DT><A HREF="https://www.youtube.com/watch?v=LuhJEEJQgUM">Lecture 1 How to profile CUDA kernels in PyTorch</A>
										<DT><A HREF="https://twitter.com/cHHillee/status/1777825367954432114">Horace He: see what kernels are being executed under torch.compile</A>
										<DT><A HREF="https://github.com/Chillee/llm.c/blob/master/inductor_gpt2.cpp">torch compile can also generate and emit C++ code (llm.c)</A>
										<DT><A HREF="https://pytorch.org/tutorials/prototype/inductor_cpp_wrapper_tutorial.html">Inductor C++ Wrapper Tutorial</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/fea1b99d89204989db64d0d63f5e46fce60d1962/torch/_inductor/config.py#L34">TORCHINDUCTOR_CPP_WRAPPER</A>
										<DT><A HREF="https://x.com/mrsiipa/status/1976410789348323727/photo/2">triton_poi_fused_cat_0</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/164212">[Inductor] Enable Custom op Autotune Decompositions and Parameter Tuning by tianrengao ¬∑ Pull Request #164212 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://x.com/gauravisnotme/status/1998630535854436838">(1) Gaurav en X: "Okay. If I could, I would send Christmas gifts to the Pytorch team every year. Okay not year but yes for sure at least once. When you use torch.compile, during TorchInductor generates this Python wrapper which also a neat function called `benchmark_compiled_module`. Look at https://t.co/RYf7O6YJov" / X</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-caching</H3>
									<DL><p>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-bring-compile-time-down-to-zero-our-plans-and-direction-may-14th-edition/2089">How To Bring Compile Time Down to Zero: Our Plans and Direction (May 14th Edition) - compiler - PyTorch Developer Mailing List</A>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/torch_compile_caching_tutorial.html">Compile Time Caching in torch.compile ‚Äî PyTorch Tutorials 2.7.0+cu126 documentation</A>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/torch_compile_caching_configuration_tutorial.html?utm_source=chatgpt.com">Compile Time Caching Configuration ‚Äî PyTorch Tutorials 2.7.0+cu126 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-profiling</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_inductor_profiling.html">TorchInductor GPU Profiling ‚Äî PyTorch 2.4 documentation</A>
										<DT><A HREF="https://github.com/ai-compiler-study/test_attn/blob/main/inductor_profiling.py">test_attn/inductor_profiling.py at main ¬∑ ai-compiler-study/test_attn</A>
										<DT><A HREF="https://colab.research.google.com/drive/1XQwio7DsqB5LP2D574f_uIb8G7KhirNa?usp=sharing#scrollTo=5qmmcFxtePrz">PT2-Benchmark - Colab</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/7eb2a99585b683e5486bfbf2e78c8165f08c392b/benchmarks/dynamo/microbenchmarks/microbench.py">pytorch/benchmarks/dynamo/microbenchmarks/microbench.py</A>
										<DT><A HREF="https://gist.github.com/chenyang78/703498efed5de6161fcf1514c2bc6531">parse_kernel_metadata_csv.py</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-tests</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/c2ff9fe042ffe39a2684aecc6c6062a066489f54/test/inductor/test_fp8.py#L441">test_fp8.py#L441 backend="inductor", mode="max-autotune"</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-backend</H3>
									<DL><p>
										<DT><H3 FOLDED>inductor-custom-backend</H3>
										<DL><p>
											<DT><H3 FOLDED>inductor-custom-backend-examples</H3>
											<DL><p>
												<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/inductor/cases/custom_fuse/run.py">ml_scripts/inductor/cases/custom_fuse/run.py at main ¬∑ FindHao/ml_scripts</A>
												<DT><A HREF="https://discuss.pytorch.org/t/functional-collectives-used-in-torch-compile/190627">torch.compiler toy_compiler torch.fx.GraphModule fx_compile</A>
											</DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/164212">[Inductor] Enable Custom op Autotune Decompositions and Parameter Tuning by tianrengao ¬∑ Pull Request #164212 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://dev-discuss.pytorch.org/t/developer-docs-for-pytorch-inductor/1714">Developer docs for PyTorch inductor? - compiler - PyTorch Developer Mailing List</A>
											<DT><A HREF="https://github.com/tianrengao">tianrengao (Terry Gao)</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/167193">Add dynamic config generation for custom op autotuning by tianrengao ¬∑ Pull Request #167193 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/167193/commits/484434bdae531ec6c72f60c85e54dffd07311c97">Add dynamic config generation for custom op autotuning by tianrengao ¬∑ Pull Request #167193 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>cortex</H3>
										<DL><p>
											<DT><H3 FOLDED>cortex-ops</H3>
											<DL><p>
												<DT><H3 FOLDED>cortex-ops-attention</H3>
												<DL><p>
													<DT><A HREF="https://github.com/antferdom/cortex/blob/e3fec5fae80f1ec49ce738db1f8b9d59dd7b7d5e/src/cortex/backends/cuda/op_registry.py">cortex/src/cortex/backends/cuda/op_registry.py at e3fec5fae80f1ec49ce738db1f8b9d59dd7b7d5e ¬∑ antferdom/cortex</A>
													<DT><A HREF="https://github.com/pytorch/FBGEMM/blob/f9ccd0126207c149bf99877c5e863d8018208858/fbgemm_gpu/experimental/gen_ai/src/attention/cuda/cutlass_blackwell_fmha/README.md">FBGEMM/fbgemm_gpu/experimental/gen_ai/src/attention/cuda/cutlass_blackwell_fmha/README.md at f9ccd0126207c149bf99877c5e863d8018208858 ¬∑ pytorch/FBGEMM</A>
													<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/0baf4b3fd3c568964acd4f176c35e8f073c70c20/src/quantum_attn/quantum_attn_interface.py">QuantumAttention/src/quantum_attn/quantum_attn_interface.py at 0baf4b3fd3c568964acd4f176c35e8f073c70c20 ¬∑ WaveSpeedAI/QuantumAttention</A>
													<DT><A HREF="https://github.com/feifeibear/test_attn/blob/main/test.py">test_attn/test.py at main ¬∑ feifeibear/test_attn</A>
												</DL><p>
												<DT><H3 FOLDED>cortex-ops-linear</H3>
												<DL><p>
													<DT><A HREF="https://github.com/Dao-AILab/quack/blob/3d0ab3ec2164749caac8f269f771e66a40efd2de/quack/gemm_sm100.py#L78">quack/quack/gemm_sm100.py at 3d0ab3ec2164749caac8f269f771e66a40efd2de ¬∑ Dao-AILab/quack</A>
												</DL><p>
												<DT><A HREF="https://github.com/pytorch/pytorch/pull/164212">[Inductor] Enable Custom op Autotune Decompositions and Parameter Tuning by tianrengao ¬∑ Pull Request #164212 ¬∑ pytorch/pytorch</A>
											</DL><p>
											<DT><H3 FOLDED>cortex.ao</H3>
											<DL><p>
												<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/commit/32cf5d32cebedf4992ebc742cd15fc0901b2f2b1">Qwen-Image FP8 (#761) ¬∑ modelscope/DiffSynth-Studio@32cf5d3</A>
												<DT><A HREF="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization">A Visual Guide to Quantization - by Maarten Grootendorst</A>
												<DT><A HREF="https://docs.pytorch.org/ao/stable/subclass_basic.html">Writing Your Own Quantized Tensor ‚Äî torchao 0.13 documentation</A>
											</DL><p>
											<DT><H3 FOLDED>cortex-build</H3>
											<DL><p>
												<DT><H3 FOLDED>pip-no-deps</H3>
												<DL><p>
													<DT><A HREF="https://grok.com/chat/46299d90-1c9d-413d-8bf4-908add2acbc7">Distributing Python Wheels via GitHub - Grok</A>
												</DL><p>
												<DT><A HREF="https://github.com/antferdom/cortex/blob/main/build.sh">cortex/build.sh at main ¬∑ antferdom/cortex</A>
											</DL><p>
											<DT><H3 FOLDED>cortex-video</H3>
											<DL><p>
												<DT><H3 FOLDED>wan2.2-benchmark</H3>
												<DL><p>
													<DT><A HREF="https://gist.github.com/a-r-r-o-w/2551f05b67380818da22d94fedebcadf">benchmark_flux_3.py</A>
													<DT><A HREF="https://x.com/aryanvs_/status/1957271148896653708">(1) Aryan V S en X: "No wizardry required here... Apply context parallel on compute bound models for easy speedups. Oh, and don't forget flash attention 3! Further, you can compile the model and set a few inductor flags for near perfect compute-communication overlap. Don't want to use compile? - https://t.co/9dUupSmA2k" / X</A>
													<DT><A HREF="https://x.com/aryanvs_/status/1961418610762813459">(1) Aryan V S en X: "It's kinda amazing that we can generate such high quality videos faster than we can play them. Super cool @DecartAI. Want to know how you can self-host and run models like Wan-5B this fast? Look inside for code ü§ó 1. Copy a diffusers model implementation 2. Apply context https://t.co/vQw1mVtPrg" / X</A>
													<DT><A HREF="https://gist.github.com/a-r-r-o-w/a4a9d889857d1b36a52fadfdc1aca249">Wan 2.2 5B T2V benchmarks</A>
													<DT><A HREF="https://gist.github.com/a-r-r-o-w/451e6ed5de1c635165c308d1098ddf84">Lossless system-level only optimizations benchmark for Wan WAN 2.2 A14B</A>
												</DL><p>
											</DL><p>
											<DT><A HREF="https://github.com/antferdom/cortex">antferdom/cortex: Torch compiler custom backend model agnostic</A>
											<DT><A HREF="https://github.com/huggingface/flux-fast/blob/main/utils/pipeline_utils.py#L283">flux-fast/utils/pipeline_utils.py at main aoti</A>
											<DT><A HREF="https://gist.github.com/a-r-r-o-w/2551f05b67380818da22d94fedebcadf">benchmark_flux_3.py</A>
											<DT><A HREF="https://gist.github.com/a-r-r-o-w/451e6ed5de1c635165c308d1098ddf84">Lossless system-level only optimizations benchmark for Wan</A>
											<DT><A HREF="https://gist.github.com/a-r-r-o-w/a4a9d889857d1b36a52fadfdc1aca249">Wan 2.2 5B T2V benchmarks</A>
											<DT><A HREF="https://gist.github.com/a-r-r-o-w/d34c53ca9d4f69cd45872931b0f3855d">Flux with cuda stream</A>
											<DT><A HREF="https://github.com/search?q=repo%3Apytorch%2FFBGEMM%20cutlass_blackwell&type=code">FBGEMM GPU CUTLASS</A>
										</DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/10118">[RFC] SGLang unified kernel fusion and torch compile optimisations ¬∑ Issue #10118 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-autotuning</H3>
									<DL><p>
										<DT><H3 FOLDED>inductor-persistent-kernels</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/config.py">TORCHINDUCTOR_MULTI_KERNEL (i.e. no loops kernels)</A>
											<DT><A HREF="https://x.com/cHHillee/status/1943416186412449946">persistent reductions kernels (i.e. no loops)</A>
											<DT><A HREF="https://gist.github.com/Chillee/6f1a8995dc25c08b11494485d4a53460">Random Kernel Microbenchmarks</A>
											<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-05-27-no-bubbles">Look Ma, No Bubbles! Designing a Low-Latency Megakernel for Llama-1B ¬∑ Hazy Research</A>
											<DT><A HREF="https://github.com/alexarmbr/cute_kernels/blob/main/sm100_persistent_matmul.py">cute_kernels/sm100_persistent_matmul.py at main ¬∑ alexarmbr/cute_kernels</A>
											<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops/blob/9bfcaf6c29c5d1413971c8fb16da325fa1602d7d/batch_invariant_ops/batch_invariant_ops.py#L483">batch_invariant_ops/batch_invariant_ops/batch_invariant_ops.py at 9bfcaf6c29c5d1413971c8fb16da325fa1602d7d ¬∑ thinking-machines-lab/batch_invariant_ops</A>
											<DT><A HREF="https://x.com/bfspector/status/1972384521149718541">(1) Benjamin F Spector en X: "(1/8) We‚Äôre releasing an 8-GPU Llama-70B inference engine megakernel! Our megakernel supports arbitrary batch sizes, mixed prefill+decode, a paged KV cache, instruction pipelining, dynamic scheduling, interleaved communication, and more! On ShareGPT it‚Äôs 22% faster than SGLang. https://t.co/nRUfEiCubk" / X</A>
											<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-09-28-tp-llama-main">We Bought the Whole GPU, So We're Damn Well Going to Use the Whole GPU ¬∑ Hazy Research</A>
											<DT><A HREF="https://www.youtube.com/watch?v=PAsL680eWUw">Triton Pipelining Persistent Kernels - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>inductor-autotuning-tests</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/87fb258cd122a6cb2704e3992d768bce3683d1d1/test/inductor/test_custom_op_autotune.py#L33">pytorch/test/inductor/test_custom_op_autotune.py _run_autotune_test</A>
										</DL><p>
										<DT><A HREF="https://gist.github.com/Chillee/2ec89696db8b7ed1c24461159e325405">H100 peak matmul FLOPS</A>
										<DT><A HREF="https://x.com/cHHillee/status/1943416186412449946">persistent reductions kernels (i.e. no loops)</A>
										<DT><A HREF="https://www.youtube.com/watch?v=SewGbEAx548&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=5">Generating State-of-the-Art GEMMs for Heterogeneous Hardware with... - Michael Lazos &amp; Henry Tsang - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-logs</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/YouJiacheng/fc66d04f3874ba558b823d0965ee619f">log_inductor_output.py trace_structured</A>
										<DT><A HREF="https://grok.com/c/134d9225-5692-40f6-8919-a661e36cd53b">PyTorch Inductor Debugging Patch - Grok</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-regional</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/regional_compilation.html">Reducing torch.compile cold start compilation time with regional compilation ‚Äî PyTorch Tutorials 2.9.0+cu128 documentation</A>
										<DT><A HREF="https://pytorch.org/blog/pytorch2-5/?utm_content=312749699&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">PyTorch 2.5 Release Blog ‚Äì PyTorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/a51208c656fb3e9a8b091a4d181f9a9cda783c04/torch/fx/passes/regional_inductor.py#L167">pytorch/torch/fx/passes/regional_inductor.py</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/a51208c656fb3e9a8b091a4d181f9a9cda783c04/test/dynamo/test_regional_inductor.py#L40">pytorch/test/dynamo/test_regional_inductor.py</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-attention-backend</H3>
									<DL><p>
										<DT><H3 FOLDED>attention-backend-cuDNN</H3>
										<DL><p>
											<DT><A HREF="https://x.com/SemiAnalysis_/status/1983205722734375014">(1) SemiAnalysis en X: "In the latest PyTorch 2.9, cuDNN attention was re-enabled as the default kernel for the scaled_dot_product_attention API, but unfortunately, there continue to be more NaN and numeric convergence issues, as confirmed in Issue #166211. This may result in cuDNN being disabled as the" / X</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>compile_fx</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/compile_fx.py#L2464">pytorch/torch/_inductor/compile_fx.py at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/debug.py#L1234">pytorch/torch/_inductor/debug.py at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://discuss.pytorch.org/t/functional-collectives-used-in-torch-compile/190627">_functional_collectives used in torch.compile - distributed - PyTorch Forums</A>
									</DL><p>
									<DT><H3 FOLDED>inductor-pattern-matcher</H3>
									<DL><p>
										<DT><A HREF="https://karthick.ai/blog/2026/Learn-By-Doing-Torchinductor-Pattern-Matcher/">Learn by doing: TorchInductor Pattern Matcher | Karthick Panner Selvam</A>
									</DL><p>
									<DT><H3 FOLDED>torch._inductor.utils</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/utils.py">add_scheduler_init_hook (compiled region) use scheduler hooks to observe ops and estiamte runtime</A>
									</DL><p>
									<DT><H3 FOLDED>aot</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/402153d95aa20f8c1b625b11a99440e5fc38004f/docs/source/user_guide/torch_compiler/torch.compiler_aot_inductor.md">pytorch/docs/source/user_guide/torch_compiler/torch.compiler_aot_inductor.md at 402153d95aa20f8c1b625b11a99440e5fc38004f ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c&t=352s">Walk through compile_fx - YouTube</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/402153d95aa20f8c1b625b11a99440e5fc38004f/docs/source/user_guide/torch_compiler/torch.compiler_troubleshooting.md?plain=1#L1022">pytorch/docs/source/user_guide/torch_compiler/torch.compiler_troubleshooting.md at 402153d95aa20f8c1b625b11a99440e5fc38004f ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>decomps</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/96039">[inductor] Add some simple decomps by jansel ¬∑ Pull Request #96039 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c&t=352s">Walk through compile_fx - YouTube</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/164212">[Inductor] Enable Custom op Autotune Decompositions and Parameter Tuning by tianrengao ¬∑ Pull Request #164212 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/87fb258cd122a6cb2704e3992d768bce3683d1d1/test/inductor/test_custom_op_autotune.py#L43">pytorch/test/inductor/test_custom_op_autotune.py at 87fb258cd122a6cb2704e3992d768bce3683d1d1 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>torch-cute</H3>
									<DL><p>
										<DT><H3 FOLDED>CuteDSLTemplate</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/47f048afa57d90eba0717741e4309443767e4e8e/torch/_inductor/codegen/cutedsl/cutedsl_template.py#L21">pytorch/torch/_inductor/codegen/cutedsl/cutedsl_template.py</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/160108">Add cutedsl template support to compile by drisspg ¬∑ Pull Request #160108 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><A HREF="https://docs.nvidia.com/cutlass/latest/media/docs/pythonDSL/cute_dsl_general/compile_with_tvm_ffi.html">Pass PyTorch tensors directly to the compiled function to avoid explicit DLPack conversion.</A>
										<DT><A HREF="https://x.com/tqchenml/status/1994411541274182099">(1) Tianqi Chen en X: "CuteDSL 4.3.1 is here üöÄ Major host overhead optimization (10-40¬µs down to a 2¬µs in hot loops_, streamlined PyTorch interop (pass torch.Tensors directly, no more conversions needed)¬†and export and use in more languages and envs. All powered by apache tvm-ffi ABI https://t.co/VnplRiD7jP" / X</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/workshops/blob/master/ASPLOS_2024/inductor.pdf">workshops/ASPLOS_2024/inductor.pdf at master ¬∑ pytorch/workshops</A>
									<DT><A HREF="https://github.com/thuml/depyf">thuml/depyf: understand and adapt to PyTorch compiler</A>
									<DT><A HREF="https://github.com/alpha0422/study">alpha0422/study: Study for various topics.</A>
									<DT><A HREF="https://pytorch.org/docs/main/torch.compiler_aot_inductor.html">AHEAD-OF-TIME COMPILATION FOR TORCH.EXPORT</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/the-future-of-c-model-deployment/1282">The future of C++ model deployment</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/codegen/wrapper.py">codegen/wrapper.py</A>
									<DT><A HREF="https://www.youtube.com/watch?v=w7d4oWzwZ0c">AOTInductor: Ahead-of-Time Compilation for PT2 Exported Models</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747">TorchInductor: a PyTorch-native Compiler with Define-by-Run IR and Symbolic Shapes</A>
									<DT><A HREF="https://twitter.com/mathemakitten/status/1744861826528211323">inductor + triton = kernels &gt; handcoded FlashAttention 2</A>
									<DT><A HREF="https://www.youtube.com/watch?v=682pQYiS4cQ">Fixing an PyTorch Inductor bug: Views, Buffers, Realize - YouTube</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/111434">[Inductor] Support user defined triton kernels in inductor by oulgen ¬∑ Pull Request #111434 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/inductor-file-structure-explanation/1860/2">Inductor file structure explanation - PyTorch Dev Discussions</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/107802">[Inductor CUTLASS backend] Step 1: Inductor config for cuda / cutlass, util functions. by ipiszy ¬∑ Pull Request #107802 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/e91c37c1c39734359637e3fd999ba20e26b6bfa7/torch/_inductor/config.py">pytorch/torch/_inductor/config.py</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/111434">[Inductor] Support user defined triton kernels in inductor</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/inductor-file-structure-explanation/1860/2">Inductor file structure explanation</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/107802">[Inductor CUTLASS backend] Step 1: Inductor config for cuda / cutlass, util functions</A>
									<DT><A HREF="https://github.com/ngimel/inductor_generated">ngimel/inductor_generated</A>
									<DT><A HREF="https://github.com/thuml/learn_torch.compile">thuml/learn_torch.compile: torch.compile artifacts for common deep learning models</A>
									<DT><A HREF="https://twitter.com/cHHillee/status/1777825367954432114/photo/1">TORCH_LOGS="output_code" python t.py</A>
									<DT><A HREF="https://gist.github.com/Chillee/f86675147366a7a0c6e244eaa78660f7">1-pw_op_fusion.py</A>
									<DT><A HREF="https://pytorch.org/blog/introducing-depyf/">Introducing depyf: mastering torch.compile with ease | PyTorch</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/when-does-the-inductor-code-run/2088/3">When does the inductor code run? - compiler - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://www.youtube.com/watch?v=qYqrfq452ig&t=4548s">Hardcore CUDA Hackathon Talks at AGI House SF - YouTube</A>
									<DT><A HREF="https://pytorch.org/assets/images/pytorch-2.0-img4.jpg">compilation process</A>
									<DT><A HREF="https://wentao.site/compiler_introduction/">Pytorch Compiler Introduction - Yewentao's Blog</A>
									<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/inductor/filter_kernel_num.py">ml_scripts/inductor/filter_kernel_num.py at main ¬∑ FindHao/ml_scripts</A>
									<DT><A HREF="https://gist.github.com/YouJiacheng/fc66d04f3874ba558b823d0965ee619f">monkey patch: log_inductor_output.py</A>
									<DT><A HREF="https://x.com/gauravisnotme/status/1998594217145188359">(1) Gaurav en X: "So the last few days - Take the diffusion model, look at the torch profiler trace, figure out the compilation/recompilation overhead, read about regional compilations, come across one of @PyTorch's best tool - tlparse, sing praises for the Pytorch team for an hour, watch this" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=GmhnYe9QQoM">Inside torch.compile Guards: How They Work, What They Cost, &amp; Ways to Optimize, PyTorch Compiler - YouTube</A>
									<DT><A HREF="https://github.com/meta-pytorch/tritonbench/blob/3e833879c6798e3549f74b1f25ae199809d98d6f/tritonbench/utils/env_utils.py#L106">tritonbench/tritonbench/utils/env_utils.py rmtree INDUCTOR_DIR</A>
								</DL><p>
								<DT><H3 FOLDED>Dynamo</H3>
								<DL><p>
									<DT><H3 FOLDED>dynamo-docs</H3>
									<DL><p>
										<DT><H3 FOLDED>dynamo-walk-through</H3>
										<DL><p>
											<DT><A HREF="https://depyf.readthedocs.io/en/latest/walk_through.html">A Walk Through Example of torch.compile ‚Äî depyf documentation</A>
											<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c">Walk through compile_fx - YouTube</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_dynamo_overview.md">pytorch/docs/source/torch.compiler_dynamo_overview.md at main ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_dynamo_overview.md">pytorch/docs/source/torch.compiler_dynamo_overview.md at</A>
										<DT><A HREF="https://fkong.tech/posts/2023-05-20-dynamo/">‰∏ÄÊñáÊêûÊáÇ TorchDynamo ÂéüÁêÜ ¬∑ fkong' tech blog</A>
										<DT><A HREF="https://fkong.tech/posts/2023-05-14-dynamo-01/">TorchDynamo Ê∫êÁ†ÅÂâñÊûê 01 - Frame Evaluation ‰∏éÂ≠óËäÇÁ†ÅÂü∫Á°Ä ¬∑ fkong' tech blog</A>
										<DT><A HREF="https://fkong.tech/posts/2023-05-14-dynamo-02/">TorchDynamo Ê∫êÁ†ÅÂâñÊûê 02 - Â≠óËäÇÁ†ÅÁøªËØë ¬∑ fkong' tech blog</A>
										<DT><A HREF="https://fkong.tech/posts/2023-05-14-dynamo-03/">TorchDynamo Ê∫êÁ†ÅÂâñÊûê 03 - Graph Break ¬∑ fkong' tech blog</A>
										<DT><A HREF="https://github.com/chenzomi12/AISystem/blob/main/03Compiler/06PyTorch/02.torchscript.pdf">AISystem/03Compiler/06PyTorch/02.torchscript.pdf at main ¬∑ chenzomi12/AISystem</A>
										<DT><A HREF="https://github.com/chenzomi12/AISystem/blob/main/03Compiler/06PyTorch/04.torchdynamo.pdf">AISystem/03Compiler/06PyTorch/04.torchdynamo.pdf at main ¬∑ chenzomi12/AISystem</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/59cf4bc5ae64aea2c6a9b870243821695adfc30b/docs/source/torch.compiler_fine_grain_apis.rst#L29">pytorch/docs/source/torch.compiler_fine_grain_apis.rst: torch.compiler.is_compiling</A>
									</DL><p>
									<DT><H3 FOLDED>dynamo-config</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_dynamo/config.py">pytorch/torch/_dynamo/config.py at main ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>torch-symbolic-shapes</H3>
									<DL><p>
										<DT><H3 FOLDED>dynamic-shapes</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=41SJlmrjpYk&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=127">Lightning Talk: Dynamic Shape Recompilations - Bob Ren, Meta - YouTube</A>
										</DL><p>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/state-of-symbolic-shapes-branch/777">State of Symbolic Shapes</A>
										<DT><A HREF="https://www.youtube.com/watch?v=R-AVYgBIZRY">Dynamic Shapes</A>
										<DT><A HREF="https://medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd">Shape Suffixes ‚Äî Good Coding Style | by Noam Shazeer | Feb, 2024 | Medium</A>
										<DT><A HREF="https://github.com/ezyang/data-dependent-shape-puzzles">ezyang/data-dependent-shape-puzzles: Puzzlers regarding data-dependent shapes in PT2</A>
										<DT><A HREF="https://docs.google.com/document/d/1HSuTTVvYH1pTew89Rtpeu84Ht3nQEFTYhAX3Ypa_xJs/edit#heading=h.44gwi83jepaj">Dealing with GuardOnDataDependentSymNode errors - Google Docs</A>
										<DT><A HREF="https://colab.research.google.com/github/ezyang/data-dependent-shape-puzzles/blob/main/data-dependent-shape-puzzles.ipynb#scrollTo=65eb2hyriPM0">data-dependent-shape-puzzles.ipynb - Colab</A>
										<DT><A HREF="https://static.sched.com/hosted_files/pytorch2024/a6/Data-dependent%20shapes%20in%20PT2.pdf">Data-dependent shapes in PT2</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/135859">torch.bmm, torch.topk with out variants set causing recompilations in torch.compile ¬∑ Issue #135859 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/replicate/autocompile">replicate/autocompile: automatically infer dynamic shapes for Torch-Tensor compilation</A>
									</DL><p>
									<DT><H3 FOLDED>dynamo-graph-breaks</H3>
									<DL><p>
										<DT><H3 FOLDED>Guard Model</H3>
										<DL><p>
											<DT><A HREF="https://dev-discuss.pytorch.org/t/understanding-dynamic-shapes-and-guards-and-when-it-does-does-not-cause-graph-breaks/2429">Understanding dynamic shapes and guards and when it does/does not cause graph breaks - compiler - PyTorch Developer Mailing List</A>
											<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_dynamic_shapes.html#the-guard-model">Dynamic shapes ‚Äî PyTorch 2.4 documentation</A>
											<DT><A HREF="https://www.youtube.com/watch?v=O8AkwKHOFDw">How does Guard and GuardBuilder work in torchdynamo - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>torch._dynamo.error_on_graph_break()</H3>
										<DL><p>
											<DT><A HREF="https://docs.pytorch.org/docs/main/compile/programming_model.error_on_graph_break.html">Toggling error_on_graph_break ‚Äî PyTorch main documentation</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>torch._dynamo.mark_static</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=06HuwNR9-uI">PyTorch: Implementing a Dynamo frontend feature - torch._dynamo.mark_static - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>dynamo-debug</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=egZB5Uxki0I">torchdynamo deep dive - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=X6RXkTXQOb0">Debugging torchdynamo symbolic shapes: Part 2 - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>dynamo-graph-splitting</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>torch._dynamo.utils</H3>
									<DL><p>
										<DT><H3 FOLDED>dynamo_timed</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_dynamo/utils.py#L662">pytorch/torch/_dynamo/utils.py at main ¬∑ pytorch/pytorch</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=egZB5Uxki0I">torchdynamo deep dive - YouTube</A>
									<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_dynamo_deepdive.html">Dynamo Deep-Dive ‚Äî PyTorch 2.6 documentation</A>
									<DT><A HREF="https://github.com/pytorch/workshops/blob/master/ASPLOS_2024/dynamo_example.pdf">workshops/ASPLOS_2024/dynamo_example.pdf at master ¬∑ pytorch/workshops</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/torchdynamo-update-4-lazytensor-nvfuser-experiments/496">TorchDynamo Update 4: LazyTensor &amp; nvFuser Experiments - compiler - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/torchdynamo-update-7-inference-with-fx2trt/576">TorchDynamo Update 7: Inference with FX2TRT - compiler - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://strint.github.io/221203-torchdynamo.html">TorchDynamo ÂàùÊé¢: Python ByteCode ÁöÑÂä®ÊÄÅ‰øÆÊîπ | strint‚Äôs blog (nexfort)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=w30xteQDeO8">Lightning Talk: PT2 Export - A Sound Full Graph Capture Mechanism for PyTorch - Avik Chaudhuri, Meta - YouTube</A>
									<DT><A HREF="https://github.com/Skylion007/pytorch/blob/ad8448497290394b50f84a2932fcb4f078793b3f/test/dynamo/test_functions.py#L1603">pytorch/test/dynamo/test_functions.py</A>
									<DT><A HREF="https://github.com/thuml/learn_torch.compile">thuml/learn_torch.compile: torch.compile artifacts for common deep learning models</A>
									<DT><A HREF="https://github.com/thuml/depyf">thuml/depyf: understand and adapt to PyTorch compiler</A>
									<DT><A HREF="https://www.youtube.com/watch?v=w30xteQDeO8">Export - A Sound Full Graph Capture Mechanism for PyTorch</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/a-torchdynamo-trace-time-ablation-study/1961">A TorchDynamo trace time ablation study - compiler - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://www.youtube.com/watch?v=X6RXkTXQOb0">Debugging torchdynamo symbolic shapes: Part 2 - YouTube</A>
									<DT><A HREF="https://colab.research.google.com/github/ezyang/data-dependent-shape-puzzles/blob/main/data-dependent-shape-puzzles.ipynb#scrollTo=eXgUk-MfiPM2">data-dependent-shape-puzzles.ipynb - Colab</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/issues/117045">cache_entries empty after torch.compile() ? ¬∑ Issue #117045 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/commit/9dcf57345999c2ce5d271680a7bbdac2c8e0f527#diff-7188946c2f4f60af53ffb2e2f55bd09a3b00c12b49989fe085933585edcb3c5cR26">torch.compiler.is_compiling()</A>
									<DT><A HREF="https://github.com/replicate/autocompile">replicate/autocompile: automatically infer dynamic shapes for Torch-Tensor compilation</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/133137/files">[Dynamo] Trace torch function modes entered outside of torch.compile by mlazos ¬∑ Pull Request #133137 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://docs.google.com/document/d/1GgvOe7C8_NVOMLOCwDaYV1mXXyHMXY7ExoewHqooxrs/edit?tab=t.0#heading=h.fh8zzonyw8ng">The dynamic shapes manual - Google Docs</A>
									<DT><A HREF="https://docs.pytorch.org/docs/stable/torch.compiler_dynamo_deepdive.html">Dynamo Deep-Dive ‚Äî PyTorch 2.8 documentation</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/166063/files">Add Gluon based grouped MM kernel for Blackwell into Inductor by alexsamardzic ¬∑ Pull Request #166063 ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-debug</H3>
								<DL><p>
									<DT><H3 FOLDED>TORCH_TRACE</H3>
									<DL><p>
										<DT><H3 FOLDED>Stack trie</H3>
										<DL><p>
											<DT><A HREF="https://web.mit.edu/~ezyang/Public/bhack-20240609-tlparse/index.html">https://web.mit.edu/~ezyang/Public/bhack-20240609-tlparse/index.html</A>
										</DL><p>
										<DT><H3 FOLDED>tlparser</H3>
										<DL><p>
											<DT><A HREF="https://github.com/meta-pytorch/tlparse">meta-pytorch/tlparse: TORCH_LOGS parser for PT2</A>
											<DT><A HREF="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/compile/programming_model.observability.html">tlparse / TORCH_TRACE ‚Äî PyTorch 2.10 documentation</A>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/compile/programming_model.observability.md">pytorch/docs/source/compile/programming_model.observability.md at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://www.youtube.com/watch?v=JE6kTSFkf-U">rm -rf /tmp/a &amp;&amp; TORCH_TRACE=/tmp/a TORCH_LOGS=dynamo python3</A>
										<DT><A HREF="https://x.com/kalomaze/status/2003665976848711777">If you are able to pull a tlparse (TORCH_TRACE=/tmp/dumpdir) from a sample run</A>
										<DT><A HREF="https://docs.pytorch.org/docs/stable/user_guide/torch_compiler/compile/programming_model.observability.html">tlparse / TORCH_TRACE ‚Äî PyTorch 2.10 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>TORCH_COMPILE_DEBUG=1</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_inductor_provenance.rst">pytorch/docs/source/torch.compiler_inductor_provenance.rst at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c">Walk through compile_fx - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>TORCH_LOGS</H3>
									<DL><p>
										<DT><H3 FOLDED>provenance-tracking</H3>
										<DL><p>
											<DT><A HREF="https://docs.pytorch.org/docs/stable/torch.compiler_inductor_provenance.html?utm_source=chatgpt.com">TorchInductor and AOTInductor Provenance Tracking ‚Äî PyTorch 2.8 documentation</A>
										</DL><p>
										<DT><H3 FOLDED>torch_logs-aot</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c&t=352s">Walk through compile_fx - YouTube</A>
										</DL><p>
										<DT><A HREF="https://github.com/ezyang/tlparse">ezyang/tlparse: TORCH_LOG parser for PT2</A>
										<DT><A HREF="https://twitter.com/johnowhitaker/status/1746275479806742664/photo/1">TORCH_LOGS="output_code" python compile_square.py</A>
										<DT><A HREF="https://github.com/ezyang/tlparse">ezyang/tlparse: TORCH_LOGS parser for PT2</A>
										<DT><A HREF="https://chatgpt.com/c/68e5276f-f538-8332-93a8-c8f60ec9d3b2">links generated kernels back to FX nodes `TORCH_LOGS="+inductor"`</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/402153d95aa20f8c1b625b11a99440e5fc38004f/docs/source/user_guide/torch_compiler/torch.compiler_troubleshooting.md?plain=1#L1022">pytorch/docs/source/user_guide/torch_compiler/torch.compiler_troubleshooting.md: Summary of TORCH_LOGS</A>
									</DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/torch-compile-can-be-debugged-now/1595">Torch.compile can be debugged now! - compiler - PyTorch Dev Discussions</A>
									<DT><A HREF="https://www.youtube.com/watch?v=w30xteQDeO8">Lightning Talk: PT2 Export - A Sound Full Graph Capture Mechanism for PyTorch - Avik Chaudhuri, Meta - YouTube</A>
									<DT><A HREF="https://github.com/youkaichao/hello_frame_eval">youkaichao/hello_frame_eval: A hello-world usage for frame eval api.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=LuhJEEJQgUM">Lecture 1 How to profile CUDA kernels in PyTorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_troubleshooting.rst">pytorch/docs/source/torch.compiler_troubleshooting.rst at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/torch-compile-can-be-debugged-now/1595">Torch.compile can be debugged now</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_troubleshooting.rst">pytorch/docs/source/torch.compiler_troubleshooting.rst</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/31c0467594c7c41c8e8ff1828bf01fa31fc4454f/docs/source/torch.compiler_troubleshooting.rst#L20">pytorch/docs/source/torch.compiler_troubleshooting.rst at 31c0467594c7c41c8e8ff1828bf01fa31fc4454f ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/alpha0422/study/blob/main/inductor/common.py">study/inductor/common.py at main ¬∑ alpha0422/study</A>
									<DT><A HREF="https://discuss.pytorch.org/t/getting-triton-to-generate-all-kernels/189173/4">Getting Triton to generate all kernels - torch.compile / torch._inductor - PyTorch Forums</A>
									<DT><A HREF="https://www.youtube.com/watch?v=JE6kTSFkf-U">Compile and export Zonos - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=682pQYiS4cQ">Fixing an PyTorch Inductor bug: Views, Buffers, Realize - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c">Walk through compile_fx - YouTube</A>
									<DT><A HREF="https://docs.pytorch.org/docs/stable/torch.compiler_inductor_provenance.html?utm_source=chatgpt.com">TorchInductor and AOTInductor Provenance Tracking ‚Äî PyTorch 2.8 documentation</A>
									<DT><A HREF="https://karthick.ai/blog/2025/Learn-By-Doing-Torchinductor-DeviceAssert/">Learn by doing: TorchInductor (DeviceAssert) | Karthick Panner Selvam</A>
								</DL><p>
								<DT><H3 FOLDED>depyf</H3>
								<DL><p>
									<DT><H3 FOLDED>depyf-dynamo</H3>
									<DL><p>
										<DT><A HREF="https://github.com/thuml/depyf/blob/master/docs/_static/images/dynamo-workflow.svg">dynamo-workflow.svg</A>
									</DL><p>
									<DT><A HREF="https://github.com/thuml/depyf">thuml/depyf: depyf is a tool to help you understand and adapt to PyTorch compiler torch.compile.</A>
									<DT><A HREF="https://pytorch.org/blog/introducing-depyf/">Introducing depyf: mastering torch.compile with ease | PyTorch</A>
									<DT><A HREF="https://github.com/thuml/depyf/blob/master/docs/walk_through.rst">depyf/docs/walk_through.rst at master ¬∑ thuml/depyf</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/interactively-explore-what-torch-compile-does-to-your-code/1576">Interactively explore what torch.compile does to your code! - compiler</A>
									<DT><A HREF="https://findhao.net/easycoding/2621">How to Debug PyTorch Compiler - FindHao</A>
									<DT><A HREF="https://depyf.readthedocs.io/en/latest/walk_through.html">A Walk Through Example of torch.compile ‚Äî depyf documentation</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-benchmark</H3>
								<DL><p>
									<DT><A HREF="https://hud.pytorch.org/benchmark/compilers">compilers</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/7eb2a99585b683e5486bfbf2e78c8165f08c392b/benchmarks/dynamo/microbenchmarks/microbench.py">pytorch/benchmarks/dynamo/microbenchmarks/microbench.py</A>
									<DT><A HREF="https://github.com/iree-org/iree-comparative-benchmark/blob/main/comparative_benchmark/pt_inductor/run_benchmarks.py">iree-comparative-benchmark/comparative_benchmark/pt_inductor/run_benchmarks.py at main ¬∑ iree-org/iree-comparative-benchmark</A>
									<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_inductor_profiling.html#benchmark-individual-triton-kernel">TorchInductor GPU Profiling ‚Äî PyTorch 2.4 documentation</A>
									<DT><A HREF="https://gist.github.com/Chillee/6f1a8995dc25c08b11494485d4a53460">Random Kernel Microbenchmarks softmax_quack.py</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-cache</H3>
								<DL><p>
									<DT><H3 FOLDED>Mega-Cache</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_caching_tutorial.html">Compile Time Caching in torch.compile ‚Äî PyTorch Tutorials 2.6.0+cu124 documentation</A>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/torch_compile_caching_tutorial.html">Compile Time Caching in torch.compile ‚Äî PyTorch Tutorials 2.7.0+cu126 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>TRITON_CACHE_DIR</H3>
									<DL><p>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/torch_compile_caching_configuration_tutorial.html?utm_source=chatgpt.com">Compile Time Caching Configuration ‚Äî PyTorch Tutorials 2.7.0+cu126 documentation</A>
									</DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-bring-compile-time-down-to-zero-our-plans-and-direction-may-14th-edition/2089">How To Bring Compile Time Down to Zero: Our Plans and Direction (May 14th Edition) - compiler - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_caching_tutorial.html">Compile Time Caching in torch.compile ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/remote-compilation-caching-system-testing/2179">Remote compilation caching system testing - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://github.com/siliconflow/nexfort-gpt/blob/6253c6bb054e658d67566150f87329b87815ae63/generate.py#L27">torch._inductor.config.fx_graph_cache = True</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/4bf583b51d5d5bc5232f6350f78c7822c0f07a78/onediff_diffusers_extensions/README.md#fast-lora-loading-and-switching">Compiled graph re-using</A>
								</DL><p>
								<DT><H3 FOLDED>fx-graph</H3>
								<DL><p>
									<DT><H3 FOLDED>fx_graph-debug</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c">Walk through compile_fx - YouTube</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docs/source/torch.compiler_inductor_provenance.rst">pytorch/docs/source/torch.compiler_inductor_provenance.rst</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c&t=736s">Walk through compile_fx - YouTube</A>
									<DT><A HREF="http://giantpandacv.com/project/PyTorch/%E7%94%A8%E6%B2%90%E7%A5%9E%E7%9A%84%E6%96%B9%E6%B3%95%E9%98%85%E8%AF%BBPyTorch%20FX%E8%AE%BA%E6%96%87/">Reading PyTorch FX Papers Using Mushen‚Äôs Method</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/different-points-at-which-fusion-occurs/2099">Different points at which fusion occurs? - compiler / FX - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://arxiv.org/pdf/2112.08429">TORCH.FX: PRACTICAL PROGRAM CAPTURE AND TRANSFORMATION FOR DEEP LEARNING IN PYTHON</A>
									<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_transformations.html">Writing Graph Transformations on ATen IR ‚Äî PyTorch 2.4 documentation</A>
									<DT><A HREF="https://github.com/pytorch/tutorials/blob/main/intermediate_source/fx_conv_bn_fuser.py">tutorials/intermediate_source/fx_conv_bn_fuser.py at main ¬∑ pytorch/tutorials</A>
									<DT><A HREF="https://www.youtube.com/watch?v=wCdTaL0X9Bg&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=5">A torch.fx Based Compression Toolkit Empowered by torch_musa - Fan Mo, Moore Threads - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-fusion</H3>
								<DL><p>
									<DT><A HREF="https://towardsdatascience.com/how-pytorch-2-0-accelerates-deep-learning-with-operator-fusion-and-cpu-gpu-code-generation-35132a85bd26">Operator Fusion &amp; Compilation</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-breaks</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sayakpaul/diffusers-torchao">Benefitting from torch.compile(): torchao &amp; diffusers</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-examples</H3>
								<DL><p>
									<DT><A HREF="https://github.com/thuml/learn_torch.compile">thuml/learn_torch.compile: torch.compile artifacts for common DNN</A>
									<DT><A HREF="https://github.com/xdit-project/xDiT/blob/94642cabbf570f159d8305f859fa018be4a0b561/xfuser/model_executor/pipelines/base_pipeline.py#L231">xDiT/xfuser/model_executor/pipelines/base_pipeline.py: _convert_transformer_backbone</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-export</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=w30xteQDeO8">PT2 Export - A Sound Full Graph Capture Mechanism</A>
									<DT><A HREF="https://www.youtube.com/watch?v=krwpwbH7NJc">PyTorch's Computational Graph</A>
									<DT><A HREF="https://github.com/microsoft/Olive">microsoft/Olive: Olive is an easy-to-use hardware-aware model optimization tool that composes industry-leading techniques across model compression, optimization, and compilation.</A>
									<DT><A HREF="https://pytorch.org/docs/stable/export.html">torch.export ‚Äî PyTorch 2.5 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>torch-compiler-einops</H3>
								<DL><p>
									<DT><A HREF="https://github.com/arogozhnikov/einops/wiki/Using-torch.compile-with-einops">Using torch.compile with einops ¬∑ arogozhnikov/einops Wiki</A>
								</DL><p>
								<DT><H3 FOLDED>torch-jit</H3>
								<DL><p>
									<DT><A HREF="https://strint.notion.site/torch-jit-trace-177dbc92e21d4c66ab8d208a2a86a27f">torch.jit.trace ÁÆÄÊûê</A>
								</DL><p>
								<DT><H3 FOLDED>torch-cortex</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/developer-docs-for-pytorch-inductor/1714">Developer docs for PyTorch inductor? - compiler - PyTorch Developer Mailing List</A>
								</DL><p>
								<DT><H3 FOLDED>torch-control-flow</H3>
								<DL><p>
									<DT><A HREF="https://blog.ezyang.com/2025/09/so-you-want-to-control-flow-in-pt2/">So you want to control flow in PT2 : ezyang‚Äôs blog</A>
								</DL><p>
								<DT><A HREF="https://github.com/thuml/depyf/blob/master/docs/walk_through.rst">depyf/docs/walk_through.rst at master ¬∑ thuml/depyf</A>
								<DT><A HREF="https://github.com/thuml/learn_torch.compile">thuml/learn_torch.compile: torch.compile artifacts for common deep learning models, can be used as a learning resource for torch.compile</A>
								<DT><A HREF="https://www.youtube.com/watch?v=kdZwgRghy3M">XLA Internal</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/functionalization-in-pytorch-everything-you-wanted-to-know/965">Functionalization in PyTorch: Everything You Wanted To Know - compiler - PyTorch Dev Discussions</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/min-cut-optimal-recomputation-i-e-activation-checkpointing-with-aotautograd/467">Min-cut optimal(*) recomputation (i.e. activation checkpointing) with AOTAutograd - compiler - PyTorch Dev Discussions</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/interactively-explore-what-torch-compile-does-to-your-code/1576">Interactively explore what torch.compile does to your code! - compiler</A>
								<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler.html#torch-compiler">torch.compiler ‚Äî PyTorch 2.3 documentation</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747">TorchInductor: a PyTorch-native Compiler with Define-by-Run IR and Symbolic Shapes</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/i-build-a-decompiler-to-convert-bytecode-generated-by-dynamo-into-readable-source-code/1471/4">I build a decompiler to convert bytecode generated by dynamo into readable source code</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-capture-nccl-communication-ops-in-faketensormode/1410">How to capture NCCL communication ops in FakeTensorMode</A>
								<DT><A HREF="https://pytorch.org/docs/stable/fx.html">torch.fx ‚Äî PyTorch 2.1 documentation</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/torch-compile-tech-talks-at-ptc23/1625">Torch.compile() tech talks at PTC'23</A>
								<DT><A HREF="https://www.youtube.com/watch?v=krwpwbH7NJc">PyTorch's Computational Graph</A>
								<DT><A HREF="https://www.youtube.com/watch?v=w30xteQDeO8">PT2 Export - A Sound Full Graph Capture Mechanism</A>
								<DT><A HREF="https://peps.python.org/pep-0523/">PEP 523 ‚Äì Adding a frame evaluation API to CPython | peps.python.org</A>
								<DT><A HREF="https://huggingface.co/spaces/PixArt-alpha/PixArt-alpha/blob/main/app.py">HF Transformer simple example</A>
								<DT><A HREF="https://github.com/thuml/depyf">thuml/depyf: understand and adapt to PyTorch compiler</A>
								<DT><A HREF="https://github.com/thuml/learn_torch.compile">thuml/learn_torch.compile: torch.compile artifacts for common deep learning models</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/functionalization-in-pytorch-everything-you-wanted-to-know/965">Functionalization in PyTorch: Everything You Wanted To Know</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/min-cut-optimal-recomputation-i-e-activation-checkpointing-with-aotautograd/467">Min-cut optimal(*) recomputation (i.e. activation checkpointing) with AOTAutograd - compiler</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/interactively-explore-what-torch-compile-does-to-your-code/1576">Interactively explore what torch.compile does to your code</A>
								<DT><A HREF="https://peps.python.org/pep-0523/">PEP 523 ‚Äì Adding a frame evaluation API to CPython</A>
								<DT><A HREF="https://www.youtube.com/watch?v=mEYzE1iIEDI">Composability sync - Hierarchical compilation, torchrec PT2, NF4, accuracy - YouTube</A>
								<DT><A HREF="https://en.cppreference.com/w/c/numeric/math/fma">fma, fmaf, fmal - cppreference.com</A>
								<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with torch.compile ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
								<DT><A HREF="https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html">Introduction to torch.compile ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-bring-compile-time-down-to-zero-our-plans-and-direction-may-14th-edition/2089">How To Bring Compile Time Down to Zero: Our Plans and Direction (May 14th Edition) - compiler - PyTorch Developer Mailing List</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/how-can-i-dump-the-prims-ir-triton-code-and-ptx-code-when-using-torch-compile/2057">How can I dump the prims IR, triton code, and ptx code when using torch.compile() - compiler - PyTorch Developer Mailing List</A>
								<DT><A HREF="https://github.com/Lightning-AI/lightning-thunder">Lightning-AI/lightning-thunder: Make PyTorch models up to 40% faster! Thunder is a source to source compiler for PyTorch. It enables using different hardware executors at once; across one or thousands of GPUs.</A>
								<DT><A HREF="https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/96ad88eb476f41a5403dcdade086afb8/torch_compile_tutorial.ipynb">torch_compile_tutorial.ipynb - Colab</A>
								<DT><A HREF="https://blog.christianperone.com/wp-content/uploads/2023/12/talk_torch_v2.pdf">PyTorch 2 internals</A>
								<DT><A HREF="https://www.youtube.com/watch?v=139UPjoq7Kw&t=3115s">Building Machine Learning Systems for a Trillion Trillion Floating Point Operations - YouTube</A>
								<DT><A HREF="https://github.com/xdit-project/xDiT/blob/21dcdcf1fbf427d2b8a39f37110efadc38ef9ed1/xfuser/model_executor/pipelines/base_pipeline.py#L409">xDiT/xfuser/model_executor/pipelines/base_pipeline.py</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/03c4c4aa9deb2ad09a95c7997d2e5578c8db68d6/vllm/compilation/backends.py">vllm/vllm/compilation/backends.py</A>
								<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=1aEFHpF69Lc">[vLLM Office Hours #26] Intro to torch.compile and how it works with vLLM - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>torch-numerics</H3>
							<DL><p>
								<DT><H3 FOLDED>fx_traceback.annotate</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/a51208c656fb3e9a8b091a4d181f9a9cda783c04/torch/fx/passes/regional_inductor.py#L167">pytorch/torch/fx/passes/regional_inductor.py at a51208c656fb3e9a8b091a4d181f9a9cda783c04 ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>torch-quantization</H3>
								<DL><p>
									<DT><H3 FOLDED>Transformer Engine</H3>
									<DL><p>
										<DT><H3 FOLDED>te-blackwell</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/pull/1418/files">Initial Support Blackwell Build by johnnynunez ¬∑ Pull Request #1418 ¬∑ NVIDIA/TransformerEngine</A>
											<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/1747">B200 Slow GEMM (16384, 1024, 8192) Only when run in a particular order ¬∑ Issue #1747 ¬∑ NVIDIA/TransformerEngine</A>
										</DL><p>
										<DT><H3 FOLDED>te-fp4</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/pull/2177/files">[Core][PyTorch] NVFP4 recipe by ksivaman ¬∑ Pull Request #2177 ¬∑ NVIDIA/TransformerEngine</A>
										</DL><p>
										<DT><A HREF="https://github.com/cchan/nanoGPT-fp8">cchan/nanoGPT-fp8</A>
										<DT><A HREF="https://twitter.com/itsclivetime/status/1655515089506820097">(1) Clive Chan en Twitter: "WIP FP8 training on consumer graphics cards - üßµ/4 I hacked nanoGPT to use TransformerEngine on RTX 4090 and ran a few iterations of GPT-2 training: - nanoGPT Block (+flashattn) =&amp;gt; TE TransformerLayer (both BF16): 15% faster - BF16 =&amp;gt; FP8: additional +18% https://t.co/cJNWehoGeu" / Twitter</A>
										<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/blob/main/docs/examples/te_llama/tutorial_accelerate_hf_llama_with_te.ipynb">TransformerEngine/docs/examples/te_llama/tutorial_accelerate_hf_llama_with_te.ipynb</A>
										<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/15">Ada Lovelace support</A>
										<DT><A HREF="https://github.com/NVIDIA/TransformerEngine">NVIDIA/TransformerEngine: A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.</A>
										<DT><A HREF="http://giantpandacv.com/project/CUDA/%E8%AF%A6%E8%A7%A3%20NVIDIA%20H100%20TransformerEngine/">ËØ¶Ëß£ NVIDIA H100 TransformerEngine - GiantPandaCV</A>
										<DT><A HREF="https://github.com/NVIDIA/Model-Optimizer/blob/0f05d676d36eb7fc2bb5a5d67f44b6b9e10ce7ad/tests/gpu/torch/quantization/plugins/test_transformer_engine.py#L28">Model-Optimizer/tests/gpu/torch/quantization/plugins/test_transformer_engine.py at 0f05d676d36eb7fc2bb5a5d67f44b6b9e10ce7ad ¬∑ NVIDIA/Model-Optimizer</A>
									</DL><p>
									<DT><H3 FOLDED>torchao</H3>
									<DL><p>
										<DT><H3 FOLDED>torch-block_scaling</H3>
										<DL><p>
											<DT><A HREF="https://docs.nvidia.com/cuda/cublas/">1D Block Scaling for FP8 and FP4 Data Types</A>
											<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=61">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>ao-fp4</H3>
										<DL><p>
											<DT><H3 FOLDED>nvfp4</H3>
											<DL><p>
											</DL><p>
											<DT><A HREF="https://github.com/antferdom/cortex/blob/e3fec5fae80f1ec49ce738db1f8b9d59dd7b7d5e/tests/ao/test_fp4.py#L12">cortex/tests/ao/test_fp4.py</A>
											<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=64">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
											<DT><A HREF="https://github.com/pytorch/ao/blob/315e9b4555f2245bb452b9e22f485419188ce8b4/torchao/prototype/mx_formats/nvfp4_tensor.py#L676">ao/torchao/prototype/mx_formats/nvfp4_tensor.py: nvfp4_quantize</A>
											<DT><A HREF="https://gist.github.com/Maharshi-Pandya/fa92c0b01ab684a413c73237334c9d48">NVFP4 quantization in torch with bit shifts</A>
											<DT><A HREF="https://docs.nvidia.com/cuda/cublas/index.html#d-block-quantization">Computing scaling and conversion factors for FP8 with UE8M0 scales</A>
											<DT><A HREF="https://arxiv.org/pdf/2509.25149">Pretraining Large Language Models with NVFP4</A>
											<DT><A HREF="https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf">OCP Microscaling Formats (MX) Specification</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/test/test_scaled_matmul_cuda.py#L1798">pytorch/test/test_scaled_matmul_cuda.py at main ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://www.kapilsharma.dev/mxfp4/">MXFP4 Visualizer | Kapil Sharma</A>
											<DT><A HREF="https://www.kapilsharma.dev/posts/mxfp4-visualizer/">Understanding MXFP4 Quantization | Kapil Sharma</A>
											<DT><A HREF="https://x.com/mrsiipa/status/1986152319004856491">NVFP4 quantization procedure</A>
											<DT><A HREF="https://veitner.bearblog.dev/nvfp4-gemv-improved/">NVFP4 GEMV improved | simons blog</A>
											<DT><A HREF="https://github.com/meta-pytorch/MSLK/blob/main/test/gemm/gemm_test.py">MSLK/test/gemm/gemm_test.py at main ¬∑ meta-pytorch/MSLK</A>
											<DT><A HREF="https://github.com/pytorch/ao/blob/main/benchmarks/float8/float8_inference_roofline.py">ao/benchmarks/float8/float8_inference_roofline.py at main ¬∑ pytorch/ao</A>
											<DT><A HREF="https://github.com/ModelTC/LightX2V/blob/main/lightx2v_kernel/docs/en_US/nvfp4_quantization_basics.md">LightX2V/lightx2v_kernel/docs/en_US/nvfp4_quantization_basics.md at main ¬∑ ModelTC/LightX2V</A>
											<DT><A HREF="https://github.com/ModelTC/LightX2V/blob/main/lightx2v_kernel/docs/en_US/mx_formats_quantization_basics.md">LightX2V/lightx2v_kernel/docs/en_US/mx_formats_quantization_basics.md at main ¬∑ ModelTC/LightX2V</A>
											<DT><A HREF="https://github.com/ModelTC/LightX2V/tree/main/lightx2v_kernel/csrc/gemm">LightX2V/lightx2v_kernel/csrc/gemm at main ¬∑ ModelTC/LightX2V</A>
											<DT><A HREF="https://x.com/cHHillee/status/2000091700136693761">(1) Horace He en X: "From a game of ML Infra jeopardy we played https://t.co/NFEWBtckos" / X</A>
											<DT><A HREF="https://www.radicalnumerics.ai/blog/nvfp4-part1#the-nvfp4-recipe">NVFP4 Pretraining: From Theory to Implementation (Part 1) ¬∑ Radical Numerics</A>
											<DT><A HREF="https://github.com/Overworldai/world_engine/blob/main/src/quantize.py">world_engine/src/quantize.py fp4_linear torch.librerary.custom_op</A>
										</DL><p>
										<DT><H3 FOLDED>ao-fp8</H3>
										<DL><p>
											<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/d51243e946b25e437ba02e2c9d1aaad08da17c93/benchmarks/profile_fp8_matmul.py">transformer_nuggets/benchmarks/profile_fp8_matmul.py at d51243e946b25e437ba02e2c9d1aaad08da17c93 ¬∑ drisspg/transformer_nuggets</A>
											<DT><A HREF="https://github.com/stas00/ml-engineering/pull/111/files#diff-5c3320b045743bb91449430d7ecc32e2eae04aaa773ebf5b711aae603e36f9b6R291">[mamf-finder] add mxfp8 support by stas00 ¬∑ Pull Request #111 ¬∑ stas00/ml-engineering</A>
											<DT><A HREF="https://github.com/pytorch/ao/issues/3290">FP8 Blockwise Training Tracker ¬∑ Issue #3290 ¬∑ pytorch/ao</A>
											<DT><A HREF="https://blog.fal.ai/chasing-6-tb-s-an-mxfp8-quantizer-on-blackwell/">Chasing 6+ TB/s: an MXFP8 quantizer on Blackwell</A>
										</DL><p>
										<DT><H3 FOLDED>triton-quant</H3>
										<DL><p>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/2bb88ffaab57ea7c86d4f844493ce76abb3d3f71/python/triton_kernels/triton_kernels/matmul_ogs.py#L118">triton/python/triton_kernels/triton_kernels/matmul_ogs.py</A>
											<DT><A HREF="https://github.com/search?q=repo%3Aopenai%2Fgpt-oss%20triton_kernels&type=code">gpt-oss triton_kernels</A>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/2bb88ffaab57ea7c86d4f844493ce76abb3d3f71/python/triton_kernels/triton_kernels/numerics.py">triton/python/triton_kernels/triton_kernels/numerics.py</A>
											<DT><A HREF="https://github.com/triton-lang/kernels">triton-lang/kernels</A>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/2bb88ffaab57ea7c86d4f844493ce76abb3d3f71/python/triton_kernels/tests/test_mxfp.py">triton/python/triton_kernels/tests/test_mxfp.py at 2bb88ffaab57ea7c86d4f844493ce76abb3d3f71 ¬∑ triton-lang/triton</A>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/2bb88ffaab57ea7c86d4f844493ce76abb3d3f71/python/triton_kernels/triton_kernels/tensor_details/layout_details/blackwell_scale.py">triton/python/triton_kernels/triton_kernels/tensor_details/layout_details/blackwell_scale.py at 2bb88ffaab57ea7c86d4f844493ce76abb3d3f71 ¬∑ triton-lang/triton</A>
											<DT><A HREF="https://github.com/openai/gpt-oss/blob/b5cc884079145a112c2c840790dcb8dd2fc6425e/gpt_oss/triton/moe.py#L18">gpt-oss/gpt_oss/triton/moe.py at b5cc884079145a112c2c840790dcb8dd2fc6425e ¬∑ openai/gpt-oss</A>
										</DL><p>
										<DT><H3 FOLDED>torchao-quant-error</H3>
										<DL><p>
											<DT><H3 FOLDED>SNR</H3>
											<DL><p>
												<DT><A HREF="https://en.wikipedia.org/wiki/Signal-to-noise_ratio">Signal-to-noise ratio - Wikipedia</A>
											</DL><p>
											<DT><A HREF="https://github.com/antferdom/cortex/blob/e3fec5fae80f1ec49ce738db1f8b9d59dd7b7d5e/tests/ao/test_fp4.py#L12">def compute_error(x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor: error in dB S2N ratio</A>
										</DL><p>
										<DT><H3 FOLDED>tensorRT-modelopt</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-Model-Optimizer">NVIDIA/TensorRT-Model-Optimizer: nvidia-modelopt is a unified library of state-of-the-art model optimization techniques like quantization, pruning, distillation, speculative decoding, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM or TensorRT to optimize inference speed.</A>
										</DL><p>
										<DT><H3 FOLDED>QuTLASS</H3>
										<DL><p>
											<DT><A HREF="https://x.com/DAlistarh/status/1965157635617087885">Dan Alistarh en X: "üöÄ Excited to announce QuTLASS v0.1.0 üéâ QuTLASS is a high-performance library for low-precision deep learning kernels, following NVIDIA CUTLASS. The new release brings 4-bit NVFP4 microscaling and fast transforms to NVIDIA Blackwell GPUs (including the B200!) [1/N] https://t.co/QGs5vBuAem" / X</A>
											<DT><A HREF="https://github.com/IST-DASLab/qutlass">IST-DASLab/qutlass: QuTLASS: CUTLASS-Powered Quantized BLAS for Deep Learning</A>
										</DL><p>
										<DT><A HREF="https://docs.nvidia.com/cuda/cublas/">1D Block Scaling for FP8 and FP4 Data Types</A>
										<DT><A HREF="https://github.com/pytorch-labs/ao/issues/47">[RFC] Plans for torchao ¬∑ Issue #47 ¬∑ pytorch-labs/ao</A>
										<DT><A HREF="https://www.youtube.com/watch?v=Up0EfrudTSQ&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=61">mxfp8, mxfp4, nvfp4 formats and applications in PyTorch - Vasily Kuznetsov &amp; Driss Guessous, Meta - YouTube</A>
										<DT><A HREF="https://github.com/pytorch-labs/ao">pytorch-labs/ao: api's and workflows for quantization and pruning gpu models.</A>
										<DT><A HREF="https://github.com/pytorch-labs/applied-ai">pytorch-labs/applied-ai: Applied AI experiments and examples for PyTorch</A>
										<DT><A HREF="https://pytorch.org/blog/accelerating-generative-ai-2/">Accelerating Generative AI with PyTorch II: GPT, Fast | PyTorch</A>
										<DT><A HREF="https://github.com/pytorch/ao">pytorch/ao: Create and integrate custom data types, layouts and kernels with up to 2x speedups with 65% less VRAM for inference and training</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/srt/layers/torchao_utils.py">sglang/python/sglang/srt/layers/torchao_utils.py at main ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/pytorch/benchmark/blob/main/userbenchmark/torchao/install.py">benchmark/userbenchmark/torchao/install.py</A>
										<DT><A HREF="https://github.com/microsoft/microxcaling?tab=readme-ov-file#Spec-Configuration">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
										<DT><A HREF="https://github.com/mobiusml/gemlite">mobiusml/gemlite: Fast low-bit matmul kernels in Triton</A>
										<DT><A HREF="https://github.com/pytorch/FBGEMM/tree/main/fbgemm_gpu/experimental/gen_ai">FBGEMM/fbgemm_gpu/experimental/gen_ai at main ¬∑ pytorch/FBGEMM</A>
										<DT><A HREF="https://github.com/pytorch/ao/blob/4d1c7741842a1dfbd479b3481fcdc93c64db703e/torchao/dtypes/floatx/float8_layout.py#L279">ao/torchao/dtypes/floatx/float8_layout.py preprocess_data</A>
										<DT><A HREF="https://developer.nvidia.com/blog/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/">NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit | NVIDIA Technical Blog</A>
										<DT><A HREF="https://x.com/HuggingPapers/status/1985198366293160311">Bytedn INT v.s. FP</A>
										<DT><A HREF="https://x.com/elonmusk/status/1987885633004831109">(1) Elon Musk en X: "@itsclivetime AI is moving to primarily 4 bit weights. Int4 for Tesla inference. Like a physical address, which has state, city and street. If you already know the state and city, only street need be specified. You still get the precision you need with far fewer bits." / X</A>
										<DT><A HREF="https://r0m1t.com/fp8forllms.html">Mechanics of FP8 for LLMs</A>
										<DT><A HREF="https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf">OCP Microscaling Formats (MX) Specification</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Defeating Nondeterminism in LLM Inference - Thinking Machines Lab</A>
								<DT><A HREF="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">A postmortem of three recent issues \ Anthropic</A>
								<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
								<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/sample-workload.html">Running a Sample Workload ‚Äî NVIDIA Container Toolkit</A>
								<DT><A HREF="https://zcnrex.github.io/2024/02/04/low-precision-numeric-data-types.html">Low Precision Numeric Data Types | Rex‚Äôs Blog</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72458/">Blackwell Numerics for AI S72458 | GTC 2025 | NVIDIA On-Demand</A>
							</DL><p>
							<DT><H3 FOLDED>torch-internals</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-internals-notes</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=txxSXeBwp18&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=150">Lifecycle of a Parameter - Philip Bontrager, Meta - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>ATen</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-autograd</H3>
									<DL><p>
										<DT><A HREF="https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation">Automatic differentiation - Wikipedia</A>
										<DT><A HREF="https://x.com/i/bookmarks?post_id=1803963383018066272">94 lines of code are everything that is needed</A>
										<DT><A HREF="https://www.youtube.com/watch?v=dEnUP6_kpeo">04 PyTorch tutorial - How do computational graphs and autograd in PyTorch work - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=MswxJw-8PvE">PyTorch Autograd Explained - In-depth Tutorial - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=ne99laPUxN4">The Simple Essence of Automatic Differentiation - Conal Elliott - YouTube</A>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-read-the-autograd-codebase/383">How to read the autograd codebase - frontend API - PyTorch Dev Discussions</A>
										<DT><A HREF="https://www.youtube.com/watch?v=S7VG-0Tw6a4">Building an autograd engine with only Triton GPU kernels - live 2025.1.28 - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=MswxJw-8PvE&t=2s">PyTorch Autograd Explained - In-depth Tutorial - YouTube</A>
										<DT><A HREF="https://x.com/StasBekman/status/1998490033813336173">torch.autograd.detect_anomaly()</A>
										<DT><A HREF="https://github.com/AndreSlavescu/mHC.cu/blob/main/src/python/mhc/ops.py">mHC.cu/src/python/mhc/ops.py at main ¬∑ AndreSlavescu/mHC.cu</A>
									</DL><p>
									<DT><H3 FOLDED>torch-tensor</H3>
									<DL><p>
										<DT><H3 FOLDED>torch-tensor-manipulation</H3>
										<DL><p>
											<DT><A HREF="https://x.com/francoisfleuret/status/1986854483238724045">r = (2*c.cumsum(0)-c-1)[i] - torch.arange(x.numel(), device=x.device)</A>
										</DL><p>
										<DT><H3 FOLDED>torch-dtypes</H3>
										<DL><p>
											<DT><H3 FOLDED>Floating-Point Numbers</H3>
											<DL><p>
												<DT><A HREF="https://www.youtube.com/watch?v=PhYeUg1zXq4">An In-Depth Look at Floating-Point Numbers - YouTube</A>
												<DT><A HREF="https://www.youtube.com/watch?v=d1LNUvkRMEg&t=13076s">GPT-2 from Scratch in C (Day 1/2) - YouTube</A>
											</DL><p>
											<DT><H3 FOLDED>torch-fp8</H3>
											<DL><p>
												<DT><A HREF="https://github.com/facebookexperimental/protoquant">facebookexperimental/protoquant: Prototype routines for GPU quantization written using PyTorch.</A>
												<DT><A HREF="https://pytorch.org/docs/stable/quantization.html">Quantization ‚Äî PyTorch 2.0 documentation</A>
												<DT><A HREF="https://github.com/pytorch/pytorch/pull/109168">Basic fp8 support in Inductor</A>
												<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/53b48f35ad87603df882d036c1a2e3f7d88f2bd8/kernels/needs_perf_help/fp8_gemm_bench.py#L102">applied-ai/kernels/needs_perf_help/fp8_gemm_bench.py</A>
												<DT><A HREF="https://github.com/Azure/MS-AMP">Azure/MS-AMP: Microsoft Automatic Mixed Precision Library</A>
												<DT><A HREF="https://github.com/vllm-project/llm-compressor">vllm-project/llm-compressor</A>
												<DT><A HREF="https://github.com/neuralmagic/AutoFP8">neuralmagic/AutoFP8</A>
												<DT><A HREF="https://x.com/i/bookmarks?post_id=1815769704415342890">Neural Magic: vLLM Llama-3.1-405B FP8</A>
												<DT><A HREF="https://github.com/vllm-project/vllm/pull/4749">[Kernel] Add w8a8 CUTLASS kernels by tlrmchlsmth ¬∑ Pull Request #4749 ¬∑ vllm-project/vllm</A>
												<DT><A HREF="https://github.com/vllm-project/vllm/pull/5975">[Kernel] Expand FP8 support to Ampere GPUs using FP8 Marlin by mgoin ¬∑ Pull Request #5975 ¬∑ vllm-project/vllm</A>
												<DT><A HREF="https://github.com/vllm-project/vllm/pull/6559">[ Misc ] `fbgemm` checkpoints by robertgshaw2-neuralmagic ¬∑ Pull Request #6559 ¬∑ vllm-project/vllm</A>
												<DT><A HREF="https://gist.github.com/wkcn/232d2cf8d50e15cdb38be3e577cc4e3a">FP8GEMM</A>
												<DT><A HREF="https://arxiv.org/pdf/2303.17951">FP8 versus INT8 for efficient deep learning inference</A>
												<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/main/transformer_nuggets/fp8/scaled_quant.py">transformer_nuggets/transformer_nuggets/fp8/scaled_quant.py at main ¬∑ drisspg/transformer_nuggets</A>
												<DT><A HREF="https://01-ai.github.io/blog.html?post=zh/2024-07-30-%E5%A4%A7%E6%A8%A1%E5%9E%8B%20FP8%20%E4%BD%8E%E7%B2%BE%E5%BA%A6%E9%87%8F%E5%8C%96%E6%8E%A8%E7%90%86.md">Â§ßÊ®°Âûã FP8 ‰ΩéÁ≤æÂ∫¶ÈáèÂåñÊé®ÁêÜ - 01.AI Blog</A>
												<DT><A HREF="https://arxiv.org/abs/2209.05433">[2209.05433] FP8 Formats for Deep Learning</A>
												<DT><A HREF="https://dev-discuss.pytorch.org/t/float8-in-pytorch-1-x/1815">Float8 in PyTorch [1/x] - PyTorch Developer Mailing List</A>
												<DT><A HREF="https://kuterdinel.com/float-gallery.html">Float Gallery</A>
												<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/">Stable and Scalable FP8 Deep Learning Training on Blackwell S72778 | GTC 2025 | NVIDIA On-Demand</A>
											</DL><p>
											<DT><H3 FOLDED>torch-bfloat16</H3>
											<DL><p>
												<DT><A HREF="https://dev-discuss.pytorch.org/t/summation-bfloat16/390">Summation bfloat16 - documentation - PyTorch Developer Mailing List</A>
												<DT><A HREF="https://www.youtube.com/watch?v=B1eFGn5nN84">Are Numerical Linear Algebra Algorithms Accurate at Extreme Scale and at Low Precisions?</A>
												<DT><A HREF="https://x.com/_xjdr/status/1817612850820788557">(1) xjdr en X: "I should probably explain this madness: numpy doesn't natively support bfloat16 but most (good) models are trained in it. If you are using torch or huggingface and you need to convert to something else (like jax as the gods intended) then you are going to have to copy, throw it https://t.co/SB6ISHTIrg" / X</A>
												<DT><A HREF="https://x.com/_xjdr/status/1817604436887498884">(1) xjdr en X: "protip for working with bfloat16 with torch and numpy bf16_np = param.cpu().view(dtype=torch.uint16).numpy().view(ml_dtypes.bfloat16)" / X</A>
												<DT><A HREF="https://github.com/jax-ml/ml_dtypes">jax-ml/ml_dtypes: A stand-alone implementation of several NumPy dtype extensions used in machine learning.</A>
												<DT><A HREF="https://x.com/torchcompiled/status/1862096374864687331">Ethan üá¶üá∫ en X: "it's crazy to me that RoPE's issue with BF16 wasn't noticed earlier. For a reasonable N of 2048, these are the computed frequencies prior to cos(x) &amp;amp; sin(x) for fp32 above and bf16 below. At small values there is little loss of precision, but for larger values the difference is https://t.co/HoHrudJEj9" / X</A>
												<DT><A HREF="https://x.com/cloneofsimo/status/1862167638061023376">Simo Ryu en X: "Jesus christ, the problem is worse with 2d RoPE. Left is RoPE with bfloat visualized, (for w axis info, last half of RoPE) Right is float32 visualized. https://t.co/UzR0EO4V6l" / X</A>
											</DL><p>
											<DT><H3 FOLDED>floats</H3>
											<DL><p>
												<DT><A HREF="https://kuterdinel.com/float-gallery.html">Float Gallery</A>
												<DT><A HREF="http://www.johngustafson.net/pdfs/BeatingFloatingPoint.pdf">‚Äéwww.johngustafson.net/pdfs/BeatingFloatingPoint.pdf</A>
												<DT><A HREF="https://zhuanlan.zhihu.com/p/587687376">How to understand floating point numbers in a simple way?</A>
												<DT><A HREF="https://www.quant.exposed/">Quant Exposed</A>
												<DT><A HREF="https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf">OCP MX FP spec</A>
												<DT><A HREF="https://float.exposed/0x69a1e181">Float Exposed</A>
												<DT><A HREF="https://x.com/HuggingPapers/status/1985198366293160311">(1) DailyPapers en X: "ByteDance challenges prevailing AI hardware trends on Hugging Face! New research "INT v.s. FP" on fine-grained low-bit quantization reveals MXINT8 is superior to MXFP8 in both accuracy &amp;amp; efficiency, suggesting a shift from floating-point to integer formats for future AI https://t.co/XlBfnA0dsQ" / X</A>
												<DT><A HREF="https://www.kapilsharma.dev/mxfp4/">MXFP4 Visualizer | Kapil Sharma</A>
												<DT><A HREF="https://www.kapilsharma.dev/posts/mxfp4-visualizer/">Understanding MXFP4 Quantization | Kapil Sharma</A>
												<DT><A HREF="https://x.com/itsclivetime/status/1987736564731134071">(1) Clive Chan en X: "Floats are complex, but they‚Äôre often cheaper in silicon! They‚Äôre made of two *smaller* integers (exp, mant), and E4M3 FP8 mul is dominated by the 4b mantissa mul which is far smaller than an INT8 mul. (INT8 is also a worse fit for typical weight/act distributions.)" / X</A>
												<DT><A HREF="https://x.com/elonmusk/status/1987618109524783491">‚ÄúFloating point‚Äù is not real. It is emulated with 2 integers and a lot of complexity.</A>
												<DT><A HREF="https://fabiensanglard.net/floating_point_visually_explained/">Floating Point Visually Explained</A>
												<DT><A HREF="https://zcnrex.github.io/2024/02/04/low-precision-numeric-data-types.html">Low Precision Numeric Data Types | Rex‚Äôs Blog</A>
											</DL><p>
											<DT><A HREF="https://pytorch.org/docs/stable/tensors.html">torch.Tensor ‚Äî PyTorch 2.2 documentation</A>
											<DT><A HREF="https://dev-discuss.pytorch.org/t/summation-bfloat16/390/2">Summation bfloat16 - documentation - PyTorch Developer Mailing List</A>
											<DT><A HREF="http://giantpandacv.com/project/CUDA/%E5%9C%A8OneFlow%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%87%AA%E5%8A%A8%E6%8F%90%E5%8D%87/">torch dtypes promotion procedure</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/csrc/api/include/torch/types.h">pytorch/torch/csrc/api/include/torch/types.h at main ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>torch-row-major</H3>
										<DL><p>
											<DT><A HREF="https://research.colfax-intl.com/tutorial-python-binding-for-cuda-libraries-in-pytorch/">Tutorial: Python bindings for CUDA libraries in PyTorch ‚Äì Colfax Research</A>
										</DL><p>
										<DT><H3 FOLDED>torch.tensor.subclasses</H3>
										<DL><p>
											<DT><H3 FOLDED>Module Swaps</H3>
											<DL><p>
												<DT><A HREF="https://docs.pytorch.org/ao/stable/subclass_basic.html">Writing Your Own Quantized Tensor ‚Äî torchao 0.13 documentation</A>
												<DT><A HREF="https://github.com/pytorch/ao/blob/main/tutorials/examples/quantized_module_swap.py">ao/tutorials/examples/quantized_module_swap.py at main ¬∑ pytorch/ao</A>
												<DT><A HREF="https://github.com/Overworldai/world_engine/blob/main/src/quantize.py">for name, child in model.named_children(): quantize layers</A>
											</DL><p>
											<DT><H3 FOLDED>__torch_dispatch__</H3>
											<DL><p>
												<DT><A HREF="https://dev-discuss.pytorch.org/t/what-and-why-is-torch-dispatch/557">What (and Why) is __torch_dispatch__? - frontend API - PyTorch Developer Mailing List</A>
												<DT><A HREF="https://colab.research.google.com/drive/1zjAisRrc8R6uixKsrs1DRm3lwz5MWN68?usp=sharing#scrollTo=f8dqgcNmQEVq">Tensor_subclasses.ipynb - Colab</A>
												<DT><A HREF="https://docs.pytorch.org/docs/stable/notes/extending.html#extending-torch-native-api">Extending PyTorch ‚Äî PyTorch 2.8 documentation</A>
												<DT><A HREF="http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/">Let‚Äôs talk about the PyTorch dispatcher : ezyang‚Äôs blog</A>
												<DT><A HREF="https://www.youtube.com/watch?v=_qB2Ho1O3u4&t=8s">PyTorch Developer Podcast - Dispatcher Questions - YouTube</A>
												<DT><A HREF="https://gist.github.com/malfet/3a0925b69ba69567bab13b2fc6cc4bee">bench-dispatch.py</A>
											</DL><p>
											<DT><A HREF="https://colab.research.google.com/drive/1zjAisRrc8R6uixKsrs1DRm3lwz5MWN68#scrollTo=3KS38qNL0-E5">Tensor_subclasses.ipynb - Colab</A>
											<DT><A HREF="https://docs.pytorch.org/ao/stable/subclass_basic.html">Writing Your Own Quantized Tensor ‚Äî torchao 0.13 documentation</A>
											<DT><A HREF="https://docs.pytorch.org/docs/stable/notes/extending.html#extending-torch-with-a-tensor-like-type">Extending PyTorch ‚Äî PyTorch 2.8 documentation</A>
											<DT><A HREF="https://github.com/albanD/subclass_zoo">albanD/subclass_zoo</A>
											<DT><A HREF="https://podcasts.apple.com/us/podcast/tensor-subclasses-and-pt2/id1566080008?i=1000646728968">Tensor subclass podcast by Edward Yang</A>
											<DT><A HREF="https://github.com/pytorch/ao/blob/main/tutorials/examples/quantized_module_swap.py">ao/tutorials/examples/quantized_module_swap.py at main ¬∑ pytorch/ao</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/distributed/tensor/_api.py#L217">pytorch/torch/distributed/tensor/_api.py at main ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/ao/blob/v0.8.0/torchao/dtypes/affine_quantized_tensor.py#L46">ao/torchao/dtypes/affine_quantized_tensor.py at v0.8.0 ¬∑ pytorch/ao</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/nested/_internal/nested_tensor.py#L53">pytorch/torch/nested/_internal/nested_tensor.py at main ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://docs.pytorch.org/ao/stable/subclass_advanced.html">Writing Your Own Quantized Tensor (advanced) ‚Äî torchao 0.13 documentation</A>
											<DT><A HREF="https://github.com/albanD/subclass_zoo/blob/main/uint4_tensor.py">subclass_zoo/uint4_tensor.py at main ¬∑ albanD/subclass_zoo</A>
										</DL><p>
										<DT><H3 FOLDED>torch-tensor-render</H3>
										<DL><p>
											<DT><A HREF="https://gist.github.com/ezyang/15791ae363900f42c704c09ca34346e3">Matrix-of-matrices tensor render</A>
											<DT><A HREF="https://blog.ezyang.com/2025/10/draw-high-dimensional-tensors-as-a-matrix-of-matrices/">Draw high dimensional tensors as a matrix of matrices : ezyang‚Äôs blog</A>
											<DT><A HREF="https://x.com/ezyang/status/1982132802674974964">(2) Edward Z. Yang en X: "A small thread about how you should be drawing the contents of higher dimensional tensors https://t.co/DaU3r1ASk5" / X</A>
										</DL><p>
										<DT><A HREF="http://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals : ezyang‚Äôs blog</A>
										<DT><A HREF="http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/">PyTorch dispatcher</A>
										<DT><A HREF="http://blog.ezyang.com/2020/05/a-brief-taxonomy-of-pytorch-operators-by-shape-behavior/">A brief taxonomy of PyTorch operators by shape behavior : ezyang‚Äôs blog</A>
										<DT><A HREF="https://ezyang.github.io/stride-visualizer/index.html">STRIDE Visualizer</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/c10/core/TensorImpl.h">TensorImpl.h at main</A>
										<DT><A HREF="https://theaisummer.com/einsum-attention/">Einsum: Transformer example</A>
										<DT><A HREF="https://pytorch.org/blog/a-tour-of-pytorch-internals-1/">A Tour of PyTorch Internals (Part I) | PyTorch</A>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/what-and-why-is-torch-dispatch/557">What (and Why) is __torch_dispatch__? - frontend API - PyTorch Developer Mailing List</A>
										<DT><A HREF="https://www.youtube.com/watch?v=_qB2Ho1O3u4&t=8s">PyTorch Developer Podcast - Dispatcher Questions - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>aten-custom-ops</H3>
									<DL><p>
										<DT><A HREF="https://github.com/drisspg/driss_torch">drisspg/driss_torch: Cuda extensions for PyTorch</A>
										<DT><A HREF="https://github.com/TiledTensor/TiledCUDA/blob/master/pytiledcuda/__init__.py">TiledCUDA/pytiledcuda/__init__.py at master ¬∑ TiledTensor/TiledCUDA</A>
									</DL><p>
									<DT><H3 FOLDED>aten-mm</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/drisspg/783616821043ab4594b9784f556c6714">Scaled MM API</A>
										<DT><A HREF="https://gist.github.com/Chillee/2ec89696db8b7ed1c24461159e325405">H100 peak matmul FLOPS</A>
									</DL><p>
									<DT><A HREF="https://x.com/karpathy/status/1803963383018066272">(1) Andrej Karpathy en X: "These 94 lines of code are everything that is needed to train a neural network. Everything else is just efficiency. This is my earlier project Micrograd. It implements a scalar-valued auto-grad engine. You start with some numbers at the leafs (usually the input data and the https://t.co/2zVJP3cNJ0" / X</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-read-the-autograd-codebase/383">How to read the autograd codebase - frontend API - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC?usp=sharing">Simple Grad - Colab</A>
									<DT><A HREF="https://pytorch.org/docs/main/torch.compiler_ir.html#prims-ir">IRs ‚Äî PyTorch main documentation</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/tree/main/aten/src#the-c-interface">low-level tensor libraries for PyTorch, as well as the new ATen C++ bindings</A>
									<DT><A HREF="https://github.com/FlagOpen/FlagGems">FlagOpen/FlagGems: FlagGems is an operator library for large language models implemented in Triton Language.</A>
									<DT><A HREF="https://x.com/__tinygrad__/status/1864162388754280820">(1) the tiny corp en X: "@giffmana Oh wait we have to add CUDA and METAL support: cpu_conv2d_fp16 cpu_conv2d_fp16_with_bias cpu_conv2d_fp32 cpu_conv2d_fp32_with_bias cpu_conv2d_int8 cpu_conv2d_int8_with_bias cuda_conv2d_fp16 cuda_conv2d_fp16_with_bias cuda_conv2d_fp32 cuda_conv2d_fp32_with_bias cuda_conv2d_int8" / X</A>
									<DT><A HREF="https://docs.pytorch.org/cppdocs/notes/tensor_basics.html">Tensor Basics ‚Äî PyTorch main documentation</A>
									<DT><A HREF="https://docs.pytorch.org/cppdocs/api/namespace_at.html#functions">Namespace at ‚Äî PyTorch main documentation</A>
									<DT><A HREF="https://docs.pytorch.org/cppdocs/notes/tensor_creation.html">Tensor Creation API ‚Äî PyTorch main documentation</A>
								</DL><p>
								<DT><H3 FOLDED>torch-device</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/pull/4508">add available memory check to accelerators by jeffra ¬∑ Pull Request #4508 ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/pull/4508">add available memory check to accelerators</A>
								</DL><p>
								<DT><H3 FOLDED>torch-cuda</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-cudagraphs</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/ezyang/870e899e078a7ff56913be249a3d4950">claude-cuda-graph-mempool-lifetime.md</A>
									</DL><p>
									<DT><H3 FOLDED>torch-blackwell</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/145949">[CUDA][Blackwell] Blackwell Tracking Issue ¬∑ Issue #145949 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>torch.cuda._compile_kernel()</H3>
									<DL><p>
										<DT><H3 FOLDED>nvrtc_compile</H3>
										<DL><p>
											<DT><A HREF="https://x.com/gaunernst/status/2015242181049745607">Thien Tran en X: "one of the cool new changes in PyTorch 2.10 is that it's now much easier to use the NVRTC wrapper in PyTorch. C++ template works out-of-the-box! just pass the templated kernel name thanks to @marksaroufim for started this efforts https://t.co/8EHFrM5gCE" / X</A>
											<DT><A HREF="https://gist.github.com/malfet/2c9a25976dd7396430c38af603f791da">ctypes-nvrtc.py</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/162875">[NVRTC] Enable compiling templated kernels by gau-nernst ¬∑ Pull Request #162875 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://gist.github.com/msaroufim/10a0717d7d28b8b970e8fc438ba96d79">def _nvrtc_compile SM100</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/156332">Validate custom op support for compile_kernel by msaroufim ¬∑ Pull Request #156332 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/156332/changes">Validate custom op support for compile_kernel by msaroufim ¬∑ Pull Request #156332 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/156336">reduction test with compile_kernel by msaroufim ¬∑ Pull Request #156336 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><A HREF="https://gau-nernst.github.io/nvrtc-matmul/">Use NVRTC to explore MMA instruction variants - gau-nernst's blog</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/163142">`compile_kernel`: fast inline compilation with nvrtc tracker ¬∑ Issue #163142 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/106667">[docs] Idea collection of examples of custom ops / inline torch extensions ¬∑ Issue #106667 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/151484">Add torch.cuda._compile_kernel() by msaroufim ¬∑ Pull Request #151484 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/cuda/__init__.py">pytorch/torch/cuda/__init__.py at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics">CUDA semantics ‚Äî PyTorch 2.0 documentation</A>
									<DT><A HREF="https://www.youtube.com/watch?v=LuhJEEJQgUM">Lecture 1 How to profile CUDA kernels in PyTorch - YouTube</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/custom_kernels/setup.py">text-generation-inference/server/custom_kernels/setup.py at main ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/custom-cuda-extension-support-in-inductor/1924">Custom cuda extension support in Inductor - compiler - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/wiki/CUDA-basics">CUDA basics ¬∑ pytorch/pytorch Wiki</A>
									<DT><A HREF="https://github.com/drisspg/driss_torch">drisspg/driss_torch: Cuda extensions for PyTorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/c3ee07c71cef9f085577c5e53dfe5faf8f2b3b4e/docs/source/notes/cuda.rst#L809">pytorch/docs/source/notes/cuda.rst</A>
									<DT><A HREF="https://pytorch.org/docs/stable/notes/cuda.html">CUDA semantics ‚Äî PyTorch 2.4 documentation</A>
									<DT><A HREF="https://christianjmills.com/posts/cuda-mode-notes/lecture-004/">Christian Mills - CUDA MODE Lecture 4: Compute and Memory Basics</A>
									<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
								</DL><p>
								<DT><H3 FOLDED>torch-backends</H3>
								<DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/weight-sharing-on-cuda/701">Weight sharing on cuda</A>
									<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with torch.compile</A>
								</DL><p>
								<DT><H3 FOLDED>torch-hooks</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-hooks-activation</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-pytorch/torchtune/blob/main/torchtune/training/_activation_offloading.py">torchtune/torchtune/training/_activation_offloading.py  activation hooks</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=syLFCVYua6Q">PyTorch Hooks Explained</A>
									<DT><A HREF="https://x.com/mrsiipa/status/1987884784849473659">_hook: register fwd/bwd pre &amp; post hooks in torch modules to intercept values</A>
								</DL><p>
								<DT><H3 FOLDED>torch.nn</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/d04957c0c682d766987cad07dce20986ca4a5b78/torch/_refs/nn/functional/__init__.py#L304">pytorch/torch/_refs/nn/functional/__init__.py OPS</A>
								</DL><p>
								<DT><H3 FOLDED>torch.testing</H3>
								<DL><p>
									<DT><H3 FOLDED>SMOrLater</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/2f5a24c2a2d66156ffd0ae8785a8ebc589ddf6f6/torch/testing/_internal/common_cuda.py#L36">pytorch/torch/testing/_internal/common_cuda.py at 2f5a24c2a2d66156ffd0ae8785a8ebc589ddf6f6 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://chatgpt.com/c/68c2f77b-3c78-8328-9630-a65b68b6d352">Skip tests on B200</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>torch-benchmarking</H3>
								<DL><p>
									<DT><H3 FOLDED>cuda-sync</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TransformerEngine/issues/15">Proper benchmarkign with CUDA synchronization NVIDIA/TransformerEngine</A>
										<DT><A HREF="https://github.com/facebookresearch/param/blob/main/inference/compute/pt/pytorch_linear.py">torch.cuda.symnchronize() before st and stop host timers (et)</A>
										<DT><A HREF="https://discuss.pytorch.org/t/torch-gets-slower-when-upgrading-the-version/186525/4">torch.cuda.symnchronize() before st and stop host timers (et)</A>
										<DT><A HREF="https://discuss.pytorch.org/t/torch-gets-slower-when-upgrading-the-version/186525">Torch gets slower when upgrading the version (good stats)</A>
										<DT><A HREF="https://github.com/Chillee/llm.c/blob/3f232c12f688233ae7949add457fd50192bba867/train_gpt2.py#L394C3-L394C4">llm.c: train_gpt2.py#L394C3-L394C4</A>
										<DT><A HREF="https://github.com/huggingface/diffusers/pull/12072/files">optimize QwenImagePipeline to reduce unnecessary CUDA synchronization by chengzeyi (cpu syncs)</A>
									</DL><p>
									<DT><H3 FOLDED>torch.utils.benchmark</H3>
									<DL><p>
										<DT><H3 FOLDED>torch.utils.benchmark.Timer</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/cee5acfb31f1247cf38d3e2a8dec0fa1f89a1cf1/torch/utils/benchmark/utils/timer.py#L11">pytorch/torch/utils/benchmark/utils/timer.py Timer, Compare</A>
										</DL><p>
										<DT><A HREF="https://docs.pytorch.org/docs/stable/benchmark_utils.html">Benchmark Utils - torch.utils.benchmark ‚Äî PyTorch 2.8 documentation</A>
										<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/main/transformer_nuggets/utils/benchmark.py">transformer_nuggets/transformer_nuggets/utils/benchmark.py at main ¬∑ drisspg/transformer_nuggets</A>
										<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/c089938fea102d75bde269cb2dbda46fa36827eb/mla/test.py#L50">deepseekv2-profile/mla/test.py at c089938fea102d75bde269cb2dbda46fa36827eb ¬∑ madsys-dev/deepseekv2-profile</A>
										<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/c089938fea102d75bde269cb2dbda46fa36827eb/mla/benchmark.py">deepseekv2-profile/mla/benchmark.py</A>
									</DL><p>
									<DT><H3 FOLDED>benchmark_forward</H3>
									<DL><p>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/utils/benchmark.py">flash-attention/flash_attn/utils/benchmark.py at main ¬∑ Dao-AILab/flash-attention</A>
									</DL><p>
									<DT><H3 FOLDED>benchmark_torch_function</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/9df4bc6a0dc72caccee142555d1668fad1621206/benchmarks/transformer/better_transformer_vs_mha_functional.py#L114">benchmark_torch_function</A>
										<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/main/transformer_nuggets/utils/benchmark.py">transformer_nuggets/transformer_nuggets/utils/benchmark.py</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/04adaf0e9028d4bec7073f69e4dfa3f6d3357189/flash_attn/utils/benchmark.py#L8">flash-attention/flash_attn/utils/benchmark.py at 04adaf0e9028d4bec7073f69e4dfa3f6d3357189 ¬∑ Dao-AILab/flash-attention</A>
									</DL><p>
									<DT><H3 FOLDED>torch.cuda.nvtx.range_push</H3>
									<DL><p>
										<DT><A HREF="https://github.com/MARD1NO/SimpleBenchMark/blob/main/bench_scaled_mm/test.py">SimpleBenchMark/bench_scaled_mm/test.py:  torch.cuda.nvtx.range_push("matmul_torch_{}_{}_{}".format(M, N, K))</A>
										<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/cases/test_ncu.py">ml_scripts/cases/test_ncu.py at main ¬∑ FindHao/ml_scripts</A>
									</DL><p>
									<DT><A HREF="https://github.com/madsys-dev/deepseekv2-profile/blob/main/mla/benchmark.py#L164">deepseekv2-profile/mla/benchmark.py: class BenchmarkFixture</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/9df4bc6a0dc72caccee142555d1668fad1621206/benchmarks/transformer/better_transformer_vs_mha_functional.py#L167">pytorch/benchmarks/transformer/better_transformer_vs_mha_functional.py</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/utils/benchmark.py">flash-attention/flash_attn/utils/benchmark.py at main ¬∑ Dao-AILab/flash-attention</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/9df4bc6a0dc72caccee142555d1668fad1621206/benchmarks/transformer/better_transformer_vs_mha_functional.py#L114">benchmark_torch_function</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/main/transformer_nuggets/utils/benchmark.py">transformer_nuggets/transformer_nuggets/utils/benchmark.py</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/8e0c7b425ac149c43183de966ffa423fd46e4762/python/triton/testing.py">triton/python/triton/testing.py systematic testing</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/c3a31d90e7d10a9b89b11396b6f8b20ed52bf394/torch/utils/throughput_benchmark.py">pytorch/torch/utils/throughput_benchmark.py</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/7eb2a99585b683e5486bfbf2e78c8165f08c392b/benchmarks/dynamo/microbenchmarks/bench_mm_fusion.py#L92">pytorch/benchmarks/dynamo/microbenchmarks/bench_mm_fusion.py</A>
									<DT><A HREF="https://gist.github.com/malfet/6a17156d7f5663b8b12054a1beff3fe1">Measure performance difference of `torch.mm` vs `torch.bmm`</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/d1f73fd844ba8b84dc1ac581f0c938c6a64d823f/torch/utils/throughput_benchmark.py">pytorch/torch/utils/throughput_benchmark.py</A>
									<DT><A HREF="https://blog.csdn.net/qq_40507857/article/details/118764782">Understanding of model computational capacity (FLOPs) and parameter quantity (Params) in deep learning and summary of four calculation methods</A>
									<DT><A HREF="https://github.com/EleutherAI/cookbook/blob/main/benchmarks/sizing/transformer_flops.py#L139">cookbook/benchmarks/sizing/transformer_flops.py at main ¬∑ EleutherAI/cookbook</A>
									<DT><A HREF="https://github.com/tgale96/grouped_gemm/pull/14#issuecomment-2211362572">Use CUTLASS for both `trans_a` and `trans_b` on Ampere by dfyz ¬∑ Pull Request #14 ¬∑ tgale96/grouped_gemm</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/e9024c691f27a41fabd94617d39d75813b649f26/tinygrad/nn/state.py#L87">tinygrad/tinygrad/nn/state.py: model number of parameters (get_parameters)</A>
									<DT><A HREF="https://discuss.pytorch.org/t/how-to-measure-time-in-pytorch/26964">How to measure time in PyTorch - PyTorch Forums</A>
									<DT><A HREF="https://github.com/cchan/nanoGPT-fp8/blob/master/bench.py">nanoGPT-fp8/bench.py at master ¬∑ cchan/nanoGPT-fp8</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/utils/benchmark/utils/compare.py#L270">pytorch/torch/utils/benchmark/utils/compare.py at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://pytorch.org/tutorials/recipes/recipes/benchmark.html">PyTorch Benchmark ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/4c1dd13ba33d0fcd1f039ea67b026979a09ae00a/benchmarks/transformer/sdp.py#L66">pytorch/benchmarks/transformer/sdp.py: PrettyTable</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/utils/benchmark.py#L60">benchmark_torch_function_in_microseconds</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/f3c54ccf8f6139807f4623037c0174964a286652/torch/_inductor/utils.py#L121">do_bench_using_profiling</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/f3c54ccf8f6139807f4623037c0174964a286652/torch/_inductor/config.py#L682">TORCHINDUCTOR_PROFILE_WITH_DO_BENCH_USING_PROFILING</A>
									<DT><A HREF="http://arthurchiao.art/blog/understanding-gpu-performance/">Understanding NVIDIA GPU Performance: Utilization vs. Saturation (2023)</A>
									<DT><A HREF="https://github.com/sayakpaul/diffusers-torchao/blob/bade7a6abb1cab9ef44782e6bcfab76d0237ae1f/inference/launch_image_benchmarks.sh#L5">diffusers-torchao/inference/launch_image_benchmarks.sh: Possibl values for each argument -&gt; loop over all combinations</A>
									<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/01965457bf998f8c314a8dab921403b399e96dc5/blackwell/79-triton-matmul.py">gpu-experiments/blackwell/79-triton-matmul.py torch.cuda.Event(enable_timing=True)</A>
									<DT><A HREF="https://github.com/alibaba-damo-academy/Inferix/blob/main/inferix/profiling/EXTENDING_PROFILING.md">Inferix/inferix/profiling/EXTENDING_PROFILING.md</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/166063/files">Add Gluon based grouped MM kernel for Blackwell into Inductor by alexsamardzic ¬∑ Pull Request #166063 ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>torch-profiling</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-utils</H3>
									<DL><p>
										<DT><H3 FOLDED>flop_counter</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/27d97b9649f26565c640f8710db740b71e615f0d/torch/utils/flop_counter.py#L597">pytorch/torch/utils/flop_counter.py</A>
											<DT><A HREF="https://gist.github.com/soumith/5f81c3d40d41bb9d08041431c656b233">Horace's flop counter, but with flops metric fixed correctly</A>
											<DT><A HREF="https://github.com/zugexiaodui/torch_flops/tree/dc72fb62934e107987fc3e9cb59d74d32b3910ef?tab=readme-ov-file">zugexiaodui/torch_flops at dc72fb62934e107987fc3e9cb59d74d32b3910ef</A>
											<DT><A HREF="https://github.com/zugexiaodui/torch_flops/tree/main?tab=readme-ov-file">zugexiaodui/torch_flops: A library for calculating the FLOPs in the forward() process based on torch.fx</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/123800">add `FlopCounterMode` documentation ¬∑ Issue #123800 ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/ao/blob/e283743b3cc4612bb641b88dca3670231724d396/torchao/profiler/performance_counter.py">ao/torchao/profiler/performance_counter.py</A>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/663566912">torch_flops: ÂáÜÁ°ÆÊçïËé∑forward‰∏≠ÊâÄÊúâÁÆóÂ≠êÁöÑFLOPsËÆ°ÁÆóÂ∫ì - Áü•‰πé</A>
											<DT><A HREF="https://github.com/zugexiaodui/torch_flops?tab=readme-ov-file">zugexiaodui/torch_flops: A library for calculating the FLOPs in the forward() process based on torch.fx</A>
										</DL><p>
										<DT><H3 FOLDED>torch.utils.collect_env</H3>
										<DL><p>
											<DT><A HREF="https://github.com/triton-lang/triton/issues/4310">torch.utils.collect_env</A>
											<DT><A HREF="https://medium.com/the-owl/quick-tips-1-how-to-obtain-environment-information-using-pytorch-a6a8e03f4422">python -m torch.utils.collect_env</A>
										</DL><p>
										<DT><H3 FOLDED>torch.model_size</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/torchsnapshot/blob/df45917d12b1e64a4567e8ca1a591909fffad02e/benchmarks/fsdp/main.py#L30">torchsnapshot/benchmarks/fsdp/main.py: sum(p.numel() * p.element_size() for p in model.parameters() if p.requires_grad)</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/26b0a0c2f37a8ad376f261df7bb4fee65ff2f230/torch/nn/parallel/distributed.py#L1378">distributed.py#L1378</A>
											<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/e9024c691f27a41fabd94617d39d75813b649f26/tinygrad/nn/state.py#L87">tinygrad/tinygrad/nn/state.py: model number of parameters (get_parameters)</A>
											<DT><A HREF="https://github.com/huggingface/transformers/blob/b7ea171403d53a2aa9bce422f1fad8fb1150844b/examples/research_projects/movement-pruning/counts_parameters.py#L4">transformers/examples/research_projects/movement-pruning/counts_parameters.py at b7ea171403d53a2aa9bce422f1fad8fb1150844b ¬∑ huggingface/transformers</A>
										</DL><p>
										<DT><A HREF="https://github.com/lucidrains/pytorch-custom-utils/blob/main/pytorch_custom_utils/total_parameters.py">pytorch-custom-utils/pytorch_custom_utils/total_parameters.py at main ¬∑ lucidrains/pytorch-custom-utils</A>
										<DT><A HREF="https://github.com/FindHao/ml_scripts">FindHao/ml_scripts: A collection of my own scripts to run pytorch models, debugging pytorch compiler, and filter the results</A>
										<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/install_conda_env.sh">ml_scripts/install_conda_env.sh at main ¬∑ FindHao/ml_scripts</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/04adaf0e9028d4bec7073f69e4dfa3f6d3357189/flash_attn/utils/benchmark.py#L8">flash-attention/flash_attn/utils/benchmark.py at 04adaf0e9028d4bec7073f69e4dfa3f6d3357189 ¬∑ Dao-AILab/flash-attention</A>
									</DL><p>
									<DT><H3 FOLDED>torch-memory</H3>
									<DL><p>
										<DT><H3 FOLDED>torch.utils.bottleneck</H3>
										<DL><p>
											<DT><A HREF="https://pytorch.org/docs/main/bottleneck.html">torch.utils.bottleneck ‚Äî PyTorch main documentation</A>
											<DT><A HREF="https://medium.com/biased-algorithms/mastering-memory-profiling-in-pytorch-40007ced2e46">Mastering Memory Profiling in PyTorch | by Hey Amit | Biased-Algorithms | Nov, 2024 | Medium</A>
										</DL><p>
										<DT><H3 FOLDED>torch-memory-snapshot</H3>
										<DL><p>
											<DT><A HREF="https://www.linkedin.com/pulse/analyzing-gpu-memory-leaks-torch-snapshot-vlm-rl-chenyang-zhao-9gaxe/">(3) Analyzing GPU Memory Leaks with Torch Memory Snapshot For VLM RL | LinkedIn</A>
											<DT><A HREF="https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html">A guide to PyTorch‚Äôs CUDA Caching Allocator | Zach‚Äôs Blog</A>
											<DT><A HREF="https://zdevito.github.io/2022/08/16/memory-snapshots.html">Debugging PyTorch memory use with snapshots | Zach‚Äôs Blog</A>
											<DT><A HREF="https://github.com/datacrunch-research/text-generation-inference/blob/main/server/tests/models/test_causal_lm.py">text-generation-inference/server/tests/models/test_causal_lm.py activation memory</A>
											<DT><A HREF="https://arxiv.org/pdf/1910.02054">3 Where Did All the Memory Go? ZeRO</A>
										</DL><p>
										<DT><H3 FOLDED>residual-memory</H3>
										<DL><p>
											<DT><A HREF="https://github.com/modelscope/DiffSynth-Studio/blob/de4e2703cac0aa55d4c41ea5b4b39efa75060d3f/diffsynth/vram_management/layers.py">used_memory = (gpu_mem_state[1] - gpu_mem_state[0]) / (1024 ** 3)</A>
											<DT><A HREF="https://github.com/datacrunch-research/text-generation-inference/blob/main/server/tests/models/test_causal_lm.py">text-generation-inference/server/tests/models/test_causal_lm.py activation memory</A>
											<DT><A HREF="https://www.linkedin.com/pulse/analyzing-gpu-memory-leaks-torch-snapshot-vlm-rl-chenyang-zhao-9gaxe/">(3) Analyzing GPU Memory Leaks with Torch Memory Snapshot For VLM RL | LinkedIn</A>
											<DT><A HREF="https://arxiv.org/pdf/1910.02054">3 Where Did All the Memory Go? ZeRO</A>
										</DL><p>
										<DT><H3 FOLDED>torch-lazy</H3>
										<DL><p>
											<DT><H3 FOLDED>torch_memory_saver</H3>
											<DL><p>
												<DT><A HREF="https://github.com/fzyzcjy/torch_memory_saver">fzyzcjy/torch_memory_saver: Allow torch tensor memory to be released and resumed later</A>
											</DL><p>
										</DL><p>
										<DT><A HREF="https://pytorch.org/docs/stable/torch_cuda_memory.html">Understanding CUDA Memory Usage ‚Äî PyTorch 2.2 documentation</A>
										<DT><A HREF="https://pytorch.org/blog/understanding-gpu-memory-1/">Understanding GPU Memory 1: Visualizing All Allocations over Time ‚Äì PyTorch</A>
										<DT><A HREF="https://pytorch.org/blog/understanding-gpu-memory-2/">Understanding GPU Memory 2: Finding and Removing Reference Cycles | PyTorch</A>
										<DT><A HREF="https://github.com/fzyzcjy/torch_memory_saver">fzyzcjy/torch_memory_saver: Allow torch tensor memory to be released and resumed later</A>
										<DT><A HREF="https://github.com/deepspeedai/DeepSpeed/blob/a01a2688b98aa90ac1dcf23012efbe13ba69ebcd/deepspeed/compile/profilers/graph_profile.py#L54">graph_profile.py#L54: _get_mem_usage_out_of_torch()</A>
										<DT><A HREF="https://zdevito.github.io/2022/12/09/memory-traces.html">Visualizing PyTorch memory usage over time | Zach‚Äôs Blog</A>
										<DT><A HREF="https://pytorch.org/memory_viz">https://pytorch.org/memory_viz</A>
										<DT><A HREF="https://zdevito.github.io/2022/08/16/memory-snapshots.html">Debugging PyTorch memory use with snapshots | Zach‚Äôs Blog</A>
										<DT><A HREF="https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html">A guide to PyTorch‚Äôs CUDA Caching Allocator | Zach‚Äôs Blog</A>
										<DT><A HREF="https://github.com/google/zerocopy">google/zerocopy</A>
										<DT><A HREF="https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html">1. Overview ‚Äî cuda-binary-utilities (SaSS)</A>
										<DT><A HREF="https://x.com/StasBekman/status/1938270423978021291">A deep dive in activation memory offloading:</A>
										<DT><A HREF="https://github.com/lodestone-rock/RamTorch">lodestone-rock/RamTorch: RAM is all you need</A>
										<DT><A HREF="https://huggingface.co/spaces/Leiyre/memory-viz">Memory Viz - a Hugging Face Space by Leiyre</A>
										<DT><A HREF="https://github.com/vipshop/cache-dit/blob/abac1e5d2df695992aa0281081c33c82c25010db/examples/utils.py#L13">cache-dit/examples/utils.py</A>
									</DL><p>
									<DT><H3 FOLDED>torch-profilling-cuda-events</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.cuda.Event.html#">Event ‚Äî PyTorch 2.2 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>Warm-Up Steps</H3>
									<DL><p>
										<DT><A HREF="https://github.com/horseee/DeepCache/blob/97813f6406ab71e236bfeb2f8a0e58c6a25b7397/stable_diffusion.py#L29">DeepCache: stable_diffusion.py#L29 (benchmark)</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/78f87d5a0c7d82911a639c397577284868a53c42/server/text_generation_server/models/flash_causal_lm.py#L690">flash_causal_lm.py#L690</A>
									</DL><p>
									<DT><H3 FOLDED>Fixed Clocks</H3>
									<DL><p>
										<DT><A HREF="https://blog.speechmatics.com/cuda-timings">How to Accurately Time CUDA Kernels in Pytorch</A>
										<DT><A HREF="https://github.com/google-deepmind/alphatensor/blob/1949163da3bef7e3eb268a3ac015fd1c2dbfc767/benchmarking/run_gpu_benchmark.py#L60">alphatensor/benchmarking/run_gpu_benchmark.py --lock-gpu-clocks</A>
										<DT><A HREF="https://github.com/openai/triton/blob/8e0c7b425ac149c43183de966ffa423fd46e4762/python/triton/testing.py#L441">Triton testing.py#L441 set_gpu_clock</A>
										<DT><A HREF="https://github.com/openai/triton/blob/8e0c7b425ac149c43183de966ffa423fd46e4762/python/test/regression/test_performance.py#L25">Triton test_performance.py#L25</A>
										<DT><A HREF="https://twitter.com/mike64_t/status/1763239211254030365">RTX 4090 Core and Mem overclock</A>
										<DT><A HREF="https://www.thonking.ai/p/strangely-matrix-multiplications">Strangely, Matrix Multiplications on GPUs Run Faster When Given "Predictable" Data! [short]</A>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/3c189dd306982e44db607c54195f625941ae16c1/python/triton/testing.py#L461">triton/python/triton/testing.py at 3c189dd306982e44db607c54195f625941ae16c1 ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><H3 FOLDED>Cache Flush</H3>
									<DL><p>
										<DT><A HREF="https://github.com/openai/triton/blob/8e0c7b425ac149c43183de966ffa423fd46e4762/python/triton/testing.py#L141">A100 L2 cache 40 MB (Triton testing.py#L141)</A>
									</DL><p>
									<DT><H3 FOLDED>torch-profilling-cuda-graphs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/78f87d5a0c7d82911a639c397577284868a53c42/server/text_generation_server/models/flash_causal_lm.py#L690">flash_causal_lm.py#L690</A>
									</DL><p>
									<DT><H3 FOLDED>kineto</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch-labs/tritonbench/commit/1fb46a37d012ed1a59709afd9735e0bed88e430c#diff-c4ac117ad0a56f447b3f1a1c139113a637f01798caf1408824be2bb13694f957R22">Enable cudagraph mode for kineto_trace (#106) ¬∑ pytorch-labs/tritonbench@1fb46a3</A>
										<DT><A HREF="https://github.com/pytorch-labs/tritonbench/issues/85">Explain the kineto trace with an example ¬∑ Issue #85 ¬∑ pytorch-labs/tritonbench</A>
										<DT><A HREF="https://github.com/pytorch-labs/tritonbench/blob/main/docs/kineto_trace.md">tritonbench/docs/kineto_trace.md at main ¬∑ pytorch-labs/tritonbench</A>
										<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/0f16757edc065603bb19e0457c34a451c5d7c042/examples/matmul/this-sm100/test_this_perf.py">MatmulTutorial/examples/matmul/this-sm100/test_this_perf: bench_kineto</A>
									</DL><p>
									<DT><H3 FOLDED>torch-profiling-cpu</H3>
									<DL><p>
										<DT><H3 FOLDED>torch-item</H3>
										<DL><p>
											<DT><A HREF="https://x.com/JingyuanLiu123/status/1950661527729836112">.item() forces cpu cuda sync,</A>
											<DT><A HREF="https://github.com/search?q=repo%3Adatacrunch-research%2Fseedvr2%20.item()&type=code">seedvr2 .items() cpu sync</A>
											<DT><A HREF="https://x.com/_xjdr/status/1985007955549487536">rg '.item()' . is usually my first step</A>
										</DL><p>
										<DT><H3 FOLDED>cpu-overhead</H3>
										<DL><p>
											<DT><A HREF="https://x.com/mike64_t/status/1984526366965186921">(1) mike64_t en X: "Friendly reminder that your forward pass CPU overhead could be in the neighborhood of the time it takes for your data loader to copy the input to your GPU over PCI-E. https://t.co/0BbaDT8zwy" / X</A>
											<DT><A HREF="https://modal.com/blog/host-overhead-inference-efficiency">Host overhead is killing your inference efficiency | Modal Blog</A>
											<DT><A HREF="https://x.com/lm_zheng/status/1992497243686080769">(1) Lianmin Zheng en X: "Fun fact: While inference is running on the GPU, I probably spent more time optimizing CPU overhead than the GPU kernels themselves during my development of SGLang. Many big refactors and small details were needed to achieve a zero-CPU-overhead batch scheduler." / X</A>
											<DT><A HREF="https://tomasruizt.github.io/posts/08_cpu_gpu_synchronization/#sec-profiling-analysis">PyTorch and CPU-GPU Synchronizations ‚Äì All Posts</A>
											<DT><A HREF="https://x.com/charles_irl/status/2017075226417516795">never blog the GPU, async H2D</A>
										</DL><p>
										<DT><A HREF="https://github.com/gaogaotiantian/viztracer">gaogaotiantian/viztracer: A debugging and profiling tool that can trace and visualize python code execution</A>
										<DT><A HREF="https://github.com/stas00/the-art-of-debugging/tree/master/pytorch#getting-programs-cpu-peak-memory-usage">Getting program's CPU peak memory usage</A>
										<DT><A HREF="https://tomasruizt.github.io/posts/08_cpu_gpu_synchronization/#sec-profiling-analysis">PyTorch and CPU-GPU Synchronizations ‚Äì All Posts</A>
									</DL><p>
									<DT><H3 FOLDED>torch.autograd.profiler.record_function.record_function</H3>
									<DL><p>
										<DT><A HREF="https://github.com/openai/gpt-oss/blob/b5cc884079145a112c2c840790dcb8dd2fc6425e/gpt_oss/triton/moe.py#L18">gpt-oss/gpt_oss/triton/moe.py</A>
										<DT><A HREF="https://docs.pytorch.org/docs/stable/generated/torch.autograd.profiler.record_function.html">record_function ‚Äî PyTorch 2.8 documentation</A>
										<DT><A HREF="https://docs.jax.dev/en/latest/_autosummary/jax.named_scope.html">jax.named_scope ‚Äî JAX documentation</A>
									</DL><p>
									<DT><H3 FOLDED>torch.cuda.nvtx</H3>
									<DL><p>
										<DT><A HREF="https://docs.pytorch.org/docs/stable/generated/torch.cuda.nvtx.range_push.html">torch.cuda.nvtx.range_push ‚Äî PyTorch 2.8 documentation</A>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/main/third_party/proton/test/test_profile.py">triton/third_party/proton/test/test_profile.py</A>
										<DT><A HREF="https://github.com/MARD1NO/SimpleBenchMark/blob/main/bench_scaled_mm/test.py">SimpleBenchMark/bench_scaled_mm/test.py at main ¬∑ MARD1NO/SimpleBenchMark</A>
									</DL><p>
									<DT><H3 FOLDED>torch-profile-compare</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ezyang/torch-profile-compare">ezyang/torch-profile-compare: easily compare pytorch json profiles. vibe coded</A>
									</DL><p>
									<DT><H3 FOLDED>torch-profile-cuda-sync</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/diffusers/pull/12072/files">optimize QwenImagePipeline to reduce unnecessary CUDA synchronization by chengzeyi ¬∑ Pull Request #12072 ¬∑ huggingface/diffusers</A>
										<DT><A HREF="https://tomasruizt.github.io/posts/08_cpu_gpu_synchronization/#sec-profiling-analysis">PyTorch and CPU-GPU Synchronizations ‚Äì All Posts</A>
									</DL><p>
									<DT><H3 FOLDED>viztracer</H3>
									<DL><p>
										<DT><A HREF="https://github.com/gaogaotiantian/viztracer">gaogaotiantian/viztracer: A debugging and profiling tool that can trace and visualize python code execution</A>
										<DT><A HREF="https://x.com/drisspg/status/1984123476190622077">(1) driss guessous en X: "As someone who spends way to much time in the PyTorch Profiler; https://t.co/ipNpGQFKnD ^^ I really like this ^^" / X</A>
										<DT><A HREF="https://x.com/vikhyatk/status/1987195219104956874">(1) vik en X: "trying out viztracer: - flashinfer segfault if i try to trace torch, so can't do that - asyncio support is amazing - super easy to use - CUDA_LAUNCH_BLOCKING=1 as a hack to see where time is actually being spent" / X</A>
									</DL><p>
									<DT><H3 FOLDED>torch-profile-systematic</H3>
									<DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1987623785982076436">How to systematically locate and analyze performance bottlenecks in PyTorch model inference?</A>
									</DL><p>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/main/flash_attn/utils/benchmark.py#L15">from flash_attn.utils.benchmark import pytorch_profiler</A>
									<DT><A HREF="https://blog.speechmatics.com/cuda-timings">How to Accurately Time CUDA Kernels in Pytorch</A>
									<DT><A HREF="https://pytorch.org/blog/understanding-gpu-memory-2/">Understanding GPU Memory 2: Finding and Removing Reference Cycles</A>
									<DT><A HREF="https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics">CUDA semantics ‚Äî PyTorch 2.0 documentation</A>
									<DT><A HREF="https://www.youtube.com/watch?v=LuhJEEJQgUM">Lecture 1 How to profile CUDA kernels in PyTorch - YouTube</A>
									<DT><A HREF="https://github.com/quentinf00/article-memory-log?tab=readme-ov-file">quentinf00/article-memory-log</A>
									<DT><A HREF="https://docs.google.com/presentation/d/110dnMW94LX1ySWxu9La17AVUxjgSaQDLOotFC3BZZD4/edit#slide=id.p">Lecture 1 How to profile CUDA kernels in PyTorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#codebase-structure">Lecture 1 How to profile CUDA kernels in PyTorch</A>
									<DT><A HREF="https://github.com/pytorch/kineto">pytorch/kineto: A CPU+GPU Profiling library that provides access to timeline traces and hardware performance counters.</A>
									<DT><A HREF="https://www.speechmatics.com/company/articles-and-news/timing-operations-in-pytorch">How to Accurately Time CUDA Kernels in Pytorch</A>
									<DT><A HREF="https://github.com/cloneofsimo/reverse_eng_deepspeed_study/blob/main/day3/run.py">reverse_eng_deepspeed_study/day3/run.py at main</A>
									<DT><A HREF="https://github.com/pytorch/kineto?tab=readme-ov-file">pytorch/kineto: A CPU+GPU Profiling library that provides access to timeline traces and hardware performance counters.</A>
									<DT><A HREF="https://discuss.pytorch.org/t/torch-gets-slower-when-upgrading-the-version/186525/4">torch.cuda.symnchronize() before st and stop host timers (et)</A>
									<DT><A HREF="https://discuss.pytorch.org/t/torch-gets-slower-when-upgrading-the-version/186525">Torch gets slower when upgrading the version (good stats)</A>
									<DT><A HREF="https://twitter.com/neurosp1ke/status/1784239369949159740">CUDA-MODE 16: Profiling</A>
									<DT><A HREF="https://www.youtube.com/watch?v=SKV6kDk1s94">Lecture 16: On Hands Profiling - YouTube</A>
									<DT><A HREF="https://gist.github.com/Chillee/41baf11aac8036d25d637321c48dad20">You Could Have Invented Flash-Attention!</A>
									<DT><A HREF="https://gist.github.com/Chillee/07b36672a0ca2d1280e42b8d10f23174">Compute Flop Utilization in PyTorch</A>
									<DT><A HREF="https://pytorch.org/blog/accelerating-llama3/">Accelerating Llama3 FP8 Inference with Triton Kernels | PyTorch</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/9df4bc6a0dc72caccee142555d1668fad1621206/benchmarks/transformer/better_transformer_vs_mha_functional.py#L114">pytorch/benchmarks/transformer/benchmark_torch_function</A>
									<DT><A HREF="https://github.com/tgale96/grouped_gemm/pull/14#issuecomment-2211362572">Use CUTLASS for both `trans_a` and `trans_b` on Ampere by dfyz ¬∑ Pull Request #14 ¬∑ tgale96/grouped_gemm</A>
									<DT><A HREF="https://christianjmills.com/posts/cuda-mode-notes/lecture-001/">Christian Mills - CUDA MODE Lecture 1: How to profile CUDA kernels in PyTorch</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/83f754eb670b73aa789a924b6b9fab67784ca28f/transformer_nuggets/utils/benchmark.py#L60">transformer_nuggets/transformer_nuggets/utils/benchmark.py at 83f754eb670b73aa789a924b6b9fab67784ca28f ¬∑ drisspg/transformer_nuggets</A>
									<DT><A HREF="https://github.com/search?q=repo%3Apytorch%2Fao%20profiler_runner&type=code">torchao: profiler_runner</A>
									<DT><A HREF="https://github.com/FindHao/TorchExpert/blob/master/test_example.py">TorchExpert/test_example.py at master ¬∑ FindHao/TorchExpert</A>
									<DT><A HREF="https://colab.research.google.com/drive/1XQwio7DsqB5LP2D574f_uIb8G7KhirNa?usp=sharing#scrollTo=fMsppme9eqnl">PT2-Benchmark - Colab</A>
									<DT><A HREF="https://github.com/pytorch/workshops/blob/master/ASPLOS_2024/profiling.pdf">workshops/ASPLOS_2024/profiling.pdf</A>
									<DT><A HREF="https://github.com/zugexiaodui/torch_flops?tab=readme-ov-file">zugexiaodui/torch_flops: A library for calculating the FLOPs in the forward() process based on torch.fx</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59">Using Nsight Systems to profile GPU workload - hardware-backends / NVIDIA CUDA - PyTorch Developer Mailing List</A>
									<DT><A HREF="https://gist.github.com/mcarilli/376821aa1a7182dfcf59928a7cde3223">Favorite nsight systems profiling commands for Pytorch scripts</A>
									<DT><A HREF="https://pytorch.org/docs/stable/torch.compiler_profiling_torch_compile.html">Profiling to understand torch.compile performance ‚Äî PyTorch 2.6 documentation</A>
									<DT><A HREF="https://github.com/Quentin-Anthony/torch-profiling-tutorial">Quentin-Anthony/torch-profiling-tutorial</A>
									<DT><A HREF="https://jax-ml.github.io/scaling-book/gpus/">How to Think About GPUs | How To Scale Your Model</A>
									<DT><A HREF="https://github.com/search?q=repo%3Adrisspg%2Ftransformer_nuggets%20ProfileConfig&type=code">repo:drisspg/transformer_nuggets ProfileConfig</A>
									<DT><A HREF="https://x.com/difficultyang/status/1974944299184968168">(1) difficultyang en X: "PyTorch's default profiling experience is exasperatingly bad I don't understaaaand" / X</A>
									<DT><A HREF="https://x.com/aryagxr/status/1980096601063673873">(4) arya en X: "I‚Äôve been using the PyTorch profiler a lot what you‚Äôre seeing here is a profile trace of 10 forward passes (10 token predictions), and profiler step 0 telling me that the most obvious performance bottleneck is the prefill stage I will come back to this trace to compare when I https://t.co/NCAgIFOdrr" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=pHqcHzxx6I8">Making GPUs Actually Fast: A Deep Dive into Training Performance - YouTube</A>
									<DT><A HREF="https://x.com/drisspg/status/1990974698205950302">zshfuncs for tracing, dumping, ncu</A>
									<DT><A HREF="https://docs.nvidia.com/nsight-python/overview/quickstart.html">Quickstart ‚Äî nsight-python</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/commit/767e708c2bac6f60db9dc62e455d6993cda2c3fd">def cuda_kernel_profiler(kernel_pattern: str | None = None, record_name: str | None = None):</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/7a89a27a53f60fa055bc67ee715339153d21b88f/transformer_nuggets/utils/benchmark.py#L327">from transformer_nuggets.utils.benchmark import profiler</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/bf3499695d6d604572311fa23ee9f02db9f0cc7b/python/sglang/multimodal_gen/docs/profiling.md">sglang/python/sglang/multimodal_gen/docs/profiling.md at bf3499695d6d604572311fa23ee9f02db9f0cc7b ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/multimodal_gen/runtime/utils/profiler.py">sglang/python/sglang/multimodal_gen/runtime/utils/profiler.py at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/pytorch/ao/blob/e4bfca1fb2bf02800eae66579d39777564601b6c/test/prototype/mx_formats/test_inference_workflow.py#L47">ao/test/prototype: def cuda_kernel_profiler(kernel_pattern):</A>
									<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/commit/0f16757edc065603bb19e0457c34a451c5d7c042#diff-c4c43a43be8bf1d1236a1d324cea2240859b67d99690aed466ffe68f83e16d4d">add sm100 matmul ¬∑ KnowingNothing/MatmulTutorial@0f16757</A>
									<DT><A HREF="https://github.com/alibaba-damo-academy/Inferix/blob/main/inferix/profiling/profiler.py">Inferix/inferix/profiling/profiler.py at main ¬∑ alibaba-damo-academy/Inferix</A>
									<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/cases/test_profile.py">ml_scripts/cases/test_profile.py at main ¬∑ FindHao/ml_scripts</A>
									<DT><A HREF="https://github.com/Overworldai/world_engine/blob/main/examples/prof.py">world_engine/examples/prof.py wan profiling</A>
								</DL><p>
								<DT><H3 FOLDED>torch-amp</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/docs/stable/amp.html">Automatic Mixed Precision package - torch.amp ‚Äî PyTorch 2.3 documentation</A>
									<DT><A HREF="https://tspeterkim.github.io/posts/mixed-precision-from-scratch">Mixed Precision Training from Scratch | Taeksang Peter Kim</A>
									<DT><A HREF="https://github.com/tspeterkim/mixed-precision-from-scratch">tspeterkim/mixed-precision-from-scratch: Mixed precision training from scratch with Tensors and CUDA</A>
								</DL><p>
								<DT><H3 FOLDED>torch-dispatchmode</H3>
								<DL><p>
									<DT><H3 FOLDED>torch.utils._debug_mode.DebugMode</H3>
									<DL><p>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/debug_mode_tutorial.html">DebugMode: Recording Dispatched Operations and Numerical Debugging ‚Äî PyTorch Tutorials 2.10.0+cu130 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>TorchDispatchMode</H3>
									<DL><p>
										<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/debug_mode_tutorial.html">DebugMode: Recording Dispatched Operations and Numerical Debugging ‚Äî PyTorch Tutorials 2.10.0+cu130 documentation</A>
									</DL><p>
									<DT><A HREF="https://x.com/YouJiacheng/status/1916680035408265485">(1) You Jiacheng en X: "@cHHillee @TimDarcet Somewhat realized that `make_fx` (which uses ProxyTorchDispatchMode) can do this. https://t.co/xEoR7zVEWL" / X</A>
								</DL><p>
								<DT><H3 FOLDED>torch-logs</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/document/d/1ZRfTWKa8eaPq1AxaiHrq4ASTPouzzlPiuquSBEJYwS8/edit?tab=t.0#heading=h.jl2u5d4l2lgy">PT2 Logging Design - Google Docs</A>
								</DL><p>
								<DT><H3 FOLDED>torch.transpose</H3>
								<DL><p>
									<DT><A HREF="https://docs.pytorch.org/docs/stable/generated/torch.transpose.html#torch-transpose">torch.transpose ‚Äî PyTorch 2.8 documentation</A>
									<DT><A HREF="https://x.com/mrsiipa/status/1970936246416572423">transpose: a new view of the existing data with differetn shape and stride, new memory intepretation O(1). do not call contigous() if not necessary</A>
								</DL><p>
								<DT><H3 FOLDED>libtorch</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=HNdEmnvMvGE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=129">Lightning Talk: A Stable Limited LibTorch ABI? How?! (and Why?) - Jane Xu, Meta - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>torch-caching_allocator</H3>
								<DL><p>
									<DT><A HREF="https://x.com/mike64_t/status/2012278253885493666">mike64_t en X: "The PyTorch Caching Allocator technically has zero justification for its existence. Cuda memory pools when properly configured can already serve hot-loop async memallocs essentially for free, and the cuda driver has the option to virtually defragment the memory pool before" / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/aten/src/ATen/native/native_functions.yaml">native_functions.yaml</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/wiki/Codegen-and-Structured-Kernels">Codegen and Structured Kernels ¬∑ pytorch/pytorch Wiki</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/CONTRIBUTING.md#codebase-structure">Onboarding to PyTorch Internals (WIKI): Codebase structure</A>
								<DT><A HREF="http://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals : ezyang‚Äôs blog</A>
								<DT><A HREF="http://blog.ezyang.com/2020/01/vmap-in-haskell/">vmap in Haskell : ezyang‚Äôs blog</A>
								<DT><A HREF="https://docs.google.com/spreadsheets/d/e/2PACX-1vQQFW0T_bucT5KZn0BHYTC1KYhkL6ZMG5ZxQWc6UmAkHUDYpqkpzXnsb59uv2TB0Jgc1Q6qO63bx6WQ/pubhtml">Copy of The PyTorch Operator Spreadsheet - Google Drive</A>
								<DT><A HREF="https://docs.google.com/document/d/1tlgPcR2YmC3PcQuYDPUORFmEaBPQEmo8dsh4eUjnlyI/edit#heading=h.unax8xdp403v">PT2 Manifesto - Google Docs</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-find-the-c-cuda-implementation-of-specific-operators-in-pytorch-source-code/1551/3">How to find the c++/cuda implementation of specific operators in pytorch source code - PyTorch Dev Discussions</A>
								<DT><A HREF="https://github.com/ToluClassics/candle-tutorial">Convert PyTorch Models to Candle</A>
								<DT><A HREF="https://github.com/albanD/pytorch_dev_env_setup">albanD/pytorch_dev_env_setup</A>
								<DT><A HREF="https://github.com/albanD/pytorchviz">albanD/pytorchviz: A small package to create visualizations of PyTorch execution graphs</A>
								<DT><A HREF="https://pytorch-dev-podcast.simplecast.com/episodes">Episodes | PyTorch Developer Podcast</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/csrc/jit/docs/serialization.md">pytorch/torch/csrc/jit/docs/serialization.md at main ¬∑ pytorch/pytorch</A>
								<DT><A HREF="https://pytorch.org/blog/understanding-gpu-memory-2/">Understanding GPU Memory 2: Finding and Removing Reference Cycles | PyTorch</A>
								<DT><A HREF="https://www.youtube.com/watch?v=asWINANITgg">PyTorch composability sync: Full step capture, sub-byte dtypes - YouTube</A>
								<DT><A HREF="https://drive.google.com/file/d/1XBox0G3FI-71efQQjmqGh0-VkCd-AHPL/view">pytorch2_internals.pdf - Google Drive</A>
								<DT><A HREF="https://zdevito.github.io/2022/08/04/cuda-caching-allocator.html">A guide to PyTorch‚Äôs CUDA Caching Allocator | Zach‚Äôs Blog</A>
								<DT><A HREF="https://www.youtube.com/watch?v=kSOmyARCbyM">PyTorch composability sync</A>
								<DT><A HREF="https://pytorch.org/blog/pytorch-2-paper-tutorial/?utm_content=282093849&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">PyTorch 2 paper and tutorial @ ASPLOS 2024 | PyTorch</A>
								<DT><A HREF="https://pytorch.org/assets/pytorch_2.pdf">PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation</A>
								<DT><A HREF="https://drive.google.com/file/d/1XBox0G3FI-71efQQjmqGh0-VkCd-AHPL/view">pytorch2_internals.pdf</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-find-the-c-cuda-implementation-of-specific-operators-in-pytorch-source-code/1551/3">How to find the c++/cuda implementation of specific operators in pytorch source code</A>
								<DT><A HREF="https://www.youtube.com/watch?v=asWINANITgg">PyTorch composability sync: Full step capture, sub-byte dtypes</A>
								<DT><A HREF="https://pytorch.org/blog/accelerating-generative-ai/">Accelerating Generative AI with PyTorch: Segment Anything, Fast</A>
								<DT><A HREF="https://docs.google.com/document/d/1QTR3t3KdRu5JT1lvAuJLsPd3LruCfv0LecpsgR8eWhg/edit">Composability meeting notes - Google Docs</A>
								<DT><A HREF="https://github.com/lernapparat/torchhacks/blob/main/test/test_lazyload.py">torchhacks/test/test_lazyload.py</A>
								<DT><A HREF="https://pytorch.org/blog/a-tour-of-pytorch-internals-2/">PyTorch Internals Part II - The Build System | PyTorch</A>
							</DL><p>
							<DT><H3 FOLDED>torch-research</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-experiments</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-labs-fp8</H3>
									<DL><p>
										<DT><A HREF="https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization">A Visual Guide to Quantization - by Maarten Grootendorst</A>
										<DT><A HREF="https://github.com/facebookexperimental/protoquant">facebookexperimental/protoquant: Prototype routines for GPU quantization written using PyTorch.</A>
										<DT><A HREF="https://pytorch.org/docs/stable/quantization.html">Quantization ‚Äî PyTorch 2.0 documentation</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/109168">Basic fp8 support in Inductor by ipiszy ¬∑ Pull Request #109168 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://twitter.com/MSFTDeepSpeed/status/1765923648773525795">DeepSpeed-FP6</A>
										<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fp6/03-05-2024">DeepSpeed/blogs/deepspeed-fp6/03-05-2024 at master ¬∑ microsoft/DeepSpeed</A>
										<DT><A HREF="https://huggingface.co/docs/transformers/quantization/fbgemm_fp8">FBGEMM FP8</A>
										<DT><A HREF="https://github.com/pytorch/FBGEMM">pytorch/FBGEMM: FB (Facebook) + GEMM (General Matrix-Matrix Multiplication)</A>
										<DT><A HREF="https://pytorch.org/blog/accelerating-llama3/">Accelerating Llama3 FP8 Inference with Triton Kernels | PyTorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/138536">[Prototype] Adding lowering to persistent-tma device kernel for _scaled_mm by drisspg ¬∑ Pull Request #138536 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/search?q=repo%3Adrisspg%2Ftransformer_nuggets%20ProfileConfig&type=code">repo:drisspg/transformer_nuggets ProfileConfig</A>
									</DL><p>
									<DT><A HREF="https://pytorch.org/blog/accelerating-generative-ai-2/">Accelerating Generative AI with PyTorch II: GPT, Fast | PyTorch</A>
									<DT><A HREF="https://github.com/pytorch-labs">PyTorch Labs</A>
									<DT><A HREF="https://github.com/pytorch-labs/gpt-fast">pytorch-labs/gpt-fast: Simple and efficient pytorch-native transformer text generation in &lt;1000 LOC of python.</A>
									<DT><A HREF="https://github.com/pytorch-labs/float8_experimental">pytorch-labs/float8_experimental</A>
									<DT><A HREF="https://github.com/pytorch-labs/ao/issues/47">[RFC] Plans for torchao ¬∑ Issue #47 ¬∑ pytorch-labs/ao</A>
									<DT><A HREF="https://github.com/pytorch-labs/segment-anything-fast">pytorch-labs/segment-anything-fast: A batched offline inference oriented version of SAM</A>
									<DT><A HREF="https://github.com/pytorch-labs/ao">pytorch-labs/ao: api's and workflows for quantization and pruning gpu models.</A>
									<DT><A HREF="https://github.com/Chillee/lit-llama">Chillee/lit-llama: Simple transformer inference in PyTorch with torch.compile + lit-llama code</A>
									<DT><A HREF="https://github.com/pytorch-labs/torchfix">pytorch-labs/torchfix: TorchFix - a linter for PyTorch-using code with autofix support</A>
									<DT><A HREF="https://github.com/pytorch-labs/applied-ai">pytorch-labs/applied-ai: Applied AI experiments and examples for PyTorch</A>
									<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/de17730a993b1d2cce4fd09e3654b5f79fd23c96/kernels/triton/inference/gptq/a100_qlinear.py#L109">applied-ai: Triton GPTQ a100_qlinear.py (print perf stats)</A>
								</DL><p>
								<DT><H3 FOLDED>torch-research-facebookexperimental</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookexperimental/protoquant">facebookexperimental/protoquant: Prototype routines for GPU quantization written using PyTorch.</A>
									<DT><A HREF="https://github.com/youkaichao/TRUMPY">youkaichao/TRUMPY: Analyze backward memory usage in pytorch!</A>
									<DT><A HREF="https://github.com/lucidrains/pytorch-custom-utils">lucidrains/pytorch-custom-utils: Just some miscellaneous utility functions / decorators / modules related to Pytorch and Accelerate to help speed up implementation of new AI research</A>
									<DT><A HREF="https://github.com/pytorch-labs/ao">pytorch-labs/ao: The torchao repository contains api's and workflows for quantization and pruning gpu models.</A>
									<DT><A HREF="https://pytorch.org/blog/accelerating-triton/?utm_content=278887799&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Accelerating Triton Dequantization Kernels for GPTQ | PyTorch</A>
									<DT><A HREF="https://github.com/NVIDIA/TransformerEngine">NVIDIA/TransformerEngine: A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.</A>
									<DT><A HREF="https://github.com/facebookincubator">Meta Incubator</A>
									<DT><A HREF="https://pytorch.org/blog/accelerating-llama3/">Accelerating Llama3 FP8 Inference with Triton Kernels | PyTorch</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/tensordict">pytorch/tensordict: TensorDict is a pytorch dedicated tensor container.</A>
								<DT><A HREF="https://github.com/BobMcDear/attorch">BobMcDear/attorch: A subset of PyTorch's neural network modules, written in Python using OpenAI's Triton.</A>
								<DT><A HREF="https://github.com/lernapparat/torchhacks">lernapparat/torchhacks: Hacks for PyTorch</A>
							</DL><p>
							<DT><H3 FOLDED>torch-debug</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-watchdog</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/2101d93b4f2749cfd8a15b70a4c1f7f57b606075/python/sglang/srt/managers/scheduler.py#L2303">sglang/python/sglang/srt/managers/scheduler.py at 2101d93b4f2749cfd8a15b70a4c1f7f57b606075 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/148284dcf6c64b3abdaa2dca2e784f9c245425f6/megatron/training/inprocess_restart.py#L108">Megatron-LM/megatron/training/inprocess_restart.py at 148284dcf6c64b3abdaa2dca2e784f9c245425f6 ¬∑ NVIDIA/Megatron-LM</A>
								</DL><p>
								<DT><H3 FOLDED>torch-debug-tracing</H3>
								<DL><p>
									<DT><H3 FOLDED>dynolog</H3>
									<DL><p>
										<DT><A HREF="https://github.com/facebookincubator/dynolog">facebookincubator/dynolog: Dynolog is a telemetry daemon for performance monitoring and tracing. It exports metrics from different components in the system like the linux kernel, CPU, disks, Intel PT, GPUs etc. Dynolog also integrates with pytorch and can trigger traces for distributed training applications.</A>
										<DT><A HREF="https://pytorch.org/blog/performance-debugging-of-production-pytorch-models-at-meta/">Performance Debugging of Production PyTorch Models at Meta ‚Äì PyTorch</A>
									</DL><p>
									<DT><A HREF="https://pytorch.org/blog/trace-analysis-for-masses/">PyTorch Trace Analysis for the Masses | PyTorch</A>
									<DT><A HREF="https://pytorch.org/blog/trace-analysis-for-masses/">PyTorch Trace Analysis for the Masses</A>
									<DT><A HREF="https://pytorch-dev-podcast.simplecast.com/episodes/torch-trace-and-tlparse">TORCH_TRACE and tlparse | PyTorch Developer Podcast</A>
									<DT><A HREF="https://twitter.com/ezyang/status/1777475405642907887">(1) Edward Z. Yang en X: "I spent my airplane ride home polishing up torchdbg on a trace of maskrcnn. Here's the result (no need to collect a trace yourself, this downloads one I pre-baked for you): https://t.co/1E3pVnxO9g" / X</A>
								</DL><p>
								<DT><H3 FOLDED>torch-metrics</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Lightning-AI/torchmetrics">Lightning-AI/torchmetrics: Torchmetrics - Machine learning metrics for distributed, scalable PyTorch applications.</A>
								</DL><p>
								<DT><H3 FOLDED>torch-debug-cuda-kernels</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=tNe-18qVRXg&list=LL&index=163&t=569s">Demystify CUDA Debugging and Performance with Powerful Developer Tools NVIDIA On Demand - YouTube</A>
									<DT><A HREF="https://christianjmills.com/posts/cuda-mode-notes/lecture-001/">Christian Mills - CUDA MODE Lecture 1: How to profile CUDA kernels in PyTorch</A>
								</DL><p>
								<DT><H3 FOLDED>torch-graph</H3>
								<DL><p>
									<DT><A HREF="https://fkong.tech/posts/2023-05-31-torch-graph/">50 lines of code to capture PyTorch forward and reverse computation graphs</A>
									<DT><A HREF="https://github.com/alpha0422/torch-graph/tree/main">alpha0422/torch-graph: Simple PyTorch graph capturing.</A>
								</DL><p>
								<DT><A HREF="https://github.com/zasdfgbnm/TorchSnooper">zasdfgbnm/TorchSnooper: Debug PyTorch code using PySnooper</A>
								<DT><A HREF="https://github.com/xl0/lovely-tensors">xl0/lovely-tensors: Tensors, for human consumption</A>
								<DT><A HREF="https://github.com/graphcore-research/pytorch-tensor-tracker">graphcore-research/pytorch-tensor-tracker: Flexibly track outputs and grad-outputs of torch.nn.Module.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=iSCF-VOJtEw">PyTorch: Debugging session - reference cycle - YouTube</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/torch-compile-can-be-debugged-now/1595">Torch.compile can be debugged now! - compiler - PyTorch Dev Discussions</A>
								<DT><A HREF="https://pytorch.org/blog/understanding-gpu-memory-2/">Understanding GPU Memory 2: Finding and Removing Reference Cycles | PyTorch</A>
								<DT><A HREF="https://www.youtube.com/watch?v=LuhJEEJQgUM">Lecture 1 How to profile CUDA kernels in PyTorch - YouTube</A>
								<DT><A HREF="https://medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd">Shape Suffixes ‚Äî Good Coding Style | by Noam Shazeer | Feb, 2024 | Medium</A>
								<DT><A HREF="https://github.com/facebookincubator/dynolog">facebookincubator/dynolog: Dynolog is a telemetry daemon for performance monitoring and tracing. It exports metrics from different components in the system like the linux kernel, CPU, disks, Intel PT, GPUs etc. Dynolog also integrates with pytorch and can trigger traces for distributed training applications.</A>
								<DT><A HREF="https://github.com/ezyang/torchdbg">ezyang/torchdbg: PyTorch centric eager mode debugger</A>
								<DT><A HREF="https://github.com/ezyang/tlparse">ezyang/tlparse: TORCH_LOGS parser for PT2</A>
								<DT><A HREF="https://github.com/google-ai-edge/model-explorer/tree/main">google-ai-edge/model-explorer: A modern model graph visualizer and debugger</A>
								<DT><A HREF="https://github.com/cloneofsimo/reverse_eng_deepspeed_study/blob/main/day3/multiprocessing_pdb/multiprocessing_pdb/multiprocessing_pdb.py">nvoke-pdb-on-a-specific-rank-in-multi-node-training</A>
								<DT><A HREF="https://leimao.github.io/article/How-To-Debug-Deep-Learning-Inference-Applications/">How To Debug Deep Learning Inference Applications - Lei Mao's Log Book</A>
								<DT><A HREF="https://fkong.tech/posts/2023-05-24-torch-source/">Some thoughts on reading PyTorch source code</A>
								<DT><A HREF="https://github.com/stas00/the-art-of-debugging/tree/master/pytorch#memory-usage">the-art-of-debugging/pytorch at master ¬∑ stas00/the-art-of-debugging</A>
								<DT><A HREF="https://github.com/stas00/the-art-of-debugging/tree/master">stas00/the-art-of-debugging: The Art of Debugging</A>
								<DT><A HREF="https://github.com/stas00/the-art-of-debugging/tree/master/pytorch#2-editing-the-config-object-on-the-fly">the-art-of-debugging/pytorch at master ¬∑ stas00/the-art-of-debugging</A>
							</DL><p>
							<DT><H3 FOLDED>torch-inference</H3>
							<DL><p>
								<DT><A HREF="https://pytorch.org/blog/accelerating-generative-ai/">Accelerating Generative AI with PyTorch: Segment Anything, Fast | PyTorch</A>
								<DT><A HREF="https://twitter.com/PyTorch/status/1725242585667584453">(1) PyTorch en X: "New blog series: Accelerating Generative AI using native PyTorch. üî• In this post we talk through new PyTorch performance features from the conference and how they can be used to produce an 8x faster, entirely PyTorch implementation of Segment Anything. https://t.co/o4kc037DN8 https://t.co/QaOs0dIDB9" / X</A>
								<DT><A HREF="https://pytorch.org/blog/pytorch-compile-to-speed-up-inference/">PyTorch compile to speed up inference on Llama 2 | PyTorch</A>
								<DT><A HREF="https://pytorch.org/blog/high-performance-llama-2/?utm_content=270816312&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">High-Performance Llama 2 Training and Inference with PyTorch/XLA on Cloud TPUs | PyTorch</A>
								<DT><A HREF="https://github.com/NVIDIA/TransformerEngine">NVIDIA/TransformerEngine: A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/pull/114001">Introduce 3 low-latency, intra-node allreduce algorithms for small messages to PyTorch by yifuwang ¬∑ Pull Request #114001 ¬∑ pytorch/pytorch</A>
							</DL><p>
							<DT><H3 FOLDED>torch-deployment</H3>
							<DL><p>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/the-future-of-c-model-deployment/1282">The future of C++ model deployment</A>
							</DL><p>
							<DT><H3 FOLDED>torch.distributed</H3>
							<DL><p>
								<DT><H3 FOLDED>torchcomms</H3>
								<DL><p>
									<DT><H3 FOLDED>CTran</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-pytorch/torchcomms/tree/main/comms/ctran">torchcomms/comms/ctran at main ¬∑ meta-pytorch/torchcomms</A>
									</DL><p>
									<DT><H3 FOLDED>torchcomms-torchtitan</H3>
									<DL><p>
										<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:activity:7387514371779846144/">TorchComms' integration with TorchTitan</A>
										<DT><A HREF="https://github.com/pytorch/torchtitan/blob/main/torchtitan/experiments/torchcomms/README.md">torchtitan/torchtitan/experiments/torchcomms/README.md at main ¬∑ pytorch/torchtitan</A>
										<DT><A HREF="https://pytorch.org/blog/torchcomms/">torchcomms: a modern PyTorch communications API ‚Äì PyTorch</A>
									</DL><p>
									<DT><A HREF="https://github.com/meta-pytorch/torchcomms">meta-pytorch/torchcomms: torchcomms: a modern PyTorch communications API</A>
									<DT><A HREF="https://github.com/pytorch/torchtitan/blob/2ea6197b957936bdd4941e59a000cf31987a3184/torchtitan/experiments/torchcomms/README.md">torchtitan/torchtitan/experiments/torchcomms/README.md at 2ea6197b957936bdd4941e59a000cf31987a3184 ¬∑ pytorch/torchtitan</A>
									<DT><A HREF="https://github.com/fduwjj?tab=stars">fduwjj (Junjie Wang) / Starred</A>
									<DT><A HREF="https://pytorch.org/blog/torchcomms/">torchcomms: a modern PyTorch communications API ‚Äì PyTorch</A>
									<DT><A HREF="https://www.youtube.com/watch?v=B-BXSRwAVdE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=106">Sponsored Session: PyTorch Distributed and Fault Tolerance - Tristan Rice, Meta - YouTube</A>
									<DT><A HREF="https://x.com/sleenyre/status/1982160370723926033">(1) NYRE en X: "Reading through Torchcomms paper, there are a few nice features it introduces It defaults to zero copy transfer for comms. With copy-based transfers, it uses SM / HBM memory on GPU and maintains a small FIFO queue to transfer data. This can introduce some overhead + contention https://t.co/yku81z1cB1" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2510.20171">[2510.20171] Collective Communication for 100k+ GPUs</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-programming-model</H3>
								<DL><p>
									<DT><A HREF="https://github.com/cloneofsimo/min-fsdp/tree/main/journey/understanding_torch_distributed">min-fsdp/journey/understanding_torch_distributed at main ¬∑ cloneofsimo/min-fsdp</A>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1861606582234030265">With the Nvidia GB200 NVL72, can a single process launch kernels on all GPUs, CUDA:0 to CUDA:71, or do you still have to start CPU processes on 18 different hosts?</A>
									<DT><A HREF="https://github.com/pytorch/rfcs/pull/71">RFC-0042-torch-distributed-redesign by youkaichao ¬∑ Pull Request #71 ¬∑ pytorch/rfcs</A>
									<DT><A HREF="https://github.com/youkaichao/rfcs/blob/master/RFC-0042-torch-distributed-redesign.md">rfcs/RFC-0042-torch-distributed-redesign.md at master ¬∑ youkaichao/rfcs</A>
									<DT><A HREF="https://x.com/main_horse/status/1868667994995593534">Visualizing 6D Mesh Parallelism</A>
									<DT><A HREF="https://main-horse.github.io/posts/visualizing-6d/">Visualizing 6D Mesh Parallelism ¬∑ main</A>
									<DT><A HREF="https://www.youtube.com/watch?v=9MvD-XsowsE">Stanford CS231N | Spring 2025 | Lecture 11: Large Scale Distributed Training - YouTube</A>
									<DT><A HREF="https://handbook.eng.kempnerinstitute.harvard.edu/s5_ai_scaling_and_engineering/scalability/distributed_gpu_computing.html">17.4. Distributed GPU Computing ‚Äî Kempner Institute Computing Handbook</A>
									<DT><A HREF="https://ggrigorev.me/posts/introduction-to-parallelism/">Introduction to parallelism in PyTorch | George Grigorev Blog</A>
								</DL><p>
								<DT><H3 FOLDED>DeepSpeed</H3>
								<DL><p>
									<DT><H3 FOLDED>deepcompile</H3>
									<DL><p>
										<DT><H3 FOLDED>jax-shard-map</H3>
										<DL><p>
											<DT><A HREF="https://docs.jax.dev/en/latest/jep/14273-shard-map.html">shmap (shard_map) for simple per-device code ‚Äî JAX documentation</A>
										</DL><p>
										<DT><A HREF="https://github.com/deepspeedai/DeepSpeed/blob/master/blogs/deepcompile/README.md">DeepSpeed/blogs/deepcompile/README.md at master ¬∑ deepspeedai/DeepSpeed</A>
										<DT><A HREF="https://github.com/deepspeedai/DeepSpeed/tree/a01a2688b98aa90ac1dcf23012efbe13ba69ebcd/deepspeed/compile">DeepSpeed/deepspeed/compile at</A>
										<DT><A HREF="https://arxiv.org/abs/2105.04663">[2105.04663] GSPMD: General and Scalable Parallelization for ML Computation Graphs</A>
										<DT><A HREF="https://x.com/deepspeedai/status/1912457258270597264?s=12">Introducing üöÄDeepCompileüöÄ: compiler-based distributed training optimizations.</A>
										<DT><A HREF="https://arxiv.org/pdf/2504.09983">DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep Learning Training</A>
									</DL><p>
									<DT><A HREF="https://github.com/karpathy/nanochat/blob/master/nanochat/adamw.py">nanochat/nanochat/adamw.py at master ¬∑ karpathy/nanochat</A>
								</DL><p>
								<DT><H3 FOLDED>torch-NCCL</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-distributed-multi-node</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/tutorials/intermediate/ddp_series_multinode.html">Multinode Training ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
										<DT><A HREF="https://github.com/stas00/ml-engineering/blob/58bdecd9d245d4275b78f38a869631f9f08be168/network/benchmarks/all_reduce_bench.py#L49">ml-engineering/network/benchmarks/all_reduce_bench.py at 58bdecd9d245d4275b78f38a869631f9f08be168 ¬∑ stas00/ml-engineering</A>
										<DT><A HREF="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">Multi node PyTorch Distributed Training Guide For People In A Hurry</A>
										<DT><A HREF="https://docs.csc.fi/support/tutorials/ml-multi/">Multi-GPU and multi-node machine learning - Docs CSC</A>
										<DT><A HREF="https://aistudio.google.com/app/prompts/new_chat?pli=1">passwordless SSH setup to connect to the remote nodes and start the processes.</A>
										<DT><A HREF="https://www.ssh.com/academy/ssh/copy-id">What is ssh-copy-id? How ssh-copy-id works?</A>
									</DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/how-to-capture-nccl-communication-ops-in-faketensormode/1410">How to capture NCCL communication ops in FakeTensorMode</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/114001">Introduce 3 low-latency, intra-node allreduce algorithms for small messages to PyTorch by yifuwang ¬∑ Pull Request #114001 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://hazyresearch.stanford.edu/blog/2025-09-22-pgl">One Kernel for All Your GPUs ¬∑ Hazy Research</A>
								</DL><p>
								<DT><H3 FOLDED>DTensor</H3>
								<DL><p>
									<DT><H3 FOLDED>dtensor-docs</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=yd37O-xu2-4">Introduction to PyTorch DeviceMesh and DTensor - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=b8lplOf2g4g">Learning DTensor - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>dtensor-debug</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/162665">[DTensor] Introduce DebugMode by SherlockNoMad ¬∑ Pull Request #162665 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/162665/files">[DTensor] Introduce DebugMode by SherlockNoMad ¬∑ Pull Request #162665 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>Async Tensor Parallelism</H3>
									<DL><p>
										<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-introducing-async-tensor-parallelism-in-pytorch/209487">[Distributed w/ TorchTitan] Introducing Async Tensor Parallelism in PyTorch - distributed / torchtitan - PyTorch Forums</A>
										<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/05/26/async-tp.html">An illustrated deep-dive into how the compute and comms in TP+SP are overlapped using Async TP | ML Perf Notes</A>
									</DL><p>
									<DT><H3 FOLDED>SP</H3>
									<DL><p>
										<DT><A HREF="https://github.com/facebookresearch/xformers/blob/a99afbbd042ae2ab6cd63d67a7b26e6851da44ba/xformers/ops/sequence_parallel_fused_ops.py">xformers/xformers/ops/sequence_parallel_fused_ops.py: FusedSequenceParallel</A>
										<DT><A HREF="https://huggingface.co/blog/exploding-gradients/ulysses-ring-attention">Ultra-Long Sequence Parallelism: Ulysses + Ring-Attention Technical Principles and Implementation</A>
									</DL><p>
									<DT><H3 FOLDED>DTensorTestBase</H3>
									<DL><p>
										<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/tests/context_parallel/test_diffusers_adapters.py">xDiT/tests/context_parallel/test_diffusers_adapters.py at main ¬∑ xdit-project/xDiT</A>
										<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/16ab3b17c415b80bb757fe48fa6e95d0adda9430/tests/context_parallel/test_diffusers_adapters.py">ParaAttention/tests/context_parallel/test_diffusers_adapters.py at 16ab3b17c415b80bb757fe48fa6e95d0adda9430 ¬∑ chengzeyi/ParaAttention</A>
									</DL><p>
									<DT><H3 FOLDED>dtensor-sharding</H3>
									<DL><p>
										<DT><A HREF="https://blog.ezyang.com/2026/01/computing-sharding-with-einsum/">Computing sharding with einsum : ezyang's blog</A>
									</DL><p>
									<DT><H3 FOLDED>dtensor-by-hand</H3>
									<DL><p>
										<DT><A HREF="https://dev.to/lewis_won/tensor-parallelism-by-hand-3eh">Tensor parallelism by hand - DEV Community</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=yd37O-xu2-4">Introduction to PyTorch DeviceMesh and DTensor - YouTube</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/distributed/_tensor/README.md">pytorch/torch/distributed/_tensor/README.md at main</A>
									<DT><A HREF="https://pytorch.org/blog/training-moes/?utm_content=298456196&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Training MoEs at Scale with PyTorch | PyTorch</A>
									<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-training-with-zero-bubble-pipeline-parallelism/214420">[Distributed w/ TorchTitan] Training with Zero-Bubble Pipeline Parallelism - distributed / torchtitan - PyTorch Forums</A>
									<DT><A HREF="https://docs.google.com/document/d/1nFeJ8NSFNhNlCkNgWK31ZGRqm1L9rd0i_XN_RprphaI/edit?tab=t.0#heading=h.s66tp71b0w6g">[RFC] PyTorch DistributedTensor - Google Docs</A>
									<DT><A HREF="https://wassimseifeddine.com/posts/torchtitan/">TensorParallism using DTensor in Torchtitan</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/tree/main/torch/distributed/tensor">pytorch/torch/distributed/tensor at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/wangkuiyi/dtensor">wangkuiyi/dtensor: Facilities for PyTorch DTensor</A>
									<DT><A HREF="https://www.linkedin.com/posts/yidewang_oneflow-activity-7323911573947797504--nDC/">Partial(): The Partial Placement of PyTorch's DTensors</A>
									<DT><A HREF="https://arxiv.org/abs/2204.10923">[2204.10923] You Only Linearize Once: Tangents Transpose to Gradients</A>
									<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/03/30/illustrated-megatron.html">An illustrated deep-dive into Megatron-style tensor parallelism | ML Perf Notes</A>
									<DT><A HREF="https://dev.to/lewis_won/tensor-parallelism-by-hand-3eh">Tensor parallelism by hand - DEV Community</A>
									<DT><A HREF="https://www.youtube.com/watch?v=wZAsO9qx3_c&t=736s">Walk through compile_fx - YouTube</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1979470062361530986">torchtitan: (I) Introduction to DTensor Principles and Usage</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1980403741661361517">torchtitan: (Part 2) Detailed Explanation and Usage of DeviceMesh and Placement</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/dtensor-status-design-and-looking-forward/2749">DTensor - Status, Design and Looking Forward - distributed - PyTorch Developer Mailing List</A>
								</DL><p>
								<DT><H3 FOLDED>DeviceMesh</H3>
								<DL><p>
									<DT><H3 FOLDED>deviceMesh-docs</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=yd37O-xu2-4">Introduction to PyTorch DeviceMesh and DTensor - YouTube</A>
									</DL><p>
									<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:ugcPost:7304979416915361792/?commentUrn=urn%3Ali%3Acomment%3A%28ugcPost%3A7304979416915361792%2C7305031143198760960%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287305031143198760960%2Curn%3Ali%3AugcPost%3A7304979416915361792%29">Yi Wang: FSDP + TP</A>
									<DT><A HREF="https://www.linkedin.com/in/antferdom/recent-activity/reactions/">(3) Activity | Antonio J. Dominguez | LinkedIn</A>
									<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:activity:7315771292253614080/">A Path to Learn PyTorch Device Mesh for LLM Training</A>
									<DT><A HREF="https://docs.google.com/document/d/1no2_lv5zS6YMg1nG_64Er_b2it58h_R2dmchJcEu_QQ/edit?tab=t.0#heading=h.t0e4hkur98pp">The relationship between local and global ranks in device mesh - Google Docs</A>
									<DT><A HREF="https://x.com/ezyang/status/1962364978393981433">(1) Edward Z. Yang en X: "A Short Note About Complements of CuTe Layout</A>
									<DT><A HREF="https://x.com/difficultyang/status/1960186140159308124">(1) difficultyang en X: "I'm a dumbass, I thought you need separate dims in your device mesh for DP and FSDP" / X</A>
									<DT><A HREF="https://x.com/cHHillee/status/1960818949840626085">(1) Horace He en X: "@rvarm1 @JingyuanLiu123 The TPU scaling book is quite good and so is the HF ultra-scale book. If you search internally at Meta, I also wrote a "When you need to go beyond FSDP" note a long time ago that I think is still a good place to start! (although I would want to update a number of things)" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=yd37O-xu2-4">Introduction to PyTorch DeviceMesh and DTensor - YouTube</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1980403741661361517">torchtitan: (Part 2) Detailed Explanation and Usage of DeviceMesh and Placement</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1979114298774142999">SGLang Torch Compile &amp; Piecewise CUDA Graph Ë∞ÉËØïÊåáÂçó</A>
								</DL><p>
								<DT><H3 FOLDED>overlap-compute-comm</H3>
								<DL><p>
									<DT><H3 FOLDED>tokenweave</H3>
									<DL><p>
										<DT><A HREF="https://github.com/microsoft/tokenweave">microsoft/tokenweave: Efficient Compute-Communication Overlap for Distributed LLM Inference</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/_inductor/config.py">pytorch/torch/_inductor/config.py at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/pytorch/torchtitan/blob/main/docs/fsdp.md">torchtitan/docs/fsdp.md at main ¬∑ pytorch/torchtitan</A>
									<DT><A HREF="https://pytorch.org/docs/stable/fsdp.html">FullyShardedDataParallel ‚Äî PyTorch 2.6 documentation</A>
									<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-introducing-async-tensor-parallelism-in-pytorch/209487">[Distributed w/ TorchTitan] Introducing Async Tensor Parallelism in PyTorch - distributed / torchtitan - PyTorch Forums</A>
									<DT><A HREF="https://www.youtube.com/watch?v=NAZdEzcGGJM">Streaming DiLoCo with overlapping communication: Towards a Distributed Free Lunch - YouTube</A>
									<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/05/26/async-tp.html">An illustrated deep-dive into how the compute and comms in TP+SP are overlapped using Async TP | ML Perf Notes</A>
									<DT><A HREF="https://x.com/apaszke/status/1977749757930950862">(1) Adam Paszke en X: "Want to improve GPU compute/comms overlap? We just published a new short tutorial for you! A few small changes to the Pallas:MGPU matmul kernel is all it takes to turn it into an all-gather collective matmul that overlaps NVLINK comms with local compute: https://t.co/HY4C3MwMb7" / X</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/collective_matmul.html">Collective matrix multiplication ‚Äî JAX documentation</A>
								</DL><p>
								<DT><H3 FOLDED>ddp</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-ddp-multi-node</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/examples/blob/main/distributed/ddp-tutorial-series/multinode.py">examples/distributed/ddp-tutorial-series/multinode.py at main ¬∑ pytorch/examples</A>
									</DL><p>
									<DT><H3 FOLDED>torch-ddp-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/examples/blob/main/distributed/ddp-tutorial-series/multinode.py">examples/distributed/ddp-tutorial-series/multinode.py at main ¬∑ pytorch/examples</A>
										<DT><A HREF="https://github.com/pytorch/examples/blob/main/distributed/ddp/README.md">examples/distributed/ddp/README.md at main ¬∑ pytorch/examples</A>
									</DL><p>
									<DT><A HREF="https://lambdalabs.com/blog/multi-node-pytorch-distributed-training-guide">Multi node PyTorch Distributed Training Guide For People In A Hurry</A>
									<DT><A HREF="https://ggrigorev.me/posts/introduction-to-parallelism/">Introduction to parallelism in PyTorch | George Grigorev Blog</A>
									<DT><A HREF="https://x.com/mrsiipa/status/1857634705299915110">(1) maharshi en X: "Some notes on adding distributed data parallelism (DDP) on CPU to smolgrad: 1. DDP basically means that the whole model is distributed to different devices/cores/processes and each core uses the same model to process the batch of data given to that specific core (same model, https://t.co/GoYVNg6Yb2" / X</A>
									<DT><A HREF="https://github.com/smolorg/smolgrad/blob/distributed/smolgrad/distributed/ddp.py">smolgrad/smolgrad/distributed/ddp.py at distributed ¬∑ smolorg/smolgrad</A>
									<DT><A HREF="https://x.com/mrsiipa/status/1916467874136285329">understanding DDP is easy: these two functions are technically all you need to implement Distributed Data Parallel (DDP)</A>
									<DT><A HREF="https://siboehm.com/articles/22/data-parallel-training">Data-Parallel Distributed Training of Deep Learning Models</A>
								</DL><p>
								<DT><H3 FOLDED>torch-fsdp</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-fsdp-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/examples/tree/main/distributed/FSDP">examples/distributed/FSDP at main ¬∑ pytorch/examples</A>
									</DL><p>
									<DT><H3 FOLDED>FSDP</H3>
									<DL><p>
										<DT><H3 FOLDED>fsdp-torch-compile</H3>
										<DL><p>
											<DT><A HREF="https://pytorch.org/blog/maximizing-training-throughput/?utm_content=293931524&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Maximizing Training Throughput Using PyTorch FSDP and Torch.compile | PyTorch</A>
											<DT><A HREF="https://github.com/ByronHsu/torch-compile-fsdp-error/blob/master/training.py">torch-compile-fsdp-error/training.py at master ¬∑ ByronHsu/torch-compile-fsdp-error</A>
											<DT><A HREF="https://x.com/main_horse/status/1937900381574717940">del compiled objects &amp;&amp; call torch._dynamo.reset() distributed group cleanup</A>
											<DT><A HREF="https://x.com/cloneofsimo/status/1856456622308241744">ont you dare fucking use mode = 'reduce-overhead' when using both torch.compile and fsdp2 (fully_shard)</A>
										</DL><p>
										<DT><H3 FOLDED>fsdp-CUDACachingAllocator</H3>
										<DL><p>
											<DT><A HREF="https://dev-discuss.pytorch.org/t/fsdp-cudacachingallocator-an-outsider-newb-perspective/1486/1">FSDP &amp; CUDACachingAllocator: an outsider newb perspective - distributed - PyTorch Developer Mailing List</A>
										</DL><p>
										<DT><H3 FOLDED>fsdp-memory</H3>
										<DL><p>
											<DT><A HREF="https://x.com/main_horse/status/1951907968137744746">grad reduce scatter hack for fsdpv2</A>
										</DL><p>
										<DT><H3 FOLDED>fsdp-compute-comm-overlap</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=mzHed-fKHx8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=116">Lightning Talk: Accelerating PyTorch FSDP Via Overlapping Collectives With In... - Nariaki Tateiwa - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>fsdp-optimization</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=EoePOh9bTKs&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=119">Enabling Lightweight, High-Performance FSDP With NVIDIA GPU - J. Chang CN, C. Ye, X. Chen &amp; S. Lym - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>simpleFSDP</H3>
										<DL><p>
											<DT><A HREF="https://arxiv.org/pdf/2411.00284">SimpleFSDP: Simpler Fully Sharded Data Parallel with torch.compile</A>
											<DT><A HREF="https://github.com/pytorch/torchtitan/tree/ad78ed86ccbbe0c5026a61f58d2246e6aab627c2/torchtitan/experiments/simple_fsdp">torchtitan/torchtitan/experiments/simple_fsdp</A>
											<DT><A HREF="https://github.com/LinB203/FSDP-Training">LinB203/FSDP-Training: Minimal PyTorch implementation of TP, SP, FSDP and sharded-EMA</A>
										</DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=h8PzTlTcfDg">George Hotz | Programming | FSDP explorations (distributed training) | tinycorp.myshopify.com - YouTube</A>
										<DT><A HREF="https://arxiv.org/abs/2304.11277">[2304.11277] PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</A>
										<DT><A HREF="https://engineering.fb.com/2021/07/15/open-source/fsdp/">Fully Sharded Data Parallel: faster AI training with fewer GPUs Engineering at Meta -</A>
										<DT><A HREF="https://engineering.fb.com/2020/08/24/production-engineering/scaling-services-with-shard-manager/">Scaling services with Shard Manager - Engineering at Meta</A>
										<DT><A HREF="https://github.com/pytorch/tutorials/blob/main/intermediate_source/FSDP_tutorial.rst">tutorials/intermediate_source/FSDP_tutorial.rst</A>
										<DT><A HREF="https://github.com/pytorch/tutorials/blob/main/intermediate_source/FSDP_adavnced_tutorial.rst">tutorials/intermediate_source/FSDP_adavnced_tutorial.rst</A>
										<DT><A HREF="https://scholar.google.co.uk/citations?view_op=view_citation&hl=en&user=_cHRq1kAAAAJ&citft=1&email_for_op=antonio.jfdominguez%40gmail.com&citation_for_view=_cHRq1kAAAAJ:mVmsd5A6BfQC">PyTorch FSDP: experiences on scaling fully sharded data parallel</A>
										<DT><A HREF="https://www.youtube.com/watch?v=a3iW6Cggccw">Part 4: FSDP Sharding Strategies</A>
										<DT><A HREF="https://www.youtube.com/watch?v=NiL7egqyJEI">[Long Review] Fully Sharded Data Parallel</A>
										<DT><A HREF="https://www.youtube.com/watch?v=By_O0k102PY">How Fully Sharded Data Parallel (FSDP) works</A>
										<DT><A HREF="https://github.com/facebookresearch/llama-recipes/blob/main/docs/multi_gpu.md">llama-recipes/docs/multi_gpu.md</A>
										<DT><A HREF="https://www.youtube.com/watch?v=3XUG7cjte2U">Invited Talk: PyTorch Distributed (DDP, RPC) - By Facebook Research Scientist Shen Li - YouTube</A>
										<DT><A HREF="https://github.com/foundation-model-stack/fms-fsdp">foundation-model-stack/fms-fsdp: üöÄ Efficiently (pre)training foundation models with native PyTorch features, including FSDP for training and SDPA implementation of Flash attention v2.</A>
										<DT><A HREF="https://github.com/pytorch/torchtitan">pytorch/torchtitan: A native PyTorch Library for large model training</A>
										<DT><A HREF="https://github.com/pytorch/torchsnapshot/blob/ce8d7b6d118816313b1da733cdb5a29ec0cd686a/benchmarks/fsdp/main.py#L38">torchsnapshot/benchmarks/fsdp/main.py</A>
										<DT><A HREF="https://sumanthrh.com/post/distributed-and-efficient-finetuning/">Everything about Distributed Training and Efficient Finetuning | Sumanth's Personal Website</A>
										<DT><A HREF="https://medium.com/pytorch/training-a-1-trillion-parameter-model-with-pytorch-fully-sharded-data-parallel-on-aws-3ac13aa96cff">Training a 1 Trillion Parameter Model With PyTorch Fully Sharded Data Parallel on AWS | by PyTorch | PyTorch | Medium</A>
										<DT><A HREF="https://www.youtube.com/watch?v=Hr2FWHBuNXs">L12b Parallelization -- Instructor: Wilson Yan - YouTube</A>
										<DT><A HREF="https://vitalflux.com/distributed-llm-training-explained-with-examples/">Distributed LLM Training &amp; DDP, FSDP Patterns: Examples</A>
										<DT><A HREF="https://github.com/Aleph-Alpha/scaling">Aleph-Alpha/scaling: Scaling is a distributed training library and installable dependency designed to scale up neural networks, with a dedicated module for training large language models.</A>
										<DT><A HREF="https://www.youtube.com/watch?v=pHFUUnXa6nU">PyTorch Composability Sync - AutoFSDP - YouTube</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/tree/main/torch/distributed/fsdp">pytorch/torch/distributed/fsdp at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://x.com/giffmana/status/1982393685166936135">(1) Lucas Beyer (bl16) en X: "My hot take: I hate all the PyTorch community's distribution strategy names (FooParallel). It's not even about parallelism!! All names should just be "shard X along Y" and that's it. Fully self explanatory and never ambiguous." / X</A>
										<DT><A HREF="https://karthick.ai/blog/2024/Fully-Sharded-Data-Parallel-(FSDP)/">Fully Sharded Data Parallel (FSDP) | Karthick Panner Selvam</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1994522560612824841">Miscellaneous Thoughts: Efficiency Analysis of FSDP</A>
									</DL><p>
									<DT><H3 FOLDED>FSDP2</H3>
									<DL><p>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/enabling-float8-all-gather-in-fsdp2/2359">Enabling Float8 All-Gather in FSDP2 - distributed - PyTorch Developer Mailing List</A>
										<DT><A HREF="https://pytorch.org/blog/training-using-float8-fsdp2/?utm_content=317436495&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Supercharging Training using float8 and FSDP2 | PyTorch</A>
										<DT><A HREF="https://docs.pytorch.org/tutorials/intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel (FSDP2) ‚Äî PyTorch Tutorials 2.7.0+cu126 documentation</A>
										<DT><A HREF="https://www.linkedin.com/pulse/rl-system-deep-dive-fsdp-training-backend-chenyang-zhao-jjeoe/">RL System Deep Dive: FSDP Training Backend | LinkedIn</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/commit/0a0023d9840570938a10472418eaac85098ec41b">Enable NCCL zero-copy (user buffer registration) for FSDP2 (#150564) ¬∑ pytorch/pytorch@0a0023d</A>
										<DT><A HREF="https://huggingface.co/docs/accelerate/main/en/concept_guides/fsdp1_vs_fsdp2">FSDP1 vs FSDP2</A>
										<DT><A HREF="https://pyemma.github.io/FSDP2-Code-Walk/">FSDP2 Under the Hood - A Deep Dive into PyTorch's Fully Sharded Data Parallel Implementation | Coding Monkey</A>
									</DL><p>
									<DT><H3 FOLDED>YaFSDP</H3>
									<DL><p>
										<DT><A HREF="https://github.com/yandex/YaFSDP">yandex/YaFSDP: YaFSDP: Yet another Fully Sharded Data Parallel</A>
									</DL><p>
									<DT><A HREF="https://engineering.fb.com/2021/07/15/open-source/fsdp/">Fully Sharded Data Parallel: faster AI training with fewer GPUs Engineering at Meta -</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/49f6ea6dd91c7d069cf6103eb00b1b849f1bdc03/torch/distributed/checkpoint/examples/fsdp_checkpoint_example.py#L59">pytorch/torch/distributed/checkpoint/examples/fsdp_checkpoint_example.py at 49f6ea6dd91c7d069cf6103eb00b1b849f1bdc03 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://www.youtube.com/watch?v=pHFUUnXa6nU">PyTorch Composability Sync - AutoFSDP - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-test</H3>
								<DL><p>
									<DT><A HREF="https://github.com/cupy/cupy/blob/1794c835a086dda4cfb82d1152a495b61a82cbdc/tests/cupyx_tests/distributed_tests/comm_runner.py">cupy/tests/cupyx_tests/distributed_tests/comm_runner.py</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-profiling</H3>
								<DL><p>
									<DT><H3 FOLDED>all-reduce</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/geohot/e11dc1b1058ed9e0bc6610249263b024">Test Bandwidth of all reduce</A>
										<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/playground/other/test_cupy_partial_transfer.py">alpa/playground/other/test_cupy_partial_transfer.py</A>
										<DT><A HREF="https://github.com/cupy/cupy/blob/cf9b4a517725b803fba4828ed0b1c93a231cc5da/cupyx/distributed/_nccl_comm.py#L56">cupy/cupyx/distributed/_nccl_comm.py</A>
										<DT><A HREF="https://github.com/cupy/cupy/blob/1794c835a086dda4cfb82d1152a495b61a82cbdc/tests/cupyx_tests/distributed_tests/test_comm.py#L20">cupy/tests/cupyx_tests/distributed_tests/test_comm.py: test_broadcast</A>
										<DT><A HREF="https://github.com/cupy/cupy/blob/1794c835a086dda4cfb82d1152a495b61a82cbdc/tests/cupyx_tests/distributed_tests/comm_runner.py">cupy/tests/cupyx_tests/distributed_tests/comm_runner.py</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/nccl-tests">NVIDIA/nccl-tests: NCCL Tests</A>
									<DT><A HREF="https://github.com/cupy/cupy/blob/cf9b4a517725b803fba4828ed0b1c93a231cc5da/cupyx/distributed/_nccl_comm.py#L56">cupy/cupyx/distributed/_nccl_comm.py: All NCCL primitives</A>
									<DT><A HREF="https://github.com/cupy/cupy/blob/1794c835a086dda4cfb82d1152a495b61a82cbdc/tests/cupyx_tests/distributed_tests/comm_runner.py">cupy/tests/cupyx_tests/distributed_tests/comm_runner.py</A>
									<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/85e385b87f5a83bef6e2acfb56a273cb50a1fb1d/transformer_nuggets/utils/benchmark.py#L49">transformer_nuggets/transformer_nuggets/utils/benchmark.py at 85e385b87f5a83bef6e2acfb56a273cb50a1fb1d ¬∑ drisspg/transformer_nuggets</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-debug</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/69d401d01054a739f6e50ee83e23c14e6de50352/docs/source/distributed.rst#L604">pytorch/docs/source/distributed.rst: torch.distributed.breakpoint(rank=0)</A>
									<DT><A HREF="https://github.com/stas00/ml-engineering/blob/master/debug/pytorch.md#invoke-pdb-on-a-specific-rank-in-multi-node-training">ml-engineering/debug/pytorch.md: torch.distributed.breakpoint() -&gt; up;;n back to normal code</A>
									<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/sglang/latency-accelerte-for-weight-updates/readme.md">Awesome-ML-SYS-Tutorial/sglang/latency-accelerte-for-weight-updates/readme.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
									<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/tree/main/torch-distributed">dist.barrier(device_ids=[0], group=pg)</A>
									<DT><A HREF="https://pytorch.org/tutorials/beginner/hta_intro_tutorial.html">Introduction to Holistic Trace Analysis ‚Äî PyTorch Tutorials 2.6.0+cu124 documentation</A>
									<DT><A HREF="https://github.com/microsoft/debugpy/issues/783">use vscode to remote debug python program with tmux session ¬∑ Issue #783 ¬∑ microsoft/debugpy</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-utils</H3>
								<DL><p>
									<DT><H3 FOLDED>rank_0_print</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/torchsnapshot/blob/df45917d12b1e64a4567e8ca1a591909fffad02e/benchmarks/fsdp/main.py#L30">torchsnapshot/benchmarks/fsdp/main.py</A>
									</DL><p>
									<DT><A HREF="https://github.com/huggingface/nanotron/blob/03d67f2103d5be0dc15ea6022a6cf16d6a633064/src/nanotron/distributed.py#L247">initialize_torch_distributed: torch.distributed utils (nanotron)</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-shampo</H3>
								<DL><p>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1824368214371188848">distributed low-precision shampoo + ZeRO1 only with torch.dist primitive</A>
									<DT><A HREF="https://github.com/cloneofsimo/zeroshampoo">cloneofsimo/zeroshampoo</A>
								</DL><p>
								<DT><H3 FOLDED>torch-fault-tolerant</H3>
								<DL><p>
									<DT><H3 FOLDED>pccl</H3>
									<DL><p>
										<DT><A HREF="https://x.com/mike64_t/status/1925023713843675609">(1) mike64_t en X: "Excited to finally release what I‚Äôve been working on for the past 6 months - that being PCCL, a collective communications library / general training orchestration protocol designed to work over the public internet and find optimal routes. PCCL has been designed from the ground up" / X</A>
										<DT><A HREF="https://github.com/PrimeIntellect-ai/pccl">PrimeIntellect-ai/pccl: PCCL (Prime Collective Communications Library) implements fault tolerant collective communications over IP</A>
									</DL><p>
									<DT><H3 FOLDED>monarch</H3>
									<DL><p>
										<DT><H3 FOLDED>monarch-examples</H3>
										<DL><p>
											<DT><A HREF="https://meta-pytorch.org/monarch/generated/examples/index.html">Examples ‚Äî Monarch documentation</A>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch-labs/monarch">pytorch-labs/monarch: PyTorch Single Controller</A>
										<DT><A HREF="https://meta-pytorch.org/monarch/index.html">Monarch ü¶ã ‚Äî Monarch documentation</A>
										<DT><A HREF="https://pytorch.org/blog/introducing-pytorch-monarch/">Introducing PyTorch Monarch ‚Äì PyTorch</A>
										<DT><A HREF="https://pytorch.org/blog/integration-idea-monarch/">Monarch + Lightning AI: Unlocking New Possibilities in Distributed Training ‚Äì PyTorch</A>
									</DL><p>
									<DT><H3 FOLDED>torchft</H3>
									<DL><p>
										<DT><H3 FOLDED>torchft-torchtitan</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/torchtitan/commit/42fe05f8de2a7217f0c57b5bb3b6da8f0a792bae">add script to train with ft (#1812) ¬∑ pytorch/torchtitan@42fe05f</A>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch/torchft">pytorch/torchft: PyTorch per step fault tolerance (actively under development)</A>
										<DT><A HREF="https://www.youtube.com/watch?v=B-BXSRwAVdE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=106">Sponsored Session: PyTorch Distributed and Fault Tolerance - Tristan Rice, Meta - YouTube</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/nvidia-resiliency-ext">NVIDIA/nvidia-resiliency-ext: NVIDIA Resiliency Extension is a python package for framework developers and users to implement fault-tolerant features. It improves the effective training time by minimizing the downtime due to failures and interruptions.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=z9RHaQZnWM4">How xAI Scales Image &amp; Video Processing with Ray | Ray Summit 2025 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-experimental</H3>
								<DL><p>
									<DT><H3 FOLDED>_attention</H3>
									<DL><p>
										<DT><H3 FOLDED>_attention-test-ring-attention</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/ddd0ed1b430f3241490d9bc071036188466b0f22/test/distributed/_tensor/test_attention.py#L49">pytorch/test/distributed/_tensor/test_attention.py at ddd0ed1b430f3241490d9bc071036188466b0f22 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><H3 FOLDED>_attention-ring-attention</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/3c63e76b03737085e2eb2e7fb7163d7ba16986ba/torch/distributed/tensor/experimental/_attention.py#L358C5-L358C30">pytorch/torch/distributed/tensor/experimental/_attention.py at 3c63e76b03737085e2eb2e7fb7163d7ba16986ba ¬∑ pytorch/pytorch</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/commit/ddd0ed1b430f3241490d9bc071036188466b0f22">distributed: templated ring attention (#124215) ¬∑ pytorch/pytorch@ddd0ed1</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/3c63e76b03737085e2eb2e7fb7163d7ba16986ba/torch/distributed/tensor/experimental/_attention.py#L358">pytorch/torch/distributed/tensor/experimental/_attention.py at 3c63e76b03737085e2eb2e7fb7163d7ba16986ba ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><A HREF="https://github.com/xdit-project/xDiT/blob/main/xfuser/model_executor/layers/usp.py">xDiT/xfuser/model_executor/layers/usp.py at main</A>
									</DL><p>
									<DT><H3 FOLDED>torch-communication-overlap</H3>
									<DL><p>
										<DT><H3 FOLDED>torch-inductor-reorder_for_locality</H3>
										<DL><p>
											<DT><A HREF="https://x.com/YouJiacheng/status/1916063151034143022">(1) You Jiacheng en X: "despite the name of the pass, it really does the overlapping job..." / X</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/150074">[inductor][comms] skip reorder_for_locality for wait nodes by xmfan ¬∑ Pull Request #150074 ¬∑ pytorch/pytorch</A>
										</DL><p>
										<DT><A HREF="https://arxiv.org/html/2406.06858v1">Flux: Fast Software-based Communication Overlap on GPUs through Kernel Fusion</A>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/enabling-float8-all-gather-in-fsdp2/2359">Enabling Float8 All-Gather in FSDP2 - distributed - PyTorch Developer Mailing List</A>
									</DL><p>
									<DT><H3 FOLDED>symm-mem</H3>
									<DL><p>
										<DT><H3 FOLDED>symm-mem-NVSHMEM</H3>
										<DL><p>
											<DT><A HREF="https://x.com/SemiAnalysis_/status/1984722871848223158">(1) SemiAnalysis en X: "PyTorch symmetrical memory now supports multinode too üöÄexclusively on CUDA through NVSHMEM. We explain why this is important belowüëá This feature is crucial because it enables easy authoring of multi-GPU, multi-node compute-communication overlapping kernels using Triton or C++. https://t.co/ZHfhNEHCwF" / X</A>
											<DT><A HREF="https://github.com/meta-pytorch/kraken">meta-pytorch/kraken: Triton-based Symmetric Memory operators and examples</A>
										</DL><p>
										<DT><H3 FOLDED>symm-mem-theory</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=5vfcTjosGLg&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=112">PyTorch Symmetric Memory: A New Programming Paradigm for Distributed AI - Ke Wen &amp; Chien-Chin Huang - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>symm-mem-moe</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=5vfcTjosGLg&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=116">PyTorch Symmetric Memory: A New Programming Paradigm for Distributed AI - Ke Wen &amp; Chien-Chin Huang - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>kraken</H3>
										<DL><p>
											<DT><A HREF="https://github.com/meta-pytorch/kraken">meta-pytorch/kraken: Triton-based Symmetric Memory operators and examples</A>
										</DL><p>
										<DT><A HREF="https://github.com/yifuwang/symm-mem-recipes/blob/main/symm_mem_recipes/utils.py">symm-mem-recipes/symm_mem_recipes/utils.py at main ¬∑ yifuwang/symm-mem-recipes</A>
										<DT><A HREF="https://github.com/yifuwang/symm-mem-recipes/tree/main">yifuwang/symm-mem-recipes</A>
										<DT><A HREF="https://x.com/cloneofsimo/status/1962970961386627287">overlapped a2a with compute completely, as well as cc itself being faster</A>
										<DT><A HREF="https://x.com/cloneofsimo/status/1962795533933912158">(1) Simo Ryu en X: "Ok so im outside of rabbit hole, so it seems like you can get as large as 4x faster intranode all2all if you use torch's symmetric memory and implement it yourself but it wasnt implemented in torch Just Cause ‚Ñ¢ ? https://t.co/GPWE4cB5X6" / X</A>
										<DT><A HREF="https://github.com/meta-pytorch/kraken?tab=readme-ov-file">meta-pytorch/kraken: Triton-based Symmetric Memory operators and examples</A>
										<DT><A HREF="https://x.com/suryaasub/status/1978571295978930372">(1) surya en X: "take triton + symmetric memory for a spin in pytorch inter-node comms as well!</A>
										<DT><A HREF="https://x.com/suryaasub/status/1950480972593635383">gpu symmetric memory is underrated as a communication backend</A>
										<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-symmetricmemory-harnessing-nvlink-programmability-with-ease/2798">PyTorch SymmetricMemory: Harnessing NVLink Programmability with Ease - distributed - PyTorch Developer Mailing List</A>
									</DL><p>
									<DT><H3 FOLDED>autoparallel</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-pytorch/autoparallel">meta-pytorch/autoparallel: An experimental implementation of compiler-driven automatic sharding of models across a given device mesh.</A>
										<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
										<DT><A HREF="https://github.com/pytorch/torchtitan/pull/2231/changes">[autoparallel] Update local_map_deepseek_v3 device mesh usage by xmfan ¬∑ Pull Request #2231 ¬∑ pytorch/torchtitan</A>
									</DL><p>
									<DT><A HREF="https://x.com/eliebakouch/status/1980642834404319388">(1) elie en X: "Here is what the future looks like for training at scale: 1) Pre training: torchtitan -&amp;gt; for coms: torchcoms (new) -&amp;gt; low precision: torchao -&amp;gt; framework: monarch -&amp;gt; decentralize: torchft 2) Post training: torchforge (new) -&amp;gt; training: torchtitan -&amp;gt; inference: vllm -&amp;gt; RL env:" / X</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-cp</H3>
								<DL><p>
									<DT><H3 FOLDED>async-ulysses</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/distributed/sequence_parallel/ulysses.py">VeOmni/veomni/distributed/sequence_parallel/ulysses.py</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1939640210221671459">ÂõæËß£Async Ulysses CP - Áü•‰πé</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>_functional_collectives</H3>
								<DL><p>
									<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/main/src/para_attn/primitives.py">ParaAttention/src/para_attn/primitives.py: ft_c</A>
								</DL><p>
								<DT><H3 FOLDED>_tools.runtime_estimator</H3>
								<DL><p>
									<DT><H3 FOLDED>AutoFSDP</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=pHFUUnXa6nU&t=107s">PyTorch Composability Sync - AutoFSDP - YouTube</A>
									</DL><p>
									<DT><A HREF="https://x.com/typedfemale/status/1849716677560369201?s=12">AutoFSDP: grouping parameters to overlap communication with compute</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/afb173d9b9440d804b5f77d0c291e53c720d1fcf/torch/distributed/_tools/runtime_estimator.py#L27">pytorch/torch/distributed/_tools/runtime_estimator.py at afb173d9b9440d804b5f77d0c291e53c720d1fcf ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>torchrun</H3>
								<DL><p>
									<DT><H3 FOLDED>torchrun-numa</H3>
									<DL><p>
										<DT><A HREF="https://docs.pytorch.org/docs/main/elastic/numa.html#module-torch.distributed.numa">NUMA Binding Utilities ‚Äî PyTorch main documentation</A>
									</DL><p>
									<DT><H3 FOLDED>torch-distributed-logs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/pull/162999">[RFC]: No Distributed Log Spew by msaroufim ¬∑ Pull Request #162999 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><A HREF="https://x.com/apoorvkh/status/1899502812981350655">(2) Apoorv Khandelwal en X: "We made a library (torchrunx) to make multi-GPU / multi-node PyTorch easier, more robust, and more modular! üßµ https://t.co/EhrHVfMKWQ Docs: https://t.co/ExOfQZDIa5 `(uv) pip install torchrunx` today! (w/ the very talented, Peter Curtin, Brown CS '25)" / X</A>
									<DT><A HREF="https://torchrun.xyz/">torchrunx documentation</A>
									<DT><A HREF="https://github.com/apoorvkh/torchrunx">apoorvkh/torchrunx: Easily run PyTorch on multiple GPUs &amp; machines</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-sim</H3>
								<DL><p>
									<DT><H3 FOLDED>LocalTensor</H3>
									<DL><p>
										<DT><A HREF="https://x.com/ezyang/status/1991551453274788192">Edward Z. Yang en X: "On PyTorch nightlies you can easily simulate distributed programs on a single process with LocalTensor. Here's a little prologue that's good for putting in Colab that sets up all the scaffolding you need, and a small example: https://t.co/M1hGTGZZPN https://t.co/qmnRATyto2" / X</A>
										<DT><A HREF="https://gist.github.com/ezyang/9ef3300cd516150637592af1e8b76d7d">localtensor.py</A>
										<DT><A HREF="https://gist.github.com/ezyang/dc297e0234d0f61a0ada7c6aa61216c1">gist:dc297e0234d0f61a0ada7c6aa61216c1</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>global-trainer-scheduler</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>MAST</H3>
								<DL><p>
									<DT><A HREF="https://www.usenix.org/system/files/osdi24-choudhury.pdf">MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale</A>
									<DT><A HREF="https://www.linkedin.com/pulse/mast-how-meta-trained-ai-models-trillion-parameters-100k-yun-jin-ns4tc/">MAST: How Meta trained AI models with trillion parameters on 100K GPU clusters</A>
									<DT><A HREF="https://x.com/ShanuMathew93/status/1984344925090304175">(1) Shanu Mathew en X: "Feel like this didn't get enough attention! Big deal if true &amp;amp; rolling out. You've heard the GPU/ASICs guys already talk about scaling ACROSS data centers. This isn't just data centers located on state borders away from each other. Talking about 1,000 kms+. If true, this offers https://t.co/aCGo1bsV1Y" / X</A>
									<DT><A HREF="https://developer.nvidia.com/blog/turbocharge-llm-training-across-long-haul-data-center-networks-with-nvidia-nemo-framework/">Turbocharge LLM Training Across Long-Haul Data Center Networks with NVIDIA Nemo Framework | NVIDIA Technical Blog</A>
									<DT><A HREF="https://epochai.substack.com/p/solving-ais-power-problem-with-decentralized?utm_source=post-email-title&publication_id=3755861&post_id=177395137&utm_campaign=email-post-title&isFreemail=true&r=oqv1&triedRedirect=true&utm_medium=email">Solving AI‚Äôs power problem with decentralized training</A>
									<DT><A HREF="https://x.com/tenderizzation/status/1984303216050552969">dynamic range of bf16 with the precision of fp16</A>
								</DL><p>
								<DT><H3 FOLDED>torch-distributed-compile</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/130935">Introduce torch._dynamo.config.enable_compiler_collectives for syncing compilation across ranks by ezyang ¬∑ Pull Request #130935 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://discuss.pytorch.org/t/functional-collectives-used-in-torch-compile/190627">_functional_collectives used in torch.compile - distributed - PyTorch Forums</A>
								</DL><p>
								<DT><H3 FOLDED>torch.distributed._functional_collectives</H3>
								<DL><p>
									<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/4de137c5b96416489f06e43e19f2c14a772e28fd/src/para_attn/primitives.py">ParaAttention/src/para_attn/primitives.py ft_c</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/distributed/_functional_collectives.py">pytorch/torch/distributed/_functional_collectives.py at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://discuss.pytorch.org/t/functional-collectives-used-in-torch-compile/190627">_functional_collectives used in torch.compile - distributed - PyTorch Forums</A>
								</DL><p>
								<DT><H3 FOLDED>PrimeIntellect</H3>
								<DL><p>
									<DT><H3 FOLDED>pccl</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://x.com/voooooogel/status/1863101056575832174">LLaMA 3 405B BF16 16xH100 over 100Gbe</A>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1862607165669900407">Releasing INTELLECT-1: We‚Äôre open-sourcing the first decentralized trained 10B model:</A>
									<DT><A HREF="https://github.com/PrimeIntellect-ai/prime/blob/main/INTELLECT_1_Technical_Report.pdf">prime/INTELLECT_1_Technical_Report.pdf at main ¬∑ PrimeIntellect-ai/prime</A>
									<DT><A HREF="https://github.com/PrimeIntellect-ai/prime">PrimeIntellect-ai/prime: prime is a framework for efficient, globally distributed training of AI models over the internet.</A>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1862607175350460775">Technical innovations in PRIME framework:</A>
									<DT><A HREF="https://x.com/PrimeIntellect/status/1862607165669900407">Prime Intellect en X: "Releasing INTELLECT-1: We‚Äôre open-sourcing the first decentralized trained 10B model: - INTELLECT-1 base model &amp;amp; intermediate checkpoints - Pre-training dataset - Post-trained instruct models by @arcee_ai - PRIME training framework - Technical paper with all details https://t.co/kSstiU9ZPZ" / X</A>
									<DT><A HREF="https://cacm.acm.org/research/metas-hyperscale-infrastructure-overview-and-insights/">Meta‚Äôs Hyperscale Infrastructure: Overview and Insights ‚Äì Communications of the ACM</A>
									<DT><A HREF="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/#:~:text=,open%20innovation%20across%20the%20industry">Building Meta‚Äôs GenAI Infrastructure - Engineering at Meta</A>
									<DT><A HREF="https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e">the world‚Äôs largest distributed LLM training job on TPU v5e | Google Cloud Blog</A>
									<DT><A HREF="https://www.usenix.org/system/files/osdi24-choudhury.pdf">MAST: Global Scheduling of ML Training across Geo-Distributed Datacenters at Hyperscale</A>
									<DT><A HREF="https://parsa.epfl.ch/course-info/cs723/papers/MSCCLang.pdf">MSCCLang: Microsoft Collective Communication Language</A>
									<DT><A HREF="https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2-4/#:~:text=We%20tested%20NCCL%202,180x%20improvement%20at%2024k%20GPUs">Massively Scale Your Deep Learning Training with NCCL 2.4 | NVIDIA Technical Blog</A>
									<DT><A HREF="https://research.google/pubs/the-datacenter-as-a-computer-an-introduction-to-the-design-of-warehouse-scale-machines-second-edition/">The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, Second Edition</A>
									<DT><A HREF="https://www.youtube.com/watch?v=hobvps-H38o">Dylan Patel - Inference Math, Simulation, and AI Megaclusters - Stanford CS 229S - Autumn 2024 - YouTube</A>
								</DL><p>
								<DT><A HREF="https://blog.ezyang.com/2025/08/the-parallelism-mesh-zoo/">The Parallelism Mesh Zoo : ezyang‚Äôs blog</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/rethinking-pytorch-fully-sharded-data-parallel-fsdp-from-first-principles/1019">Rethinking Fully Sharded Data Parallel (FSDP) from First Principles</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/fsdp-cudacachingallocator-an-outsider-newb-perspective/1486">FSDP &amp; CUDACachingAllocator: an outsider newb perspective</A>
								<DT><A HREF="https://github.com/facebookresearch/fairring">facebookresearch/fairring: Fairring (FAIR + Herring) is a plug-in for PyTorch that provides a process group for distributed training that outperforms NCCL at large scales</A>
								<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">DistributedDataParallel: gradient_as_bucket_view</A>
								<DT><A HREF="https://github.com/pkusys/TGS/blob/main/worker.py">TGS/worker.py at main ¬∑ pkusys/TGS</A>
								<DT><A HREF="https://github.com/RulinShao/LightSeq/blob/main/lightseq/async_communication.py">LightSeq/lightseq/async_communication.py at main ¬∑ RulinShao/LightSeq</A>
								<DT><A HREF="https://arxiv.org/pdf/2310.03294">DISTFLASHATTN: Distributed Memory-efficient Attention for Long-context LLMs Training</A>
								<DT><A HREF="https://pytorch.org/docs/stable/elastic/run.html">torchrun (Elastic Launch) ‚Äî PyTorch 2.4 documentation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=toUSzwR0EV8&list=LL&index=9&t=12s">Distributed Training with PyTorch: complete tutorial with cloud infrastructure and code - YouTube</A>
								<DT><A HREF="https://arxiv.org/abs/2006.15704">[2006.15704] PyTorch Distributed: Experiences on Accelerating Data Parallel Training</A>
								<DT><A HREF="https://github.com/bytedance/flux">bytedance/flux: A fast communication-overlapping library for tensor parallelism on GPUs.</A>
								<DT><A HREF="https://lambdalabs.com/blog/introduction-multi-gpu-multi-node-distributed-training-nccl-2-0">A Gentle Introduction to Multi GPU and Multi Node Distributed Training</A>
								<DT><A HREF="https://opus.nci.org.au/display/DAE/torchrun%3A+Multi-node+Distributed+Training">FSDP2</A>
								<DT><A HREF="https://www.geeksforgeeks.org/iotop-command-in-linux-with-examples/">iotop Command in Linux with Examples - GeeksforGeeks</A>
								<DT><A HREF="https://github.com/LambdaLabsML/distributed-training-guide">LambdaLabsML/distributed-training-guide: Best practices &amp; guides on how to write distributed pytorch training code</A>
								<DT><A HREF="https://github.com/pytorch-labs/torchft">pytorch-labs/torchft: PyTorch per step fault tolerance (actively under development)</A>
								<DT><A HREF="https://github.com/Lightning-AI/torchmetrics">Lightning-AI/torchmetrics: Machine learning metrics for distributed, scalable PyTorch applications.</A>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/">How To Scale Your Model</A>
								<DT><A HREF="https://huggingface.co/spaces/nanotron/ultrascale-playbook">The Ultra-Scale Playbook - a Hugging Face Space by nanotron</A>
								<DT><A HREF="https://github.com/zai-org/RealVideo/blob/main/core/distributed.py">RealVideo/core/distributed.py send/recv dict</A>
							</DL><p>
							<DT><H3 FOLDED>torch-jax</H3>
							<DL><p>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/help-pytorch-brain-understand-jax-flax-code/1554">Help PyTorch brain understand JAX/FLAX code - frontend API / autodiff - PyTorch Dev Discussions</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/help-pytorch-brain-understand-jax-flax-code/1554">Help PyTorch brain understand JAX/FLAX code</A>
								<DT><A HREF="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html">Tutorial 2 (JAX): Introduction to JAX+Flax</A>
							</DL><p>
							<DT><H3 FOLDED>torch-people</H3>
							<DL><p>
								<DT><A HREF="http://blog.ezyang.com/about/">Edward Z. Yang (BLOG)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=_qB2Ho1O3u4&t=7s">Edward Z. Yang (PyTorch Developer Podcast)</A>
								<DT><A HREF="https://pytorch.org/docs/stable/community/persons_of_interest.html">PyTorch Governance | Maintainers ‚Äî PyTorch 2.1 documentation</A>
								<DT><A HREF="https://github.com/albanD">albanD</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/u/penguinwu/summary">penguinwu</A>
								<DT><A HREF="https://www.linkedin.com/in/peng--wu/">Peng Wu</A>
								<DT><A HREF="https://www.youtube.com/@edwardzyang/videos">Edward Z. Yang's PyTorch and PL - YouTube</A>
								<DT><A HREF="https://jasonansel.com/">jasonansel.com</A>
								<DT><A HREF="https://github.com/Chillee">Horace He (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/natalia-gimelshein-8347a480/">Natalia Gimelshein (OpenAI)</A>
								<DT><A HREF="https://www.linkedin.com/in/animesh-jain-39244417/">Animesh Jain (Meta)</A>
								<DT><A HREF="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwiL3s_lt6iEAxXOU6QEHdc8D_gQFnoECBQQAQ&url=https%3A%2F%2Frocketreach.co%2Fmichael-voznesensky-email_1979109&usg=AOvVaw0-C9Hymj48aNDsG0DgWsG3&opi=89978449">Michael Voznesensky (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/bin-bao-9b095812/">Bin Bao (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/david-berard-2a0531176/">David Berard (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/geetachauhan/">Geeta Chauhan (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/anjali-chourdia/">Anjali Chourdia (Meta)</A>
								<DT><A HREF="https://github.com/wconstab">Will Constable (Meta)</A>
								<DT><A HREF="https://cs.stanford.edu/~zdevito/">Zachary DeVito (Meta)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Lg8F4F_qZxk">Elias Ellison (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/yfengus/">Will Feng (Meta)</A>
								<DT><A HREF="https://www.linkedin.com/in/jiong-gong-8504944/?originalSubdomain=cn">Jiong Gong (Intel)</A>
								<DT><A HREF="https://www.linkedin.com/in/philippe-tillet-809b5536/">Phil Tillet (OpenAI)</A>
								<DT><A HREF="https://www.jokeren.tech/">Keren Zhou (OpenAI)</A>
								<DT><A HREF="https://github.com/msaroufim">Mark Saroufim (PyTorch Labs)</A>
								<DT><A HREF="https://github.com/yzh119">Zihao Ye (flashinfer)</A>
								<DT><A HREF="https://github.com/efrantar">Elias Frantar (marlinn kernels)</A>
								<DT><A HREF="https://x.com/isidentical">isidentical: building the most efficient inference engine for diffusion models</A>
								<DT><A HREF="https://chengzeyi.github.io/markdown-cv/">Cheng Zeyi's CV | CV</A>
								<DT><A HREF="https://github.com/drisspg/driss_torch">drisspg/driss_torch: Cuda extensions for PyTorch</A>
								<DT><A HREF="https://github.com/drisspg">drisspg (Driss Guessous)</A>
								<DT><A HREF="https://github.com/zou3519">zou3519 (Richard Zou)</A>
								<DT><A HREF="https://github.com/cpuhrsch">cpuhrsch -&gt; compile graph breaks</A>
								<DT><A HREF="https://github.com/HydraQYH">HydraQYH (Qi Yuhang) AI Infra/MLSys Performance Analysis &amp; Tuning. Now in AML@Bytedance</A>
							</DL><p>
							<DT><H3 FOLDED>torch-rfcs</H3>
							<DL><p>
								<DT><A HREF="https://github.com/pytorch/rfcs/">pytorch/rfcs: PyTorch RFCs (experimental)</A>
								<DT><A HREF="https://github.com/pytorch/rfcs/pull/59">RFC-0033-GDS-checkpointing by antferdom ¬∑ Pull Request #59 ¬∑ pytorch/rfcs</A>
							</DL><p>
							<DT><H3 FOLDED>pybind</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-cpp_extension</H3>
								<DL><p>
									<DT><H3 FOLDED>CUDAExtension</H3>
									<DL><p>
										<DT><H3 FOLDED>CUDAExtension-cute</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://github.com/dblalock/cuda_ext_example">dblalock/cuda_ext_example: Simple example project that builds a PyTorch CUDA extension</A>
										<DT><A HREF="https://grok.com/c/e4314fb9-22b9-4b1e-b609-b325060298d1">PyTorch C++ and CUDA Extensions - Grok</A>
										<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/blob/master/cutlass_gemm/cutlass_gemm/setup.py">cfx-article-src/cutlass_gemm/cutlass_gemm/setup.py at master ¬∑ ColfaxResearch/cfx-article-src</A>
										<DT><A HREF="https://www.youtube.com/watch?v=ACR1WnRScCc">Composability Sync - User defined Triton vs custom ops / C++ FX - YouTube</A>
										<DT><A HREF="https://docs.google.com/document/d/1_W62p8WJOQQUzPsJYa7s701JXt0qf2OfLub2sbkHOaU/edit?tab=t.0">The Custom Operators Manual - Google Docs</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/152032">RFC: The State of Custom CUDA extensions in PyTorch ¬∑ Issue #152032 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://research.colfax-intl.com/tutorial-python-binding-for-cuda-libraries-in-pytorch/">Tutorial: Python bindings for CUDA libraries in PyTorch ‚Äì Colfax Research</A>
										<DT><A HREF="https://github.com/NVIDIA/cutlass/tree/main/python/cutlass_cppgen/op">cutlass/python/cutlass_cppgen/op at main ¬∑ NVIDIA/cutlass</A>
										<DT><A HREF="https://github.com/ColfaxResearch/cfx-article-src/tree/master/cutlass_gemm">cfx-article-src/cutlass_gemm at master ¬∑ ColfaxResearch/cfx-article-src</A>
										<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/benchs/python/gemm/tiledcuda/gemm.py">TiledBench/benchs/python/gemm/tiledcuda/gemm.py at master ¬∑ TiledTensor/TiledBench</A>
										<DT><A HREF="https://github.com/AndreSlavescu/mHC.cu/blob/main/setup.py">mHC.cu/setup.py at main ¬∑ AndreSlavescu/mHC.cu</A>
									</DL><p>
									<DT><H3 FOLDED>cpp_extension-load_inline</H3>
									<DL><p>
										<DT><A HREF="https://www.gpumode.com/v2/leaderboard/597?tab=rankings">Thien Tran: from torch.utils.cpp_extension import load_inline nvfp4 GEMM CUDA_SRC_COMMON</A>
										<DT><A HREF="https://github.com/gau-nernst/learn-cuda/blob/main/01_vector_addition/main.py">learn-cuda/01_vector_addition/main.py at main ¬∑ gau-nernst/learn-cuda</A>
										<DT><A HREF="https://github.com/WaveSpeedAI/QuantumAttention/blob/main/src/quantum_attn/tk/attention.py">QuantumAttention/src/quantum_attn/tk/attention.py at main ¬∑ WaveSpeedAI/QuantumAttention</A>
										<DT><A HREF="https://gist.github.com/malfet/2c9a25976dd7396430c38af603f791da">ctypes-nvrtc.py</A>
									</DL><p>
									<DT><A HREF="https://twitter.com/francoisfleuret/status/1741481952618676698">(1) Fran√ßois Fleuret en X: "Wow, inline C++ extensions for @pytorch are that simple?</A>
									<DT><A HREF="https://pytorch.org/tutorials/advanced/cpp_extension.html">Custom C++ and CUDA Extensions ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
									<DT><A HREF="https://research.colfax-intl.com/tutorial-python-binding-for-cuda-libraries-in-pytorch/">Tutorial: Python bindings for CUDA libraries in PyTorch ‚Äì Colfax Research</A>
									<DT><A HREF="https://github.com/sophiawisdom/qr/blob/master/file.py">qr/file.py at master ¬∑ sophiawisdom/qr</A>
									<DT><A HREF="https://github.com/pytorch/extension-cpp">pytorch/extension-cpp: C++ extensions in PyTorch</A>
									<DT><A HREF="https://pytorch.org/tutorials/advanced/cpp_custom_ops.html#testing-an-operator">Custom C++ and CUDA Operators ‚Äî PyTorch Tutorials 2.4.0+cu121 documentation</A>
									<DT><A HREF="https://gist.github.com/sophiawisdom/88b48f7146deb0d35c09506dd3a9c09e">invocation: TORCH_CUDA_ARCH_LIST=9.0a PYTORCH_NO_CUDA_MEMORY_CACHING=1 compute-sanitizer python3 test.py attention.cu example</A>
								</DL><p>
								<DT><H3 FOLDED>pybind-example</H3>
								<DL><p>
									<DT><A HREF="https://github.com/torstem/demo-cuda-pybind11">torstem/demo-cuda-pybind11: How to use CUDA with Python numpy</A>
									<DT><A HREF="https://github.com/hyhieu/easy_pybind">hyhieu/easy_pybind</A>
								</DL><p>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/custom-cuda-extension-support-in-inductor/1924">Custom cuda extension support in Inductor - compiler - PyTorch Developer Mailing List</A>
								<DT><A HREF="https://github.com/youkaichao/compare_pass_data/blob/main/example.cpp">compare_pass_data/example.cpp at main ¬∑ youkaichao/compare_pass_data</A>
								<DT><A HREF="https://github.com/openai/triton/blob/main/third_party/amd/python/triton_amd.cc">triton/third_party/amd/python/triton_amd.cc at main ¬∑ openai/triton</A>
								<DT><A HREF="https://github.com/rapidsai/cudf/tree/branch-0.7/python/cudf/bindings">cudf/python/cudf/bindings pxd &amp; pyx cython</A>
								<DT><A HREF="https://pybind11.readthedocs.io/en/stable/">pybind11 documentation</A>
								<DT><A HREF="https://twitter.com/SkyLi0n">Aaron Gokaslan (@SkyLi0n) / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-XLSyaJ6m3o&t=902s">WTF is Build.Zig? by Ed Yu - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=MUISz2qA640&t=19s">Will Ada Replace C/C++? - YouTube</A>
								<DT><A HREF="https://research.colfax-intl.com/tutorial-python-binding-for-cuda-libraries-in-pytorch/">Tutorial: Python bindings for CUDA libraries in PyTorch ‚Äì Colfax Research</A>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/custom_kernels/setup.py">text-generation-inference/server/custom_kernels/setup.py at main ¬∑ huggingface/text-generation-inference</A>
								<DT><A HREF="https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary">flash-attention/csrc/rotary at main ¬∑ Dao-AILab/flash-attention</A>
								<DT><A HREF="https://github.com/mlecauchois/micrograd-cuda/blob/main/micrograd_cuda/operations.py">micrograd-cuda/micrograd_cuda/operations.py at main ¬∑ mlecauchois/micrograd-cuda</A>
								<DT><A HREF="https://github.com/neuralmagic/causal-conv1d/blob/main/setup.py">causal-conv1d/setup.py at main ¬∑ neuralmagic/causal-conv1d</A>
								<DT><A HREF="https://github.com/FlagOpen/FlagGems">FlagOpen/FlagGems: FlagGems is an operator library for large language models implemented in Triton Language.</A>
								<DT><A HREF="https://github.com/ifromeast/cuda_learning/blob/main/01_cuda_op/setup.py">cuda_learning/01_cuda_op/setup.py at main ¬∑ ifromeast/cuda_learning ¬∑ GitHub</A>
								<DT><A HREF="https://github.com/vdesai2014/inference-optimization-blog-post">vdesai2014/inference-optimization-blog-post</A>
								<DT><A HREF="https://github.com/efeslab/Nanoflow/blob/main/pipeline/utils/pybindUtil.py">Nanoflow/pipeline/utils/pybindUtil.py at main ¬∑ efeslab/Nanoflow</A>
								<DT><A HREF="https://github.com/wjakob/nanobind">wjakob/nanobind: nanobind: tiny and efficient C++/Python bindings</A>
								<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/main/cutlass.py/hw_info.py">MatmulTutorial/cutlass.py/hw_info.py at main ¬∑ KnowingNothing/MatmulTutorial</A>
								<DT><A HREF="https://github.com/drisspg/driss_torch">drisspg/driss_torch: Cuda extensions for PyTorch</A>
								<DT><A HREF="https://github.com/search?q=repo%3ATiledTensor%2FTiledCUDA++language%3APython&type=code">tiledCuda torch bindings</A>
								<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/bdf733be55f0b323a8cf7cc6745a81c3f43cd7f0/hopper/setup.py#L163">flash-attention/hopper/setup.py at bdf733be55f0b323a8cf7cc6745a81c3f43cd7f0 ¬∑ Dao-AILab/flash-attention</A>
								<DT><A HREF="https://github.com/TiledTensor/benchmarks/blob/master/gemm/cutlass/compile.py">benchmarks/gemm/cutlass/compile.py at master ¬∑ TiledTensor/benchmarks</A>
								<DT><A HREF="https://github.com/HazyResearch/ThunderKittens/tree/main/kernels/example_bind">ThunderKittens/kernels/example_bind at main ¬∑ HazyResearch/ThunderKittens</A>
								<DT><A HREF="https://github.com/gpusgobrr/explore-gemm/blob/main/cuda/py/cuda_extension_loader.py">explore-gemm/cuda/py/cuda_extension_loader.py at main ¬∑ gpusgobrr/explore-gemm</A>
								<DT><A HREF="https://github.com/AndreSlavescu/mHC.cu/blob/main/src/python/bindings.cu">mHC.cu/src/python/bindings.cu at main ¬∑ AndreSlavescu/mHC.cu</A>
								<DT><A HREF="https://github.com/TiledTensor/TiledBench/blob/master/scripts/cmake/generic.cmake">TiledBench/scripts/cmake/generic.cmake at master ¬∑ TiledTensor/TiledBench</A>
								<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/kernels/blackwell/cute_gemm_01/driver.py">applied-ai/kernels/blackwell/cute_gemm_01/driver.py at main ¬∑ meta-pytorch/applied-ai</A>
								<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/kernels/blackwell/cute_gemm_01/setup.py">applied-ai/kernels/blackwell/cute_gemm_01/setup.py at main ¬∑ meta-pytorch/applied-ai</A>
							</DL><p>
							<DT><H3 FOLDED>torch-dataloader</H3>
							<DL><p>
								<DT><H3 FOLDED>spdl</H3>
								<DL><p>
									<DT><A HREF="https://facebookresearch.github.io/spdl/main/overview.html">Overview - SPDL 0.0.6 documentation</A>
									<DT><A HREF="https://ai.meta.com/blog/spdl-faster-ai-model-training-with-thread-based-data-loading-reality-labs/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=research">Introducing SPDL: Faster AI model training with thread-based data loading</A>
									<DT><A HREF="https://github.com/facebookresearch/spdl">facebookresearch/spdl: Scalable and Performant Data Loading</A>
								</DL><p>
								<DT><H3 FOLDED>torch-concurrent-dataloader</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/pull/158218">Multi-threaded concurrent fetching in Dataloader for high-latency storage. by Kai-46 ¬∑ Pull Request #158218 ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=Sk35MKtCXfQ&t=1748s">celeba_iterate</A>
								<DT><A HREF="https://www.youtube.com/watch?v=9Vfauv4ErwA&list=LL&index=7&pp=gAQBiAQB">ü§ó Accelerate DataLoaders during Distributed Training: How Do They Work? - YouTube</A>
								<DT><A HREF="https://github.com/cloneofsimo/min-max-gpt/blob/master/run_trainer.py#L328">min-max-gpt/run_trainer.py at master ¬∑ cloneofsimo/min-max-gpt</A>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1835586720424702387">Benjamin: NoGIL python torch.DataLoader context (Go data fetcher)</A>
								<DT><A HREF="https://developer.nvidia.com/blog/improved-data-loading-with-threads/">Improved Data Loading with Threads | NVIDIA Technical Blog</A>
								<DT><A HREF="https://static.sched.com/hosted_files/pytorch2024/2a/What%20could%20go%20wrong.pdf">Using Iterable Datasets What could go wrong?</A>
								<DT><A HREF="https://colab.research.google.com/github/NicolasHug/Iterable-Datasets-what-could-go-wrong/blob/main/whatcouldgowrong.ipynb">whatcouldgowrong.ipynb - Colab</A>
								<DT><A HREF="https://github.com/Photoroom/datago">Photoroom/datago: A golang-based data loader which can be used from Python. Useful to interact with a typical VectorDB stack through HTTP requests and then fetch payloads per sample, at GB/s speeds.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=z9RHaQZnWM4">How xAI Scales Image &amp; Video Processing with Ray | Ray Summit 2025 - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>torch-optim</H3>
							<DL><p>
								<DT><H3 FOLDED>cross-entropy</H3>
								<DL><p>
									<DT><A HREF="https://github.com/mgmalek/efficient_cross_entropy">mgmalek/efficient_cross_entropy</A>
								</DL><p>
								<DT><H3 FOLDED>torch-muon</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/issues/148819#issuecomment-3070108227">addition of muon optimizer to torch.optim ¬∑ Issue #148819 ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://x.com/i/broadcasts/1MnxnPmbgMkGO">(2) Live RL Research on PufferLib w/ Joseph Suarez / X</A>
									<DT><A HREF="https://docs.pytorch.org/docs/2.9/generated/torch.optim.Muon.html">Muon ‚Äî PyTorch 2.9 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>HeavyBall</H3>
								<DL><p>
									<DT><A HREF="https://github.com/HomebrewML/HeavyBall">HomebrewML/HeavyBall: Efficient optimizers</A>
									<DT><A HREF="https://github.com/HomebrewML/HeavyBall/blob/f9727cdc0c6883a15597facf7acb9bfddb59ccca/heavyball/__init__.py#L452">HeavyBall/heavyball/__init__.py at f9727cdc0c6883a15597facf7acb9bfddb59ccca ¬∑ HomebrewML/HeavyBall</A>
								</DL><p>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/performance-comparison-between-torch-compile-and-apex-optimizers/2023">Performance Comparison between Torch.Compile and APEX optimizers - compiler - PyTorch Developer Mailing List</A>
								<DT><A HREF="https://github.com/lucidrains/adam-atan2-pytorch">lucidrains/adam-atan2-pytorch: Implementation of the proposed Adam-atan2 from Google Deepmind in Pytorch</A>
							</DL><p>
							<DT><H3 FOLDED>torch-tensorrt</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=eGDMJ3MY4zk&t=450s">Accelerated Inference in PyTorch 2.X with Torch-TensorRT</A>
								<DT><A HREF="https://pytorch.org/TensorRT/ts/getting_started_with_python_api.html#getting-started-with-python-api">Using Torch-TensorRT in Python ‚Äî Torch-TensorRT v2.2.0.dev0+4da330d documentation</A>
								<DT><A HREF="https://pypi.org/project/torch-tensorrt/">torch-tensorrt ¬∑ PyPI</A>
								<DT><A HREF="https://pytorch.org/TensorRT/">Torch-TensorRT ‚Äî Torch-TensorRT v2.2.0.dev</A>
							</DL><p>
							<DT><H3 FOLDED>torch-tests</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-tests-correctness</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/04adaf0e9028d4bec7073f69e4dfa3f6d3357189/hopper/test_attn_kvcache.py#L195">flash-attention/hopper/test_attn_kvcache.py at 04adaf0e9028d4bec7073f69e4dfa3f6d3357189 ¬∑ Dao-AILab/flash-attention</A>
								</DL><p>
								<DT><H3 FOLDED>torch-tests-b200</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a/.ci/pytorch/test.sh">pytorch/.ci/pytorch/test.sh: test_python_smoke_b200()</A>
								</DL><p>
								<DT><H3 FOLDED>torch-tests-multi_gpu</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a/.ci/pytorch/multigpu-test.sh">pytorch/.ci/pytorch/multigpu-test.sh at a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/d444815c02227b2eb9ab27ec09112a98e482f19c/xformers/benchmarks/benchmark_mem_eff_attention.py#L201">xformers/xformers/benchmarks/benchmark_mem_eff_attention.py at d444815c02227b2eb9ab27ec09112a98e482f19c ¬∑ facebookresearch/xformers</A>
								<DT><A HREF="https://github.com/chengzeyi/ParaAttention/blob/16ab3b17c415b80bb757fe48fa6e95d0adda9430/tests/context_parallel/test_diffusers_adapters.py#L44">ParaAttention/tests/context_parallel/test_diffusers_adapters.py at 16ab3b17c415b80bb757fe48fa6e95d0adda9430 ¬∑ chengzeyi/ParaAttention</A>
								<DT><A HREF="https://github.com/meta-pytorch/FACTO">meta-pytorch/FACTO: Framework for Algorithmic Correctness Testing of Operators</A>
							</DL><p>
							<DT><H3 FOLDED>torch-bwd</H3>
							<DL><p>
								<DT><H3 FOLDED>bwd-simulate</H3>
								<DL><p>
									<DT><A HREF="https://grok.com/c/8d3b2e89-ce6d-44b0-8b3f-a7fe3a13eb8a">Simulating Neural Network Backward Pass - Grok</A>
									<DT><A HREF="https://github.com/youkaichao/TRUMPY/blob/master/trumpy/lib.py">TRUMPY/trumpy/lib.py at master ¬∑ youkaichao/TRUMPY</A>
									<DT><A HREF="https://github.com/daniel-geon-park/triton_bwd/blob/main/tests/test_triton_bwd_flashattn.py">triton_bwd/tests/test_triton_bwd_flashattn.py: fake gradient simulation</A>
									<DT><A HREF="https://github.com/pytorch/ao/tree/main/torchao/prototype/moe_training"># Compute loss with fake labels for demonstration purposes</A>
								</DL><p>
								<DT><H3 FOLDED>bwd-fp4</H3>
								<DL><p>
									<DT><A HREF="https://x.com/giffmana/status/1984668844812636513">(1) Lucas Beyer (bl16) en X: "Just wait, i can already see it coming: with https://t.co/kfvU7sTQe9_nvfp4(): loss(model(x), y).backward()" / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/youkaichao/TRUMPY/blob/master/trumpy/lib.py">TRUMPY/trumpy/lib.py at master ¬∑ youkaichao/TRUMPY</A>
								<DT><A HREF="https://x.com/StasBekman/status/1998490033813336173">torch.autograd.detect_anomaly()</A>
							</DL><p>
							<DT><H3 FOLDED>torch-bugs</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ElanaPearl/status/1981389648695025849">(1) Elana Simon en X: "New blog post: The bug that taught me more about PyTorch than years of using it started with a simple training loss plateau... ended up digging through optimizer states, memory layouts, kernel dispatch, and finally understanding how PyTorch works! https://t.co/3UbtZGzKpa" / X</A>
								<DT><A HREF="https://elanapearl.github.io/blog/2025/the-bug-that-taught-me-pytorch/?t=1">the bug that taught me more about PyTorch than years of using it | Elana Simon</A>
							</DL><p>
							<DT><H3 FOLDED>torch-notes</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ezyang/status/1984057501059346925">(1) Edward Z. Yang en X: "I've been brainstorming episodes for the next season of PyTorch Developer Podcast. DTensor StridedShard, FSDP-TP order Redistributing a DTensor Prefetching vs Bucketing History of FSDP in PyTorch Multiprocessing: DataParallel versus DistributedDataParallel Monarch Parallelism" / X</A>
							</DL><p>
							<DT><H3 FOLDED>torch-ci</H3>
							<DL><p>
								<DT><H3 FOLDED>test-infra</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-ci-scripts</H3>
									<DL><p>
										<DT><H3 FOLDED>torch-ci-b200</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a/.ci/pytorch/test.sh">pytorch/.ci/pytorch/test.sh</A>
										<DT><A HREF="https://github.com/search?q=repo%3Apytorch%2Fpytorch%20install_flash_attn_cute&type=code">install_flash_attn_cute</A>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/test-infra">pytorch/test-infra: This repository hosts code that supports the testing infrastructure for the PyTorch organization. For example, this repo hosts the logic to track disabled tests and slow tests, as well as our continuation integration jobs HUD/dashboard.</A>
									<DT><A HREF="https://github.com/pytorch/test-infra/blob/fe19bd49e98c162bd35912b2f32756d7a9ea6071/terraform-aws-github-runner/README.md">test-infra/terraform-aws-github-runner/README.md at fe19bd49e98c162bd35912b2f32756d7a9ea6071 ¬∑ pytorch/test-infra</A>
									<DT><A HREF="https://zoom.us/rec/play/_EFoGFP1ZJOAjNhMs05XaNvMcokBpUK5O6R5q1qBFYzJ66V14UZBYJT-KhpC37puttRLCz9YBC9o7vJL._3o4S_EWv5GqY8V_?eagerLoadZvaPages=sidemenu.billing.plan_management&accessLevel=meeting&canPlayFromShare=true&from=share_recording_detail&continueMode=true&componentName=rec-play&originRequestUrl=https%3A%2F%2Fzoom.us%2Frec%2Fshare%2FXob0_IiyV9u4t47Ljc-g0jNXXmmIpDdf7b9srIsPClsQOHw32FETX9TIB_2u25Or.AmVCbPNuelq7-1Lz">PyTorch CI Infrastructure Training - Part 1 - Zoom</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/a9c6a8f1b9aaf506c13de2bc50d5e6ba6478a17a/.github/workflows/test-b200.yml">pytorch/.github/workflows/test-b200.yml: .ci/pytorch/test.sh -&gt; test_python_smoke_b200() function</A>
									<DT><A HREF="https://grok.com/c/5f9829ed-f153-4f2a-b006-59f0e788659e">Setting Up B200 GPU Environment - Grok</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://github.com/chu-tianxiang/llama-cpp-torch">chu-tianxiang/llama-cpp-torch: llama.cpp to PyTorch Converter</A>
							<DT><A HREF="https://github.com/NVIDIA/TransformerEngine">NVIDIA/TransformerEngine: A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.</A>
							<DT><A HREF="https://pytorch.org/torchx/latest/">torchx: universal job launcher for PyTorch</A>
							<DT><A HREF="https://dev-discuss.pytorch.org/latest">Latest topics - PyTorch Dev Discussions</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/c22e77abfdb55f8248db852126737fbecfd52a7b/tinygrad/tensor.py">tinygrad/tinygrad/tensor.py at c22e77abfdb55f8248db852126737fbecfd52a7b ¬∑ tinygrad/tinygrad</A>
							<DT><A HREF="https://gist.github.com/thecharlieblake/82f1b54bbf608d8d339043ed8852cf91">Given a numpy function, prints equivalent PyTorch code (as canonical ATen ops) and returns it as a new function.</A>
							<DT><A HREF="https://github.com/pytorch/torchtitan/issues/305">reload existing llama checkpoints</A>
							<DT><A HREF="https://github.com/SeoLabCornell/torch2chip">SeoLabCornell/torch2chip: Torch2Chip (MLSys, 2024)</A>
							<DT><A HREF="https://x.com/PyTorch/status/1831797748762607618">PyTorch en X: "Looking for new ways to get your PyTorch skills to the next level? Join us at the PyTorch Conference to learn about the latest features and components available in PyTorch. Here are some talks at the PyTorch Conference that will uplevel your PyTorch skills üßµ (1/6)" / X</A>
						</DL><p>
						<DT><H3 FOLDED>Compilers Fundamentals</H3>
						<DL><p>
							<DT><H3 FOLDED>compiler-grammar</H3>
							<DL><p>
								<DT><H3 FOLDED>BNF</H3>
								<DL><p>
									<DT><A HREF="https://www.icosaedro.it/bnf_chk/">BNF Syntax Checker</A>
									<DT><A HREF="https://bnfplayground.pauliankline.com/">BNF Playground</A>
									<DT><A HREF="http://arran.fi.muni.cz/bnfparser2/bnfweb.php?sf=1&tf=">The BNF Verification Service</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">Backus‚ÄìNaur form - Wikipedia</A>
									<DT><A HREF="https://docs.python.org/3/reference/grammar.html">10. Full Grammar specification ‚Äî Python 3.10.4 documentation</A>
									<DT><A HREF="https://inst.eecs.berkeley.edu/~cs164/sp18/python-grammar.html">Official Python Grammar (Python 2.5)</A>
									<DT><A HREF="https://github.com/python/cpython/blob/3.10/Grammar/python.gram">cpython/python.gram at 3.10 ¬∑ python/cpython</A>
									<DT><A HREF="https://www.iso.org/standard/26153.html">ISO - ISO/IEC 14977:1996 - Extended BNF</A>
								</DL><p>
								<DT><H3 FOLDED>ANTLR</H3>
								<DL><p>
									<DT><A HREF="https://datacadamia.com/antlr/start">Antlr (ANother Tool for Language Recognition</A>
									<DT><A HREF="https://datacadamia.com/code/compiler/compiler-compiler">Language - Compiler compilers or (lexer|parser) generators</A>
									<DT><A HREF="https://datacadamia.com/antlr/grammar">Antlr - (Grammar|Lexicon) (g4)</A>
									<DT><A HREF="https://github.com/antlr/antlr4/blob/master/doc/grammars.md">Grammar Structure</A>
									<DT><A HREF="https://github.com/antlr/antlr4/blob/master/doc/lexicon.md">Grammar Lexicon</A>
									<DT><A HREF="http://bearcave.com/software/antlr/antlr_examples.html">ANTLR Examples</A>
									<DT><A HREF="https://github.com/antlr/grammars-v4">Grammars written for ANTLR4</A>
									<DT><H3 FOLDED>Indentation</H3>
									<DL><p>
										<DT><A HREF="https://github.com/yshavit/antlr-denter">Helper class for generating python-like INDENT/DEDENT tokens with antlr4.</A>
										<DT><A HREF="https://groups.google.com/g/antlr-discussion/c/Let2Q5gOvGo/m/-ieYBGv9CwAJ">Indentation/whitespace in actions with Python target</A>
										<DT><A HREF="https://github.com/wevre/wry/blob/master/grammars/DentLexer.g4">DentLexer.g4</A>
										<DT><A HREF="http://blog.yuvalshavit.com/2014/02/python-like-indentation-using-antlr4.html">Yuval Shavit: Python-like indentation using Antlr4</A>
										<DT><A HREF="https://docs.python.org/3/reference/lexical_analysis.html#indentation">2. Lexical analysis ‚Äî Python 3.10.4 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>Functional parsing</H3>
									<DL><p>
										<DT><A HREF="https://github.com/cronburg/antlr-haskell">cronburg/antlr-haskell: A language parsing quasiquoter for Haskell based heavily on ANTLR4.</A>
									</DL><p>
									<DT><A HREF="https://stackoverflow.com/questions/8642154/antlr-what-is-simpliest-way-to-realize-python-like-indent-depending-grammar">lexer - ANTLR What is simpliest way to realize python like indent-depending grammar? - Stack Overflow</A>
								</DL><p>
								<DT><H3 FOLDED>PEG</H3>
								<DL><p>
									<DT><A HREF="https://en.wikipedia.org/wiki/Parsing_expression_grammar">Parsing expression grammar (PEG)</A>
									<DT><A HREF="https://nim-lang.org/docs/pegs.html">PEG syntax and semantics (draft)</A>
								</DL><p>
								<DT><H3 FOLDED>grammar-conversions</H3>
								<DL><p>
									<DT><H3 FOLDED>EBNF to PEG</H3>
									<DL><p>
										<DT><A HREF="http://ceur-ws.org/Vol-928/0324.pdf">‚Äéceur-ws.org/Vol-928/0324.pdf</A>
										<DT><A HREF="https://stackoverflow.com/questions/53053899/convert-ebnf-grammar-to-peg">php - Convert EBNF grammar to PEG - Stack Overflow</A>
										<DT><A HREF="https://issueantenna.com/repo/dryruby/ebnf">gem ebnf</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://github.com/prql/prql/blob/main/prql-compiler/src/prql.pest">prql/prql.pest at main ¬∑ prql/prql</A>
								<DT><A HREF="http://essay.utwente.nl/85728/1/vanderWal_BA_FMT.pdf">Rosetta ANTLR: Ultimate Grammar Extractor</A>
								<DT><A HREF="https://stackoverflow.com/questions/8816759/ll-versus-peg-parsers-what-is-the-difference">parsing - LL(*) versus PEG parsers : what is the difference?</A>
								<DT><A HREF="https://en.wikipedia.org/wiki/Left_recursion#Removing_left_recursion">Left recursion - Wikipedia</A>
								<DT><A HREF="https://github.com/rust-lang/wg-grammar/tree/master/testdata">test grammar</A>
								<DT><A HREF="https://www.libtrends.info/npm-compare/antlr4-vs-chevrotain-vs-peg-parser-vs-pegjs">antlr4 vs chevrotain vs peg parser vs pegjs comparison - LibTrends</A>
								<DT><A HREF="https://www.boost.org/doc/libs/1_47_0/libs/spirit/doc/html/spirit/abstracts/syntax_diagram.html">Terminal vs non-terminal</A>
								<DT><A HREF="https://news.ycombinator.com/item?id=2644458">Language.js - A fast PEG parser written in JavaScript | Hacker News</A>
								<DT><A HREF="https://www.w3.org/2000/10/swap/grammar/ebnf2turtle.py">Motivation</A>
								<DT><A HREF="https://www.reddit.com/r/rust/comments/cobadh/antlr_grammars_in_rust/">(1) Antlr grammars in Rust : rust</A>
								<DT><A HREF="https://github.com/kaby76/Domemtech.Trash">kaby76/Domemtech.Trash: Toolkit for grammars</A>
							</DL><p>
							<DT><H3 FOLDED>compilers-template-engine</H3>
							<DL><p>
								<DT><H3 FOLDED>Jinja2</H3>
								<DL><p>
									<DT><A HREF="https://sites.google.com/a/chromium.org/dev/developers/jinja">Jinja - The Chromium Projects</A>
									<DT><A HREF="https://jinja.palletsprojects.com/en/3.1.x/">Jinja ‚Äî Jinja Documentation (3.1.x)</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Template_processor">Template processor - Wikipedia</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>compilers-courses</H3>
							<DL><p>
								<DT><A HREF="https://suif.stanford.edu/~courses/cs243/">CS243 - Advanced Compilers | Winter 2021</A>
								<DT><A HREF="https://ocw.mit.edu/courses/6-172-performance-engineering-of-software-systems-fall-2018/pages/lecture-slides/">Lecture Slides | Performance Engineering of Software Systems</A>
							</DL><p>
							<DT><H3 FOLDED>JIT</H3>
							<DL><p>
								<DT><A HREF="https://kipp.ly/jits-intro/">A Deep Introduction to JIT Compilers: JITs are not very Just-in-time | kipply's blog</A>
								<DT><A HREF="https://kipp.ly/jits-impls/">How JIT Compilers are Implemented and Fast: Pypy, LuaJIT, Graal and More | kipply's blog</A>
							</DL><p>
							<DT><A HREF="https://godbolt.org/">Compiler Explorer</A>
							<DT><A HREF="https://www.kirupa.com/hodgepodge/compiling_transpiling.htm">Compiling (and Transpiling) Explained</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Source-to-source_compiler">Source-to-source compiler - Wikipedia</A>
							<DT><A HREF="https://datacadamia.com/code/compiler/compiler">Translation</A>
							<DT><A HREF="https://datacadamia.com/code/compiler/lexer">Lexical Analysis - Lexer (Tokenizer)</A>
							<DT><A HREF="https://www.youtube.com/watch?v=k6ZsRiLSyvY">Compilation, Libraries and the pesky "unresolved external symbol" error - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=zX-kazAtX0c&t=47s">Calling Functions Across Languages ‚Äî Richard Feldman - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ZI198eFghJk">Modernizing Compiler Design for Carbon Toolchain - Chandler Carruth - CppNow 2023 - YouTube</A>
							<DT><A HREF="https://twitter.com/chandlerc1024/status/1549411352657133568?lang=en">(1) Chandler Carruth on X: "Really excited we've been able to start sharing our experimental work on #CarbonLang with the wider C++ community. That said, I'd suggest folks read up on the docs and maaaybe wait for our announcement keynote and Q&amp;amp;A from #CppNorth before leaping to too many assumptions. =]" / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=L6f--pEHJMo">Writing a Programming Language (in Rust) 23: Laurel: Continuing a bash script port</A>
							<DT><A HREF="https://github.com/compiler-explorer/compiler-explorer">compiler-explorer/compiler-explorer: Run compilers interactively from your web browser and interact with the assembly</A>
							<DT><A HREF="https://www.youtube.com/watch?v=MC7qoiJ5uPc">Why is C is so important for compiler developers? - YouTube</A>
							<DT><A HREF="https://github.com/gergo-/missed-optimizations">gergo-/missed-optimizations: Missed optimizations in C compilers</A>
							<DT><A HREF="https://www.youtube.com/watch?v=M6NoMv69sgU">Writing a Compiler and Interpreter in Rust - Part 1 - YouTube</A>
							<DT><A HREF="https://kuterdinel.com/writing-a-very-simple-jit-compiler-in-about-1000-lines-of-c.html">Writing a very simple JIT Compiler in about 1000 lines of C ‚Ä¢ Kuter Dinel's blog</A>
							<DT><A HREF="https://github.com/davidhalter/parso">davidhalter/parso: A Python Parser</A>
							<DT><A HREF="https://github.com/KnowingNothing/compiler-and-arch">KnowingNothing/compiler-and-arch: A list of tutorials, paper, talks, and open-source projects for emerging compiler and architecture</A>
							<DT><A HREF="https://haqr.eu/tinycompiler/">TinyCompiler: source code -&gt; tokens -&gt; AST -&gt; decoration -&gt; target code</A>
							<DT><A HREF="https://github.com/ssloy/tinycompiler">ssloy/tinycompiler: Writing a compiler in a week-end</A>
							<DT><A HREF="https://www.youtube.com/watch?v=wzn3Vi9HMSI">studying compilers every day until i land a compiler role (day 142) - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>Triton</H3>
						<DL><p>
							<DT><H3 FOLDED>triton-programming-model</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-tutorials</H3>
								<DL><p>
									<DT><A HREF="https://triton-lang.org/main/getting-started/tutorials/index.html">Tutorials ‚Äî Triton documentation</A>
									<DT><A HREF="https://isamu-website.medium.com/understanding-the-triton-tutorials-part-1-6191b59ba4c">Understanding the Triton Tutorials Part 1 | by Isamu Isozaki | Medium</A>
									<DT><A HREF="https://gpu.camp/">Transformer fwd triton</A>
									<DT><A HREF="https://github.com/dsl-learn/Triton-blog-file/tree/main">dsl-learn/Triton-blog-file</A>
								</DL><p>
								<DT><H3 FOLDED>triton-linear-layouts</H3>
								<DL><p>
									<DT><A HREF="https://x.com/typedfemale/status/1929601592522580126">a paper describing triton's linear layouts is out!</A>
									<DT><A HREF="https://arxiv.org/abs/2505.23819">[2505.23819] Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using $\mathbb{F}_2$</A>
									<DT><A HREF="https://damek.github.io/random/linear-layouts-triton-and-linear-algebra-over-f-2/">Linear layouts, triton, and linear algebra over F_2 | Damek Davis‚Äô Website</A>
									<DT><A HREF="https://x.com/difficultyang/status/1963972221577109738">Who needs CuTe layouts, just brute force it with a representation that can literally represent any rearrangement of bits from your input coordinates!</A>
									<DT><A HREF="https://arxiv.org/abs/2204.10923">[2204.10923] You Only Linearize Once: Tangents Transpose to Gradients</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1915468456821788929">Triton Linear Layouts Notes</A>
									<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/10/27/ll-in-triton-part-1.html">Linear Layout in Triton (1): Basic Idea - Hyunsung Lee's Blog</A>
									<DT><A HREF="https://ita9naiwa.github.io/mlsys/2025/10/27/ll-in-triton-part-2.html">Linear Layout in Triton (2): LL Examples - Hyunsung Lee's Blog</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/d9facf3/include/triton/Tools/LinearLayout.h#L19-L313">triton/include/triton/Tools/LinearLayout.h High-level overview of linear layouts</A>
									<DT><A HREF="https://www.lei.chat/posts/triton-bespoke-layouts/">Triton Bespoke Layouts | Lei.Chat()</A>
									<DT><A HREF="https://www.lei.chat/posts/triton-linear-layout-examples/">Triton Linear Layout: Examples | Lei.Chat()</A>
									<DT><A HREF="https://www.lei.chat/posts/triton-linear-layout-concept/">Triton Linear Layout: Concept | Lei.Chat()</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2505.23819">Linear Layouts: Robust Code Generation of Efficient Tensor Computation Using F2</A>
								<DT><A HREF="https://github.com/kshama-msft/triton/blob/f0cf3a2e7a35260a013e639aea558fe1b7befa7b/docs/programming-guide/chapter-1/introduction.rst">triton/docs/programming-guide/chapter-1/introduction.rst</A>
								<DT><A HREF="http://giantpandacv.com/project/%E9%83%A8%E7%BD%B2%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/OpenAITriton%20MLIR%20%E7%AC%AC%E4%BA%8C%E7%AB%A0%20Batch%20GEMM%20benchmark/#giantpandacv">OpenAITriton MLIR Á¨¨‰∫åÁ´† Batch GEMM benchmark - GiantPandaCV</A>
								<DT><A HREF="https://github.com/kimbochen/md-blogs/tree/main/what-triton-does-in-a-matmul">md-blogs/what-triton-does-in-a-matmul at main</A>
								<DT><A HREF="https://github.com/cuda-mode/lectures/blob/main/lecture_014/A_Practitioners_Guide_to_Triton.ipynb">lectures/lecture_014/A_Practitioners_Guide_to_Triton.ipynb at main ¬∑ cuda-mode/lectures</A>
								<DT><A HREF="https://github.com/gpu-mode/lectures/blob/main/lecture_014/A_Practitioners_Guide_to_Triton.ipynb">lectures/lecture_014/A_Practitioners_Guide_to_Triton.ipynb at main ¬∑ gpu-mode/lectures</A>
								<DT><A HREF="https://chatgpt.com/c/66fd7308-78e4-800c-bdc1-6ffafff28651">pid &amp; groups &amp; grid</A>
								<DT><A HREF="https://github.com/alexzhang13/Triton-Puzzles-Solutions">alexzhang13/Triton-Puzzles-Solutions: Personal solutions to the Triton Puzzles</A>
								<DT><A HREF="https://github.com/S-LoRA/S-LoRA/blob/main/slora/models/peft/triton_kernel/lora/lora_prefill.py">x@W</A>
								<DT><A HREF="https://github.com/MekkCyber/TritonAcademy">MekkCyber/TritonAcademy: A repository to unravel the language of GPUs, making their kernel conversations easy to understand</A>
								<DT><A HREF="https://github.com/rkinas/triton-resources?tab=readme-ov-file">rkinas/triton-resources: A curated list of resources for learning and exploring Triton, OpenAI's programming language for writing efficient GPU code.</A>
								<DT><A HREF="https://arxiv.org/pdf/2503.14985">ML-Triton, A Multi-Level Compilation and Language Extension to Triton GPU Programming</A>
							</DL><p>
							<DT><H3 FOLDED>triton-examples</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ELS-RD/kernl/blob/main/test/debugger/test_debugger.py">Example: addition</A>
								<DT><A HREF="https://github.com/openai/triton/blob/main/python/triton/ops/blocksparse/matmul.py">Flash-Attention/blocksparse/matmul.py</A>
								<DT><A HREF="https://github.com/lucidrains/triton-transformer">lucidrains/triton-transformer: Implementation of a Transformer, but completely in Triton</A>
								<DT><A HREF="https://github.com/ELS-RD/kernl/blob/91e2cd92db44d503874d39a9f6dec42c9f481a8e/src/kernl/model_optimization.py#L27">kernl/src/kernl/model_optimization.py</A>
								<DT><A HREF="https://github.com/srush/Triton-Puzzles">srush/Triton-Puzzles: Puzzles for learning Triton</A>
								<DT><A HREF="https://github.com/nikitaved/Intro_to_Triton/blob/main/Intro%20to%20Triton.ipynb">Intro_to_Triton/Intro to Triton.ipynb at main ¬∑ nikitaved/Intro_to_Triton</A>
								<DT><A HREF="https://x.com/pommedeterre33/status/1681935636129873920">(1) Micha√´l Benesty en X: "Boosted Llama V2 inference speed by 1.8x using @OpenAI's Triton (one key tech behind GPT-4) at batch=1 FP16 on a 3090 GPU, no quality compromises (-&amp;gt; no quant, etc.) Triton allows efficient custom GPU kernels, letting us merge operations together. Here's how we did + how it works" / X</A>
								<DT><A HREF="https://github.com/ELS-RD/kernl/tree/main/experimental/llama-v2">kernl/experimental/llama-v2 at main ¬∑ ELS-RD/kernl</A>
								<DT><A HREF="http://giantpandacv.com/project/%E9%83%A8%E7%BD%B2%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/OpenAITriton%20MLIR%20%E7%AC%AC%E4%BA%8C%E7%AB%A0%20Batch%20GEMM%20benchmark/#giantpandacv">OpenAITriton MLIR Á¨¨‰∫åÁ´† Batch GEMM benchmark - GiantPandaCV</A>
								<DT><A HREF="http://giantpandacv.com/project/CUDA/%E3%80%90BBuf%E7%9A%84CUDA%E7%AC%94%E8%AE%B0%E3%80%91%E5%8D%81%E4%BA%94%EF%BC%8COpenAI%20Triton%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%E4%B8%89%20FusedAttention/">FlashAttention V2 (chinese blog)</A>
								<DT><A HREF="https://github.com/RulinShao/LightSeq/blob/main/lightseq/lightseq_async_attn.py#L436">LightSeq/lightseq/lightseq_async_attn.py</A>
								<DT><A HREF="https://github.com/FlagOpen/FlagAttention">FlagOpen/FlagAttention: A collection of memory efficient attention operators implemented in the Triton language.</A>
								<DT><A HREF="https://github.com/pytorch/ao/blob/main/torchao/kernel/intmm_triton.py">ao/torchao/kernel/intmm_triton.py</A>
								<DT><A HREF="https://gist.github.com/malfet/77ed58fdb34681ff094716ae7c085780">Test triton</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/5ff25cdf5b1310e83d9e595142b39ae4d7b561e9/python/sglang/srt/layers/layernorm.py">sglang/python/sglang/srt/layers/layernorm.py at 5ff25cdf5b1310e83d9e595142b39ae4d7b561e9 ¬∑ sgl-project/sglang</A>
								<DT><A HREF="https://github.com/linkedin/Liger-Kernel/issues/119">[fun] llama.triton ¬∑ Issue #119 ¬∑ linkedin/Liger-Kernel</A>
								<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/fmha/triton_splitk.py">xformers/xformers/ops/fmha/triton_splitk.py at 0004c67c7e9ec3c9e7b3907db0e0b2957430b35b ¬∑ facebookresearch/xformers</A>
								<DT><A HREF="https://github.com/lucidrains/triton-transformer/tree/main/triton_transformer">triton-transformer/triton_transformer</A>
								<DT><A HREF="https://isamu-website.medium.com/understanding-triton-tutorials-part-2-f6839ce50ae7">Understanding Triton Tutorials Part 2 | by Isamu Isozaki | Medium</A>
								<DT><A HREF="https://github.com/Jokeren/triton-samples/blob/main/sum-2d.py">triton-samples/sum-2d.py at main ¬∑ Jokeren/triton-samples</A>
								<DT><A HREF="https://github.com/lessw2020/AdamW-Triton-PyTorch">lessw2020/AdamW-Triton-PyTorch: Can AdamW written in Triton be as performat as fused CUDA impl?</A>
								<DT><A HREF="https://github.com/lessw2020/triton_kernels_for_fun_and_profit">lessw2020/triton_kernels_for_fun_and_profit: Custom kernels in Triton language for accelerating LLMs</A>
								<DT><A HREF="https://ut21.github.io/blog/triton.html">‚ÄúThe G in GPU is for Graphics damnit!‚Äù: Adventures in Triton Kernels, Profiling, Parallelism and More</A>
								<DT><A HREF="https://nathanchen.me/public/Triton-Matrix-Multiplication.html">Implementing Matrix Multiplication in Triton with L2 Cache Optimization: A Tutorial</A>
								<DT><A HREF="https://github.com/SiriusNEO/Triton-Puzzles-Lite">SiriusNEO/Triton-Puzzles-Lite: Puzzles for learning Triton, play it with minimal environment configuration!</A>
							</DL><p>
							<DT><H3 FOLDED>triton-kernels</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-layers</H3>
								<DL><p>
									<DT><H3 FOLDED>monkey-patches</H3>
									<DL><p>
										<DT><A HREF="https://github.com/linkedin/Liger-Kernel/blob/main/README.md">Liger-Kernel/README.md at main ¬∑ linkedin/Liger-Kernel</A>
										<DT><A HREF="https://github.com/linkedin/Liger-Kernel/blob/ce71d59b0b0894f9f3e7512f5a3bf3780c5a1499/test/transformers/test_monkey_patch.py#L179">Liger-Kernel/test/transformers/test_monkey_patch.py at ce71d59b0b0894f9f3e7512f5a3bf3780c5a1499 ¬∑ linkedin/Liger-Kernel</A>
										<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/bedf8774677315c5eb7e640eca6d7aa15e87775a/flash_attn/layers/patch_embed.py">flash-attention/flash_attn/layers/patch_embed.py at bedf8774677315c5eb7e640eca6d7aa15e87775a ¬∑ Dao-AILab/flash-attention</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/commit/55842eb81a782da7e522ec0210c3fa1f3f74dc0a">feat: fused_moe fp8 monkey patch (#2174) ¬∑ sgl-project/sglang@55842eb</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/f96413c444a4ce16c6b01770e28a636350df24bf/python/sglang/srt/patch_torch.py">sglang/python/sglang/srt/patch_torch.py at f96413c444a4ce16c6b01770e28a636350df24bf ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/NVIDIA/TileGym/blob/main/src/tilegym/transformers/monkey_patch.py">TileGym/src/tilegym/transformers/monkey_patch.py at main ¬∑ NVIDIA/TileGym</A>
										<DT><A HREF="https://github.com/Overworldai/world_engine/blob/main/src/quantize.py">for name, child in model.named_children():</A>
									</DL><p>
									<DT><H3 FOLDED>kernel-fallback</H3>
									<DL><p>
										<DT><A HREF="https://github.com/timudk/flux_triton/blob/40ba90d35b97891ff92e3df53effc51b6e71c582/src/flux/modules/layers.py#L17">TRITON_LN = os.getenv("TRITON_LN")</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/4353acb469d46afe3b652928729803492873d0cd/python/sglang/srt/layers/layernorm.py#L25">sglang/python/sglang/srt/layers/layernorm.py: forward_native, forward_cuda</A>
									</DL><p>
									<DT><H3 FOLDED>triton-moe</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/6429">[BENCH] fp4 experts added production kernels and micro-benchmark for mixture-of-experts MLP by ptillet ¬∑ Pull Request #6429 ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://x.com/typedfemale/status/1911925432120914002">Fp4 experts? GB200 benches? Basic switch transformer style routing?</A>
									</DL><p>
									<DT><A HREF="https://github.com/linkedin/Liger-Kernel">linkedin/Liger-Kernel: Efficient Triton Kernels for LLM Training</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/a7c47e0f028c2a9e67cbc99ab67692ec765d3dd0/python/sglang/srt/layers/activation.py">sglang/python/sglang/srt/layers/activation.py</A>
									<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/main/examples/matmul/triton/triton_matmul_sm90.py">MatmulTutorial/examples/matmul/triton/triton_matmul_sm90.py at main ¬∑ KnowingNothing/MatmulTutorial</A>
									<DT><A HREF="https://github.com/ModelTC/lightllm/blob/main/lightllm/models/llama/triton_kernel/flash_decoding.py">lightllm/lightllm/models/llama/triton_kernel/flash_decoding.py at main ¬∑ ModelTC/lightllm</A>
									<DT><A HREF="https://github.com/ModelTC/lightllm/blob/main/lightllm/models/llama/triton_kernel/rmsnorm.py">lightllm/lightllm/models/llama/triton_kernel/rmsnorm.py at main ¬∑ ModelTC/lightllm</A>
									<DT><A HREF="https://github.com/dtunai/triton-activations/blob/main/triton_activations/functions.py#L207">triton-activations/triton_activations/functions.py at main ¬∑ dtunai/triton-activations</A>
									<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/528a9301587f5fb135b25d973a87ba0a40a703a7/flashnn/kernel_backend.py#L44">FLASHNN/flashnn/kernel_backend.py at 528a9301587f5fb135b25d973a87ba0a40a703a7 ¬∑ AlibabaPAI/FLASHNN</A>
									<DT><A HREF="https://github.com/FlagOpen/FlagGems">FlagOpen/FlagGems: FlagGems is an operator library for large language models implemented in Triton Language.</A>
									<DT><A HREF="https://github.com/FlagOpen/FlagGems/blob/master/src/flag_gems/fused/gelu_and_mul.py">FlagGems/src/flag_gems/fused/gelu_and_mul.py at master ¬∑ FlagOpen/FlagGems</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/af314d400663fe895199b0586a9f1f718b1d7b79/flash_attn/ops/triton/linear.py#L131">flash-attention/flash_attn/ops/triton/linear.py at af314d400663fe895199b0586a9f1f718b1d7b79 ¬∑ Dao-AILab/flash-attention</A>
									<DT><A HREF="https://github.com/Dao-AILab/flash-attention/blob/af314d400663fe895199b0586a9f1f718b1d7b79/flash_attn/ops/triton/mlp.py">flash-attention/flash_attn/ops/triton/mlp.py at af314d400663fe895199b0586a9f1f718b1d7b79 ¬∑ Dao-AILab/flash-attention</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/3ae95a858eac26088102075500e3860864432106/python/test/unit/hopper/test_flashattention.py#L294">triton/python/test/unit/hopper/test_flashattention.py: torch.autograd.Function</A>
									<DT><A HREF="https://github.com/BobMcDear/attorch">BobMcDear/attorch: A subset of PyTorch's neural network modules, written in Python using OpenAI's Triton.</A>
									<DT><A HREF="https://github.com/BobMcDear/attorch/blob/main/attorch/glu_kernels.py">attorch/attorch/glu_kernels.py</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/7efcb5e0ed6403f08965b999626c5807680b46ed/server/text_generation_server/layers/attention/flash_attn_triton.py#L811">text-generation-inference/server/text_generation_server/layers/attention/flash_attn_triton.py at 7efcb5e0ed6403f08965b999626c5807680b46ed ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/7efcb5e0ed6403f08965b999626c5807680b46ed/server/text_generation_server/layers/gptq/quant_linear.py#L7">text-generation-inference/server/text_generation_server/layers/gptq/quant_linear.py at 7efcb5e0ed6403f08965b999626c5807680b46ed ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/PygmalionAI/aphrodite-engine/blob/0e0bd02b52a9bd32c0709c47f501abd6c70453ad/aphrodite/_custom_ops.py#L228">aphrodite-engine/aphrodite/_custom_ops.py at 0e0bd02b52a9bd32c0709c47f501abd6c70453ad ¬∑ PygmalionAI/aphrodite-engine</A>
									<DT><A HREF="https://github.com/ModelTC/lightllm/blob/0d418dcaca3c2090fcae2a87e5411e08e1ecbd42/lightllm/models/gemma_2b/triton_kernel/gelu_and_mul.py#L4">lightllm/lightllm/models/gemma_2b/triton_kernel/gelu_and_mul.py</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/layers/rotary_embedding.py#L75">vllm/vllm/model_executor/layers/rotary_embedding.py</A>
									<DT><A HREF="https://github.com/ModelTC/lightllm/blob/452baa708559a1d09c0a8819b69f3fea3cd50d12/lightllm/models/bloom/triton_kernel/layernorm.py#L70">lightllm/lightllm/models/bloom/triton_kernel/layernorm.py</A>
									<DT><A HREF="https://github.com/ModelTC/lightllm/blob/452baa708559a1d09c0a8819b69f3fea3cd50d12/lightllm/models/gemma_2b/triton_kernel/gelu_and_mul.py#L9">lightllm/lightllm/models/gemma_2b/triton_kernel/gelu_and_mul.py</A>
									<DT><A HREF="https://github.com/ModelTC/lightllm/blob/452baa708559a1d09c0a8819b69f3fea3cd50d12/lightllm/models/llama/triton_kernel/silu_and_mul.py#L4">lightllm/lightllm/models/llama/triton_kernel/silu_and_mul.py</A>
									<DT><A HREF="https://arxiv.org/pdf/1910.07467">Root Mean Square Layer Normalization</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/main/third_party/proton/tutorials/matmul.py#L189">triton/third_party/proton/tutorials/matmul.py at main ¬∑ triton-lang/triton</A>
									<DT><A HREF="https://github.com/INT-FlashAttention2024/INT-FlashAttention/blob/main/flash_atten_fp.py">INT-FlashAttention/flash_atten_fp.py at main ¬∑ INT-FlashAttention2024/INT-FlashAttention</A>
									<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/528a9301587f5fb135b25d973a87ba0a40a703a7/flashnn/triton_kernels/rotary_embedding.py#L157">FLASHNN/flashnn/triton_kernels/rotary_embedding.py at 528a9301587f5fb135b25d973a87ba0a40a703a7 ¬∑ AlibabaPAI/FLASHNN</A>
									<DT><A HREF="https://github.com/lianakoleva/no-libtorch-compile/blob/master/triton-aoti.py">no-libtorch-compile/triton-aoti.py at master ¬∑ lianakoleva/no-libtorch-compile</A>
									<DT><A HREF="https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html">Linear/Fully-Connected Layers User's Guide - NVIDIA Docs</A>
									<DT><A HREF="https://github.com/dame-cell/Triformer">dame-cell/Triformer: Transformers components but in Triton</A>
									<DT><A HREF="https://github.com/PaliC/categorize_triton_functions">PaliC/categorize_triton_functions</A>
								</DL><p>
								<DT><H3 FOLDED>Liger-Kernel</H3>
								<DL><p>
									<DT><A HREF="https://github.com/linkedin/Liger-Kernel">linkedin/Liger-Kernel: Efficient Triton Kernels for LLM Training</A>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1827072737673982056">ntroducing Liger-Kernel: Efficient Triton Kernels for LLM Training.</A>
									<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN">AlibabaPAI/FLASHNN</A>
								</DL><p>
								<DT><H3 FOLDED>generative-recommenders-kernels</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookresearch/generative-recommenders/tree/main/generative_recommenders/ops/triton">generative-recommenders/generative_recommenders/ops/triton at main ¬∑ facebookresearch/generative-recommenders</A>
								</DL><p>
								<DT><H3 FOLDED>mirage</H3>
								<DL><p>
									<DT><A HREF="https://github.com/mirage-project/mirage">mirage-project/mirage: Mirage: Automatically Generating Fast GPU Kernels without Programming in Triton/CUDA</A>
								</DL><p>
								<DT><H3 FOLDED>triton-bwd</H3>
								<DL><p>
									<DT><A HREF="https://x.com/JingyuanLiu123/status/1971253848997351867">use autograd to valide derivation from custom Torch first, compare intermediates</A>
									<DT><A HREF="https://github.com/daniel-geon-park/triton_bwd">daniel-geon-park/triton_bwd: Automatic differentiation for Triton Kernels</A>
									<DT><A HREF="https://github.com/daniel-geon-park/triton_bwd/tree/main/tests">triton_bwd/tests at main ¬∑ daniel-geon-park/triton_bwd</A>
								</DL><p>
								<DT><A HREF="https://github.com/Dao-AILab/flash-attention/tree/main/flash_attn/ops/triton">flash-attention/flash_attn/ops/triton at main ¬∑ Dao-AILab/flash-attention</A>
								<DT><A HREF="https://github.com/cuda-mode/triton-index">cuda-mode/triton-index: Cataloging released Triton kernels.</A>
								<DT><A HREF="https://github.com/cuda-mode/triton-index/blob/main/kernel_overview.md">triton-index/kernel_overview.md</A>
								<DT><A HREF="https://github.com/ELS-RD/kernl/blob/main/test/debugger/test_debugger.py">Example: addition</A>
								<DT><A HREF="https://github.com/openai/triton/blob/main/python/triton/ops/blocksparse/matmul.py">Flash-Attention/blocksparse/matmul.py</A>
								<DT><A HREF="https://github.com/ai-compiler-study/kernels/tree/main">ai-compiler-study/kernels</A>
								<DT><A HREF="https://github.com/zinccat/Awesome-Triton-Kernels?tab=readme-ov-file">zinccat/Awesome-Triton-Kernels: Collection of kernels written in Triton language</A>
								<DT><A HREF="https://github.com/mobiusml/gemlite/">mobiusml/gemlite: Simple and fast low-bit matmul kernels in CUDA / Triton</A>
								<DT><A HREF="https://github.com/ModelTC/lightllm/blob/0d418dcaca3c2090fcae2a87e5411e08e1ecbd42/lightllm/models/cohere/triton_kernels/rotary_emb.py#L4">lightllm/lightllm/models/cohere/triton_kernels/rotary_emb.py (rope)</A>
								<DT><A HREF="https://github.com/ModelTC/lightllm/blob/452baa708559a1d09c0a8819b69f3fea3cd50d12/lightllm/models/llama/triton_kernel/rmsnorm.py#L7">lightllm/lightllm/models/llama/triton_kernel/rmsnorm.py</A>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/4a9dd7ec079e0c935db10daa2a1a89fd19cfa231/xformers/ops/_triton/tiled_matmul_kernels.py#L150">xformers/xformers/ops/_triton/tiled_matmul_kernels.py</A>
								<DT><A HREF="https://github.com/gpu-mode/triton-index/blob/main/kernel_overview.md">triton-index/kernel_overview.md at main ¬∑ gpu-mode/triton-index</A>
								<DT><A HREF="https://github.com/Dao-AILab/flash-attention/tree/main/flash_attn/ops">flash-attention/flash_attn/ops at main ¬∑ Dao-AILab/flash-attention</A>
								<DT><A HREF="https://github.com/facebookresearch/generative-recommenders/blob/main/ops/triton/triton_addmm.py">generative-recommenders/ops/triton/triton_addmm.py at main ¬∑ facebookresearch/generative-recommenders</A>
							</DL><p>
							<DT><H3 FOLDED>triton-compiler</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-dev</H3>
								<DL><p>
									<DT><A HREF="https://www.lei.chat/posts/triton-compiler-development-tips/">Triton Compiler Development Tips | Lei.Chat()</A>
								</DL><p>
								<DT><H3 FOLDED>TTIR</H3>
								<DL><p>
									<DT><H3 FOLDED>triton-mlir</H3>
									<DL><p>
										<DT><H3 FOLDED>tritonc</H3>
										<DL><p>
											<DT><A HREF="https://x.com/i/bookmarks?post_id=1833331103131734071">autotuner constants search</A>
										</DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=NZz5sczZ_30&t=16s">Triton Conference 2024: Morning Session - YouTube</A>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/f43badbb0e9810b79477cf4d1087cc8906cf3813/test/TritonGPU/pipeline-loop-nest.mlir">// RUN: triton-opt %s -pass-pipeline='builtin.module(convert-triton-to-tritongpu{num-warps=4 target=cuda:100},tritongpu-coalesce,tritongpu-accelerate-matmul,tritongpu-remove-layout-conversions,tritongpu-optimize-dot-operands,cse,tritongpu-fuse-nested-loops,canonicalize,tritongpu-optimize-accumulator-init,tritongpu-hoist-tmem-alloc,tritongpu-pipeline,canonicalize)' | FileCheck %s --check-prefix=BLACKWELL</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1924011555437155686">Analyzing the Triton compiler's MatMul optimization (Part 3) ‚Äì TMA</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=etlFyqSsmL0">Compiler Tools: Writing an MLIR Pass - YouTube</A>
									<DT><A HREF="https://github.com/drisspg/triton_differ">drisspg/triton_differ: A command-line tool for generating HTML comparisons of Triton IR files</A>
									<DT><A HREF="https://github.com/dsl-learn/Triton-blog-file/blob/main/matmul/with_tma_v2/.cache/matmul_kernel_make_tensor_desciptor.ttir">Triton-blog-file/matmul/with_tma_v2/.cache/matmul_kernel_make_tensor_desciptor.ttir at main ¬∑ dsl-learn/Triton-blog-file</A>
								</DL><p>
								<DT><H3 FOLDED>triton-dtypes</H3>
								<DL><p>
									<DT><H3 FOLDED>triton-fp8</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/10f59d8ce04052521c1bc0cb3a3f8b98918fc7e3/lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp#L10">triton/lib/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVM.cpp at 10f59d8ce04052521c1bc0cb3a3f8b98918fc7e3 ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/8494/files">[NVIDIA] Add native FP4 scaled_dot for SM120 by ita9naiwa ¬∑ Pull Request #8494 ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><H3 FOLDED>triton-fp4</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/8494/files">[NVIDIA] Add native FP4 scaled_dot for SM120 by ita9naiwa ¬∑ Pull Request #8494 ¬∑ triton-lang/triton</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>triton-hopper</H3>
								<DL><p>
									<DT><H3 FOLDED>triton-warp-specialization</H3>
									<DL><p>
										<DT><A HREF="https://www.linkedin.com/posts/bertrand-maher_automatic-warp-specialization-optimization-activity-7285852014599655424-RV5M/?utm_source=share&utm_medium=member_ios">(2) Post | LinkedIn</A>
										<DT><A HREF="https://x.com/andrew_n_carr/status/1880098533350732203">(1) Andrew Carr (e/ü§∏) en X: "Crazy new feature in Triton Basically, Warp specialization in Triton takes advantage of the GPU‚Äôs hardware-level concurrency by splitting your kernel into multiple asynchronous tasks (‚Äúwarp groups‚Äù). Each warp group runs in parallel‚Äîcommunicating efficiently via H100‚Äôs fast https://t.co/GDORoUuKpP" / X</A>
										<DT><A HREF="https://pytorch.org/blog/warp-specialization/?utm_campaign=4079123-PyTorch%20Blog%20Post%20Promotion&utm_content=324019352&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Enabling advanced GPU features in PyTorch - Warp Specialization | PyTorch</A>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/5622">Automatic Warp Specialization Optimization by htyu ¬∑ Pull Request #5622 ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://pytorch.org/blog/warp-specialization-in-triton-design-and-roadmap/">Warp Specialization in Triton: Design and Roadmap ‚Äì PyTorch</A>
										<DT><A HREF="https://arxiv.org/abs/2510.14719">[2510.14719] Tawa: Automatic Warp Specialization for Modern GPUs with Asynchronous References</A>
									</DL><p>
									<DT><H3 FOLDED>triton-tma</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/blog/hopper-tma-unit/">Deep Dive on the Hopper TMA Unit for FP8 GEMMs | PyTorch</A>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/main/python/triton/tools/experimental_descriptor.py">triton/python/triton/tools/experimental_descriptor.py: TMA experimental API</A>
										<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/pull/43/files#diff-6278ea2f3ba2c5944e0975de46068b9ef1f6451e2c54899d03172264dc3b3f6b">fix: refine and test tma copy. by lcy-seso ¬∑ Pull Request #43 ¬∑ lcy-seso/DLFrameworkTest</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/721163129">„ÄêÂçöÂÆ¢ÁøªËØë„ÄëÊ∑±ÂÖ•Êé¢ËÆ® Hopper TMA ÂçïÂÖÉÂú® FP8 GEMM ËøêÁÆó‰∏≠ÁöÑÂ∫îÁî® - Áü•‰πé</A>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/5622">Automatic Warp Specialization Optimization by htyu ¬∑ Pull Request #5622 ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://research.colfax-intl.com/tutorial-hopper-tma/">CUTLASS Tutorial: Mastering the NVIDIA¬Æ Tensor Memory Accelerator (TMA) ‚Äì Colfax Research</A>
										<DT><A HREF="https://github.com/meta-pytorch/applied-ai/blob/main/dev/triton_groupGEMM/tma_utils.py">applied-ai/dev/triton_groupGEMM/tma_utils.py: triton.runtime.driver.active.utils.fill_2d_tma_descriptor</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1924011555437155686">Analyzing the Triton compiler's MatMul optimization (Part 3) ‚Äì TMA</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>triton-blackwell</H3>
								<DL><p>
									<DT><H3 FOLDED>Gluon</H3>
									<DL><p>
										<DT><H3 FOLDED>gluon-examples</H3>
										<DL><p>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/main/python/tutorials/gluon/01-intro.py">triton/python/tutorials/gluon/01-intro.py at main ¬∑ triton-lang/triton</A>
											<DT><A HREF="https://github.com/triton-lang/triton/blob/main/python/tutorials/gluon/02-layouts.py">triton/python/tutorials/gluon/02-layouts.py at main ¬∑ triton-lang/triton</A>
										</DL><p>
										<DT><H3 FOLDED>gluon-sm103</H3>
										<DL><p>
											<DT><A HREF="https://github.com/triton-lang/triton/pull/9151">[Blackwell][Gluon] implement tcgen05.ld.red for sm103 by 3gx ¬∑ Pull Request #9151 ¬∑ triton-lang/triton</A>
										</DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/tree/main/python/tutorials/gluon">triton/python/tutorials/gluon at main ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://github.com/triton-lang/triton/tree/main/python/triton/experimental">triton/python/triton/experimental at main ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://github.com/triton-lang/triton/issues/7392">Gluon? ¬∑ Issue #7392 ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://x.com/_xjdr/status/1968122114407534674">(1) xjdr en X: "if you have wondered why i have been skeptical of triton and gone head first into cute dsl everywhere, this is one of the reasons" / X</A>
										<DT><A HREF="https://x.com/difficultyang/status/1968027448622379387">(1) difficultyang en X: "TIL, RIP Triton, killed by inability to have good Blackwell performance" / X</A>
										<DT><A HREF="https://www.youtube.com/watch?v=5e1YKqsP8i8&t=1039s">Triton Community Meetup 20250709 130219 Meeting Recording - YouTube</A>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/7298">gluon see ptxas</A>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/8922/changes">[BACKEND] Support M=64 2CTA mode by lezcano ¬∑ Pull Request #8922 ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><H3 FOLDED>triton-tmem</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/40f3945c6970d372355440a6c635f42932fc6987/python/test/unit/blackwell/test_tmem.py#L8">triton/python/test/unit/blackwell/test_tmem.py</A>
									</DL><p>
									<DT><H3 FOLDED>triton-sm120</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/6131#pullrequestreview-2665754616">Fix Compilation Issue for RTX 5090 GPUs with Compute Capability = 120 by oteroantoniogom ¬∑ Pull Request #6131 ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><H3 FOLDED>TRITON_PTXAS_PATH</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/30484">[Feature] Add SM103 (Blackwell Ultra) Support to vLLM by LopezCastroRoberto ¬∑ Pull Request #30484 ¬∑ vllm-project/vllm</A>
									</DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72876/">Blackwell Programming for the Masses With OpenAI Triton | GTC 25 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://github.com/triton-lang/triton/pull/6429">[BENCH] added production kernels and micro-benchmark for mixture-of-experts MLP by ptillet ¬∑ Pull Request #6429 ¬∑ triton-lang/triton</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/f43badbb0e9810b79477cf4d1087cc8906cf3813/README.md">triton/README.md: Enabling Blackwell support (pytorch-triton 3.3)</A>
									<DT><A HREF="https://webstorms.github.io/2025/02/06/5080-install.html">Running PyTorch and Triton on the RTX 5080 | Luke‚Äôs Blog</A>
									<DT><A HREF="https://www.youtube.com/watch?v=RW2-HtWaOS0">Accelerating the Future: Triton on Blackwell Architecture - YouTube</A>
									<DT><A HREF="https://github.com/triton-lang/triton/pull/6429/files">[BENCH] added production kernels and micro-benchmark for mixture-of-experts MLP by ptillet ¬∑ Pull Request #6429 ¬∑ triton-lang/triton</A>
									<DT><A HREF="https://github.com/facebookexperimental/triton/commit/cc65c1b6b555ea5bc30f002aa56b0f3d21be2006">Code refactoring to Blackwell FA kernels (#402) ¬∑ facebookexperimental/triton@cc65c1b</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/main/python/triton_kernels/triton_kernels/tensor_details/layout_details/blackwell_scale.py">triton/python/triton_kernels/triton_kernels/tensor_details/layout_details/blackwell_scale.py at main ¬∑ triton-lang/triton</A>
								</DL><p>
								<DT><H3 FOLDED>tritonparse</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/commit/734bccc3a2b714c1021fedbae4e4f2a602f51f45">[TritonParse] Enable Launch Tracing, Default Parsing, and Enhanced Do... ¬∑ pytorch-labs/tritonbench@734bccc</A>
									<DT><A HREF="https://github.com/pytorch-labs/tritonparse">pytorch-labs/tritonparse: TritonParse: A Compiler Tracer, Visualizer, and mini-Reproducer(WIP) for Triton Kernels</A>
									<DT><A HREF="https://github.com/search?q=repo%3Apytorch-labs%2Ftritonbench+tritonparse&type=code">install_triontparse, parser.py, tritonparser_utils</A>
									<DT><A HREF="https://github.com/meta-pytorch/tritonparse">meta-pytorch/tritonparse: TritonParse: A Compiler Tracer, Visualizer, and mini-Reproducer (WIP) for Triton Kernels</A>
									<DT><A HREF="https://meta-pytorch.org/tritonparse/?json_url=https%3A%2F%2Fmeta-pytorch.org%2Ftritonparse%2Fdedicated_log_triton_trace_findhao__mapped.ndjson.gz">TritonParse visual</A>
									<DT><A HREF="https://www.linkedin.com/feed/">Feed | LinkedIn</A>
									<DT><A HREF="https://github.com/meta-pytorch/tritonparse/wiki">Home ¬∑ meta-pytorch/tritonparse Wiki</A>
								</DL><p>
								<DT><H3 FOLDED>TLX</H3>
								<DL><p>
									<DT><H3 FOLDED>tlx-clc</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/cutlass/media/docs/cpp/blackwell_cluster_launch_control.html#blackwell-cluster-launch-control">Blackwell Cluster Launch Control ‚Äî NVIDIA CUTLASS Documentation</A>
										<DT><A HREF="https://pytorch.org/blog/enabling-cluster-launch-control-with-tlx/">Enabling Cluster Launch Control with TLX ‚Äì PyTorch</A>
									</DL><p>
									<DT><A HREF="https://x.com/tensorbert/status/1968508004694634680">Bert Maher en X: "Since I‚Äôve seen various discussion of Triton and Gluon bouncing around this website, I thought I‚Äôd throw TLX into the mix (from my old team!) https://t.co/Br28fTVDT1 I like that it gives you direct control over warp specialization and concurrency" / X</A>
									<DT><A HREF="https://github.com/facebookexperimental/triton?tab=readme-ov-file#tlx---triton-low-level-language-extensions">facebookexperimental/triton: Github mirror of trition-lang/triton repo.</A>
									<DT><A HREF="https://github.com/facebookexperimental/triton/commit/cc65c1b6b555ea5bc30f002aa56b0f3d21be2006">Code refactoring to Blackwell FA kernels (#402) ¬∑ facebookexperimental/triton@cc65c1b</A>
									<DT><A HREF="https://github.com/facebookexperimental/triton/blob/main/third_party/tlx/tutorials/hopper-fa-ws-pipelined-pingpong_test.py">triton/third_party/tlx/tutorials/hopper-fa-ws-pipelined-pingpong_test.py at main ¬∑ facebookexperimental/triton</A>
									<DT><A HREF="https://pytorch.org/blog/fast-2-simplicial-attention-hardware-efficient-kernels-in-tlx/">Fast 2-Simplicial Attention: Hardware-Efficient Kernels in TLX ‚Äì PyTorch</A>
								</DL><p>
								<DT><H3 FOLDED>triton-tuner</H3>
								<DL><p>
									<DT><H3 FOLDED>proton-KPerfIR</H3>
									<DL><p>
										<DT><A HREF="https://arxiv.org/abs/2505.21661">[2505.21661] KPerfIR: Towards an Open and Compiler-centric Ecosystem for GPU Kernel Performance Tooling on Modern AI Workloads</A>
										<DT><A HREF="https://github.com/triton-lang/triton/tree/main/third_party/proton/dialect">triton/third_party/proton/dialect at main ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><H3 FOLDED>TRITON_PRINT_AUTOTUNING</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/ita9naiwa/4aa5f323ef9e2b87400d20ca8366a1c9">VLLM_USE_V1=1 VLLM_DISABLE_COMPILE_CACHE=1 TRITON_PRINT_AUTOTUNING=1 python3 vllm_benchmark.py --input-len $in_len --output-len $out_len --model $model --dtype float16 --batch-size $batch_size --num_iters_warmup 5 --num_iters 5</A>
										<DT><A HREF="https://github.com/search?q=repo%3Atriton-lang%2Ftriton%20TRITON_PRINT_AUTOTUNING&type=code">Code search results</A>
									</DL><p>
									<DT><A HREF="https://gist.github.com/a-r-r-o-w/ad460e6ff0155a5bf6511be7f6defcb5">triton autotuning somehow reports slower times</A>
								</DL><p>
								<DT><H3 FOLDED>triton-env-vars</H3>
								<DL><p>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/c186592a17299439900d712e85556e8578345821/python/triton/knobs.py#L376">triton/python/triton/knobs.py: env_bool</A>
								</DL><p>
								<DT><H3 FOLDED>triton-lowering</H3>
								<DL><p>
									<DT><A HREF="https://www.kapilsharma.dev/posts/gpu-mode-triton-internals-talk/">GPU Mode - Triton Internals Talk | Kapil Sharma</A>
									<DT><A HREF="https://www.albresky.cn/triton-insight/">Triton ÁºñËØëÊµÅÁ®ãÂèä Op lowering - Albresky's Blog</A>
								</DL><p>
								<DT><H3 FOLDED>triton-ptx</H3>
								<DL><p>
									<DT><A HREF="https://aminediro.com/posts/flash_attn/">TRITON_CACHE_DIR</A>
								</DL><p>
								<DT><A HREF="https://github.com/triton-lang/triton/blob/main/python/triton/tools/compile.py">triton/python/triton/tools/compile.py</A>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/528a9301587f5fb135b25d973a87ba0a40a703a7/flashnn/triton_kernels/triton_utils.py#L84">FLASHNN/flashnn/triton_kernels/triton_utils.py at 528a9301587f5fb135b25d973a87ba0a40a703a7 ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://www.kapilsharma.dev/posts/deep-dive-into-triton-internals/">Deep Dive into Triton Internals (Part 1) | Kapil Sharma</A>
								<DT><A HREF="https://www.kapilsharma.dev/posts/deep-dive-into-triton-internals-2/">Deep Dive into Triton Internals (Part 2) | Kapil Sharma</A>
								<DT><A HREF="https://www.kapilsharma.dev/posts/deep-dive-into-triton-internals-3/">Deep Dive into Triton Internals (Part 3) | Kapil Sharma</A>
								<DT><A HREF="https://www.youtube.com/watch?v=njgow_zaJMw">Lecture 29: Triton Internals - YouTube</A>
								<DT><A HREF="https://pytorch.org/blog/triton-kernel-compilation-stages/?utm_content=314838032&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Triton Kernel Compilation Stages | PyTorch</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/11901442836">CUDA-MODE ËØæÁ®ãÁ¨îËÆ∞ Á¨¨29ËØæ TritonÂÜÖÈÉ®Êú∫Âà∂ - Áü•‰πé</A>
								<DT><A HREF="https://github.com/triton-lang/triton/blob/40f3945c6970d372355440a6c635f42932fc6987/python/test/unit/blackwell/test_tmem.py#L8">kernel = triton.compile(f.name, target=GPUTarget("cuda", 100, 32))</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1924011555437155686">Analyzing the Triton compiler's MatMul optimization (Part 3) ‚Äì TMA</A>
							</DL><p>
							<DT><H3 FOLDED>triton-backends</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-backends-llvm</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ptillet/triton-llvm-releases">ptillet/triton-llvm-releases</A>
									<DT><A HREF="https://github.com/acollins3/triton-llvm-releases">acollins3/triton-llvm-releases</A>
								</DL><p>
								<DT><H3 FOLDED>triton-backends-ptx</H3>
								<DL><p>
									<DT><H3 FOLDED>triton-blackwell</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/5724">Add support for Nvidia Blackwell GPUs by ThomasRaoux ¬∑ Pull Request #5724 ¬∑ triton-lang/triton</A>
									</DL><p>
									<DT><A HREF="https://twitter.com/cHHillee/status/1779141387876962469">Triton kernels can be precompiled into .cubin files</A>
								</DL><p>
								<DT><H3 FOLDED>triton-tileIR</H3>
								<DL><p>
									<DT><H3 FOLDED>triton-tileIR-benchmark</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-pytorch/tritonbench/commit/3e833879c6798e3549f74b1f25ae199809d98d6f">Enable TileIR with triton backend ¬∑ meta-pytorch/tritonbench@3e83387</A>
										<DT><A HREF="https://github.com/meta-pytorch/tritonbench/blob/3e833879c6798e3549f74b1f25ae199809d98d6f/tritonbench/utils/env_utils.py#L106">tritonbench/tritonbench/utils/env_utils.py ENABLE_TILE=1</A>
									</DL><p>
									<DT><H3 FOLDED>triton-tileIR-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/search?q=repo%3Atriton-lang%2FTriton-to-tile-IR+sm100&type=code">Triton SM100</A>
									</DL><p>
									<DT><A HREF="https://github.com/triton-lang/Triton-to-tile-IR/blob/main/third_party/tileir/PerformanceTuningTips.md">Triton-to-tile-IR/third_party/tileir/PerformanceTuningTips.md</A>
									<DT><A HREF="https://github.com/triton-lang/Triton-to-tile-IR/blob/main/third_party/tileir/README.md">Triton-to-tile-IR/third_party/tileir/README.md export ENABLE_TILE=1</A>
									<DT><A HREF="https://github.com/triton-lang/Triton-to-tile-IR/blob/13b41b98743186d81ca60e3b985f440bffeff8ff/python/tutorials/tileir/attention_tma.py#L105">Triton-to-tile-IR/python/tutorials/tileir/attention_tma.py: This is tileIR backend friendly version of the Triton implementation of the Flash Attention v2</A>
								</DL><p>
								<DT><H3 FOLDED>triton-backends-hip</H3>
								<DL><p>
									<DT><A HREF="https://github.com/openai/triton/pull/1983">[ROCM] Core Functionality for AMD by micmelesse ¬∑ Pull Request #1983 ¬∑ openai/triton</A>
									<DT><A HREF="https://gemini.google.com/app/ba25862900744324">HIP: clang2py</A>
								</DL><p>
								<DT><H3 FOLDED>triton-cpu</H3>
								<DL><p>
									<DT><A HREF="https://github.com/triton-lang/triton-cpu">triton-lang/triton-cpu: An experimental CPU backend for Triton</A>
									<DT><A HREF="https://github.com/kshama-msft/triton/blob/f0cf3a2e7a35260a013e639aea558fe1b7befa7b/docs/meetups/05-07-2024/notes.md">triton/docs/meetups/05-07-2024/notes</A>
									<DT><A HREF="https://www.youtube.com/watch?v=hgINpebZ7n0">Triton May Community meetup 20240507 - YouTube</A>
									<DT><A HREF="https://drive.google.com/drive/folders/1xPnRO5P59aMVJnXz_o9ASTUgTXK1lhHW">May 2024 meetup - Google Drive</A>
									<DT><A HREF="https://siboehm.com/articles/22/Fast-MMM-on-CPU">Fast Multidimensional Matrix Multiplication on CPU from Scratch</A>
									<DT><A HREF="https://github.com/pytorch-labs/triton-cpu">pytorch-labs/triton-cpu: An experimental CPU backend for Triton (https//github.com/openai/triton)</A>
								</DL><p>
								<DT><H3 FOLDED>triton-backends-xpu</H3>
								<DL><p>
									<DT><A HREF="https://github.com/intel/intel-xpu-backend-for-triton">intel/intel-xpu-backend-for-triton: OpenAI Triton backend for Intel¬Æ GPUs</A>
								</DL><p>
								<DT><H3 FOLDED>triton-shared</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/triton-shared">microsoft/triton-shared: Shared Middle-Layer for Triton Compilation</A>
									<DT><A HREF="https://www.youtube.com/watch?v=k3JPeRo57S8&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=3">torch.accelerator: A Unified, Device-Agnostic Runtime API for Stream-Based Accelerators - Yu Guangye - YouTube</A>
								</DL><p>
								<DT><A HREF="https://github.com/NVIDIA/FasterTransformer/tree/main/src/fastertransformer/triton_backend">FasterTransformer/src/fastertransformer/triton_backend at main ¬∑ NVIDIA/FasterTransformer</A>
							</DL><p>
							<DT><H3 FOLDED>triton-profiling</H3>
							<DL><p>
								<DT><H3 FOLDED>proton</H3>
								<DL><p>
									<DT><H3 FOLDED>Hatchet</H3>
									<DL><p>
										<DT><A HREF="https://hatchet.readthedocs.io/en/latest/">Hatchet ‚Äî hatchet 1.4.0 documentation</A>
										<DT><A HREF="https://github.com/hatchet/hatchet">hatchet/hatchet: Analyze graph/hierarchical performance data using pandas dataframes</A>
									</DL><p>
									<DT><H3 FOLDED>proton-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/4dcfbc970fb6184caf025d9f7c32e1dacf01078d/examples/matmul/triton/triton_matmul_sm90.py#L18">triton_matmul_sm90.py#L18</A>
										<DT><A HREF="https://github.com/ModelTC/lightllm/pull/783/commits/dfec3761cc8bf5ab1b82d55861b00ea9334cf552">DeepseekV3 support deepep, deepgemm, PD, DP TP SP Mix mode. by hiworldwzj ¬∑ Pull Request #783 ¬∑ ModelTC/lightllm</A>
										<DT><A HREF="https://pytorch.org/blog/fast-2-simplicial-attention-hardware-efficient-kernels-in-tlx/">Fast 2-Simplicial Attention: Hardware-Efficient Kernels in TLX ‚Äì PyTorch</A>
									</DL><p>
									<DT><H3 FOLDED>proton-instruction-level-profiling</H3>
									<DL><p>
										<DT><A HREF="https://x.com/__tinygrad__/status/1951137664243212401">(1) the tiny corp en X: "tinygrad's profiler is getting very good. Just run with VIZ=1 and click Profiler in the top left. Here's three steps of Llama training on MI350X https://t.co/Td36TwaQ98" / X</A>
									</DL><p>
									<DT><H3 FOLDED>proton-nvtx</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/blob/main/third_party/proton/test/test_profile.py">triton/third_party/proton/test/test_profile.py</A>
									</DL><p>
									<DT><A HREF="https://github.com/kshama-msft/triton/blob/f0cf3a2e7a35260a013e639aea558fe1b7befa7b/docs/meetups/02-20-2024/Proton.pdf">triton/docs/meetups/02-20-2024/Proton.pdf</A>
									<DT><A HREF="https://github.com/openai/triton/tree/main/third_party/proton">triton/third_party/proton</A>
									<DT><A HREF="https://github.com/openai/triton/blob/main/third_party/proton/tutorials/matmul.py">triton/third_party/proton/tutorials/matmul.py at main ¬∑ openai/triton</A>
									<DT><A HREF="https://www.youtube.com/watch?v=NZz5sczZ_30&t=16s">Triton Conference 2024: Morning Session - YouTube</A>
									<DT><A HREF="https://github.com/triton-lang/triton/tree/main/third_party/proton">triton/third_party/proton at main ¬∑ triton-lang/triton</A>
									<DT><A HREF="https://drive.google.com/file/d/1a1FxzP9jcu1EZL6w6J0izwBjiVtirlLf/view">proton-interpreter-tutorial.pdf - Google Drive</A>
									<DT><A HREF="https://github.com/Jokeren/triton-samples/blob/main/Triton_Tools_Tutorial.ipynb">triton-samples/Triton_Tools_Tutorial.ipynb at main ¬∑ Jokeren/triton-samples</A>
									<DT><A HREF="https://github.com/pytorch-labs/tritonbench/commit/87dffcc62bb45dee364a874f649b002f48939b5b">Add proton profiling (#102) ¬∑ pytorch-labs/tritonbench@87dffcc</A>
									<DT><A HREF="https://github.com/triton-lang/triton/tree/main/third_party/proton/dialect">triton/third_party/proton/dialect at main ¬∑ triton-lang/triton</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch-labs/tritonbench/blob/42da900e856473218e12f07e91ac176752ffa80a/tritonbench/utils/triton_op.py">tritonbench/tritonbench/utils/triton_op.py</A>
							</DL><p>
							<DT><H3 FOLDED>triton-jax</H3>
							<DL><p>
								<DT><A HREF="https://github.com/jax-ml/jax-triton">jax-ml/jax-triton: jax-triton contains integrations between JAX and OpenAI Triton</A>
							</DL><p>
							<DT><H3 FOLDED>triton-community-meetup</H3>
							<DL><p>
								<DT><H3 FOLDED>04-02-2024</H3>
								<DL><p>
									<DT><A HREF="https://drive.google.com/drive/folders/1bKpvz1NiBL_fHrGhMoZPvQfXCeetV2iY">March 2024 meetup - Google Drive</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/7c42f6bf02c2583f73eccefb351f17b61bed1dfb/docs/meetups/04-02-2024/notes.md?plain=1#L16">triton/docs/meetups/04-02-2024/notes.md at 7c42f6bf02c2583f73eccefb351f17b61bed1dfb ¬∑ triton-lang/triton</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=KZAzpKx1ebI">Triton October Community meetup 20231025 - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>triton-people</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-people-openai</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pawelszczerbuk">pawelszczerbuk</A>
									<DT><A HREF="https://github.com/peterbell10">Peter Bell (@peterbell10)</A>
									<DT><A HREF="https://github.com/ptillet">Phil Tillet (@ptillet)</A>
									<DT><A HREF="https://github.com/jeffniu-openai">Jeff Niu (@jeffniu-openai)</A>
									<DT><A HREF="https://github.com/ThomasRaoux">Thomas Raoux (@ThomasRaoux)</A>
								</DL><p>
								<DT><A HREF="https://github.com/manbearian">ian Bearman (MS)</A>
								<DT><A HREF="https://twitter.com/Si_Boehm">(1) Simon Boehm (@Si_Boehm) / X</A>
								<DT><A HREF="https://x.com/nadavrot">(Nadav Rotem: Engineering director at Facebook. Interested in systems, compilers, ML, performance, and other stuff</A>
								<DT><A HREF="https://chengzeyi.github.io/markdown-cv/">Cheng Zeyi's CV | CV</A>
								<DT><A HREF="https://github.com/zhyncs?tab=stars">zhyncs (Yineng Zhang) / Starred (FlagGems, FLASHNN)</A>
								<DT><A HREF="https://github.com/daadaada?tab=stars">daadaada (Da Yan) / Starred</A>
								<DT><A HREF="https://github.com/KnowingNothing?tab=repositories">KnowingNothing (KnowingNothing) ByteDance Matmul</A>
								<DT><A HREF="https://github.com/KuangjuX">KuangjuX (ChengXiang Qi)</A>
								<DT><A HREF="https://github.com/lambda7xx?tab=stars">lambda7xx (Xiao)</A>
								<DT><A HREF="https://github.com/MARD1NO">MARD1NO (ZZK) (giantPandaCV)</A>
								<DT><A HREF="https://github.com/BBuf">BBuf (Xiaoyu Zhang) GiantPandaCV</A>
								<DT><A HREF="https://scholar.google.com/citations?user=5qCK-R0AAAAJ&hl=zh-CN">‚Ä™Keren Zhou‚Ä¨ -(OpenAI)</A>
							</DL><p>
							<DT><H3 FOLDED>triton-debug</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-debug-perf</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/main_horse/status/1742013125090795531">NVIDIA non-industrial: triton.ops.matmul</A>
									<DT><A HREF="https://twitter.com/cis_female/status/1660386176761724928">do_bench</A>
									<DT><A HREF="https://gist.github.com/Chillee/41baf11aac8036d25d637321c48dad20">You Could Have Invented Flash-Attention!</A>
									<DT><A HREF="https://pytorch.org/blog/accelerating-llama3/">Accelerating Llama3 FP8 Inference with Triton Kernels | PyTorch</A>
								</DL><p>
								<DT><H3 FOLDED>triton-interpreter</H3>
								<DL><p>
									<DT><A HREF="https://drive.google.com/drive/folders/1bKpvz1NiBL_fHrGhMoZPvQfXCeetV2iY">Triton Interpreter Update</A>
									<DT><A HREF="https://triton-lang.org/main/programming-guide/chapter-3/debugging.html">Debugging Triton ‚Äî Triton documentation</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/c6ad34f7eb42630533412d93ca2cc00a4b4f8f3c/python/triton/runtime/interpreter.py#L694">triton/python/triton/runtime/interpreter.py at c6ad34f7eb42630533412d93ca2cc00a4b4f8f3c ¬∑ triton-lang/triton</A>
									<DT><A HREF="https://github.com/triton-lang/triton/blob/c6ad34f7eb42630533412d93ca2cc00a4b4f8f3c/python/triton/_internal_testing.py#L29">TRITON_INTERPRET</A>
								</DL><p>
								<DT><H3 FOLDED>triton-debug-sass</H3>
								<DL><p>
									<DT><A HREF="https://github.com/compiler-explorer/compiler-explorer/pull/5531">Add Triton language by siboehm ¬∑ Pull Request #5531 ¬∑ compiler-explorer/compiler-explorer</A>
									<DT><A HREF="https://twitter.com/Si_Boehm/status/1708233662305910785">(1) Simon Boehm en X: "I got Triton working on (local) Godbolt instances, including Python &amp;lt;-&amp;gt; SASS line correspondence. Pretty nifty. Still got some infra issues to figure out, meanwhile PR is here if anyone wants to try it: https://t.co/FPJjgOo3tl https://t.co/U2ie1evR9o" / X</A>
								</DL><p>
								<DT><H3 FOLDED>triton-viz</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Deep-Learning-Profiling-Tools/triton-viz">Deep-Learning-Profiling-Tools/triton-viz</A>
									<DT><A HREF="https://dl.acm.org/doi/pdf/10.1145/3641554.3701795">Triton-Viz: Visualizing GPU Programming in AI Courses</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/de17730a993b1d2cce4fd09e3654b5f79fd23c96/kernels/triton/inference/gptq/a100_qlinear.py#L8">applied-ai/kernels/triton/inference/gptq/a100_qlinear.py: IR, TTGIR, PTX, registers users</A>
								<DT><A HREF="https://github.com/openai/triton/issues/517#issuecomment-2028547176">How to debug kernels ¬∑ Issue #517 TRITON_INTERPRET=1</A>
								<DT><A HREF="https://github.com/openai/triton/blob/8e0c7b425ac149c43183de966ffa423fd46e4762/python/triton/testing.py#L441">triton/python/triton/testing.py (main)</A>
								<DT><A HREF="https://chat.openai.com/c/74ad9a19-e6f0-4ba3-a0d7-0d7a0b6c5c61">Performance Logging &amp; Saving Kernel ASM &amp; IR</A>
								<DT><A HREF="https://triton-lang.org/main/programming-guide/chapter-3/debugging.html">Debugging Triton ‚Äî Triton documentation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=NZz5sczZ_30&t=16s">Triton Conference 2024: Morning Session - YouTube</A>
								<DT><A HREF="https://github.com/msaroufim/openaitritontutorial/blob/master/Down%20the%20openai%20triton%20rabbit%20hole.ipynb">openaitritontutorial/Down the openai triton rabbit hole.ipynb at master</A>
							</DL><p>
							<DT><H3 FOLDED>triton-benchmark</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-tuning</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/0f75b907c6bf6273dbb813b9e983757dab20751f/benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton.py">sglang/benchmark/kernels/fused_moe_triton/tuning_fused_moe_triton.py: get_configs_compute_bound</A>
								</DL><p>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/main/benchmark/benchmark_flash_attn.py#L78">FLASHNN/benchmark/benchmark_flash_attn.py at main ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://github.com/timudk/flux_triton/blob/40ba90d35b97891ff92e3df53effc51b6e71c582/src/profiling/profile_triton_comparison.ipynb">flux_triton/src/profiling/profile_triton_comparison.ipynb</A>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/7efcb5e0ed6403f08965b999626c5807680b46ed/server/text_generation_server/layers/gptq/custom_autotune.py#L5">text-generation-inference/server/text_generation_server/layers/gptq/custom_autotune.py at 7efcb5e0ed6403f08965b999626c5807680b46ed ¬∑ huggingface/text-generation-inference</A>
								<DT><A HREF="https://github.com/linkedin/Liger-Kernel/issues/137">Benchmark against Flash attention repo ¬∑ Issue #137 ¬∑ linkedin/Liger-Kernel</A>
								<DT><A HREF="https://gist.github.com/cloneofsimo/af610ff8aa11a3f57956e7d7f578409c">FlashAttention comparison</A>
								<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/needs_perf_help/fp8_gemm_bench.py">applied-ai/kernels/needs_perf_help/fp8_gemm_bench.py at main ¬∑ pytorch-labs/applied-ai</A>
								<DT><A HREF="https://github.com/INT-FlashAttention2024/INT-FlashAttention/blob/main/benchmark.py">INT-FlashAttention/benchmark.py at main ¬∑ INT-FlashAttention2024/INT-FlashAttention</A>
								<DT><A HREF="https://github.com/pytorch-labs/applied-ai/blob/main/kernels/triton/inference/gptq/a100_qlinear.py">applied-ai/kernels/triton/inference/gptq/a100_qlinear.py: TTGIR, PTX</A>
								<DT><A HREF="https://github.com/lessw2020/triton_kernels_for_fun_and_profit/blob/main/h100/profile_kernels.py">triton_kernels_for_fun_and_profit/h100/profile_kernels.py at main ¬∑ lessw2020/triton_kernels_for_fun_and_profit</A>
							</DL><p>
							<DT><H3 FOLDED>triton-torch-inductor</H3>
							<DL><p>
								<DT><A HREF="https://github.com/pytorch/pytorch/pull/111434">[Inductor] Support user defined triton kernels in inductor</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ACR1WnRScCc">Composability Sync - User defined Triton vs custom ops / C++</A>
								<DT><A HREF="https://github.com/BobMcDear/attorch">BobMcDear/attorch: A subset of PyTorch's neural network modules, written in Python using OpenAI's Triton.</A>
								<DT><A HREF="https://pytorch.org/tutorials/recipes/torch_compile_user_defined_triton_kernel_tutorial.html">Using User-Defined Triton Kernels with torch.compile ‚Äî PyTorch Tutorials 2.3.0+cu121 documentation</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/issues/121367">`torch.compile` makes triton kernel slower in some cases ¬∑ Issue #121367 ¬∑ pytorch/pytorch</A>
							</DL><p>
							<DT><H3 FOLDED>triton-config</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/main/xformers/ops/_triton/tiled_matmul_kernels.py">xformers/xformers/ops/_triton/tiled_matmul_kernels.py gen_config</A>
								<DT><A HREF="https://github.com/IBM/triton-dejavu/tree/main">IBM/triton-dejavu: Framework to reduce autotune overhead to zero for well known deployments.</A>
								<DT><A HREF="https://github.com/pytorch/torchtitan/blob/main/torchtitan/experiments/kernels/triton_mg_group_gemm/torchao_pr/tma_autotuning.py#L146">torchtitan/torchtitan/experiments/kernels/triton_mg_group_gemm/torchao_pr/tma_autotuning.py at main ¬∑ pytorch/torchtitan</A>
							</DL><p>
							<DT><H3 FOLDED>triton-utils</H3>
							<DL><p>
								<DT><A HREF="https://github.com/gpu-mode/lectures/blob/main/lecture_014/triton_util.py">lectures/lecture_014/triton_util.py at main ¬∑ gpu-mode/lectures</A>
								<DT><A HREF="https://github.com/IBM/triton-dejavu">IBM/triton-dejavu: Framework to reduce autotune overhead to zero for well known deployments.</A>
								<DT><A HREF="https://github.com/UmerHA/triton_util">UmerHA/triton_util: Make triton easier</A>
							</DL><p>
							<DT><H3 FOLDED>triton-test</H3>
							<DL><p>
								<DT><A HREF="https://github.com/linkedin/Liger-Kernel/blob/63dd41b15e9f1c2957c817b771536d4ab7119322/test/transformers/test_rms_norm.py#L72">triton kernel correctness testing</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/test/srt/test_triton_attention_kernels.py">sglang/test/srt/test_triton_attention_kernels.py</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/test/test_activation.py">sglang/python/sglang/test/test_activation.py</A>
								<DT><A HREF="https://github.com/lancerts/Algo-ML-Kernels/blob/main/triton_load_from_uninitialized_data/test.py">Algo-ML-Kernels/triton_load_from_uninitialized_data/test.py at main ¬∑ lancerts/Algo-ML-Kernels</A>
								<DT><A HREF="https://github.com/INT-FlashAttention2024/INT-FlashAttention/blob/main/benchmark.py">INT-FlashAttention/benchmark.py at main ¬∑ INT-FlashAttention2024/INT-FlashAttention</A>
								<DT><A HREF="https://chat.deepseek.com/a/chat/s/dafccf53-9f22-4965-9fc4-a0478e5a0a4f">FP8 Attention Kernel Implementation Plan - DeepSeek</A>
							</DL><p>
							<DT><H3 FOLDED>triton-collective-communication</H3>
							<DL><p>
								<DT><H3 FOLDED>triton-distributed</H3>
								<DL><p>
									<DT><H3 FOLDED>bytedn-tileLink</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ByteDance-Seed/Triton-distributed">ByteDance-Seed/Triton-distributed: Distributed Triton for Parallel Systems</A>
										<DT><A HREF="https://arxiv.org/abs/2503.20313">[2503.20313] TileLink: Generating Efficient Compute-Communication Overlapping Kernels using Tile-Centric Primitives</A>
									</DL><p>
									<DT><H3 FOLDED>triton-distributed-megakernel</H3>
									<DL><p>
										<DT><H3 FOLDED>triton-distributed-megakernel-all2all</H3>
										<DL><p>
											<DT><A HREF="https://triton-distributed.readthedocs.io/en/latest/kernels/nvidia/ep_all2all_fused.html">Expert Parallelism All-to-All Fused Megakernel ‚Äî Triton-distributed documentation</A>
										</DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1938977221525110949">Triton-distributed MegaKernel initial test</A>
									</DL><p>
									<DT><A HREF="https://github.com/ByteDance-Seed/Triton-distributed">ByteDance-Seed/Triton-distributed: Distributed Triton for Parallel Systems</A>
									<DT><A HREF="https://github.com/KuangjuX/AttnLink">KuangjuX/AttnLink: :construction: An experimental communicating attention kernel based on DeepEP.</A>
									<DT><A HREF="https://www.linkedin.com/posts/hanshi-sun-5b74b8228_excited-to-announce-an-update-to-%F0%9D%97%A7%F0%9D%97%BF%F0%9D%97%B6%F0%9D%98%81-activity-7355701486208569344-MOPf/">tlink end2end dense language models eg. Qwen3-32B</A>
									<DT><A HREF="https://github.com/ByteDance-Seed/Triton-distributed/blob/bf06c5cf86c9c537b44202b4ba6bdf335f527496/python/triton_dist/models/qwen.py#L114">Triton-distributed/python/triton_dist/models/qwen.py at bf06c5cf86c9c537b44202b4ba6bdf335f527496 ¬∑ ByteDance-Seed/Triton-distributed</A>
									<DT><A HREF="https://github.com/KnowingNothing?tab=stars">KnowingNothing (ZCHNO) / Starred</A>
									<DT><A HREF="https://github.com/meta-pytorch/kraken?tab=readme-ov-file">meta-pytorch/kraken: Triton-based Symmetric Memory operators and examples</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1900910901017679250">Triton-distributed: Writing high-performance computing communication overlay kernels in Python</A>
								</DL><p>
								<DT><A HREF="https://github.com/yifuwang/symm-mem-recipes">yifuwang/symm-mem-recipes</A>
								<DT><A HREF="https://github.com/cchan/tccl">cchan/tccl: extensible collectives library in triton</A>
								<DT><A HREF="https://github.com/ppl-ai/pplx-kernels">ppl-ai/pplx-kernels: Perplexity GPU Kernels</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/pull/2913">tl.gather</A>
							</DL><p>
							<DT><H3 FOLDED>triton-quant</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>triton._C.libtriton</H3>
							<DL><p>
								<DT><A HREF="https://github.com/KnowingNothing/MatmulTutorial/blob/0f16757edc065603bb19e0457c34a451c5d7c042/examples/matmul/this-sm100/test_this_perf.py#L114">from triton._C.libtriton import nvidia; nvidia.cublas.CublasLt</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=yCyZEJrlrfY&t=126s">Lightning Talk: Harnessing NVIDIA Tensor Cores: An Exploration of CUTLASS &amp; OpenAI</A>
							<DT><A HREF="https://openai.com/research/triton">Introducing Triton: Open-source GPU programming for neural networks</A>
							<DT><A HREF="https://www.youtube.com/watch?v=GHQ1M3VDOmU&t=8s">Intro to Triton: A Parallel Programming Compiler and Language (esp for AI acceleration) - YouTube</A>
							<DT><A HREF="https://github.com/ptillet/triton-llvm-releases">ptillet/triton-llvm-releases</A>
							<DT><A HREF="https://pytorch.org/blog/accelerating-triton/?utm_content=278887799&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">Accelerating Triton Dequantization Kernels for GPTQ | PyTorch</A>
							<DT><A HREF="https://github.com/pytorch/pytorch/pull/111434">[Inductor] Support user defined triton kernels in inductor by oulgen ¬∑ Pull Request #111434 ¬∑ pytorch/pytorch</A>
							<DT><A HREF="https://github.com/kakaobrain/trident">kakaobrain/trident: A performance library for machine learning applications.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=yCyZEJrlrfY&t=126s">NVIDIA Tensor Cores: An Exploration of CUTLASS &amp; OpenAI</A>
							<DT><A HREF="https://www.youtube.com/watch?v=GHQ1M3VDOmU&t=8s">Intro to Triton: A Parallel Programming Compiler and Language</A>
							<DT><A HREF="https://github.com/kakaobrain/trident">kakaobrain/trident: A performance library for machine learning</A>
							<DT><A HREF="https://research.colfax-intl.com/nvidia-hopper-gemm-cutlass/">GEMM kernels Hopper</A>
							<DT><A HREF="https://github.com/srush/Triton-Puzzles">srush/Triton-Puzzles: Puzzles for learning Triton</A>
							<DT><A HREF="https://www.youtube.com/watch?v=GHQ1M3VDOmU&t=8s">Intro to Triton: A Parallel Programming Compiler and Language (esp for AI acceleration)</A>
							<DT><A HREF="https://www.jokeren.tech/slides/triton_next.pdf">Towards Agile Development of Efficient Deep Learning Operators</A>
							<DT><A HREF="https://github.com/gfvvz/Triton-Compiler">gfvvz/Triton-Compiler: Triton Compiler related materials.</A>
							<DT><A HREF="https://x.com/cHHillee/status/1558668469335248896">(1) Horace He en X: "Some addendums: I couldn't figure out a nice way to fit this into the tweet thread, but it would be remiss of me to not mention CUTLASS (https://t.co/7wkLAL18Qi). Just like Triton, CUTLASS is another way to write highly performant matmuls in a white-box manner." / X</A>
							<DT><A HREF="https://fkong.tech/posts/2023-04-23-triton-cuda/">Demystify OpenAI Triton ¬∑ fkong' tech blog</A>
							<DT><A HREF="https://www.youtube.com/watch?v=NZz5sczZ_30">Triton Conference 2024: Morning Session - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ONrKkI7KhU4">Triton Conference 2024: Afternoon Session - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>JAX</H3>
						<DL><p>
							<DT><H3 FOLDED>TPU</H3>
							<DL><p>
								<DT><H3 FOLDED>Systolic array</H3>
								<DL><p>
									<DT><A HREF="https://en.wikipedia.org/wiki/Systolic_array">Systolic array - Wikipedia</A>
									<DT><A HREF="https://ecelabs.njit.edu/ece459/lab3.php">ECE 459 - Systolic-Array Implementation of Matrix-By-Matrix Multiplication</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-architecture</H3>
								<DL><p>
									<DT><A HREF="https://dl.acm.org/doi/pdf/10.1145/3360307">Domain Specific Hardware for training Deep Neural Networks</A>
									<DT><A HREF="https://cloud.google.com/tpu/docs/system-architecture-tpu-vm">System architecture ¬†|¬† Cloud TPU ¬†|¬† Google Cloud</A>
									<DT><A HREF="https://arxiv.org/abs/2304.01433">[2304.01433] TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings</A>
									<DT><A HREF="https://cloud.google.com/blog/products/ai-machine-learning/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu">An in-depth look at Google‚Äôs first Tensor Processing Unit (TPU) | Google Cloud Blog</A>
									<DT><A HREF="https://docs.cloud.google.com/tpu/docs/v5p#system_architecture">TPU v5p ¬†|¬† Google Cloud Documentation</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-memory-model</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=NFKubflDb1A">Memory Model</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-learning</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ayaka14732/tpu-starter#72-parallelism">ayaka14732/tpu-starter: Everything you want to know about Google Cloud TPU</A>
									<DT><A HREF="https://jax-ml.github.io/scaling-book/tpus/">How to Think About TPUs | How To Scale Your Model</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-v7-Ironwood</H3>
								<DL><p>
									<DT><A HREF="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/">Ironwood: The first Google TPU for the age of inference</A>
									<DT><A HREF="https://x.com/itsclivetime/status/1910026068746289286">tpu-v7-ironwood vs NVIDIA GB200</A>
									<DT><A HREF="https://x.com/ProfTomYeh/status/2013333184964857881">(1) Tom Yeh en X: "Google Ironwood TPU Memory Hierarchy in 9 levels by hand ‚úçÔ∏è 1. Bit ‚Äì The most basic unit of information, the on‚Äìoff decision from which every number, tensor, and model state is ultimately constructed. 2. FP8 (1√ó8 ‚Üí 8 bits) ‚Äì Eight bits are grouped to form a floating-point https://t.co/Dvm5u7lqW2" / X</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-v6-trillium</H3>
								<DL><p>
									<DT><A HREF="https://cloud.google.com/blog/products/compute/introducing-trillium-6th-gen-tpus?hl=en">Introducing Trillium, sixth-generation TPUs | Google Cloud Blog</A>
								</DL><p>
								<DT><H3 FOLDED>coral</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=rArv2NUXGU8&t=588s">George Hotz | Programming | tinygrad: on the Google Coral Edge TPU | reverse engineering part2 - YouTube</A>
									<DT><A HREF="https://research.google/blog/coral-npu-a-full-stack-platform-for-edge-ai/?utm_source=twitter&utm_medium=social&utm_campaign=social_post&utm_content=gr-acct">Coral NPU: A full-stack platform for Edge AI</A>
									<DT><A HREF="https://developers.google.com/coral">Coral ¬†|¬† Google for Developers</A>
									<DT><A HREF="https://github.com/geohot/edgetpuxray">geohot/edgetpuxray: Enabling tinygrad compatibility with the Google Edge TPU</A>
									<DT><A HREF="https://github.com/google-coral/coralnpu?tab=readme-ov-file">google-coral/coralnpu: A machine learning accelerator core designed for energy-efficient AI at the edge.</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-smi</H3>
								<DL><p>
									<DT><A HREF="https://pypi.org/project/tpu-info/">tpu-info ¬∑ PyPI</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-simulator</H3>
								<DL><p>
									<DT><A HREF="https://github.com/jinhachung/tptpu-sim">jinhachung/tptpu-sim: A Toy-Purpose TPU Simulator</A>
									<DT><A HREF="https://github.com/cameronshinn/tiny-tpu">cameronshinn/tiny-tpu: Small-scale Tensor Processing Unit built on an FPGA</A>
									<DT><A HREF="https://github.com/eevaain/tiny-tpu">eevaain/tiny-tpu: A minimal Tensor Processing Unit (TPU) inspired by Google's TPUv1.</A>
								</DL><p>
								<DT><H3 FOLDED>tpu-topology</H3>
								<DL><p>
									<DT><A HREF="https://cloud.google.com/kubernetes-engine/docs/concepts/tpus#configuration">Mapping of TPU configuration</A>
									<DT><A HREF="https://cloud.google.com/tpu/docs/multislice-introduction">Cloud TPU Multislice Overview [Public Preview]</A>
								</DL><p>
								<DT><H3 FOLDED>tiny-tpu</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=kccs9xk09rw">Lecture 88: TinyTPU - YouTube</A>
									<DT><A HREF="https://chewingonchips.substack.com/p/1207-day-7">12/07: Day 7 üéÑ - by Alan Ma and Abiral Shakya</A>
									<DT><A HREF="https://github.com/Alanma23/tinytinyTPU">Alanma23/tinytinyTPU: a mini 2x2 systolic array and PE demo</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=oSCRZkSQ1CE&t=1529s">Jeff Dean (Google): Exciting Trends in Machine Learning</A>
								<DT><A HREF="https://cloud.google.com/blog/products/compute/inside-the-ironwood-tpu-codesigned-ai-stack?e=48754805?utm_source%3Dtwitter?utm_source=twitter&utm_medium=unpaidsoc&utm_campaign=fy25q4-googlecloudtech-blog-ai-in_feed-no-brand-global&utm_content=-&utm_term=-&linkId=17613360">Inside the Ironwood TPU codesigned AI stack | Google Cloud Blog</A>
								<DT><A HREF="https://x.com/zephyr_z9/status/1987241308713591026">(1) Zephyr en X: "Interesting Google is using: - Tektronix (part of Fortive) Oscilloscope for testing/debugging - Parker Hannifin multi-purpose hoses https://t.co/Zf0hg0HVDd" / X</A>
								<DT><A HREF="https://x.com/popovicu94/status/1992502116309729638">(1) Uros Popovic en X: "I worked at Google for quite a few years, including projects on the TPU chips. And I'm sharing the ultimate lesson learned: how to maximize iteration speed when you're building systems from scratch. I designed and built a tiny microcontroller core called Mrav (Serbian for https://t.co/FXkXhpAOUX" / X</A>
								<DT><A HREF="https://popovicu.com/posts/making-a-custom-cpu-mrav/">Making a custom CPU</A>
								<DT><A HREF="https://x.com/_xjdr/status/1997759168560918913">(1) xjdr en X: "I'm finally to the point where enough of the things I rely on are b200 + cuda + torch specific that I could not get the same results on TPUs with Jax. What an unexpected turn of events." / X</A>
								<DT><A HREF="https://github.com/yuyanpeng-google/diffusers">yuyanpeng-google/diffusers: ü§ó Diffusers: State-of-the-art diffusion models for image, video, and audio generation in PyTorch.</A>
							</DL><p>
							<DT><H3 FOLDED>XLA</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-xla-auto-sharding</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=L1PSUhGtZVc">Optimizing PyTorch Auto sharding For Your Hardware 2024 04 25 09 40 GMT 7 - YouTube</A>
									<DT><A HREF="https://pytorch.org/blog/pytorch-xla-spmd/">PyTorch/XLA SPMD: Scale Up Model Training and Serving with Automatic Parallelization | PyTorch</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-xla-2-3-dev-update/2124">PyTorch/XLA 2.3 dev update - compiler - PyTorch Developer Mailing List</A>
								</DL><p>
								<DT><H3 FOLDED>xla-videos</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=e85Ceq2g5z0&t=1s">(Day 1 - Breakout Session) StableHLO &amp; PJRT - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=5ilr4gcenaA">(Google) JAX:¬†Low-level control with shard_map and Pallas - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=NFKubflDb1A">(Day 1 - Breakout Session) JAX: Pallas and Shard Map - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=5i7xrBUCD38">OpenXLA Lightning Talks - April 27, 2023 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=zS7NTHYNiF4">OpenXLA Roadmap Presentations - April 27, 2023 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>xla-primitives-operations</H3>
								<DL><p>
									<DT><A HREF="https://openxla.org/xla/operation_semantics">Operation semantics ¬†|¬† OpenXLA Project</A>
								</DL><p>
								<DT><A HREF="https://patricktoulme.substack.com/p/from-jax-to-vliw-tracing-a-computation">From JAX to VLIW: Tracing a Computation Through the TPU Compiler Stack</A>
								<DT><A HREF="https://github.com/NVIDIA/JAX-Toolbox">NVIDIA/JAX-Toolbox: JAX-Toolbox</A>
								<DT><A HREF="https://blog.research.google/2024/01/mixed-input-matrix-multiplication.html">Mixed-input matrix multiplication performance optimizations ‚Äì Google Research Blog</A>
								<DT><A HREF="https://github.com/google/jax/pull/20462/">Add MegaBlox grouped matrix multiplication kernels for TPU. by copybara-service[bot] ¬∑ Pull Request #20462 ¬∑ google/jax</A>
								<DT><A HREF="https://cloud.google.com/blog/products/ai-machine-learning/introducing-pytorch-xla-2-3">Introducing PyTorch/XLA 2.3 | Google Cloud Blog</A>
								<DT><A HREF="https://github.com/pytorch/xla">pytorch/xla: Enabling PyTorch on XLA Devices (e.g. Google TPU)</A>
								<DT><A HREF="https://github.com/ezyang/xla-redist-ref">ezyang/xla-redist-ref: Extract redistribution plans from XLA</A>
								<DT><A HREF="https://www.modular.com/blog/democratizing-ai-compute-part-6-what-about-ai-compilers">Modular: What about TVM, XLA, and AI compilers? (Democratizing AI Compute, Part 6)</A>
								<DT><A HREF="https://x.com/PatrickToulme/status/2012618229219238204">TPU VLIW execution visualized</A>
								<DT><A HREF="https://patricktoulme.substack.com/p/when-xla-isnt-enough-from-pallas?utm_medium=web">When XLA Isn't Enough: From Pallas to VLIW with Splash Attention on TPU</A>
							</DL><p>
							<DT><H3 FOLDED>tpu-smi</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>jax-lectures</H3>
							<DL><p>
								<DT><A HREF="https://afmck.in/posts/2023-05-22-jax-post/">On Learning JAX</A>
							</DL><p>
							<DT><H3 FOLDED>jax-examples</H3>
							<DL><p>
								<DT><A HREF="https://github.com/yixiaoer/tpu-training-example">yixiaoer/tpu-training-example</A>
							</DL><p>
							<DT><H3 FOLDED>jax-profilling</H3>
							<DL><p>
								<DT><A HREF="https://jax.readthedocs.io/en/latest/profiling.html">profiling Jax programs</A>
								<DT><A HREF="https://github.com/ayaka14732/jax-smi">ayaka14732/jax-smi: JAX Synergistic Memory Inspector</A>
							</DL><p>
							<DT><H3 FOLDED>jax-internals</H3>
							<DL><p>
								<DT><H3 FOLDED>pjit</H3>
								<DL><p>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/jax-101/08-pjit.html?ref=blog.salesforceairesearch.com">Introduction to pjit ‚Äî JAX documentation</A>
									<DT><A HREF="https://github.com/ayaka14732/einshard?tab=readme-ov-file">ayaka14732/einshard: High-level array sharding API for JAX</A>
									<DT><A HREF="https://irhum.github.io/blog/pjit/">irhum.github.io - Tensor Parallelism with jax.pjit</A>
								</DL><p>
								<DT><H3 FOLDED>jax-grad</H3>
								<DL><p>
									<DT><A HREF="https://docs.jax.dev/en/latest/autodidax2_part1.html">Autodidax2, part 1: JAX from scratch, again ‚Äî JAX documentation</A>
								</DL><p>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/jax-stuff/">Programming TPUs in JAX | How To Scale Your Model</A>
							</DL><p>
							<DT><H3 FOLDED>Pallas</H3>
							<DL><p>
								<DT><H3 FOLDED>pallas-people</H3>
								<DL><p>
									<DT><A HREF="https://sharadvikram.com/">Sharad Vikram</A>
									<DT><A HREF="https://github.com/sharadmv">sharadmv (Sharad Vikram)</A>
									<DT><A HREF="https://x.com/apaszke/status/1812897008031617493">(1) Adam Paszke en X: "Many of you are excited about H100 attention, so it‚Äôs a good time to show you Mosaic GPU: a Python DSL for H100s. The attention example matches FA3 performance, while being only ~200 lines of Python: https://t.co/12ecz3LftV It's easy to install too! Latest JAX packages have it." / X</A>
								</DL><p>
								<DT><H3 FOLDED>pallas-learning</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=NFKubflDb1A">(Day 1 - Breakout Session) JAX: Pallas and Shard Map - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=OR8NZyTz-yo&t=5s">Pallas A JAX Kernel Language 3 2 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=liKrhX2gm44&t=3198s">High Performance LLMs in Jax 2024 -- Session 10 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>mosaic</H3>
								<DL><p>
									<DT><H3 FOLDED>mosaic-blackwell</H3>
									<DL><p>
										<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/reference.html">Writing Mosaic GPU kernels with Pallas ‚Äî JAX documentation</A>
									</DL><p>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1812897008031617493">Mosaic GPU: A Python DSL for H100</A>
									<DT><A HREF="https://www.youtube.com/watch?v=liKrhX2gm44">High Performance LLMs in Jax 2024 -- Session 10 - YouTube</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/reference.html">Writing Mosaic GPU kernels with Pallas ‚Äî JAX documentation</A>
									<DT><A HREF="https://arxiv.org/abs/2503.20481">[2503.20481] Analyzing Modern NVIDIA GPU cores</A>
									<DT><A HREF="https://x.com/apaszke/status/1812897008031617493">(1) Adam Paszke en X: "Many of you are excited about H100 attention, so it‚Äôs a good time to show you Mosaic GPU: a Python DSL for H100s. The attention example matches FA3 performance, while being only ~200 lines of Python: https://t.co/12ecz3LftV It's easy to install too! Latest JAX packages have it." / X</A>
									<DT><A HREF="https://github.com/jax-ml/jax/blob/main/jax/experimental/mosaic/gpu/examples/flash_attention.py#L146-L354">jax/jax/experimental/mosaic/gpu/examples/flash_attention.py at main ¬∑ jax-ml/jax</A>
									<DT><A HREF="https://www.youtube.com/watch?v=NFKubflDb1A">(Day 1 - Breakout Session) JAX: Pallas and Shard Map - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>pallas-memory-model</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=NFKubflDb1A">TPU Memory Model</A>
								</DL><p>
								<DT><H3 FOLDED>pallas-matmul</H3>
								<DL><p>
									<DT><H3 FOLDED>jax-triton</H3>
									<DL><p>
										<DT><A HREF="https://github.com/jax-ml/jax-triton">jax-ml/jax-triton: integrations between JAX and OpenAI Triton</A>
									</DL><p>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/pallas/tpu/matmul.html">Matrix Multiplication ‚Äî JAX documentation</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/blackwell_matmul.html">Writing high-performance matrix multiplication kernels for Blackwell ‚Äî JAX documentation</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/collective_matmul.html">Collective matrix multiplication ‚Äî JAX documentation</A>
								</DL><p>
								<DT><H3 FOLDED>pallas-blackwell</H3>
								<DL><p>
									<DT><A HREF="https://docs.jax.dev/en/latest/pallas/gpu/blackwell_matmul.html">Writing high-performance matrix multiplication kernels for Blackwell ‚Äî JAX documentation</A>
									<DT><A HREF="https://github.com/jax-ml/jax/blob/main/tests/pallas/mgpu_examples_test.py">jax/tests/pallas/mgpu_examples_test.py at main ¬∑ jax-ml/jax</A>
								</DL><p>
								<DT><A HREF="https://github.com/google/jax/pull/17328">feat(pallas): Optimize Pallas Attention + Benchmark by jon-chuang ¬∑ Pull Request #17328 ¬∑ google/jax</A>
								<DT><A HREF="https://jax.readthedocs.io/en/latest/_images/pallas_flow.png">pallas_flow.png 908√ó832 pixels</A>
								<DT><A HREF="https://bnikolic.co.uk/blog/python/jax/2020/10/20/jax-outputgraph.html">Jax: Visualising the computational graph of a jax program | B. Nikolic Software and Computing Blog</A>
								<DT><A HREF="https://jax.readthedocs.io/en/latest/pallas/design.html">Pallas Design ‚Äî JAX documentation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=5ilr4gcenaA">(Google) JAX:¬†Low-level control with shard_map and Pallas - YouTube</A>
								<DT><A HREF="https://github.com/google/jax/pull/20462/">Add MegaBlox grouped matrix multiplication kernels for TPU. by copybara-service[bot] ¬∑ Pull Request #20462 ¬∑ google/jax</A>
								<DT><A HREF="https://github.com/LaurentMazare/jax-flash-attn3">LaurentMazare/jax-flash-attn3: JAX bindings for the flash-attention3 kernels</A>
								<DT><A HREF="https://x.com/sharadvikram/status/1822032380657594836">(1) Sharad Vikram en X: "We now have a guide to writing distributed communication on TPU using Pallas, written by @JustinFu769512! https://t.co/9TcqNizGV4 Overlapping comms + compute is a crucial performance optimization for large scale ML. Write your own custom overlapped kernels in Python! https://t.co/DABMQkI1Q5" / X</A>
								<DT><A HREF="https://jax.readthedocs.io/en/latest/pallas/tpu/distributed.html">Distributed Computing in Pallas for TPUs ‚Äî JAX documentation</A>
								<DT><A HREF="https://docs.jax.dev/en/latest/pallas/tpu/index.html">Pallas TPU ‚Äî JAX documentation</A>
								<DT><A HREF="https://henryhmko.github.io/posts/nsa_tpu/nsa_tpu.html">Optimizing NSA for TPUs - Kernel Worklog</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/bef180f00978186fcc84f7ca6328a6ae6c39676d/vllm/v1/attention/backends/pallas.py#L123">vllm/vllm/v1/attention/backends/pallas.py at bef180f00978186fcc84f7ca6328a6ae6c39676d ¬∑ vllm-project/vllm</A>
								<DT><A HREF="https://patricktoulme.substack.com/p/when-xla-isnt-enough-from-pallas?utm_medium=web">When XLA Isn't Enough: From Pallas to VLIW with Splash Attention on TPU</A>
							</DL><p>
							<DT><H3 FOLDED>jax-distributed</H3>
							<DL><p>
								<DT><H3 FOLDED>shard_map</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=5ilr4gcenaA">(Google) JAX:¬†Low-level control with shard_map and Pallas - YouTube</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/notebooks/shard_map.html">Manual parallelism with shard_map ‚Äî JAX documentation</A>
									<DT><A HREF="https://docs.jax.dev/en/latest/jep/14273-shard-map.html">shmap (shard_map) for simple per-device code ‚Äî JAX documentation</A>
								</DL><p>
								<DT><A HREF="https://www.linkedin.com/feed/">jax distributed lowering</A>
								<DT><A HREF="https://jax-ml.github.io/scaling-book/jax-stuff/">Programming TPUs in JAX | How To Scale Your Model</A>
							</DL><p>
							<DT><H3 FOLDED>jax-transformer</H3>
							<DL><p>
								<DT><A HREF="https://github.com/joschu/jax-exp/blob/master/jax_transformer.py#L96">John Schulman: jax-exp/jax_transformer.py at master</A>
								<DT><A HREF="https://github.com/xjdr-alt/simple_transformer/blob/main/simple_transformer.py">simple_transformer/simple_transformer.py at main ¬∑ xjdr-alt/simple_transformer</A>
								<DT><A HREF="https://github.com/awf/functional-transformer">functional-transformer: A pure-functional implementation of a machine learning transformer model in Python/JAX</A>
								<DT><A HREF="https://github.com/google-research/t5x">google-research/t5x</A>
								<DT><A HREF="https://twitter.com/LiamFedus/status/1536791574612303872">Switch Transformer models in T5X/JAX (1.6T param)</A>
								<DT><A HREF="https://github.com/yixiaoer/mistral-v0.2-jax">yixiaoer/mistral-v0.2-jax: JAX implementation of the Mistral 7b v0.2 model</A>
								<DT><A HREF="https://github.com/google-deepmind/nanodo/tree/main">google-deepmind/nanodo</A>
							</DL><p>
							<DT><H3 FOLDED>jax-graphs</H3>
							<DL><p>
								<DT><A HREF="https://github.com/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb">educational/intro_to_graph_nets_tutorial_with_jraph.ipynb at master ¬∑ deepmind/educational</A>
								<DT><A HREF="https://github.com/deepmind/jraph">deepmind/jraph: A Graph Neural Network Library in Jax</A>
							</DL><p>
							<DT><H3 FOLDED>jax-torch</H3>
							<DL><p>
								<DT><A HREF="https://sjmielke.com/jax-purify.htm">From PyTorch to JAX: towards neural net frameworks that purify stateful code</A>
								<DT><A HREF="https://sjmielke.com/jax-purify.htm">From PyTorch to JAX</A>
								<DT><A HREF="https://github.com/pytorch/xla/issues/9684">RFC: Evolving PyTorch/XLA for a more native experience on TPU ¬∑ Issue #9684 ¬∑ pytorch/xla</A>
							</DL><p>
							<DT><H3 FOLDED>jax-lax</H3>
							<DL><p>
								<DT><H3 FOLDED>jax-lax-scan</H3>
								<DL><p>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.scan.html">jax.lax.scan ‚Äî JAX documentation</A>
								</DL><p>
								<DT><H3 FOLDED>jax-algorithms</H3>
								<DL><p>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/jax.lax.html">jax.lax module ‚Äî JAX documentation</A>
									<DT><A HREF="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.iota.html">jax.lax.iota ‚Äî JAX documentation</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>jax.named_scope</H3>
							<DL><p>
								<DT><A HREF="https://github.com/jax-ml/jax/issues/7029">How to use `named_call` in jitted functions ¬∑ Issue #7029 ¬∑ jax-ml/jax</A>
							</DL><p>
							<DT><H3 FOLDED>jax-language-models</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ayaka14732/llama-2-jax">ayaka14732/llama-2-jax: JAX implementation of the Llama 2 model</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=e85Ceq2g5z0&t=1s">(Day 1 - Breakout Session) StableHLO &amp; PJRT - YouTube</A>
							<DT><A HREF="https://github.com/jax-ml/jax-triton">jax-ml/jax-triton: jax-triton contains integrations between JAX and OpenAI Triton</A>
							<DT><A HREF="https://github.com/n2cholas/awesome-jax">n2cholas/awesome-jax: JAX - A curated list of resources</A>
							<DT><A HREF="https://github.com/skye/gpu_jaxlib_docker_image">skye/gpu_jaxlib_docker_image</A>
							<DT><A HREF="https://github.com/NVIDIA/JAX-Toolbox">NVIDIA/JAX-Toolbox: JAX-Toolbox</A>
							<DT><A HREF="https://www.youtube.com/watch?v=NlQ1N3W3Wms&t=40s">JAX.lax.scan tutorial (for autoregressive rollout) - YouTube</A>
							<DT><A HREF="https://jax.readthedocs.io/en/latest/autodidax.html">Autodidax: JAX core from scratch ‚Äî JAX documentation</A>
							<DT><A HREF="https://research.google/pubs/pub46196/">A Computational Model for TensorFlow (An Introduction)</A>
							<DT><A HREF="https://github.com/google/jax/blob/967c38d53d632be713cde1f4caadb3e388b51f37/jax/_src/nn/functions.py#L559">jax/jax/_src/nn/functions.py OPS</A>
							<DT><A HREF="https://x.com/_xjdr/status/1801063628298412239">Megablox, splash attention, pallas and automatically sharded named axis come free and built in with Jax and y'all are still using pytorch in production?!?!" / X</A>
							<DT><A HREF="https://jax.readthedocs.io/en/latest/autodidax.html#part-2-jaxprs">Autodidax: JAX core from scratch ‚Äî JAX documentation</A>
							<DT><A HREF="https://github.com/zhuzilin/aqt-pytorch/blob/main/aqt/int8_linear.py">aqt-pytorch/aqt/int8_linear.py at main ¬∑ zhuzilin/aqt-pytorch</A>
							<DT><A HREF="https://x.com/_xjdr/status/1839391307648884834/photo/1">efficient TPU code</A>
							<DT><A HREF="https://mlsys.org/Conferences/2019/doc/2018/146.pdf">Compiling machine learning programs via high-level tracing</A>
						</DL><p>
						<DT><H3 FOLDED>MLIR</H3>
						<DL><p>
							<DT><H3 FOLDED>StableHLO</H3>
							<DL><p>
								<DT><A HREF="https://github.com/openxla/stablehlo/blob/main/docs/spec.md">stablehlo/docs/spec.md at main ¬∑ openxla/stablehlo</A>
							</DL><p>
							<DT><H3 FOLDED>NVGPU Dialect</H3>
							<DL><p>
								<DT><A HREF="https://grypp.github.io/papers/nvdsl.pdf">Programming
Nvidia Hopper with MLIR‚Äôs NVGPU Dialect</A>
							</DL><p>
							<DT><A HREF="https://mlir.llvm.org/docs/LangRef/">MLIR Language Reference - MLIR</A>
							<DT><A HREF="https://www.youtube.com/watch?v=LPlRLt9w4b0">2023 EuroLLVM - What's new in MLIR? - YouTube</A>
							<DT><A HREF="https://github.com/openxla/iree">openxla/iree: A retargetable MLIR-based machine learning compiler and runtime toolkit.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=SEwTjZvy8vw">Mojo: A system programming language for heterogenous computing</A>
							<DT><A HREF="https://github.com/iree-org/iree-experimental">iree-org/iree-experimental: Experiments and prototypes associated with IREE or MLIR</A>
							<DT><A HREF="http://hy3na.com/posts/compilers.html">Towards high-performance AI compilers.</A>
							<DT><A HREF="https://github.com/makslevental/mlir-python-extras">makslevental/mlir-python-extras: The missing pieces (as far as boilerplate reduction goes) of the upstream MLIR python bindings.</A>
						</DL><p>
						<DT><H3 FOLDED>AITemplate</H3>
						<DL><p>
							<DT><A HREF="https://github.com/facebookincubator/AITemplate/blob/992e1a08e363f0d301bc269ca092f6d999abcca8/tests/unittest/ops/test_gemm_bias.py#L39">AITemplate/tests/unittest/ops/test_gemm_bias.py</A>
							<DT><A HREF="https://facebookincubator.github.io/AITemplate/tutorial/how_to_infer_pt.html">AIT module is a container to build a graph, while PyTorch module is a container to store parameters for eager</A>
							<DT><A HREF="https://facebookincubator.github.io/AITemplate/tutorial/how_to_visualize.html">How to visualize an AIT model ‚Äî AITemplate 0.2 documentation</A>
							<DT><A HREF="https://github.com/facebookincubator/AITemplate">facebookincubator/AITemplate: AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference.</A>
						</DL><p>
						<DT><H3 FOLDED>DeepSpeed</H3>
						<DL><p>
							<DT><H3 FOLDED>deepspeed-kernels</H3>
							<DL><p>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/csrc/transformer/inference/csrc/gelu.cu#L656">DeepSpeed/csrc/transformer/inference/csrc/gelu.cu at master ¬∑ microsoft/DeepSpeed</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>Tinygrad</H3>
						<DL><p>
							<DT><H3 FOLDED>tinygrad-examples</H3>
							<DL><p>
								<DT><H3 FOLDED>tiny-VLIW</H3>
								<DL><p>
									<DT><A HREF="https://x.com/earth_ish/status/2015528742366666882">(1) Prithvish en X: "final trace for all who care, still room from improvement tbh https://t.co/WRIhYcKbfr" / X</A>
									<DT><A HREF="https://x.com/earth_ish/status/2015710738866991546">(1) Prithvish en X: "@RVCA211 @__tinygrad__ tinygrad is an ML framework but it's really a tensor compiler with a clean IR (UOps) and a PatternMatcher system for transformations. For this challenge you need to compile tree traversal to a fictional VLIW machine in minimal cycles. I used tinygrad's PatternMatcher to lower" / X</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/pull/14332">anthropic_challenge: VLIW backend achieving 1258 cycles by d4mr ¬∑ Pull Request #14332 ¬∑ tinygrad/tinygrad</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/b2e2ace85b0f1861c4cb0cd5f8651e72bccb24a1/examples/anthropic_challenge.py#L80">tinygrad/examples/anthropic_challenge.py</A>
								</DL><p>
								<DT><A HREF="https://x.com/cjpgverrier/status/2009707975506825475">(1) Cl√©ment Verrier en X: "Today, let's dive into some GPU memory bandwidth and computational throughput basics using @__tinygrad__ : https://t.co/jUStxmXBrc Later, I'll also add more details about how data gets cached on the GPU, which is crucial to avoid slow memory round-trips" / X</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-frontends</H3>
							<DL><p>
								<DT><H3 FOLDED>tinygrad-torch</H3>
								<DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1981205882936684823">(1) the tiny corp en X: "tinygrad's PyTorch frontend broke during the ShapeTracker removal. $300 bounty to fix it! Our ONNX frontend is very good, but the PyTorch one needs love. https://t.co/Z7YNkGviVg" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8">import extra.torch_backend.backend custom</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-backends</H3>
							<DL><p>
								<DT><H3 FOLDED>tinygrad-backends-triton</H3>
								<DL><p>
									<DT><A HREF="https://github.com/geohot/tinygrad/pull/470">A Triton backend for tinygrad by geohot</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-backends-llvm</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=bMdzsQuQxKs">George Hotz | Programming | tinygrad: LLVM backend</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-backends-hip</H3>
								<DL><p>
									<DT><A HREF="https://github.com/geohot/tinygrad/pull/750">HIP backend by nanamiwang ¬∑ Pull Request #750 ¬∑ geohot/tinygrad</A>
									<DT><A HREF="https://x.com/__tinygrad__/status/1979519693934465410">(1) the tiny corp en X: "Playing with my AMD Hawk Point NPU, the docs/examples are quite good! You might already have one of these in your computer. It feels very @tenstorrent https://t.co/axVNWN9lG6" / X</A>
								</DL><p>
								<DT><H3 FOLDED>tiny-verilog</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?app=desktop&si=pyQWaTtRNrqgJGLE&v=t7JQ24hywXo&feature=youtu.be">Finishing the layer mechanism for tinygrad-verilog - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-backends-llm.c</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/karpathy/status/1783527854741114981">Andrej Karpathy: 1) write a better compiler 2) write a better assembly-level program</A>
									<DT><A HREF="https://gist.github.com/geohot/7c9f10f5770f058a1de6ef0598e4c9d8">Outputted llm.c from tinygrad</A>
								</DL><p>
								<DT><A HREF="https://gemini.google.com/app/ba25862900744324">Gemini</A>
								<DT><A HREF="https://gist.github.com/fxkamd/ffd02d66a2863e444ec208ea4f3adc48">Observations about HSA and KFD backends in TinyGrad</A>
								<DT><A HREF="https://github.com/mesozoic-egg/tinygrad-notes/blob/main/backends.md">tinygrad-notes/backends.md at main ¬∑ mesozoic-egg/tinygrad-notes</A>
								<DT><A HREF="https://mesozoic-egg.github.io/tinygrad-notes/backends.html">Kernel Fusion: the backends | tinygrad-notes</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-people</H3>
							<DL><p>
								<DT><A HREF="https://github.com/Qazalin?tab=repositories">Qazalin (Qazalin) / Repositories</A>
								<DT><A HREF="https://github.com/flammit">flammit (Francis Lam): fast Torch kernels extraction</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-docs</H3>
							<DL><p>
								<DT><A HREF="https://mesozoic-egg.github.io/tinygrad-notes/">Tutorials on Tinygrad | tinygrad-notes</A>
								<DT><A HREF="https://www.youtube.com/watch?v=I_c9cdNAkH4&t=3146s">George Hotz (52:00) | Tinygrad layers of abstraction, Triton</A>
								<DT><A HREF="https://www.youtube.com/watch?v=fq__NqceKVs">George Hotz explains tinygrad's approach to winning at deep learning - YouTube</A>
								<DT><A HREF="https://mesozoic-egg.github.io/tinygrad-notes/shapetracker.html">How ShapeTracker works | tinygrad-notes</A>
								<DT><A HREF="https://docs.tinygrad.org/">tinygrad documentation - tinygrad docs</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/docs/tinygrad_intro.pdf">tinygrad/docs/tinygrad_intro.pdf at master ¬∑ tinygrad/tinygrad</A>
								<DT><A HREF="https://x.com/i/broadcasts/1mrGmBZEnZgJy">Puffer tries Tinygrad w/ Joseph Suarez / X</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-compiler</H3>
							<DL><p>
								<DT><H3 FOLDED>tinygrad/opt</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/cc3c1e4c1456dddc2beb469154d4d1f3e34b5efa/tinygrad/opt/search.py#L142">tinygrad/tinygrad/opt/search.py beam_search</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-uop</H3>
								<DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1951428489305084229">(1) the tiny corp en X: "Working on a big refactor now. We've built a minimal language (UOp) to express all neural networks and kernels in. Onward to optimization the likes of which haven't been seen in any major framework to date, enabled by the language simplicity (triangle from Halide PhD) https://t.co/aPm9Z1L31z" / X</A>
									<DT><A HREF="https://www.youtube.com/watch?v=4zwFDrsLm64">George Hotz | Programming | coding in UOps on AMD MI350X tickets.comma-con.com/events/comma/1859964 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-scheduler</H3>
								<DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1967446896081076517">tinygrad's new scheduler</A>
								</DL><p>
								<DT><A HREF="https://x.com/__tinygrad__/status/1944098747819995157">tinygrad description of a tensor core of all major gpus</A>
								<DT><A HREF="https://x.com/__tinygrad__/status/1957654494277431805">the tiny corp en X: "It's good because it's like the 5th time we rewrote it. https://t.co/9qTcWmJFiL" / X</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-kernels</H3>
							<DL><p>
								<DT><H3 FOLDED>tinygrad-hand-optimization</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/c4fdb9c725924fd1bc8a89ca07a1f405953b4d54/examples/handcode_resnet50_opt.py">tinygrad/examples/handcode_resnet50_opt.py</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-kernel-fusion</H3>
								<DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1910574691284300167">fuse() is now supported on Tensors. Automatic fusing puts one reduce in a kernel</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-flash-attention</H3>
								<DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1951787464252911884">TestFuse.test_flash_attention</A>
									<DT><A HREF="https://x.com/EitanTurok/status/1952105697119740105">I annotated the tinygrad flash attention kernel to make sure I understand it.</A>
									<DT><A HREF="https://excalidraw.com/">disecting tinygrad automatic kernels</A>
								</DL><p>
								<DT><H3 FOLDED>tinygrad-profiling</H3>
								<DL><p>
									<DT><H3 FOLDED>tinygrad-kernels-visualization</H3>
									<DL><p>
										<DT><A HREF="https://x.com/__tinygrad__/status/2016133945814024598">(1) the tiny corp en X: "WMMA has 32 cycles of latency and a queue depth of 8. Have you ever seen a GPU visualized like this before? https://t.co/OCs1DOU8os" / X</A>
									</DL><p>
									<DT><A HREF="https://x.com/__tinygrad__/status/1951745624850022878/photo/1">WMMA tinygrad profiler visualization</A>
									<DT><A HREF="https://x.com/__tinygrad__/status/1951137664243212401">(1) the tiny corp en X: "tinygrad's profiler is getting very good. Just run with VIZ=1 and click Profiler in the top left. Here's three steps of Llama training on MI350X https://t.co/Td36TwaQ98" / X</A>
								</DL><p>
								<DT><A HREF="https://x.com/__tinygrad__/status/1939922549850185772">autogenerated basic flash attention (halide)</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-pattern-matcher</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cverrier/tinygrad-tutos/blob/main/tutos/pattern_matcher.md">tinygrad-tutos/tutos/pattern_matcher.md at main ¬∑ cverrier/tinygrad-tutos</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-checkpointing</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=2QO3vzwHXhg&t=3551s">converting to float16 slowing down</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-lectures</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=Gm0t-kAsHuY">George Hotz | Programming | making tinygrad CLOUD=1 fast (even from Hong Kong!) | Good Vibes :) - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-asic</H3>
							<DL><p>
								<DT><A HREF="https://x.com/__tinygrad__/status/1924608870498107707">(1) the tiny corp en X: "This is a @comma_ai 3X with more compute power than a HW4 Tesla. It's a 9070XT + ADT-UT3G dock connected to the USB port. Those are FP16 GEMM FLOPS, should be 389 TOPS of int8. Not a tech demo, shipping to openpilot soon. Excited to see how people mount a GPU in their car. https://t.co/SBX6fm5mFV" / X</A>
							</DL><p>
							<DT><H3 FOLDED>tinygrad-inference</H3>
							<DL><p>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/tinygrad/apps/llm.py">tinygrad/tinygrad/apps/llm.py: llama 3 end2end inference code</A>
							</DL><p>
							<DT><H3 FOLDED>ShapeTracker</H3>
							<DL><p>
								<DT><A HREF="https://mesozoic-egg.github.io/tinygrad-notes/shapetracker.html">How ShapeTracker works | tinygrad-notes</A>
								<DT><A HREF="https://x.com/__tinygrad__/status/1964037572503752910">(1) the tiny corp en X: "It's been kind of quiet on the tinygrad front, and here's why. In retrospect, ShapeTracker was a huge mistake. And now we are paying with months of refactors. But there's a good path forward, and ShapeTracker/View will be completely deleted. The problem: ShapeTracker doesn't" / X</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/pull/12720">delete the ShapeTracker by geohot ¬∑ Pull Request #12720 ¬∑ tinygrad/tinygrad</A>
							</DL><p>
							<DT><H3 FOLDED>babygrad</H3>
							<DL><p>
								<DT><A HREF="https://github.com/geohot/babygrad">geohot/babygrad: One File Tensor Libraries</A>
								<DT><A HREF="https://github.com/geohot/babygrad/blob/master/lib.py">babygrad/lib.py at master ¬∑ geohot/babygrad</A>
							</DL><p>
							<DT><A HREF="https://docs.google.com/document/d/1q0VulPvi1awazH4EAsScXw3kqWHM-GAbBGY6IQzSV70/edit">tiny corp master plan - Google Docs</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/tinygrad/tensor.py">tinygrad/tinygrad/tensor.py at master ¬∑ tinygrad/tinygrad</A>
							<DT><A HREF="https://github.com/tinygrad/gpuctypes">tinygrad/gpuctypes: ctypes wrappers for HIP, CUDA, and OpenCL</A>
							<DT><A HREF="https://github.com/geohot/ctypeslib">geohot/ctypeslib: Generate python ctypes classes from C headers. Requires LLVM clang</A>
							<DT><A HREF="https://github.com/tinygrad/teenygrad">tinygrad/teenygrad: If tinygrad wasn't small enough for you...</A>
							<DT><A HREF="https://twitter.com/__tinygrad__/status/1729596377028567137">Tinybox FP16 TFLOPs JAX</A>
							<DT><A HREF="https://www.youtube.com/watch?v=-iH5wvFnsKs">George Hotz | Programming | ripping out all of AMD's userspace, AMDGPU ioctls | GPU memory | HSA KFD - YouTube</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/examples/compile_efficientnet.py">tinygrad/examples/compile_efficientnet.py C codegen</A>
							<DT><A HREF="https://github.com/karpathy/llm.c">karpathy/llm.c: LLM training in simple, raw C/CUDA</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/discussions/3342">Do we have a Model Summary Feature in Tinygrad? ¬∑ tinygrad/tinygrad ¬∑ Discussion #3342</A>
							<DT><A HREF="https://developer.nvidia.com/blog/boosting-dynamic-programming-performance-using-nvidia-hopper-gpu-dpx-instructions/">Boosting Dynamic Programming Performance Using NVIDIA Hopper GPU DPX Instructions | NVIDIA Technical Blog</A>
							<DT><A HREF="https://mesozoic-egg.github.io/tinygrad-notes/">Tutorials on Tinygrad | tinygrad-notes</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/examples/llm.c/train_gpt2.py">tinygrad/examples/llm.c/train_gpt2.py</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/de832d26c64a9ec575e47aeb58efe27a0ccf4e0b/autogen_stubs.sh">tinygrad/autogen_stubs.sh (runtime.autogen) clang2py</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Sk35MKtCXfQ&t=4743s">matrix multiplication, a@b, cube</A>
							<DT><A HREF="https://x.com/__tinygrad__/status/1742365883048284421">(1) the tiny corp en X: "tinygrad's multiGPU tensor sharding is merged. experimental, but is that not the simplest API you have ever seen for data/model parallel? (hint: it's just what axis you shard) https://t.co/HDqtRVAHUy" / X</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/docs/tinygrad_intro.pdf">tinygrad/docs/tinygrad_intro.pdf at master ¬∑ tinygrad/tinygrad</A>
							<DT><A HREF="https://github.com/geohot/cuda_ioctl_sniffer">geohot/cuda_ioctl_sniffer: Sniff CUDA ioctls</A>
							<DT><A HREF="https://github.com/tinygrad/toonygrad">tinygrad/toonygrad: Because tinygrad got out of hand with line count</A>
							<DT><A HREF="https://www.youtube.com/watch?v=h0jT60MBsvc">George Hotz | Programming | toonygrad! a rewrite of the tinygrad middleware (1/n) | Hong Kong - YouTube</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/397a2e6eb6cff0d956b22c46f63e109694695391/test/test_speed_v_torch.py#L4">tinygrad/test/test_speed_v_torch.py</A>
							<DT><A HREF="https://x.com/__tinygrad__/status/1910574691284300167?s=12">tinygrad fusion. Automatic fusing puts one reduce in a kernel</A>
							<DT><A HREF="https://dev-discuss.pytorch.org/t/where-do-the-2000-pytorch-operators-come-from-more-than-you-wanted-to-know/373">Where do the 2000+ PyTorch operators come from?: More than you wanted to know - compiler - PyTorch Developer Mailing List</A>
							<DT><A HREF="https://x.com/__tinygrad__/status/1980193031019258109">(11) the tiny corp en X: "Our GPU stack for both NVIDIA and AMD, aside from minimal pieces of signed firmware, is 100% open source and pure Python except for the compiler. It's not using vendor drivers, frameworks, or libraries. That's why it's so easy to make it work on Mac. For compilers, on AMD, we" / X</A>
							<DT><A HREF="https://x.com/__tinygrad__/status/1983478944809853299">(1) the tiny corp en X: "PyTorch frontend Halide rangeify E-graph symbolic ILP memory planner (MODeL) ThunderKittens backend Pure Python drivers" / X</A>
							<DT><A HREF="https://x.com/comma_ai/status/1982162517297442977">(1) comma en X: "While everyone else is moving to Rust, openpilot is becoming more Python over time. openpilot is so good because it's written in Python, not despite it. Self-driving cars is so far from being solved, and Python allows us to iterate as quickly as possible. Don't fall for the" / X</A>
							<DT><A HREF="https://github.com/geohot/babygrad/blob/master/lib.py">babygrad/lib.py at master ¬∑ geohot/babygrad</A>
							<DT><A HREF="https://geohot.github.io//blog/jekyll/update/2025/12/29/five-years-of-tinygrad.html">Five years of tinygrad | the singularity is nearer</A>
						</DL><p>
						<DT><H3 FOLDED>Tensors</H3>
						<DL><p>
							<DT><H3 FOLDED>tensors-examples</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ezyang/data-dependent-shape-puzzles">ezyang/data-dependent-shape-puzzles: Puzzlers regarding data-dependent shapes in PT2</A>
								<DT><A HREF="https://github.com/srush/Tensor-Puzzles">srush/Tensor-Puzzles: Solve puzzles. Improve your pytorch.</A>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/8fc8ec5a4d6498ff81c0c418b89bbaf133ae3a44/xformers/benchmarks/benchmark_tiled_matmul.py#L19">xformers/xformers/benchmarks/benchmark_tiled_matmul.py at 8fc8ec5a4d6498ff81c0c418b89bbaf133ae3a44 ¬∑ facebookresearch/xformers</A>
							</DL><p>
							<DT><H3 FOLDED>tensors-debug</H3>
							<DL><p>
								<DT><A HREF="https://github.com/xl0/lovely-tensors">xl0/lovely-tensors: Tensors, ready for human consumption</A>
								<DT><A HREF="https://github.com/xl0/lovely-grad">xl0/lovely-grad: ü´Ä Lovely Grad - tiny tensors need some love</A>
								<DT><A HREF="https://github.com/ezyang/torchdbg">ezyang/torchdbg: PyTorch centric eager mode debugger</A>
							</DL><p>
							<DT><H3 FOLDED>torch-rearrange</H3>
							<DL><p>
								<DT><A HREF="https://x.com/cloneofsimo/status/1939341498719629497">mha forward without transposes</A>
							</DL><p>
							<DT><H3 FOLDED>named-tensors</H3>
							<DL><p>
								<DT><H3 FOLDED>Haliax</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/dlwh/status/1716900734120464834/photo/1">Named tensor library</A>
									<DT><A HREF="https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html">Stanford CRFM</A>
									<DT><A HREF="https://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</A>
								</DL><p>
								<DT><A HREF="https://nlp.seas.harvard.edu/NamedTensor">Tensor Considered Harmful</A>
								<DT><A HREF="https://pytorch.org/docs/stable/named_tensor.html">Named Tensors ‚Äî PyTorch 2.3 documentation</A>
								<DT><A HREF="https://github.com/google-research/dex-lang">google-research/dex-lang: Research language for array processing in the Haskell/ML family</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/functorch/dim/README.md">Named Tensors using First-class Dimensions in PyTorch (pytorch/functorch/dim/README.md)</A>
								<DT><A HREF="https://github.com/google/maxtext/blob/53167aa550b49bfc867236790bc8065545f0d300/MaxText/layers/attentions.py#L110">MaxText attentions.py#L110</A>
								<DT><A HREF="https://github.com/google/maxtext/blob/53167aa550b49bfc867236790bc8065545f0d300/MaxText/common_types.py#L4">maxtext/MaxText/common_types.py</A>
								<DT><A HREF="https://github.com/google-deepmind/tensor_annotations">google-deepmind/tensor_annotations: Annotating tensor shapes using Python types</A>
							</DL><p>
							<DT><H3 FOLDED>Numpy</H3>
							<DL><p>
								<DT><H3 FOLDED>numpy-compile</H3>
								<DL><p>
									<DT><A HREF="https://x.com/giffmana/status/1940521160221016107">Oh wow, did you guys know that torch.compile can compile numpy code? And even run it on GPU</A>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/pytorch-2-1-automatic-dynamic-shape-compilation-torch-distributed-checkpoint-torch-compile-numpy-torch-export-prototype-and-more/1548">PyTorch 2.1: automatic dynamic shape compilation, torch.distributed.checkpoint, torch.compile + NumPy, torch.export prototype, and more! - Release Announcements - PyTorch Dev Discussions</A>
									<DT><A HREF="https://pytorch.org/blog/compiling-numpy-code/">Compiling NumPy code into C++ or CUDA via torch.compile ‚Äì PyTorch</A>
								</DL><p>
								<DT><A HREF="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html">numpy.reshape ‚Äî NumPy v1.22 Manual</A>
								<DT><A HREF="https://twitter.com/awnihannun/status/1779133564619284894">advance indexing</A>
								<DT><A HREF="https://arxiv.org/abs/1102.1523">[1102.1523] The NumPy array: a structure for efficient numerical computation</A>
								<DT><A HREF="https://github.com/joennlae/tensorli">joennlae/tensorli: Absolute minimalistic implementation of a GPT-like transformer using only numpy (&lt;650 lines).</A>
							</DL><p>
							<DT><H3 FOLDED>Shape Suffixes</H3>
							<DL><p>
								<DT><H3 FOLDED>tensor-typing</H3>
								<DL><p>
									<DT><A HREF="https://kidger.site/thoughts/jaxtyping/">No more shape errors! Type annotations for the shape+dtype of tensors/arrays</A>
									<DT><A HREF="https://github.com/patrick-kidger/jaxtyping">patrick-kidger/jaxtyping: Type annotations and runtime checking for shape and dtype of JAX/NumPy/PyTorch/etc. arrays. https://docs.kidger.site/jaxtyping/</A>
									<DT><A HREF="https://github.com/thecharlieblake/lovely-llama/blob/main/lovely_llama.py">lovely-llama/lovely_llama.py at main ¬∑ thecharlieblake/lovely-llama</A>
									<DT><A HREF="https://x.com/srush_nlp/status/1830975083646722387">raw numpy / torch tensor type checking example: multihead_attention</A>
									<DT><A HREF="https://github.com/thecharlieblake/lovely-llama/blob/main/lovely_llama.py#L68">lovely-llama/lovely_llama.py at main ¬∑ thecharlieblake/lovely-llama</A>
									<DT><A HREF="https://github.com/Narsil/zandle">Narsil/zandle: Testing zig comptime out for complex tensor typing thing.</A>
								</DL><p>
								<DT><H3 FOLDED>shape-suffixes-attention-heads</H3>
								<DL><p>
									<DT><A HREF="https://x.com/thecharlieblake/status/1830983614957527117">(1) Charlie Blake en X: "Yes! I was similarly frustrated, so did exactly what you suggest - a vmap-heavy jax implementation. Here's an attention head, I think it's much nicer this way: https://t.co/05JSiD2Dub" / X</A>
									<DT><A HREF="https://x.com/hwchung27/status/1831072828822827338">(1) Hyung Won Chung en X: "I'd like to clarify a few points on this slide from my previous talk to avoid potential confusion (https://t.co/irCiesi1Qo) 1) As cited in the slides, this function is adapted from Noam's multiquery paper, which I highly recommend. This is the best resource to learn about https://t.co/SQKGYCC5xi" / X</A>
									<DT><A HREF="https://x.com/srush_nlp/status/1830965798812422485">(1) Sasha Rush en X: "It's been 7 years of screaming into this abyss, but ü§∑ This is ugly code. This function should *not* know there is a `batch` dimension. The inner part should not know there is a `head` dimension. We are in the assembly era of math coding." / X</A>
									<DT><A HREF="https://x.com/srush_nlp/status/1830975083646722387">raw numpy / torch tensor type checking example: multihead_attention</A>
								</DL><p>
								<DT><A HREF="https://github.com/patrick-kidger/jaxtyping">patrick-kidger/jaxtyping: Type annotations and runtime checking for shape and dtype of JAX/NumPy/PyTorch/etc. arrays. https://docs.kidger.site/jaxtyping/</A>
								<DT><A HREF="https://medium.com/@NoamShazeer/shape-suffixes-good-coding-style-f836e72e24fd">Shape Suffixes ‚Äî Good Coding Style | by Noam Shazeer | Medium</A>
								<DT><A HREF="https://x.com/NoamShazeer/status/1762733550892401030">Noam Shazeer: Shape Suffixes ‚Äî Good Coding Style</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/functorch/dim/README.md">Named Tensors using First-class Dimensions in PyTorch (pytorch/functorch/dim/README.md)</A>
								<DT><A HREF="https://github.com/joschu/jax-exp/blob/master/jax_transformer.py#L96">jax-exp/jax_transformer.py at master ¬∑ joschu/jax-exp</A>
								<DT><A HREF="https://github.com/xjdr-alt/simple_transformer">xjdr-alt/simple_transformer: Simple Transformer in Jax</A>
								<DT><A HREF="https://github.com/zasdfgbnm/TorchSnooper">zasdfgbnm/TorchSnooper: Debug PyTorch code using PySnooper</A>
								<DT><A HREF="https://github.com/google-deepmind/nanodo/blob/main/nanodo/model.py">nanodo/nanodo/model.py at main ¬∑ google-deepmind/nanodo</A>
								<DT><A HREF="https://x.com/_xjdr/status/1838340564766593519/photo/1">xjdr: MLA impl</A>
								<DT><A HREF="https://github.com/Overworldai/world_engine/blob/main/src/patch_model.py">world_engine/src/patch_model.py at main ¬∑ Overworldai/world_engine</A>
							</DL><p>
							<DT><H3 FOLDED>einsum</H3>
							<DL><p>
								<DT><H3 FOLDED>einops-examples</H3>
								<DL><p>
									<DT><A HREF="https://theaisummer.com/einsum-attention/">Einsum: Transformer example</A>
								</DL><p>
								<DT><H3 FOLDED>einsum-sharding</H3>
								<DL><p>
									<DT><A HREF="https://blog.ezyang.com/2026/01/computing-sharding-with-einsum/">Computing sharding with einsum : ezyang's blog (you only linearize one transpose)</A>
								</DL><p>
								<DT><A HREF="https://sankalp.bearblog.dev/einsum-new/">Shape Rotation 101: An Intro to Einsum and Jax Transformers | sankalp's blog</A>
								<DT><A HREF="https://arxiv.org/pdf/2002.05202">GLU Variants Improve Transformer "gating einsums"</A>
								<DT><A HREF="https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g27b2b69cf28_1_205">Language Language Models (in 2023) - Google Slides: Einsum: generalization of matmul</A>
								<DT><A HREF="https://x.com/dejavucoder/status/1804379391910383784">(1) sankalp en X: "new post is up. it's split up in two parts. in the first part, i talk about the einsum operation in detail. second part is all about understanding @_xjdr 's JAX transformer implementation (that has lots of einsums). https://t.co/5fJhorgoul https://t.co/JiZcg5cknC" / X</A>
								<DT><A HREF="https://jimypbr.github.io/2020/02/fast-ai-lesson-8-notes-backprop-from-the-foundations">go-seq | James Briggs' Blog</A>
								<DT><A HREF="https://nlp.seas.harvard.edu/NamedTensor">Tensor Considered Harmful</A>
								<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.einsum.html">torch.einsum ‚Äî PyTorch 2.3 documentation</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/361209187">‰∏ÄÊñáÂ≠¶‰ºö Pytorch ‰∏≠ÁöÑ einsum - Áü•‰πé</A>
								<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&mid=2247493772&idx=1&sn=4eea0e68f2e813fb1e474bf74f3c3f6e&chksm=9f83521aa8f4db0c2d2221d259b1ff7b8fca53024fdd4be9def3d1f439b0eebd494501223079&token=650657988&lang=zh_CN#rd">A literature on einsum in Pytorch</A>
								<DT><A HREF="https://stackoverflow.com/questions/26089893/understanding-numpys-einsum/47966452#47966452">einsum</A>
								<DT><A HREF="https://rockt.ai/2018/04/30/einsum">EINSUM IS ALL YOU NEED</A>
								<DT><A HREF="https://x.com/_rockt/status/1230818967205425152/photo/1">(1) Tim Rockt√§schel en X: "In case you need convincing arguments for setting aside time to learn about einsum (https://t.co/2lA3Bsh53D) and Alex Rogozhnikov's einops (https://t.co/SY4yJAktEh). Screenshot taken from https://t.co/RsCX5P5NLv. https://t.co/TTvb8pENIb" / X</A>
							</DL><p>
							<DT><H3 FOLDED>tensors-dtypes</H3>
							<DL><p>
								<DT><A HREF="https://github.com/microsoft/microxcaling">microsoft/microxcaling: PyTorch emulation library for Microscaling (MX)-compatible data formats</A>
							</DL><p>
							<DT><H3 FOLDED>tensor-theory</H3>
							<DL><p>
								<DT><A HREF="https://github.com/EurekaLabsAI/tensor">EurekaLabsAI/tensor: The Tensor (or Array)</A>
								<DT><A HREF="http://www.continuummechanics.org/tensornotationbasic.html">Tensor Notation (Basics)</A>
								<DT><A HREF="https://link.springer.com/chapter/10.1007/978-3-030-74386-4_1">Tensor Computation | SpringerLink</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Hafo7hIl8MU">Tensor Puzzles: Let's Play - YouTube</A>
								<DT><A HREF="https://x.com/norpadon/status/1945517526894719117">Three properties a type system can have</A>
							</DL><p>
							<DT><H3 FOLDED>operators</H3>
							<DL><p>
								<DT><A HREF="https://github.com/nadavrot/fast_log">nadavrot/fast_log: A fast implementation of log() and exp()</A>
							</DL><p>
							<DT><H3 FOLDED>tensor-compression</H3>
							<DL><p>
								<DT><H3 FOLDED>compressed-tensors</H3>
								<DL><p>
									<DT><A HREF="https://github.com/neuralmagic/compressed-tensors">neuralmagic/compressed-tensors: A safetensors extension to efficiently store sparse quantized tensors on disk</A>
									<DT><A HREF="https://github.com/vllm-project/compressed-tensors">vllm-project/compressed-tensors: A safetensors extension to efficiently store sparse quantized tensors on disk</A>
								</DL><p>
								<DT><A HREF="https://github.com/zipnn/zipnn">zipnn/zipnn: A lossless and near-lossless compression method optimized for numbers/tensors in the Foundation Models environment</A>
							</DL><p>
							<DT><H3 FOLDED>zml</H3>
							<DL><p>
								<DT><A HREF="https://docs.zml.ai/learn/concepts/">ZML Concepts - ZML</A>
								<DT><A HREF="https://github.com/zml/zml?tab=readme-ov-file">zml/zml: High performance AI inference stack. Built for production. @ziglang / @openxla / MLIR / @bazelbuild</A>
							</DL><p>
							<DT><H3 FOLDED>tensors-model</H3>
							<DL><p>
								<DT><A HREF="https://areu01or00.github.io/Tensor-Slayer.github.io/ai/research/tensor-manipulation/2025/07/19/tensor-slayer-framework.html">Exploring Direct Tensor Manipulation in Language Models: A Case Study in Binary-Level Model Enhancement</A>
							</DL><p>
							<DT><H3 FOLDED>contiguous</H3>
							<DL><p>
								<DT><A HREF="https://research.colfax-intl.com/tutorial-python-binding-for-cuda-libraries-in-pytorch/">Tutorial: Python bindings for CUDA libraries in PyTorch ‚Äì Colfax Research</A>
							</DL><p>
							<DT><H3 FOLDED>tensors-render</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/ezyang/15791ae363900f42c704c09ca34346e3">Matrix-of-matrices tensor render</A>
								<DT><A HREF="https://x.com/ezyang/status/1982132802674974964">(1) Edward Z. Yang en X: "A small thread about how you should be drawing the contents of higher dimensional tensors https://t.co/DaU3r1ASk5" / X</A>
							</DL><p>
							<DT><A HREF="https://developer.nvidia.com/blog/nvidia-research-tensors-are-the-future-of-deep-learning/">NVIDIA Research: Tensors Are the Future of Deep Learning</A>
							<DT><A HREF="https://twitter.com/ayaka14732/media">Tweets con contenido multimedia de Ayaka (@ayaka14732) / Twitter</A>
							<DT><A HREF="https://github.com/Bruce-Lee-LY/cuda_hgemm">Bruce-Lee-LY/cuda_hgemm: Several optimization methods of half-precision general matrix multiplication (HGEMM) using tensor core with WMMA API and MMA PTX instruction.</A>
							<DT><A HREF="https://github.com/NVIDIA/TransformerEngine">NVIDIA/TransformerEngine: A library for accelerating Transformer models on NVIDIA GPUs, including using 8-bit floating point (FP8) precision on Hopper and Ada GPUs, to provide better performance with lower memory utilization in both training and inference.</A>
							<DT><A HREF="https://github.com/snap-research/BitsFusion">snap-research/BitsFusion</A>
							<DT><A HREF="https://x.com/mrsiipa/status/1922652408246677996">Tensor formal definition (ref CuTe tensor algebra)</A>
							<DT><A HREF="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues">A postmortem of three recent issues \ Anthropic</A>
							<DT><A HREF="https://twopug.com/interview-prep-ml-grind/">Interview Prep: The ML Grind | ‡´Æ ‚öÜÔªå‚öÜ·Éê Two Pug ‡´Æ ‚ÄìÔªå‚öÜ·Éê</A>
						</DL><p>
						<DT><H3 FOLDED>Assembler &amp; disassemblers</H3>
						<DL><p>
							<DT><A HREF="https://github.com/daadaada/turingas">daadaada/turingas: Assembler for NVIDIA Volta and Turing GPUs</A>
							<DT><A HREF="https://github.com/tinygrad/tinygrad/tree/957e9800f15bb3b8727f56b9298433432f703d9f/disassemblers">tinygrad/disassemblers/adreno/disasm-a3xx.c</A>
							<DT><A HREF="https://github.com/cloudcores/CuAssembler">cloudcores/CuAssembler: An unofficial cuda assembler, for all generations of SASS, hopefully ÔºöÔºâ</A>
							<DT><A HREF="https://github.com/vosen/ZLUDA">vosen/ZLUDA: CUDA on AMD GPUs</A>
							<DT><A HREF="https://justine.lol/matmul/">disassembly for the C++ code I'm working on will pop up on the screen in a few milliseconds (llamafile)</A>
							<DT><A HREF="https://github.com/QianyanTech/NBAssembler">QianyanTech/NBAssembler: Assembler and Decompiler for NVIDIA (Maxwell Pascal Volta Turing Ampere) GPUs.</A>
						</DL><p>
						<DT><H3 FOLDED>xformers</H3>
						<DL><p>
							<DT><H3 FOLDED>xformers-triton</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/_triton/tiled_matmul_kernels.py#L152">xformers/xformers/ops/_triton/tiled_matmul_kernels.py at 0004c67c7e9ec3c9e7b3907db0e0b2957430b35b ¬∑ facebookresearch/xformers</A>
							</DL><p>
							<DT><H3 FOLDED>xformers-custom-op</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/ops/fmha/flash3.py">xformers/xformers/ops/fmha/flash3.py at 0004c67c7e9ec3c9e7b3907db0e0b2957430b35b ¬∑ facebookresearch/xformers</A>
							</DL><p>
							<DT><H3 FOLDED>xformers-flash3</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/xformers/pull/1157">[FA3] Link to cuda library to fix the FA3 extension build by xuzhao9 ¬∑ Pull Request #1157 ¬∑ facebookresearch/xformers</A>
								<DT><A HREF="https://github.com/ohwi/xformers/commit/c6528114fecb5927d11689ec78eba444b1f78741">Update flash3 arguments ¬∑ ohwi/xformers@c652811</A>
							</DL><p>
							<DT><H3 FOLDED>xformers-benchmark</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/xformers/blob/main/BENCHMARKS.md">xformers/BENCHMARKS.md at main ¬∑ facebookresearch/xformers</A>
							</DL><p>
							<DT><A HREF="https://github.com/facebookresearch/xformers/blob/ad986981b141a218bf07bf968e920051ff2c7b41/xformers/benchmarks/benchmark_mem_eff_attention.py#L85">xformers/xformers/benchmarks/benchmark_mem_eff_attention.py at ad986981b141a218bf07bf968e920051ff2c7b41 ¬∑ facebookresearch/xformers</A>
							<DT><A HREF="https://x.com/fvsmassa/status/1580229170629849089">(1) Francisco Massa en X: "Do you need fast and memory-efficient transformers which are easy to install? I'm happy to share that xFormers now ships precompiled conda packages for PyTorch 1.12.1 and CUDA 11.3/11.6 (Linux-only for now). https://t.co/djPV1dKxVT https://t.co/zCHcg4DLZl" / X</A>
							<DT><A HREF="https://github.com/facebookresearch/xformers/blob/0004c67c7e9ec3c9e7b3907db0e0b2957430b35b/xformers/profiler/device_limits.py#L21">xformers/xformers/profiler/device_limits.py  at facebookresearch/xformers: NVIDIA datashet reports with sparsity</A>
							<DT><A HREF="https://github.com/facebookresearch/xformers/blob/4a9dd7ec079e0c935db10daa2a1a89fd19cfa231/xformers/ops/_triton/tiled_matmul_kernels.py#L150">xformers/xformers/ops/_triton/tiled_matmul_kernels.py at 4a9dd7ec079e0c935db10daa2a1a89fd19cfa231 ¬∑ facebookresearch/xformers</A>
							<DT><A HREF="https://facebookresearch.github.io/xformers/components/ops.html">xFormers optimized operators | xFormers 0.0.29 documentation</A>
							<DT><A HREF="https://github.com/vllm-project/vllm/pull/27714/files">Revert "Install pre-built xformers-0.0.32.post2 built with pt-2.9.0" by simon-mo ¬∑ Pull Request #27714 ¬∑ vllm-project/vllm</A>
							<DT><A HREF="https://x.com/divBy_zero/status/1983325005128815034">Common Fundamentals in AI and CPU Design</A>
						</DL><p>
						<DT><H3 FOLDED>ONNX</H3>
						<DL><p>
							<DT><H3 FOLDED>onnx-optimum</H3>
							<DL><p>
								<DT><H3 FOLDED>optimum-docker</H3>
								<DL><p>
									<DT><A HREF="https://github.com/awslabs/llm-hosting-container/tree/main/huggingface/pytorch/optimum/docker">llm-hosting-container/huggingface/pytorch/optimum/docker at main ¬∑ awslabs/llm-hosting-container</A>
								</DL><p>
								<DT><A HREF="https://github.com/philschmid/optimum-static-quantization">philschmid/optimum-static-quantization</A>
								<DT><A HREF="https://github.com/huggingface/optimum">huggingface/optimum: üöÄ Accelerate training and inference of ü§ó Transformers and ü§ó Diffusers with easy to use hardware optimization tools</A>
								<DT><A HREF="https://github.com/huggingface/optimum-nvidia">huggingface/optimum-nvidia</A>
							</DL><p>
							<DT><H3 FOLDED>onnxscript</H3>
							<DL><p>
								<DT><A HREF="https://github.com/microsoft/onnxscript">microsoft/onnxscript: ONNX Script enables author ONNX functions and models using a subset of Python.</A>
								<DT><A HREF="https://github.com/microsoft/onnxscript/blob/main/examples/pattern_rewriting.py">onnxscript/examples/pattern_rewriting.py</A>
							</DL><p>
							<DT><H3 FOLDED>onnx-olive</H3>
							<DL><p>
								<DT><H3 FOLDED>olive-convert</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/tlwu/sdxl-turbo-onnxruntime">tlwu/sdxl-turbo-onnxruntime -&gt; olive model generation cmdline</A>
									<DT><A HREF="https://github.com/microsoft/Olive/blob/6b93df3a493ac40c914fcae1155ac24659cba750/examples/stable_diffusion/stable_diffusion.py#L196">stable_diffusion.py#L196: optimize-model</A>
								</DL><p>
								<DT><A HREF="https://github.com/microsoft/Olive">microsoft/Olive: Olive is an easy-to-use hardware-aware model optimization tool that composes industry-leading techniques across model compression, optimization, and compilation.</A>
								<DT><A HREF="https://github.com/microsoft/Olive/tree/main/examples/stable_diffusion">Olive/examples/stable_diffusion at main ¬∑ microsoft/Olive</A>
							</DL><p>
							<DT><A HREF="https://huggingface.co/docs/optimum/onnxruntime/usage_guides/quantization">ONNX Runtime</A>
							<DT><A HREF="https://onnx.ai/">ONNX | Home</A>
							<DT><A HREF="https://onnxruntime.ai/">ONNX Runtime | Home</A>
							<DT><A HREF="https://github.com/lutzroeder/netron">lutzroeder/netron: Visualizer for neural networks</A>
							<DT><A HREF="https://onnxruntime.ai/docs/performance/olive.html">End to end optimization with Olive | onnxruntime</A>
							<DT><A HREF="https://github.com/microsoft/onnxscript/blob/main/docs/examples/04_plot_eager_mode_evaluation.py">onnxscript/docs/examples/04_plot_eager_mode_evaluation.py at main ¬∑ microsoft/onnxscript</A>
							<DT><A HREF="https://github.com/onnx/onnx/blob/main/docs/Operators.md">Operator Schemas</A>
							<DT><A HREF="https://github.com/onnx/onnx/blob/main/docs/Syntax.md">onnx/docs/Syntax.md at main ¬∑ onnx/onnx</A>
							<DT><A HREF="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html">Developer Guide :: NVIDIA Deep Learning TensorRT Documentation</A>
							<DT><A HREF="https://github.com/Ki6an/fastT5">Ki6an/fastT5: ‚ö° boost inference speed of T5 models by 5x &amp; reduce the model size by 3x.</A>
							<DT><A HREF="https://github.com/stars/pommedeterresautee/lists/quantization">pommedeterresautee's list / quantization</A>
							<DT><A HREF="https://github.com/microsoft/nnfusion/tree/main/models/pytorch2onnx">nnfusion/models/pytorch2onnx at main ¬∑ microsoft/nnfusion</A>
							<DT><A HREF="https://github.com/mlcommons/inference_results_v4.0/blob/main/closed/NVIDIA/code/stable-diffusion-xl/tensorrt/sdxl_graphsurgeon.py">inference_results_v4.0/closed/NVIDIA/code/stable-diffusion-xl/tensorrt/sdxl_graphsurgeon.py at main ¬∑ mlcommons/inference_results_v4.0</A>
							<DT><A HREF="https://github.com/daquexian/onnx-simplifier">daquexian/onnx-simplifier: Simplify your onnx model</A>
						</DL><p>
						<DT><H3 FOLDED>TensorRT</H3>
						<DL><p>
							<DT><H3 FOLDED>tensorrt-diffusion</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT/blob/release/10.2/demo/Diffusion/demo_txt2img_sd3.py">TensorRT/demo/Diffusion/demo_txt2img_sd3.py at release/10.2 ¬∑ NVIDIA/TensorRT</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT/blob/release/10.2/demo/Diffusion/README.md">TensorRT/demo/Diffusion/README.md at release/10.2 ¬∑ NVIDIA/TensorRT</A>
								<DT><A HREF="https://github.com/search?q=repo%3ANVIDIA%2FTensorRT-Model-Optimizer%20FLUX&type=code">DiT FLUX</A>
							</DL><p>
							<DT><A HREF="https://segmentfault.com/a/1190000039977778">Introduction</A>
							<DT><A HREF="https://github.com/pytorch/TensorRT">pytorch/TensorRT: PyTorch/TorchScript/FX compiler for NVIDIA GPUs using TensorRT</A>
							<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-s51714/">Exploring TensorRT</A>
							<DT><A HREF="https://developer.nvidia.com/tensorrt">TensorRT SDK | NVIDIA Developer</A>
							<DT><A HREF="https://els-rd.github.io/transformer-deploy/python/">Direct use TensorRT in Python script (no server)</A>
							<DT><A HREF="https://www.photoroom.com/inside-photoroom/stable-diffusion-25-percent-faster-and-save-seconds">Stable Diffusion</A>
							<DT><A HREF="https://github.com/wangzyon/trt_learn">wangzyon/trt_learn: TensorRT encapsulation, learn, rewrite, practice.</A>
							<DT><A HREF="https://leimao.github.io/blog/Docker-TensorRT/">TensorRT In Docker - Lei Mao's Log Book</A>
							<DT><A HREF="https://github.com/stars/pommedeterresautee/lists/quantization">pommedeterresautee's list / quantization</A>
							<DT><A HREF="https://github.com/NVIDIA/TensorRT/tree/main/tools/experimental/trt-engine-explorer">TensorRT/tools/experimental/trt-engine-explorer at main ¬∑ NVIDIA/TensorRT</A>
							<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo">neuralmagic/tensorrt-demo</A>
						</DL><p>
						<DT><H3 FOLDED>LLVM</H3>
						<DL><p>
							<DT><H3 FOLDED>llvm-compiler-optimizations</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google/ml-compiler-opt">google/ml-compiler-opt: Infrastructure for Machine Learning Guided Optimization (MLGO) in LLVM.</A>
								<DT><A HREF="https://lists.llvm.org/pipermail/llvm-dev/2020-April/140763.html">[llvm-dev] RFC: a practical mechanism for applying Machine Learning for optimization policies in LLVM</A>
							</DL><p>
							<DT><H3 FOLDED>NVPTX LLVM</H3>
							<DL><p>
								<DT><A HREF="https://github.com/llvm/llvm-project/pull/87065">[mlir][nvgpu] NVGPU Tutorials by grypp ¬∑ Pull Request #87065 ¬∑ llvm/llvm-project</A>
								<DT><A HREF="https://grypp.github.io/papers/nvdsl.pdf">Zero to Hero: Programming Nvidia Hopper Tensor Core with MLIR's NVGPU Dialect)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=xNe9fPvU7-U">Open MLIR Meeting 11-16-2023: Targeting H100 with NVGPU and NVVM Dialects - YouTube</A>
							</DL><p>
							<DT><A HREF="https://github.com/banach-space/llvm-tutor">banach-space/llvm-tutor: A collection of out-of-tree LLVM passes for teaching and learning</A>
							<DT><A HREF="https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/?utm_source=twitter&utm_medium=organic_social&utm_content=link&utm_campaign=fair">Meta Large Language Model Compiler: Foundation Models of Compiler Optimization | Research - AI at Meta</A>
							<DT><A HREF="https://compilergym.com/">Indices and tables ‚Äî CompilerGym 0.2.5 documentation</A>
							<DT><A HREF="https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/?utm_source=linkedin&utm_medium=organic_social&utm_content=image&utm_campaign=fair">Meta Large Language Model Compiler: Foundation Models of Compiler Optimization | Research - AI at Meta</A>
							<DT><A HREF="https://github.com/PacktPublishing/LLVM-Code-Generation">PacktPublishing/LLVM-Code-Generation: LLVM Code Generation, published by Packt</A>
							<DT><A HREF="https://github.com/FindHao/ml_scripts/blob/main/compile_llvm.sh">ml_scripts/compile_llvm.sh at main ¬∑ FindHao/ml_scripts</A>
						</DL><p>
						<DT><H3 FOLDED>WASM</H3>
						<DL><p>
							<DT><H3 FOLDED>wasm-internals</H3>
							<DL><p>
								<DT><A HREF="https://developer.mozilla.org/en-US/docs/WebAssembly/Understanding_the_text_format">Understanding WebAssembly text format - WebAssembly | MDN</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ojYEfRye6aE&t=13s">HELLO WEBASSEMBLY - wat</A>
								<DT><A HREF="https://developer.mozilla.org/en-US/docs/WebAssembly/Text_format_to_wasm">Converting WebAssembly text format to wasm - WebAssembly | MDN</A>
								<DT><A HREF="https://rustwasm.github.io/docs.html">Rust and WebAssembly Documentation | Rust and WebAssembly</A>
							</DL><p>
							<DT><H3 FOLDED>wasm-C/C++</H3>
							<DL><p>
								<DT><H3 FOLDED>Emscripten</H3>
								<DL><p>
									<DT><A HREF="https://emscripten.org/">Main ‚Äî Emscripten 3.0.1-git (dev) documentation</A>
									<DT><H3 FOLDED>installation</H3>
									<DL><p>
										<DT><A HREF="https://emscripten.org/docs/building_from_source/toolchain_what_is_needed.html#toolchain-what-you-need">Emscripten Toolchain Requirements ‚Äî Emscripten 3.1.9</A>
										<DT><A HREF="https://formulae.brew.sh/formula/emscripten">emscripten ‚Äî Homebrew Formulae</A>
										<DT><A HREF="https://formulae.brew.sh/formula/llvm#default">llvm ‚Äî Homebrew Formulae</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://medium.com/@tdeniffel/pragmatic-compiling-from-c-to-webassembly-a-guide-a496cc5954b8">Pragmatic compiling of C++ to WebAssembly. A Guide. | by Thomas Deniffel | Medium</A>
								<DT><A HREF="https://web.dev/loading-wasm/">Loading WebAssembly modules efficiently</A>
								<DT><A HREF="https://nodejs.dev/learn/nodejs-with-webassembly">Node.js with WebAssembly</A>
								<DT><A HREF="https://emscripten.org/docs/porting/connecting_cpp_and_javascript/Interacting-with-code.html">Interacting with code ‚Äî Emscripten 3.1.9-git (dev) documentation</A>
								<DT><A HREF="https://web.dev/emscripten-npm/">Emscripten and npm</A>
							</DL><p>
							<DT><H3 FOLDED>wasm-wabt</H3>
							<DL><p>
								<DT><A HREF="https://github.com/WebAssembly/wabt">WebAssembly/wabt: The WebAssembly Binary Toolkit</A>
							</DL><p>
							<DT><H3 FOLDED>wasm-wasi</H3>
							<DL><p>
								<DT><A HREF="https://github.com/WebAssembly/WASI">WebAssembly/WASI: WebAssembly System Interface</A>
							</DL><p>
							<DT><H3 FOLDED>wasm-containers</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=ulZGjeFZirU&t=21s">WASM + Kubernetes: Beyond Containers - YouTube</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=VhCgep06-I8">Browserless app runtime in Rust - Demo app in Zig - Wasm/WebGPU - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=b5HHyb1d4Ys">Evolution of Wasm: Past, Present, Future - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ulZGjeFZirU&t=21s">WASM + Kubernetes: Beyond Containers - YouTube</A>
							<DT><A HREF="https://wasmcloud.dev/">wasmCloud Documentation</A>
							<DT><A HREF="https://pragprog.com/titles/khrust/programming-webassembly-with-rust/">Programming WebAssembly with Rust</A>
							<DT><A HREF="https://pspdfkit.com/blog/2017/webassembly-a-new-hope/">WebAssembly: A New Hope | PSPDFKit</A>
							<DT><A HREF="https://www.youtube.com/watch?v=fh9WXPu0hw8">Bringing WebAssembly outside the web with WASI by Lin Clark - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>GGML</H3>
						<DL><p>
							<DT><H3 FOLDED>llamafile</H3>
							<DL><p>
								<DT><A HREF="https://justine.lol/matmul/">LLaMA Now Goes Faster on CPUs</A>
								<DT><A HREF="https://github.com/Mozilla-Ocho/llamafile">Mozilla-Ocho/llamafile: Distribute and run LLMs with a single file.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-mRi-B3t6fA&t=593s">Llamafile: bringing AI to the masses with fast CPU inference: Stephen Hood and Justine Tunney - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>llama.cpp</H3>
							<DL><p>
								<DT><H3 FOLDED>llama.cpp-convert</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/c8a0090922bad576623de4aae227717085249262/convert_hf_to_gguf_update.py#L234">llama.cpp/convert_hf_to_gguf_update.py</A>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/c8a0090922bad576623de4aae227717085249262/scripts/hf.sh#L6">llama.cpp/scripts/hf.sh</A>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/c8a0090922bad576623de4aae227717085249262/convert_hf_to_gguf.py">llama.cpp/convert_hf_to_gguf.py</A>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/c8a0090922bad576623de4aae227717085249262/ci/run.sh#L562">run.sh#L562</A>
								</DL><p>
								<DT><H3 FOLDED>gguf</H3>
								<DL><p>
									<DT><H3 FOLDED>gguf-models</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/TheBloke/CodeLlama-70B-Instruct-GPTQ">TheBloke/CodeLlama-70B-Instruct-GPTQ ¬∑ Hugging Face</A>
									</DL><p>
									<DT><H3 FOLDED>gguf-py</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ggerganov/llama.cpp/tree/c8a0090922bad576623de4aae227717085249262/gguf-py">llama.cpp/gguf-py</A>
									</DL><p>
									<DT><A HREF="https://github.com/ggerganov/ggml/blob/master/docs/gguf.md">ggml/docs/gguf.md at master ¬∑ ggerganov/ggml</A>
									<DT><A HREF="https://github.com/antirez/gguf-tools">antirez/gguf-tools: GGUF implementation in C as a library and a tools CLI program</A>
								</DL><p>
								<DT><H3 FOLDED>llama.cpp-apple</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/discussions/4508">Performance of llama.cpp on Apple Silicon A-series ¬∑ ggerganov/llama.cpp ¬∑ Discussion #4508</A>
								</DL><p>
								<DT><H3 FOLDED>llama.cpp-python</H3>
								<DL><p>
									<DT><A HREF="https://github.com/abetlen/llama-cpp-python">abetlen/llama-cpp-python: Python bindings for llama.cpp</A>
								</DL><p>
								<DT><H3 FOLDED>llama.cpp-torch</H3>
								<DL><p>
									<DT><A HREF="https://github.com/chu-tianxiang/llama-cpp-torch">chu-tianxiang/llama-cpp-torch: llama.cpp to PyTorch Converter</A>
								</DL><p>
								<DT><A HREF="https://steelph0enix.github.io/posts/llama-cpp-guide/">llama.cpp guide - Running LLMs locally, on any hardware, from scratch ::</A>
								<DT><A HREF="https://github.com/ggml-org/llama.cpp/discussions/16938">guide : using the new WebUI of llama.cpp ¬∑ ggml-org/llama.cpp ¬∑ Discussion #16938</A>
							</DL><p>
							<DT><A HREF="https://github.com/marella/ctransformers">marella/ctransformers: Python bindings for the Transformer models implemented in C/C++ using GGML library.</A>
							<DT><A HREF="https://huggingface.co/crusoeai">crusoeai (Crusoe AI)</A>
							<DT><A HREF="https://github.com/ggerganov/ggml/blob/master/src/ggml-quants.h">ggml/src/ggml-quants.h at master ¬∑ ggerganov/ggml</A>
						</DL><p>
						<DT><H3 FOLDED>Higher-order Virtual Machine 2</H3>
						<DL><p>
							<DT><A HREF="https://github.com/VictorTaelin">VictorTaelin (Victor Taelin)</A>
							<DT><A HREF="https://github.com/HigherOrderCO/HVM">HigherOrderCO/HVM: A massively parallel, optimal functional runtime in Rust</A>
							<DT><A HREF="https://github.com/HigherOrderCO/bend">HigherOrderCO/Bend</A>
						</DL><p>
						<DT><H3 FOLDED>Metal</H3>
						<DL><p>
							<DT><H3 FOLDED>metal-llama.cpp</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ggerganov/llama.cpp/discussions/4167">Performance of llama.cpp on Apple Silicon M-series ¬∑ ggerganov/llama.cpp ¬∑ Discussion #4167</A>
								<DT><A HREF="https://github.com/ggerganov/llama.cpp/discussions/4508">Performance of llama.cpp on Apple Silicon A-series ¬∑ ggerganov/llama.cpp ¬∑ Discussion #4508</A>
								<DT><A HREF="https://github.com/ggerganov/llama.cpp/discussions/4508#user-content-fn-4-533433ec2a70d995c2039ce1939985be">Performance of llama.cpp on Apple Silicon A-series ¬∑ ggerganov/llama.cpp ¬∑ Discussion #4508</A>
								<DT><A HREF="https://github.com/ggerganov/llama.cpp/tree/0e18b2e7d0b5c0a509ea40098def234b8d4a938a/examples/llama.swiftui">llama.cpp/examples/llama.swiftui</A>
							</DL><p>
							<DT><H3 FOLDED>metal-perf</H3>
							<DL><p>
								<DT><A HREF="https://github.com/tlkh/asitop">tlkh/asitop: Perf monitoring CLI tool for Apple Silicon</A>
							</DL><p>
							<DT><H3 FOLDED>metal-mlx</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ml-explore/mlx">ml-explore/mlx: MLX: An array framework for Apple silicon</A>
								<DT><A HREF="https://github.com/ml-explore/mlx-examples">ml-explore/mlx-examples: Examples in the MLX framework</A>
								<DT><A HREF="https://towardsdatascience.com/gpt-from-scratch-with-mlx-acf2defda30e">GPT from Scratch with MLX. Define and train GPT-2 on your MacBook | by Pranav Jadhav | Jun, 2024 | Towards Data Science</A>
							</DL><p>
							<DT><H3 FOLDED>metal-corenet</H3>
							<DL><p>
								<DT><A HREF="https://github.com/apple/corenet">apple/corenet: CoreNet: A library for training deep neural networks</A>
							</DL><p>
							<DT><A HREF="https://twitter.com/atiorh/status/1737912777153609918">(Apple) Atila en X: "My takeaways from Apple's ‚ÄúLLM in a flash" (1/n)" / X</A>
						</DL><p>
						<DT><H3 FOLDED>Tenstorrent</H3>
						<DL><p>
							<DT><A HREF="https://github.com/tenstorrent-metal/tt-metal">tenstorrent-metal/tt-metal: ttnn - a python API and OP library. TT-Metalium - a low level kernel programming model</A>
						</DL><p>
						<DT><H3 FOLDED>Exo</H3>
						<DL><p>
							<DT><A HREF="https://exo-lang.dev/">The Exo Language | Exo is a low-level language (and exocompiler) designed to help performance engineers write, optimize, and target high-performance computing kernels onto new hardware accelerators.</A>
							<DT><A HREF="https://github.com/exo-lang/ExoBLAS">exo-lang/ExoBLAS: BLAS implementation using Exo</A>
							<DT><A HREF="https://github.com/exo-lang">exo-lang</A>
						</DL><p>
						<DT><H3 FOLDED>GEMMINI</H3>
						<DL><p>
							<DT><A HREF="https://github.com/ucb-bar/gemmini">ucb-bar/gemmini: Berkeley's Spatial Array Generator</A>
							<DT><A HREF="https://people.eecs.berkeley.edu/~ysshao/assets/papers/genc2021-dac.pdf">Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration</A>
							<DT><A HREF="https://github.com/ucb-bar/chipyard">ucb-bar/chipyard: An Agile RISC-V SoC Design Framework with in-order cores, out-of-order cores, accelerators, and more</A>
							<DT><A HREF="https://www.chisel-lang.org/">Home | Chisel</A>
							<DT><A HREF="https://blog.research.google/2024/01/mixed-input-matrix-multiplication.html">Mixed-input matrix multiplication performance optimizations ‚Äì Google Research Blog</A>
							<DT><A HREF="https://research.colfax-intl.com/adding-fp8-to-flashattention/">Delivering 1 PFLOP/s of Performance with FP8 FlashAttention-2 ‚Äì Colfax Research</A>
						</DL><p>
						<DT><H3 FOLDED>TVM</H3>
						<DL><p>
							<DT><H3 FOLDED>tvm-ffi</H3>
							<DL><p>
								<DT><A HREF="https://github.com/apache/tvm-ffi">apache/tvm-ffi: Open ABI and FFI for Machine Learning Systems</A>
								<DT><A HREF="https://docs.nvidia.com/cutlass/latest/media/docs/pythonDSL/cute_dsl_general/compile_with_tvm_ffi.html">Compile with TVM FFI ‚Äî NVIDIA CUTLASS Documentation</A>
								<DT><A HREF="https://www.linkedin.com/posts/zihao-ye-045446166_building-an-open-abi-and-ffi-for-ml-systems-activity-7389162385477091328-XFbj/?utm_source=share&utm_medium=member_ios&rcm=ACoAADeEKeUBn1M9dss852p3XRMh5oYplpWg4c8">potential to evolve into a standard OpenABI (DLPack became the standard data structure for tensors)</A>
								<DT><A HREF="https://tvm.apache.org/2025/10/21/tvm-ffi">Building an Open ABI and FFI for ML Systems</A>
							</DL><p>
							<DT><H3 FOLDED>tvm-mlir</H3>
							<DL><p>
								<DT><A HREF="https://github.com/BBuf/tvm_mlir_learn">BBuf/tvm_mlir_learn: compiler learning resources collect.</A>
							</DL><p>
							<DT><A HREF="https://mlc.ai/chapter_graph_optimization/index.html#prelude">7. Computational Graph Optimization ‚Äî Machine Learing Compilation 0.0.1 documentation</A>
							<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:activity:7386503838960087040/">(9) Post | Feed | LinkedIn</A>
							<DT><A HREF="https://www.modular.com/blog/democratizing-ai-compute-part-6-what-about-ai-compilers">Modular: What about TVM, XLA, and AI compilers? (Democratizing AI Compute, Part 6)</A>
						</DL><p>
						<DT><H3 FOLDED>Mojo</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=3FKSlhZNdL0">Mojo Community Meeting #2 - YouTube</A>
							<DT><A HREF="https://www.modular.com/blog/mojo-vs-rust-is-mojo-faster-than-rust">Modular: Mojo vs. Rust: is Mojo üî• faster than Rust ü¶Ä ?</A>
						</DL><p>
						<DT><H3 FOLDED>stable-fast</H3>
						<DL><p>
							<DT><H3 FOLDED>stable-fast-installation</H3>
							<DL><p>
								<DT><A HREF="https://github.com/DataCrunch-io/inferno/blob/5b0633c8b5a9d6c84b7215b660e5e510ef00315c/Dockerfiles/Dockerfile.lcm#L24">Download the wheel corresponding to your system: pip3 install &lt;wheel file&gt;</A>
							</DL><p>
							<DT><H3 FOLDED>siliconflow</H3>
							<DL><p>
								<DT><A HREF="https://siliconflow.cn/">SiliconFlow, Accelerate AGI to Benefit Humanity</A>
								<DT><A HREF="https://chengzeyi.github.io/markdown-cv/">Cheng Zeyi's CV | CV</A>
							</DL><p>
							<DT><A HREF="https://github.com/chengzeyi/stable-fast">chengzeyi/stable-fast: Best inference performance optimization framework for HuggingFace Diffusers on NVIDIA GPUs.</A>
							<DT><A HREF="https://www.vrushankdes.ai/diffusion-inference-optimization">Diffusion Inference Optimization</A>
						</DL><p>
						<DT><H3 FOLDED>OneDiff</H3>
						<DL><p>
							<DT><H3 FOLDED>onediff-compiler</H3>
							<DL><p>
								<DT><H3 FOLDED>nexfort</H3>
								<DL><p>
									<DT><H3 FOLDED>nextfort-fp8</H3>
									<DL><p>
										<DT><A HREF="https://github.com/siliconflow/onediff/blob/6b53a83bd72952c11102c30b6d739bfcb3b0f7da/onediff_diffusers_extensions/onediffx/compilers/diffusion_pipeline_compiler.py#L192">onediff/onediff_diffusers_extensions/onediffx/compilers/diffusion_pipeline_compiler.py at 6b53a83bd72952c11102c30b6d739bfcb3b0f7da ¬∑ siliconflow/onediff</A>
										<DT><A HREF="https://github.com/lukiod/T2I-and-I2I-Report/blob/main/testi2i.py">fp8_e4m3_e4m3_dynamic</A>
									</DL><p>
									<DT><H3 FOLDED>nexfort-benchmarking</H3>
									<DL><p>
										<DT><A HREF="https://github.com/lukiod/T2I-and-I2I-Report/blob/main/testi2i.py">fp8_e4m3_e4m3_dynamic</A>
									</DL><p>
									<DT><H3 FOLDED>nexfort-installation</H3>
									<DL><p>
										<DT><A HREF="https://github.com/siliconflow/onediff/blob/main/README.md#nexfort">onediff/README.md at main ¬∑ siliconflow/onediff</A>
										<DT><A HREF="https://github.com/siliconflow/onediff/blob/6fe6fddec747b0f1f64b4160b94ec7a0a99e246b/onediff_comfy_nodes/docs/sd3/README.md">onediff/onediff_comfy_nodes/docs/sd3/README.md at 6fe6fddec747b0f1f64b4160b94ec7a0a99e246b ¬∑ siliconflow/onediff</A>
									</DL><p>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/6fe6fddec747b0f1f64b4160b94ec7a0a99e246b/onediff_comfy_nodes/extras_nodes/nodes_nexfort_booster.py#L12">compiler_modes</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/tree/main/src/onediff/infer_compiler/backends/nexfort#readme">onediff/src/onediff/infer_compiler/backends/nexfort at main ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/tree/main/src/onediff/infer_compiler">onediff/src/onediff/infer_compiler at main ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/lukiod/T2I-and-I2I-Report">lukiod/T2I-and-I2I-Report</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/6fe6fddec747b0f1f64b4160b94ec7a0a99e246b/onediff_comfy_nodes/docs/sd3/README.md">onediff/onediff_comfy_nodes/docs/sd3/README.md at 6fe6fddec747b0f1f64b4160b94ec7a0a99e246b ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/kijai/ComfyUI-CogVideoXWrapper/blob/750deb391813bfc822896599f24e740e4c14a300/nodes.py#L430">ComfyUI-CogVideoXWrapper/nodes.py: DiT cogVideoX inductor config</A>
								</DL><p>
								<DT><H3 FOLDED>onediff-diffusers-extensions</H3>
								<DL><p>
									<DT><H3 FOLDED>onediff-diffusers-extensions-installation</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/pytorch/ao">pytorch/ao: The missing pytorch dtype and layout library for training and inference</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/6b53a83bd72952c11102c30b6d739bfcb3b0f7da/onediff_diffusers_extensions/README.md#install-and-setup">onediff/onediff_diffusers_extensions/README.md at 6b53a83bd72952c11102c30b6d739bfcb3b0f7da ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/tree/7c325253d4e280e470613be43fa3e582a476923e/onediff_diffusers_extensions">onediff/onediff_diffusers_extensions at 7c325253d4e280e470613be43fa3e582a476923e ¬∑ siliconflow/onediff</A>
								</DL><p>
								<DT><A HREF="https://github.com/siliconflow/onediff/blob/main/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py">onediff/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py at main ¬∑ siliconflow/onediff</A>
							</DL><p>
							<DT><H3 FOLDED>onediff-dit</H3>
							<DL><p>
								<DT><H3 FOLDED>onediff-flux</H3>
								<DL><p>
									<DT><A HREF="https://github.com/siliconflow/onediff/issues/1066">Add acceleration support for FLUX models ¬∑ Issue #1066 ¬∑ siliconflow/onediff</A>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/main/src/onediff/infer_compiler/backends/oneflow/param_utils.py#L130">onediff/src/onediff/infer_compiler/backends/oneflow/param_utils.py: get_sub_module</A>
								</DL><p>
								<DT><H3 FOLDED>onediff-diffusers-extensions</H3>
								<DL><p>
									<DT><A HREF="https://github.com/siliconflow/onediff/blob/main/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py">onediff/onediff_diffusers_extensions/examples/sd3/text_to_image_sd3.py at main ¬∑ siliconflow/onediff</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>onediff-people</H3>
							<DL><p>
								<DT><A HREF="https://chengzeyi.github.io/markdown-cv/">Cheng Zeyi's CV | CV</A>
							</DL><p>
							<DT><A HREF="https://medium.com/@SiliconFlowAI">SiliconFlow ‚Äì Medium</A>
							<DT><A HREF="https://www.felixsanz.dev/articles/ultimate-guide-to-optimizing-stable-diffusion-xl">Ultimate guide to optimizing Stable Diffusion XL - F√©lix Sanz</A>
							<DT><A HREF="https://github.com/ccssu/how_to_write_user_op">ccssu/how_to_write_user_op: OneFlow User op ÂºÄÂèëÁ¨îËÆ∞</A>
							<DT><A HREF="https://github.com/siliconflow/onediff/wiki">Home ¬∑ siliconflow/onediff Wiki</A>
						</DL><p>
						<DT><H3 FOLDED>IREE</H3>
						<DL><p>
							<DT><A HREF="https://github.com/iree-org">IREE</A>
							<DT><A HREF="https://github.com/iree-org/iree-turbine">iree-org/iree-turbine: IREE's PyTorch Frontend, based on Torch Dynamo.</A>
						</DL><p>
						<DT><H3 FOLDED>Paddle</H3>
						<DL><p>
							<DT><A HREF="https://github.com/PaddlePaddle/Paddle">PaddlePaddle/Paddle: PArallel Distributed Deep LEarning: Machine Learning Framework from Industrial Practice Ôºà„ÄéÈ£ûÊ°®„ÄèÊ†∏ÂøÉÊ°ÜÊû∂ÔºåÊ∑±Â∫¶Â≠¶‰π†&amp;Êú∫Âô®Â≠¶‰π†È´òÊÄßËÉΩÂçïÊú∫„ÄÅÂàÜÂ∏ÉÂºèËÆ≠ÁªÉÂíåË∑®Âπ≥Âè∞ÈÉ®ÁΩ≤Ôºâ</A>
						</DL><p>
						<DT><H3 FOLDED>AI Compiler Study</H3>
						<DL><p>
							<DT><H3 FOLDED>compiler-study-slides</H3>
							<DL><p>
								<DT><A HREF="https://docs.google.com/presentation/d/1QokvjA2zwqpvIIE5p4xvKl-41Ss6eqVefu_XlWNqipM/edit#slide=id.g2ef2341fd89_0_311">week8_presentation - Google Slides</A>
							</DL><p>
							<DT><H3 FOLDED>compiler-study-meeting-notes</H3>
							<DL><p>
								<DT><A HREF="https://carpedm30.notion.site/ebd2c4ec3ab9479e8a1563e900a710af?v=9a7d402493c043078dbc172b457aab13">Diffusion opt meeting notes</A>
							</DL><p>
							<DT><A HREF="https://carpedm30.notion.site/AI-Compiler-Study-aaf4cff2c8734e50ad95ac6230dbd80b">‚ôüÔ∏è AI Compiler Study</A>
							<DT><A HREF="https://github.com/ai-compiler-study">AI Compiler Study</A>
							<DT><A HREF="https://pytorch.org/blog/cuda-free-inference-for-llms/?utm_content=306418723&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024">CUDA-Free Inference for LLMs | PyTorch</A>
							<DT><A HREF="https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/">CUTLASS Tutorial: Efficient GEMM kernel designs with Pipelining ‚Äì Colfax Research</A>
						</DL><p>
						<DT><H3 FOLDED>machine learning compilation</H3>
						<DL><p>
							<DT><A HREF="https://mlc.ai/">Machine Learning Compiler ‚Äî Machine Learing Compiler 0.0.1 documentation</A>
						</DL><p>
						<DT><H3 FOLDED>compilers-tuning</H3>
						<DL><p>
							<DT><A HREF="https://research.google/blog/advancements-in-machine-learning-for-machine-learning/">Advancements in machine learning for machine learning (Google AI)</A>
							<DT><A HREF="https://www.youtube.com/watch?v=esD_zvAf49I">Autotuning Production Machine Learning Compilers | SAMPL Talk 2021/11/04 - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>ai-compilers-people</H3>
						<DL><p>
							<DT><A HREF="https://github.com/skye?tab=stars">skye (Skye Wanderman-Milne) / Starred</A>
							<DT><A HREF="https://pytorch.org/docs/stable/community/persons_of_interest.html">PyTorch Governance | Maintainers ‚Äî PyTorch 2.1 documentation</A>
							<DT><A HREF="https://github.com/albanD">albanD</A>
							<DT><A HREF="https://github.com/ptillet">ptillet (Philippe Tillet) OpenAI Triton</A>
							<DT><A HREF="https://twitter.com/main_horse/status/1742013125090795531">main_horse</A>
							<DT><A HREF="https://github.com/philipturner/metal-flash-attention">Philip Turner: metal-flash-attention</A>
							<DT><A HREF="https://twitter.com/fluffykittnmeow">fluffy (Triton &amp; Tinygrad)</A>
							<DT><A HREF="https://github.com/Bruce-Lee-LY">Bruce-Lee-LY (Bruce-Lee-LY)</A>
							<DT><A HREF="https://twitter.com/MimeeXu/status/1736045781486846184">ML For Systems: Bill Dally (NVIDIA)</A>
							<DT><A HREF="https://github.com/scott-gray">scott-gray (Scott Gray) OpenAI</A>
							<DT><A HREF="https://github.com/sjfeng1999">sjfeng1999 (Feng Shijie)</A>
							<DT><A HREF="https://github.com/daadaada">daadaada (Da Yan)</A>
							<DT><A HREF="https://www.linkedin.com/in/rawn-henry/">Rawn Henry (NVIDIA)</A>
							<DT><A HREF="https://www.linkedin.com/in/quentincolombet/?originalSubdomain=ch">Quentin Colombet ML compiler (Google)</A>
							<DT><A HREF="https://www.linkedin.com/in/pradeep-ramani/">Pradeep Ramani (NVIDIA)</A>
							<DT><A HREF="https://github.com/thakkarV">Vijay Thakkar (NVIDIA)</A>
							<DT><A HREF="https://github.com/VictorTaelin">VictorTaelin (Victor Taelin)</A>
						</DL><p>
						<DT><H3 FOLDED>ai-compilers-tracing</H3>
						<DL><p>
							<DT><A HREF="https://github.com/facebookresearch/xformers/blob/ad986981b141a218bf07bf968e920051ff2c7b41/xformers/benchmarks/benchmark_mem_eff_attention.py#L85">xformers/xformers/benchmarks/benchmark_mem_eff_attention.py at ad986981b141a218bf07bf968e920051ff2c7b41 ¬∑ facebookresearch/xformers</A>
							<DT><A HREF="https://github.com/facebookresearch/xformers/blob/ad986981b141a218bf07bf968e920051ff2c7b41/xformers/benchmarks/benchmark_mem_eff_attention.py#L85">xformers/xformers/benchmarks/benchmark_mem_eff_attention.py</A>
						</DL><p>
						<DT><H3 FOLDED>ai-compilers-lectures</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=139UPjoq7Kw">Building Machine Learning Systems for a Trillion Trillion Floating Point Operations - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>PL</H3>
						<DL><p>
							<DT><H3 FOLDED>Python</H3>
							<DL><p>
								<DT><H3 FOLDED>py-virtual-environment</H3>
								<DL><p>
									<DT><H3 FOLDED>pipenv</H3>
									<DL><p>
										<DT><A HREF="https://pipenv.pypa.io/en/stable/">Pipenv</A>
										<DT><A HREF="https://pipenv-fork.readthedocs.io/en/latest/basics.html">Basic Usage of Pipenv</A>
										<DT><A HREF="https://stackoverflow.com/questions/50161551/set-python-version-when-creating-virtualenv-using-pipenv">Set python version when creating virtualenv</A>
									</DL><p>
									<DT><H3 FOLDED>py-virtual-environment-vanilla</H3>
									<DL><p>
										<DT><A HREF="https://docs.python.org/3/tutorial/venv.html">12. Virtual Environments and Packages ‚Äî Python 3.9.6 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>conda</H3>
									<DL><p>
										<DT><H3 FOLDED>conda-linux</H3>
										<DL><p>
											<DT><H3 FOLDED>miniconda</H3>
											<DL><p>
												<DT><A HREF="https://www.anaconda.com/docs/getting-started/miniconda/install">Installing Miniconda - Anaconda</A>
												<DT><A HREF="https://www.anaconda.com/docs/getting-started/miniconda/install#to-download-an-older-version">Installing Miniconda - Anaconda</A>
											</DL><p>
											<DT><A HREF="https://docs.anaconda.com/anaconda/install/linux/">Installing on Linux ‚Äî Anaconda documentation</A>
											<DT><A HREF="https://repo.anaconda.com/archive/">Index of conda</A>
											<DT><A HREF="https://stackoverflow.com/questions/28852841/install-anaconda-on-ubuntu-or-linux-via-command-line">python - Install Anaconda on Ubuntu (or Linux) via command line - Stack Overflow</A>
											<DT><A HREF="https://medium.com/data-professor/how-to-install-conda-on-google-colab-e7bbf9036f76">How to install conda on Google Colab</A>
											<DT><A HREF="https://askubuntu.com/questions/1268833/error-command-path-to-env-bin-python3-7-im-ensurepip-upgrade">python - Error: Command '['/path/to/env/bin/python3.7', '-Im', 'ensurepip', '--upgrade', '--default-pip']' returned non-zero exit status 1 - Ask Ubuntu</A>
										</DL><p>
										<DT><H3 FOLDED>conda-scripts</H3>
										<DL><p>
											<DT><A HREF="https://github.com/fastai/fastsetup/blob/master/setup-conda.sh">fastsetup/setup-conda.sh at master ¬∑ fastai/fastsetup</A>
										</DL><p>
										<DT><H3 FOLDED>conda-env-vars</H3>
										<DL><p>
											<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/01965457bf998f8c314a8dab921403b399e96dc5/misc/setup.sh#L15">gpu-experiments/misc/setup.sh: conda env config vars set MEGAKERNELS_ROOT=...</A>
										</DL><p>
										<DT><A HREF="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">Managing environments ‚Äî conda 4.12.0</A>
										<DT><A HREF="https://stackoverflow.com/questions/41060382/using-pip-to-install-packages-to-anaconda-environment">python - Using Pip to install packages to conda env</A>
										<DT><A HREF="https://stackoverflow.com/questions/51042589/conda-version-pip-install-r-requirements-txt-target-lib">environment.yml</A>
										<DT><A HREF="https://datumorphism.leima.is/til/programming/python/python-anaconda-install-requirements/">Installing a specific Python pip version within the virtual environment</A>
										<DT><A HREF="https://repo.anaconda.com/archive/">Index of conda</A>
										<DT><A HREF="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#viewing-a-list-of-your-environments">Managing environments ‚Äî conda 4.14.0.post16+8b846957c documentation</A>
										<DT><A HREF="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-python.html">Managing Python ‚Äî conda 4.14.0</A>
										<DT><A HREF="https://whiteboxml.com/blog/the-definitive-guide-to-python-virtual-environments-with-conda">5.2 Packaging a conda environment with conda-pack</A>
										<DT><A HREF="https://stackoverflow.com/questions/50005949/python-3-2-in-anaconda">Python 3.2 in anaconda - Stack Overflow</A>
										<DT><A HREF="https://stackoverflow.com/questions/66607225/adding-python-3-7-to-anaconda">pip - Adding Python 3.7 to Anaconda - Stack Overflow</A>
										<DT><A HREF="https://stackoverflow.com/questions/70205633/cannot-install-python-3-7-on-osx-arm64">conda - Cannot install Python 3.7 on osx-arm64 - Stack Overflow</A>
									</DL><p>
									<DT><H3 FOLDED>virtualenv</H3>
									<DL><p>
										<DT><A HREF="https://gist.github.com/Geoyi/d9fab4f609e9f75941946be45000632b">virtualenv man</A>
									</DL><p>
									<DT><A HREF="https://towardsdatascience.com/virtual-environments-104c62d48c54">A Guide to Python‚Äôs Virtual Environments</A>
									<DT><A HREF="https://towardsdatascience.com/python-and-the-module-search-path-e71ae7a7e65f">Python and the Module Search Path</A>
									<DT><A HREF="https://towardsdatascience.com/python-the-system-path-and-how-conda-and-pyenv-manipulate-it-234f8e8bbc3e">PATH and conda</A>
								</DL><p>
								<DT><H3 FOLDED>py-package-manager</H3>
								<DL><p>
									<DT><H3 FOLDED>pip</H3>
									<DL><p>
										<DT><H3 FOLDED>pip-freeze</H3>
										<DL><p>
											<DT><A HREF="https://pip.pypa.io/en/stable/cli/pip_freeze/">pip freeze | grep cudnn</A>
										</DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=gSKTfG1GXYQ">(1) uv: An Extremely Fast Python Package Manager - YouTube</A>
										<DT><A HREF="https://github.com/triton-lang/triton/issues/4310">install python module from latest or custom repo commit</A>
										<DT><A HREF="https://grok.com/c/f6fb8957-d759-4570-abe5-3ef59b104f79?rid=56725bd2-5822-4995-80d6-1613f3b166ea">GitHub Python Package Installation Guide - Grok</A>
									</DL><p>
									<DT><H3 FOLDED>uv</H3>
									<DL><p>
										<DT><A HREF="https://pypi.org/project/uv/">uv ¬∑ PyPI</A>
										<DT><A HREF="https://docs.astral.sh/uv/guides/integration/pytorch/#using-a-pytorch-index">torch uv</A>
										<DT><A HREF="https://x.com/isidentical/status/1944239784874193287">(1) batuhan the fal guy en X: "Back in 2022 at @fal, we built our own lazy environment packing format specifically to optimize container startup times (we knew the workloads were going to be very diverse, and there was a GPU crunch so scaling to 0 and scaling back up fast when there is demand was key). The" / X</A>
										<DT><A HREF="https://docs.astral.sh/uv/pip/packages/">uv pip install "git+https://github.com/astral-sh/ruff"</A>
									</DL><p>
									<DT><H3 FOLDED>py-brew</H3>
									<DL><p>
										<DT><A HREF="https://docs.brew.sh/Homebrew-and-Python">Python ‚Äî Homebrew Documentation</A>
									</DL><p>
									<DT><A HREF="https://stackoverflow.com/questions/46375576/get-the-list-of-packages-installed-in-anaconda">Get the list of packages installed in Anaconda</A>
									<DT><A HREF="https://stackoverflow.com/questions/41060382/using-pip-to-install-packages-to-anaconda-environment">python - Using Pip to install packages to Anaconda Environment</A>
									<DT><A HREF="https://github.com/pdm-project/pdm">pdm-project/pdm: A modern Python package and dependency manager supporting the latest PEP standards</A>
								</DL><p>
								<DT><H3 FOLDED>py-visualization</H3>
								<DL><p>
									<DT><A HREF="https://matplotlib.org/stable/tutorials/introductory/pyplot.html#">Pyplot tutorial ‚Äî Matplotlib 3.5.2 documentation</A>
									<DT><A HREF="https://twitter.com/andfanilo/status/1530505914981179392/photo/2">Official cheatsheet</A>
								</DL><p>
								<DT><H3 FOLDED>py-idioms</H3>
								<DL><p>
									<DT><A HREF="https://note.nkmk.me/en/python-tuple-list-unpack/">Unpack a tuple / list in Python</A>
									<DT><A HREF="https://www.freecodecamp.org/news/list-comprehension-in-python/">List Comprehension in Python Explained for Beginners</A>
									<DT><A HREF="https://towardsdatascience.com/elegant-and-efficient-usage-of-if-else-clauses-d41d3e88fe07">Elegant And Efficient Usage of If-Else Clauses</A>
									<DT><A HREF="https://towardsdatascience.com/8-more-python-best-practices-for-writing-industry-standard-code-64d97f42da5e">8 More Python Best Practices for Writing Industry-Standard Code</A>
									<DT><A HREF="https://www.w3schools.com/python/ref_dictionary_items.asp">Python Dictionary items() Method</A>
									<DT><A HREF="https://realpython.com/python-type-checking/">Python Type Checking (Guide)</A>
									<DT><A HREF="https://github.com/openai/openai-quickstart-python/blob/master/app.py">String template and formatting</A>
									<DT><A HREF="https://docs.python.org/3/library/functools.html">functools ‚Äî Higher-order functions and operations on callable objects</A>
									<DT><A HREF="https://pyneng.readthedocs.io/en/latest/book/additional_info/naming_conventions/underscore_names.html">Underscore in names - Python for network engineers</A>
									<DT><A HREF="https://docs.python.org/3/library/pprint.html">pprint ‚Äî Data pretty printer ‚Äî Python 3.10.6 documentation</A>
									<DT><A HREF="https://stackoverflow.com/questions/65214482/make-list-of-dictionaries-overwriting-one-key-entry-from-a-list-using-iterators">make list of dictionaries overwriting one key entry from a list using iterators</A>
									<DT><A HREF="https://github.com/lovasoa/marshmallow_dataclass">Dataclasses</A>
									<DT><A HREF="https://stackoverflow.com/questions/6578986/how-to-convert-json-data-into-a-python-object">How to convert JSON data into a Python object? - Stack Overflow</A>
									<DT><A HREF="https://towardsdatascience.com/how-to-use-variable-number-of-arguments-in-python-functions-d3a49a9b7db6">*args &amp; **kwargs</A>
									<DT><A HREF="https://www.programiz.com/python-programming/property">@property</A>
									<DT><A HREF="https://stackoverflow.com/questions/6981717/pythonic-way-to-combine-for-loop-and-if-statement">Combine for-loop and if-statement</A>
									<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/examples/llm_serving/model/wrapper.py#L501">model_class (dynamic import)</A>
								</DL><p>
								<DT><H3 FOLDED>py-build-system</H3>
								<DL><p>
									<DT><A HREF="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/">pyproject.toml - pip documentation v22.2</A>
									<DT><A HREF="https://stackoverflow.com/questions/62983756/what-is-pyproject-toml-file-for">What is pyproject.toml file for?</A>
									<DT><A HREF="https://docs.python.org/3/library/functions.html#compile">Built-in Functions ‚Äî Python 3.10.8 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>py-fmt</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/yapf">google/yapf: A formatter for Python files</A>
									<DT><A HREF="https://realpython.com/python-f-strings/#multiline-f-strings">f-strings</A>
									<DT><A HREF="https://google.github.io/styleguide/pyguide.html">styleguide | Style guides for Google-originated open-source projects</A>
								</DL><p>
								<DT><H3 FOLDED>py-functional-programming</H3>
								<DL><p>
									<DT><A HREF="https://towardsdatascience.com/if-you-can-write-functions-you-can-use-dask-bbb6d8b3a248">If You Can Write Functions, You Can Use Dask</A>
									<DT><A HREF="https://github.com/kykosic/pycats">kykosic/pycats: Functional Python with Typeclasses and Categories</A>
								</DL><p>
								<DT><H3 FOLDED>py-profiling</H3>
								<DL><p>
									<DT><H3 FOLDED>py-spy</H3>
									<DL><p>
										<DT><A HREF="https://www.benfrederickson.com/profiling-native-python-extensions-with-py-spy/">Profiling Native Python Extensions</A>
										<DT><A HREF="https://github.com/jlfwong/speedscope">jlfwong/speedscope: üî¨ A fast, interactive web-based viewer for performance profiles.</A>
										<DT><A HREF="https://x.com/vikhyatk/status/1971348667467784493">profile my inference server to find CPU bottlenecks</A>
										<DT><A HREF="https://github.com/benfred/py-spy">you can connect to any running python process and see what it's doing</A>
										<DT><A HREF="https://github.com/lee101/dotfiles/blob/master/agents/README.md">dotfiles/agents/README.md at master ¬∑ lee101/dotfiles</A>
									</DL><p>
									<DT><A HREF="https://blog.codingconfessions.com/p/python-profilers-intro">Everything You Wanted to Know About Profilers in Python (main)</A>
									<DT><A HREF="https://github.com/jrfonseca/gprof2dot">jrfonseca/gprof2dot: Converts profiling output to a dot graph.</A>
									<DT><A HREF="https://github.com/bloomberg/memray">bloomberg/memray: Memray is a memory profiler for Python</A>
									<DT><A HREF="https://github.com/vpelletier/pprofile">vpelletier/pprofile: Line-granularity, thread-aware deterministic and statistic pure-python profiler</A>
								</DL><p>
								<DT><H3 FOLDED>py-configuration</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/gin-config">Gin provides a lightweight configuration framework for Python</A>
									<DT><A HREF="https://www.bitecode.dev/p/python-as-a-configuration-language">Python as a configuration language - Bite code!</A>
									<DT><A HREF="https://www.bitecode.dev/">Bite code! | Substack</A>
								</DL><p>
								<DT><H3 FOLDED>py-debug</H3>
								<DL><p>
									<DT><H3 FOLDED>pdb</H3>
									<DL><p>
										<DT><A HREF="https://docs.python.org/3/library/pdb.html">pdb ‚Äî The Python Debugger ‚Äî Python 3.10.5 documentation</A>
										<DT><A HREF="https://www.uni-muenster.de/AMM/num/Vorlesungen/Pythonkurs_SS15/pdb_cheatsheet.pdf">pdb cheatsheet</A>
									</DL><p>
									<DT><H3 FOLDED>py-code</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=l8pRSuU81PU">import code; code.interact(local=locals())</A>
									</DL><p>
									<DT><H3 FOLDED>debugpy</H3>
									<DL><p>
										<DT><A HREF="https://github.com/drisspg/transformer_nuggets/blob/85e385b87f5a83bef6e2acfb56a273cb50a1fb1d/transformer_nuggets/__init__.py">transformer_nuggets/transformer_nuggets/__init__.py</A>
									</DL><p>
									<DT><A HREF="https://docs.python.org/3/library/pdb.html">pdb ‚Äî The Python Debugger ‚Äî Python 3.10.5 documentation</A>
									<DT><A HREF="https://github.com/xdit-project/xDiT/issues/324">FLUX Hopper benchmarking ¬∑ Issue #324 ¬∑ xdit-project/xDiT</A>
								</DL><p>
								<DT><H3 FOLDED>py-utils</H3>
								<DL><p>
									<DT><A HREF="https://docs.python.org/3/library/contextlib.html">contextlib ‚Äî Utilities for with-statement contexts ‚Äî Python 3.10.6 documentation</A>
									<DT><A HREF="https://book.pythontips.com/en/latest/context_managers.html">27. Context Managers ‚Äî Python Tips 0.1 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>py-built-in</H3>
								<DL><p>
									<DT><H3 FOLDED>py-iterators-generators</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=yadfyn6-TzE">20240104 Iterators, Generators</A>
										<DT><A HREF="https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do">Iterable &amp; Generators &amp; Yield</A>
									</DL><p>
									<DT><H3 FOLDED>hasattr</H3>
									<DL><p>
										<DT><A HREF="https://www.w3schools.com/python/ref_func_hasattr.asp">Python hasattr() Function</A>
										<DT><A HREF="https://www.geeksforgeeks.org/python-hasattr-method/">Python hasattr() method - GeeksforGeeks</A>
									</DL><p>
									<DT><H3 FOLDED>magic methods</H3>
									<DL><p>
										<DT><A HREF="https://rszalski.github.io/magicmethods/">A Guide to Python's Magic Methods</A>
									</DL><p>
									<DT><H3 FOLDED>py-string-formattng</H3>
									<DL><p>
										<DT><A HREF="https://docs.python.org/3/tutorial/inputoutput.html">String Formattng: 7. Input and Output ‚Äî Python 3.10.6 documentation</A>
										<DT><A HREF="https://www.bitecode.dev/p/string-manipulations-python-beginners">String manipulations Python beginners should know</A>
									</DL><p>
									<DT><H3 FOLDED>built-in-pattern-matching</H3>
									<DL><p>
										<DT><A HREF="https://peps.python.org/pep-0636/">PEP 636 ‚Äì Structural Pattern Matching: Tutorial | peps.python.org</A>
									</DL><p>
									<DT><A HREF="https://docs.python.org/3/library/functions.html#dir">dir(): With an argument, attempt to return a list of valid attributes for that object.</A>
									<DT><A HREF="https://docs.python.org/3/library/os.html#os.system">os.system()</A>
									<DT><A HREF="https://docs.python.org/3/whatsnew/3.8.html">Walrus Operator</A>
									<DT><A HREF="https://docs.python.org/3/tutorial/inputoutput.html">String Formattng: 7. Input and Output ‚Äî Python 3.10.6 documentation</A>
									<DT><A HREF="https://docs.python.org/3/tutorial/classes.html">9. Classes ‚Äî Python 3.10.6 documentation</A>
									<DT><A HREF="https://www.geeksforgeeks.org/classmethod-in-python/">classmethod() in Python - GeeksforGeeks</A>
									<DT><A HREF="https://devtut.github.io/python/property-objects.html">Python - Property Objects</A>
									<DT><A HREF="https://stackoverflow.com/questions/34439/finding-what-methods-a-python-object-has">dir() - Finding what methods a Python object</A>
									<DT><A HREF="https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do">Iterable &amp; Generators &amp; Yield</A>
									<DT><A HREF="https://rszalski.github.io/magicmethods/">A Guide to Python's Magic Methods</A>
									<DT><A HREF="https://docs.python.org/3/library/shelve.html">shelve ‚Äî Python object persistence ‚Äî Python 3.12.0 documentation</A>
									<DT><A HREF="https://wiki.python.org/moin/UsingSlots">UsingSlots - Python Wiki</A>
									<DT><A HREF="https://www.bitecode.dev/p/python-variables-references-and-mutability">Python variables, references and mutability - Bite code!</A>
									<DT><A HREF="https://www.browserstack.com/guide/assert-in-python">Assert in Python: What is it and How to use it | BrowserStack</A>
								</DL><p>
								<DT><H3 FOLDED>py-async</H3>
								<DL><p>
									<DT><H3 FOLDED>trio</H3>
									<DL><p>
										<DT><A HREF="https://github.com/python-trio/trio">python-trio/trio: Trio ‚Äì a friendly Python library for async concurrency and I/O</A>
										<DT><A HREF="https://trio.readthedocs.io/en/stable/tutorial.html">Tutorial ‚Äî Trio 0.32.0 documentation</A>
									</DL><p>
									<DT><A HREF="https://superfastpython.com/asyncio-gather/">asyncio.gather()</A>
									<DT><A HREF="https://x.com/mitsuhiko/status/1920384040005173320">(1) Armin Ronacher ‚áå en X: "asyncio is still really wild in 2025. I haven't actively written asyncio code in a while but now that I have done it for a week agian, I noticed that most problems from when I used it last are still unresolved. Problem 1: asyncio.create_task is a massive footgun because it can https://t.co/ZnosK7Rj2h" / X</A>
								</DL><p>
								<DT><H3 FOLDED>py-compiler</H3>
								<DL><p>
									<DT><H3 FOLDED>cython</H3>
									<DL><p>
										<DT><H3 FOLDED>ctypes</H3>
										<DL><p>
											<DT><A HREF="https://gist.github.com/fxkamd/ffd02d66a2863e444ec208ea4f3adc48">Observations about HSA and KFD backends in TinyGrad  (fast prototyping)</A>
											<DT><A HREF="https://pybind11.readthedocs.io/en/stable/">pybind11 documentation</A>
										</DL><p>
										<DT><H3 FOLDED>pxd &amp; pyx</H3>
										<DL><p>
											<DT><A HREF="https://cython.readthedocs.io/en/latest/src/tutorial/pxd_files.html">pxd files ‚Äî Cython 3.1.0a0 documentation</A>
											<DT><A HREF="https://github.com/rapidsai/cudf/tree/branch-0.7/python/cudf/bindings">cudf/python/cudf/bindings</A>
										</DL><p>
										<DT><H3 FOLDED>frame evaluation</H3>
										<DL><p>
											<DT><A HREF="https://peps.python.org/pep-0523/">PEP 523 ‚Äì Adding a frame evaluation API to CPython | peps.python.org</A>
											<DT><A HREF="https://www.youtube.com/watch?v=egZB5Uxki0I">torchdynamo deep dive - YouTube</A>
										</DL><p>
										<DT><A HREF="https://github.com/explosion/cython-blis?tab=readme-ov-file">cython-blis?tab=readme-ov-file</A>
										<DT><A HREF="https://cython.org/">Cython: C-Extensions for Python</A>
										<DT><A HREF="https://github.com/facebookincubator/cinder">facebookincubator/cinder: Cinder is Meta's internal performance-oriented production version of CPython.</A>
										<DT><A HREF="https://cython.readthedocs.io/en/latest/src/tutorial/pxd_files.html">pxd files ‚Äî Cython 3.1.0a0 documentation</A>
										<DT><A HREF="https://www.youtube.com/watch?v=GXwYjI9cJd0">Lightning Talk: Write Valid C++ and Python in One File - Roth Michaels - CppCon 2023 - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=MUISz2qA640&t=19s">Will Ada Replace C/C++? - YouTube</A>
										<DT><A HREF="https://trycinder.com/">Cinder Explorer</A>
										<DT><A HREF="https://github.com/mypyc/mypyc">mypyc/mypyc: Compile type annotated Python to fast C extensions</A>
										<DT><A HREF="https://blog.codingconfessions.com/p/cpython-memory-management-internals?utm_source=profile&utm_medium=reader2">CPython Memory Management Internals - by Abhinav Upadhyay</A>
										<DT><A HREF="https://github.com/google/pycnite">google/pycnite: A collection of utilities for working with compiled Python bytecode.</A>
										<DT><A HREF="https://x.com/abhi9u/status/1839631899876032540">CPython runtime internals</A>
										<DT><A HREF="https://github.com/apache/tvm/pull/18124">[Refactor] Build cython with isolate environment by LeiWang1999 ¬∑ Pull Request #18124 ¬∑ apache/tvm</A>
									</DL><p>
									<DT><H3 FOLDED>clang2py</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/extra/nv_gpu_driver/codegen.sh">tinygrad/extra/nv_gpu_driver/codegen.sh at master ¬∑ tinygrad/tinygrad</A>
										<DT><A HREF="https://github.com/trolldbois/ctypeslib/blob/master/ctypeslib/clang2py.py">ctypeslib/ctypeslib/clang2py.py at master ¬∑ trolldbois/ctypeslib</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/de832d26c64a9ec575e47aeb58efe27a0ccf4e0b/autogen_stubs.sh">tinygrad/autogen_stubs.sh  (runtimes)</A>
									</DL><p>
									<DT><H3 FOLDED>LPython</H3>
									<DL><p>
										<DT><A HREF="https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/">LPython: Novel, Fast, Retargetable Python Compiler -</A>
										<DT><A HREF="https://github.com/lcompilers/lpython">lcompilers/lpython: Python compiler</A>
										<DT><A HREF="https://dev.lpython.org/">LPython</A>
									</DL><p>
									<DT><A HREF="https://lpython.org/blog/2023/07/lpython-novel-fast-retargetable-python-compiler/">LPython: Novel, Fast, Retargetable Python Compiler -</A>
									<DT><A HREF="https://pybind11.readthedocs.io/en/stable/">pybind11 documentation</A>
								</DL><p>
								<DT><H3 FOLDED>py-PEP</H3>
								<DL><p>
									<DT><A HREF="https://peps.python.org/pep-0604/">PEP 604 ‚Äì Allow writing union types as X | Y | peps.python.org</A>
									<DT><A HREF="https://www.youtube.com/watch?v=YaDYUQ5mD5Q">NEW generic / alias syntax for python 3.12 (PEP 695) (intermediate) anthony explains #561 - YouTube</A>
									<DT><A HREF="https://peps.python.org/pep-0523/">PEP 523 ‚Äì Adding a frame evaluation API to CPython | peps.python.org</A>
								</DL><p>
								<DT><H3 FOLDED>py-type-system</H3>
								<DL><p>
									<DT><H3 FOLDED>py-types</H3>
									<DL><p>
										<DT><H3 FOLDED>TypeVar</H3>
										<DL><p>
											<DT><A HREF="https://discuss.python.org/t/differences-in-bound-object-vs-bound-any/27052">Differences in bound=object vs bound=Any - Python Help - Discussions on Python.org</A>
											<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/bb2b2959a222594dd8a41b8bb18d7b6fe280730a/server/text_generation_server/models/model.py#L12">HF-TGI: model.py#L12 TypeVar("B", bound=Batch)</A>
											<DT><A HREF="https://stackoverflow.com/questions/59933946/difference-between-typevart-a-b-and-typevart-bound-uniona-b">python - Difference between TypeVar('T', A, B) and TypeVar('T', bound=Union[A, B]) - Stack Overflow</A>
										</DL><p>
										<DT><A HREF="http://mypy-lang.org/">mypy - Optional Static Typing for Python</A>
										<DT><A HREF="https://stackoverflow.com/questions/60459641/how-do-you-get-mypy-to-recognize-a-newer-version-of-python">How do you get mypy to recognize a newer version of python? - Stack Overflow</A>
										<DT><A HREF="https://kobzol.github.io/rust/python/2023/05/20/writing-python-like-its-rust.html">Writing Python like it‚Äôs Rust | Kobzol‚Äôs blog</A>
										<DT><A HREF="https://github.com/kykosic/pycats">kykosic/pycats: Functional Python with Typeclasses and Categories</A>
										<DT><A HREF="https://github.com/twtrubiks/python-notes/blob/master/MappingProxyType_tutorial.py">python-notes/MappingProxyType_tutorial.py</A>
									</DL><p>
									<DT><H3 FOLDED>py-interfaces-classes</H3>
									<DL><p>
										<DT><A HREF="https://github.com/google/seqio/blob/1e3a46e690f4c867e7acca7e836c425a7b0f32a7/seqio/dataset_providers.py#L244">typing.Protocol: dataset_providers.py#L244 (seqio)</A>
									</DL><p>
									<DT><H3 FOLDED>static analyzer</H3>
									<DL><p>
										<DT><H3 FOLDED>mypy</H3>
										<DL><p>
											<DT><A HREF="https://mypy-lang.org/">mypy - Optional Static Typing for Python</A>
											<DT><A HREF="http://mypy-lang.org/">mypy - Optional Static Typing for Python</A>
											<DT><A HREF="https://stackoverflow.com/questions/60459641/how-do-you-get-mypy-to-recognize-a-newer-version-of-python">How do you get mypy to recognize a newer version of python? - Stack Overflow</A>
											<DT><A HREF="https://github.com/python/mypy/issues/4440">Proper way to type circular dependency</A>
											<DT><A HREF="https://vickiboykis.com/2023/12/11/why-if-type_checking/">Why if TYPE_CHECKING?</A>
											<DT><A HREF="https://www.stefaanlippens.net/circular-imports-type-hints-python.html">Yet another solution to dig you out of a circular import hole in Python - Stefaan Lippens inserts content here</A>
											<DT><A HREF="https://peps.python.org/pep-0484/#forward-references">PEP 484 ‚Äì Type Hints | peps.python.org</A>
											<DT><A HREF="https://mypy.readthedocs.io/en/stable/getting_started.html#strict-mode-and-configuration">Getting started - mypy 1.10.0 documentation</A>
											<DT><A HREF="https://www.youtube.com/watch?v=tH3Nul6jDQM">typing the untype-able with mypy plugins (advanced) anthony explains #574 - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>ty</H3>
										<DL><p>
											<DT><A HREF="https://x.com/charliermarsh/status/2001038023434047623">(1) Charlie Marsh en X: "Announcing the Beta release of ty: an extremely fast type checker and language server for Python, written in Rust. We now use ty exclusively in our own projects and are ready to recommend it to motivated users. 10x, 50x, even 100x faster than existing type checkers and LSPs. https://t.co/tYYIADTqmf" / X</A>
											<DT><A HREF="https://astral.sh/blog/ty">ty: An extremely fast Python type checker and language server</A>
										</DL><p>
										<DT><A HREF="https://github.com/google/pytype">google/pytype: A static type analyzer for Python code</A>
									</DL><p>
									<DT><H3 FOLDED>dataclasses</H3>
									<DL><p>
										<DT><A HREF="https://docs.python.org/3/library/dataclasses.html">dataclasses ‚Äî Data Classes ‚Äî Python 3.12.3 documentation</A>
									</DL><p>
									<DT><A HREF="https://docs.python.org/3/library/functions.html#float">Types ‚Äî Python 3.10.5 documentation</A>
									<DT><A HREF="https://peps.python.org/pep-0484/">PEP 484 ‚Äì Type Hints | peps.python.org</A>
									<DT><A HREF="https://www.youtube.com/watch?v=YaDYUQ5mD5Q&t=308s">NEW generic / alias syntax for python 3.12 (PEP 695) (intermediate) anthony explains #561 - YouTube</A>
									<DT><A HREF="https://mypy.readthedocs.io/en/stable/protocols.html">Protocols and structural subtyping - mypy 1.9.0 documentation</A>
									<DT><A HREF="https://vickiboykis.com/2023/12/11/why-if-type_checking/">Why if TYPE_CHECKING?</A>
									<DT><A HREF="https://docs.python.org/3/library/typing.html#constant">typing ‚Äî Support for type hints ‚Äî Python 3.12.3 documentation</A>
									<DT><A HREF="https://stackoverflow.com/questions/61545580/how-does-mypy-use-typing-type-checking-to-resolve-the-circular-import-annotation">python - How does mypy use typing.TYPE_CHECKING to resolve the circular import annotation problem? - Stack Overflow</A>
									<DT><A HREF="https://www.youtube.com/watch?v=tH3Nul6jDQM">typing the untype-able with mypy plugins (advanced) anthony explains #574 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>py-packaging</H3>
								<DL><p>
									<DT><H3 FOLDED>pyproject.toml</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/pull/2187/files#diff-50c86b7ed8ac2cf95bd48334961bf0530cdc77b5a56f852c5c61b89d735fd711">Modernize setup.py by Eliulm ¬∑ Pull Request #2187 ¬∑ tinygrad/tinygrad</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/d8a50d96f943c656672dc0cdb3f5fd3ed53abe57/setup.py">tinygrad/setup.py: keep for backwards compability</A>
										<DT><A HREF="https://gregoryszorc.com/blog/2023/10/30/my-user-experience-porting-off-setup.py/">Porting Off setup.py</A>
										<DT><A HREF="https://github.com/pypa/setuptools/issues/2088">Please do not remove `setup.py install` as it is needed for distribution packagers ¬∑ Issue #2088 ¬∑ pypa/setuptools</A>
										<DT><A HREF="https://setuptools.pypa.io/en/latest/userguide/dependency_management.html">optional dependencies: setuptools extra_require</A>
										<DT><A HREF="https://packaging.python.org/en/latest/guides/writing-pyproject-toml/">Writing your pyproject.toml - Python Packaging User Guide</A>
										<DT><A HREF="https://packaging.python.org/en/latest/specifications/dependency-specifiers/#dependency-specifiers">Dependency specifiers - Python Packaging User Guide</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/pull/2277">George Hotz suggestion: modernize setup.py</A>
										<DT><A HREF="https://github.com/meta-pytorch/tritonbench/blob/main/pyproject.toml">tritonbench/pyproject.toml at main ¬∑ meta-pytorch/tritonbench</A>
									</DL><p>
									<DT><H3 FOLDED>setup.py</H3>
									<DL><p>
										<DT><A HREF="https://github.com/python-poetry/poetry">python-poetry/poetry: Python packaging and dependency management made easy</A>
										<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/setup.py">DeepSpeed/setup.py at master ¬∑ microsoft/DeepSpeed</A>
										<DT><A HREF="https://setuptools.pypa.io/en/latest/userguide/package_discovery.html#flat-layout">Package Discovery and Namespace Packages - setuptools 69.2.0.post20240313 documentation</A>
										<DT><A HREF="https://xebia.com/blog/a-practical-guide-to-using-setup-py/">A Practical Guide to Using Setup.py - Xebia</A>
										<DT><A HREF="https://github.com/beeware/briefcase/issues/1270">Install a python requirement with an --extra-index-url argument</A>
										<DT><A HREF="https://stackoverflow.com/questions/1594827/cleaning-build-directory-in-setup-py">python - Cleaning build directory in setup.py - Stack Overflow</A>
									</DL><p>
									<DT><H3 FOLDED>py-build-system</H3>
									<DL><p>
										<DT><A HREF="https://build.pypa.io/en/latest/index.html">build 1.2.1</A>
										<DT><A HREF="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/">pyproject.toml - pip documentation v22.2</A>
										<DT><A HREF="https://stackoverflow.com/questions/62983756/what-is-pyproject-toml-file-for">What is pyproject.toml file for?</A>
										<DT><A HREF="https://docs.python.org/3/library/functions.html#compile">Built-in Functions ‚Äî Python 3.10.8 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>wheel</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pypa/wheel">pypa/wheel: The official binary distribution format for Python</A>
										<DT><A HREF="https://wheel.readthedocs.io/en/stable/user_guide.html">installing wheels ‚Äî wheel 0.43.0 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>requirements.txt</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/integration-tests/requirements.txt">text-generation-inference/integration-tests/requirements.txt</A>
									</DL><p>
									<DT><A HREF="https://github.com/python-poetry/poetry">python-poetry/poetry: Python packaging and dependency management made easy</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/setup.py">DeepSpeed/setup.py at master ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://setuptools.pypa.io/en/latest/userguide/package_discovery.html#flat-layout">Package Discovery and Namespace Packages - setuptools 69.2.0.post20240313 documentation</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/setup.py">DeepSpeed/setup.py at master</A>
									<DT><A HREF="https://xebia.com/blog/a-practical-guide-to-setuptools-and-pyproject-toml/">A Practical Guide to Setuptools and Pyproject.toml - Xebia</A>
									<DT><A HREF="https://peps.python.org/pep-0517/">PEP 517 ‚Äì A build-system independent format for source trees | peps.python.org</A>
									<DT><A HREF="https://peps.python.org/pep-0518/">PEP 518 ‚Äì Specifying Minimum Build System Requirements for Python Projects | peps.python.org</A>
								</DL><p>
								<DT><H3 FOLDED>py-cli</H3>
								<DL><p>
									<DT><H3 FOLDED>py-cli-typer</H3>
									<DL><p>
										<DT><A HREF="https://typer.tiangolo.com/">Typer</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/pyproject.toml">text-generation-server = 'text_generation_server.cli:app'</A>
										<DT><A HREF="https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#a-full-example">Writing your pyproject.toml - Python Packaging User Guide</A>
										<DT><A HREF="https://typer.tiangolo.com/tutorial/typer-command/">typer command - Typer</A>
									</DL><p>
									<DT><H3 FOLDED>py-cli-click</H3>
									<DL><p>
										<DT><A HREF="https://click.palletsprojects.com/en/8.1.x/">Welcome to Click ‚Äî Click Documentation (8.1.x)</A>
									</DL><p>
									<DT><H3 FOLDED>chz</H3>
									<DL><p>
										<DT><A HREF="https://github.com/openai/chz">openai/chz</A>
									</DL><p>
									<DT><H3 FOLDED>shlex</H3>
									<DL><p>
										<DT><A HREF="https://github.com/xdit-project/xDiT/issues/324">FLUX Hopper benchmarking ¬∑ Issue #324 ¬∑ xdit-project/xDiT</A>
										<DT><A HREF="https://docs.python.org/3/library/shlex.html">shlex ‚Äî Simple lexical analysis ‚Äî Python 3.13.1 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>py-tui</H3>
									<DL><p>
										<DT><H3 FOLDED>py-rich</H3>
										<DL><p>
											<DT><A HREF="https://github.com/bytedance/trae-agent/blob/main/trae_agent/cli.py">trae-agent/trae_agent/cli.py at main ¬∑ bytedance/trae-agent</A>
											<DT><A HREF="https://github.com/datacrunch-research/mediagen-evals/blob/main/chat/chat_terminal.py">mediagen-evals/chat/chat_terminal.py at main ¬∑ datacrunch-research/mediagen-evals</A>
											<DT><A HREF="https://github.com/Textualize/rich">Textualize/rich: Rich is a Python library for rich text and beautiful formatting in the terminal.</A>
										</DL><p>
										<DT><A HREF="https://www.textualize.io/">Textualize - Home</A>
									</DL><p>
									<DT><A HREF="https://github.com/chengzeyi/piflux/blob/main/src/piflux/config.py">optional_bool_from_env: None &amp; 1 to False and True</A>
									<DT><A HREF="https://x.com/i/bookmarks?post_id=1835575326258401733">(Simo Ryu) why bother with argparse when you can use torchrun with click?</A>
								</DL><p>
								<DT><H3 FOLDED>py-subprocess</H3>
								<DL><p>
									<DT><A HREF="https://github.com/xdit-project/xDiT/issues/324">FLUX Hopper benchmarking ¬∑ Issue #324 ¬∑ xdit-project/xDiT</A>
									<DT><A HREF="https://github.com/DataCrunch-io/xelerate-inferno/blob/main/server/diffusion_generation_server/debug_server.py">xelerate-inferno/server/diffusion_generation_server/debug_server.py at main ¬∑ DataCrunch-io/xelerate-inferno</A>
									<DT><A HREF="https://github.com/datacrunch-research/text-generation-inference/blob/main/server/text_generation_server/debug_backend.py">text-generation-inference/server/text_generation_server/debug_backend.py at main ¬∑ datacrunch-research/text-generation-inference</A>
									<DT><A HREF="https://claude.ai/chat/962b65c7-004c-4184-aac9-c241c672939e">Subprocess Deployment Debug Script: Use Lists - Claude</A>
								</DL><p>
								<DT><H3 FOLDED>py-serialization-deserialization</H3>
								<DL><p>
									<DT><A HREF="https://github.com/ijl/orjson">ijl/orjson: Fast, correct Python JSON library supporting dataclasses, datetimes, and numpy</A>
								</DL><p>
								<DT><H3 FOLDED>py-internals</H3>
								<DL><p>
									<DT><H3 FOLDED>py-bytecode</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>py-logging</H3>
									<DL><p>
										<DT><H3 FOLDED>loguru</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Delgan/loguru">Delgan/loguru: Python logging made (stupidly) simple</A>
											<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/text_generation_server/cli.py">text-generation-inference/server/text_generation_server/cli.py</A>
										</DL><p>
										<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/9b6ef9e1f0d8acaefd989440b27da9069aa69207/deepspeed/utils/logging.py">DeepSpeed/deepspeed/utils/logging.py</A>
										<DT><A HREF="https://docs.python.org/3/howto/logging.html#">Logging HOWTO ‚Äî Python 3.12.3 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>py-imports</H3>
									<DL><p>
										<DT><H3 FOLDED>importlib</H3>
										<DL><p>
											<DT><A HREF="https://docs.python.org/3/library/importlib.html">importlib ‚Äî The implementation of import ‚Äî Python 3.12.3 documentation</A>
											<DT><A HREF="https://github.com/wangzyon/pyInfer/blob/bff1d9800ffd773ab6745f2ea98d4a83dfdb032a/pyinfer/utils/common/config.py#L40">import_modules_from_strings</A>
											<DT><A HREF="https://github.com/huggingface/diffusers/blob/3511a9623f5beabf360df44cc7cb78e33d13ff4e/src/diffusers/utils/import_utils.py#L764">diffusers/src/diffusers/utils/import_utils.py</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=e6zFlbEU76I">Python 3 Gets TONS of New Features | Prime News - YouTube</A>
									<DT><A HREF="https://www.bitecode.dev/">Bite code! | Substack</A>
									<DT><A HREF="https://www.python.org/">Welcome to Python.org</A>
									<DT><A HREF="https://www.bitecode.dev/p/whats-up-python-the-gil-removed-a">What's up, Python? The GIL removed, a new compiler, optparse deprecated...</A>
									<DT><A HREF="https://github.com/LaurentMazare/hojo">LaurentMazare/hojo: A small python library to run iterators in a separate process</A>
									<DT><A HREF="https://www.geeksforgeeks.org/how-to-get-list-of-parameters-name-from-a-function-in-python/">How to get list of parameters name from a function in Python? - GeeksforGeeks</A>
									<DT><A HREF="https://www.bitecode.dev/p/python-variables-references-and-mutability">Python variables, references and mutability - Bite code!</A>
									<DT><A HREF="https://www.bitecode.dev/p/whats-up-python-the-gil-removed-a">What's up, Python? The GIL removed, a new compiler</A>
									<DT><A HREF="https://www.geeksforgeeks.org/how-to-get-list-of-parameters-name-from-a-function-in-python/">How to get list of parameters name from a function</A>
									<DT><A HREF="https://github.com/twtrubiks/python-notes/blob/master/MappingProxyType_tutorial.py">python-notes/MappingProxyType_tutorial.py</A>
									<DT><A HREF="https://www.teach.cs.toronto.edu/~csc110y/fall/notes/06-memory-model/04-python-memory-model-1.html">6.4 The Python Memory Model: Introduction</A>
									<DT><A HREF="https://www.youtube.com/@MichaelFoord/videos">py core object model, closures, decorators, references, iterators</A>
								</DL><p>
								<DT><H3 FOLDED>py-context-managers</H3>
								<DL><p>
									<DT><A HREF="https://docs.python.org/3/library/contextlib.html">contextlib ‚Äî Utilities for with-statement contexts ‚Äî Python 3.10.6 documentation</A>
									<DT><A HREF="https://book.pythontips.com/en/latest/context_managers.html">27. Context Managers ‚Äî Python Tips 0.1 documentation</A>
									<DT><A HREF="https://lwn.net/Articles/706424/">Python context managers [LWN.net]</A>
								</DL><p>
								<DT><H3 FOLDED>py-testing</H3>
								<DL><p>
									<DT><H3 FOLDED>pytest</H3>
									<DL><p>
										<DT><H3 FOLDED>pytest-examples</H3>
										<DL><p>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/tests/pytest.ini">TensorRT-LLM/tests/pytest.ini at main ¬∑ NVIDIA/TensorRT-LLM</A>
											<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/tests/unit/ops/adam/test_adamw.py">DeepSpeed/tests/unit/ops/adam/test_adamw.py</A>
											<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/integration-tests/conftest.py#L284">text-generation-inference/integration-tests/conftest.py</A>
										</DL><p>
										<DT><H3 FOLDED>pytest-debug</H3>
										<DL><p>
											<DT><A HREF="https://chatgpt.com/c/07ff34de-b541-4a89-9242-bb2db5aff30f">Pytest Debugging Options</A>
										</DL><p>
										<DT><H3 FOLDED>syrupy</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://www.bitecode.dev/p/testing-with-python-part-2-moving">Testing with Python (part 2): moving to pytest</A>
										<DT><A HREF="https://www.bitecode.dev/p/testing-with-python-part-3-pytest">Testing with Python (part 3): pytest setup - Bite code!</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/dc514df2afad386739bf8471ab351a86d5c5ffc7/test/conftest.py#L4">pytorch/test/conftest.py</A>
										<DT><A HREF="https://docs.pytest.org/en/7.1.x/how-to/parametrize.html">How to parametrize fixtures and test functions ‚Äî pytest documentation</A>
										<DT><A HREF="https://github.com/tophat/syrupy">tophat/syrupy: :pancakes: The sweeter pytest snapshot plugin</A>
										<DT><A HREF="https://claude.ai/chat/3e157484-1ce9-4dda-91b7-1e6e7072e387">pytest: print statements and logger outputs</A>
										<DT><A HREF="https://docs.pytest.org/en/stable/how-to/skipping.html">pytest.mark.skipif</A>
									</DL><p>
									<DT><H3 FOLDED>unittest</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/test/test_tensor.py">tinygrad/test/test_tensor.py at master ¬∑ tinygrad/tinygrad</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/tests/test_layer.py">TensorRT-LLM/tests/test_layer.py</A>
										<DT><A HREF="https://docs.python.org/3/library/unittest.html#classes-and-functions">unittest ‚Äî Unit testing framework ‚Äî Python 3.12.3 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>property-based testing</H3>
									<DL><p>
										<DT><H3 FOLDED>hypothesis</H3>
										<DL><p>
											<DT><A HREF="https://www.cs.toronto.edu/~david/course-notes/csc110-111/04-function-specification-and-correctness/04-testing-functions-2.html">4.4 Testing Functions II: hypothesis</A>
											<DT><A HREF="https://www.inspiredpython.com/course/testing-with-hypothesis/testing-your-python-code-with-hypothesis">Testing your Python Code with Hypothesis ‚Ä¢ Inspired Python</A>
											<DT><A HREF="https://hypothesis.readthedocs.io/en/latest/quickstart.html">Quick start guide ‚Äî Hypothesis 6.100.2 documentation</A>
											<DT><A HREF="https://hypothesis.readthedocs.io/en/latest/data.html">What you can generate and how ‚Äî Hypothesis 6.100.2 documentation</A>
											<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/test/test_tensor.py">tinygrad/test/test_tensor.py at master</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://abseil.io/docs/python/guides/testing">abseil / Testing</A>
									<DT><A HREF="https://github.com/ezyang/expecttest">ezyang/expecttest ("golden" tests)</A>
									<DT><A HREF="https://github.com/abseil/abseil-py/tree/main">abseil/abseil-py: Abseil Common Libraries (Python)</A>
									<DT><A HREF="https://www.bitecode.dev/p/xmas-decoration-part-1">Xmas decoration, part 1 - Bite code!</A>
									<DT><A HREF="https://www.bitecode.dev/p/testing-with-python-part-1-the-basics">Testing with Python (part 1): the basics - Bite code!</A>
									<DT><A HREF="https://www.bitecode.dev/p/testing-with-python-part-2-moving">Testing with Python (part 2): moving to pytest</A>
									<DT><A HREF="https://www.bitecode.dev/p/testing-with-python-part-4-why-and?utm_source=post-email-title&publication_id=1516188&post_id=144370735&utm_campaign=email-post-title&isFreemail=true&r=1tutvb&triedRedirect=true&utm_medium=email">Testing with Python (part 4): why and what to test?</A>
									<DT><A HREF="https://www.bitecode.dev/p/testing-with-python-part-5-the-different">Testing with Python (part 5): the different types of tests</A>
									<DT><A HREF="https://github.com/george0st/qgate-perf">george0st/qgate-perf: Performance tests under quality gate solution.</A>
								</DL><p>
								<DT><H3 FOLDED>py-refactor</H3>
								<DL><p>
									<DT><H3 FOLDED>AST-based search</H3>
									<DL><p>
										<DT><H3 FOLDED>ast-grep</H3>
										<DL><p>
											<DT><A HREF="https://grok.com/chat/6b45bfb9-770a-47bd-97c2-42d65967c835">Multi-Language Code Refactoring Strategies - Grok</A>
											<DT><A HREF="https://github.com/ast-grep/ast-grep">ast-grep/ast-grep: ‚ö°A CLI tool for code structural search, lint and rewriting. Written in Rust</A>
											<DT><A HREF="https://ast-grep.github.io/playground.html#eyJtb2RlIjoiUGF0Y2giLCJsYW5nIjoiamF2YXNjcmlwdCIsInF1ZXJ5IjoiY29uc29sZS5sb2coJE1BVENIKSIsInJld3JpdGUiOiJsb2dnZXIubG9nKCRNQVRDSCkiLCJzdHJpY3RuZXNzIjoic21hcnQiLCJzZWxlY3RvciI6IiIsImNvbmZpZyI6IiMgWUFNTCBSdWxlIGlzIG1vcmUgcG93ZXJmdWwhXG4jIGh0dHBzOi8vYXN0LWdyZXAuZ2l0aHViLmlvL2d1aWRlL3J1bGUtY29uZmlnLmh0bWwjcnVsZVxucnVsZTpcbiAgYW55OlxuICAgIC0gcGF0dGVybjogY29uc29sZS5sb2coJEEpXG4gICAgLSBwYXR0ZXJuOiBjb25zb2xlLmRlYnVnKCRBKVxuZml4OlxuICBsb2dnZXIubG9nKCRBKSIsInNvdXJjZSI6Ii8vIGNvbnNvbGUubG9nKCkgd2lsbCBiZSBtYXRjaGVkIGJ5IHBhdHRlcm4hXG4vLyBjbGljayBkaWZmIHRhYiB0byBzZWUgcmV3cml0ZS5cblxuZnVuY3Rpb24gdHJ5QXN0R3JlcCgpIHtcbiAgY29uc29sZS5sb2coJ21hdGNoZWQgaW4gbWV0YXZhciEnKVxufVxuXG5jb25zdCBtdWx0aUxpbmVFeHByZXNzaW9uID1cbiAgY29uc29sZVxuICAgLmxvZygnQWxzbyBtYXRjaGVkIScpXG5cbmlmICh0cnVlKSB7XG4gIGNvbnN0IG5vdFRoaXMgPSAnY29uc29sZS5sb2coXCJub3QgbWVcIiknXG59IGVsc2Uge1xuICBjb25zb2xlLmRlYnVnKCdtYXRjaGVkIGJ5IFlBTUwnKVxufSJ9">Playground | ast-grep</A>
											<DT><A HREF="https://gemini.google.com/u/3/app/2076fb342f19b9da">Step 2: Refactor the Comments with ripgrep</A>
										</DL><p>
										<DT><A HREF="https://grok.com/chat/6b45bfb9-770a-47bd-97c2-42d65967c835">Multi-Language Code Refactoring Strategies - Grok</A>
									</DL><p>
									<DT><A HREF="https://github.com/facebookincubator/Bowler">facebookincubator/Bowler: Safe code refactoring for modern Python.</A>
								</DL><p>
								<DT><H3 FOLDED>python-linter-code-formater</H3>
								<DL><p>
									<DT><H3 FOLDED>ruff</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/master/ruff.toml">tinygrad/ruff.toml at master ¬∑ tinygrad/tinygrad</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>py-imports</H3>
								<DL><p>
									<DT><H3 FOLDED>py-lazy-imports</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chengzeyi/stable-fast/blob/fffe290680ec2ddc01f511e8e7fc62357ed901d8/src/sfast/dynamo/backends/registry.py#L4">stable-fast/src/sfast/dynamo/backends/registry.py</A>
										<DT><A HREF="https://github.com/optuna/optuna/blob/master/optuna/integration/__init__.py">optuna/optuna/integration/__init__.py at master</A>
										<DT><A HREF="https://github.com/huggingface/diffusers/blob/42cae93b942ec904ead46c26c42be24422adc92c/src/diffusers/utils/import_utils.py#L760">diffusers/src/diffusers/utils/import_utils.py</A>
										<DT><A HREF="https://github.com/huggingface/diffusers/blob/67bef2027cc461af5bbe73b3c0f35bb1350f5aa8/src/diffusers/pipelines/consistency_models/__init__.py">diffusers/src/diffusers/pipelines/consistency_models/__init__.py</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>py-inheritance</H3>
								<DL><p>
									<DT><H3 FOLDED>py-mixin</H3>
									<DL><p>
										<DT><A HREF="https://www.residentmar.io/2019/07/07/python-mixins.html">Aleksey Bilogur‚Äî Blog</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>py-plots</H3>
								<DL><p>
									<DT><H3 FOLDED>matplotlib</H3>
									<DL><p>
										<DT><A HREF="https://matplotlib.org/stable/gallery/lines_bars_and_markers/step_demo.html#sphx-glr-gallery-lines-bars-and-markers-step-demo-py">Step Demo ‚Äî Matplotlib 3.10.3 documentation</A>
										<DT><A HREF="https://github.com/xjdr-alt/llmri/blob/main/plots.ipynb">llmri/plots.ipynb at main ¬∑ xjdr-alt/llmri</A>
										<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/main/misc/draw_graph.ipynb">gpu-experiments/misc/draw_graph.ipynb at main ¬∑ StuartSul/gpu-experiments</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>py-protocol</H3>
								<DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/vllm/engine/protocol.py#L27">vllm/vllm/engine/protocol.py at main ¬∑ vllm-project/vllm</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/2117f82defd589d97598830df6ec5826187d4541/python/sglang/srt/entrypoints/openai/protocol.py#L4">sglang/python/sglang/srt/entrypoints/openai/protocol.py at 2117f82defd589d97598830df6ec5826187d4541 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/AI-Hypercomputer/JetStream/blob/29329e8e73820993f77cfc8efe34eb2a73f5de98/jetstream/entrypoints/http/protocol.py#L15">JetStream/jetstream/entrypoints/http/protocol.py at 29329e8e73820993f77cfc8efe34eb2a73f5de98 ¬∑ AI-Hypercomputer/JetStream</A>
								</DL><p>
								<DT><H3 FOLDED>py-patching</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/b45ed93b0f1affcdd74c7f6e4fd085041807bb32/test/inductor/test_nv_universal_gemm.py">pytorch/test/inductor/test_nv_universal_gemm.py: patched_get_workspace_size</A>
								</DL><p>
								<DT><A HREF="https://towardsdatascience.com/if-you-can-write-functions-you-can-use-dask-bbb6d8b3a248">If You Can Write Functions, You Can Use Dask</A>
								<DT><A HREF="https://github.com/abseil/abseil-py/tree/main">abseil/abseil-py: Abseil Common Libraries (Python)</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/9b6ef9e1f0d8acaefd989440b27da9069aa69207/deepspeed/utils/logging.py">DeepSpeed/deepspeed/utils/logging.py</A>
								<DT><A HREF="https://www.youtube.com/watch?v=yadfyn6-TzE">20240104 Iterators, Generators - YouTube</A>
								<DT><A HREF="https://towardsdatascience.com/virtual-environments-104c62d48c54">A Guide to Python‚Äôs Virtual Environments</A>
								<DT><A HREF="https://github.com/huggingface/safetensors/blob/079781fd0dc455ba0fe851e2b4507c33d0c0d407/bindings/python/convert.py#L4">errors as values: safetensors/bindings/python/convert.py</A>
								<DT><A HREF="https://www.youtube.com/watch?v=SzL2Oo3RktU">Breaking up long lines of code in Python - YouTube</A>
								<DT><A HREF="https://github.com/igrek51/wat">igrek51/wat: Deep inspection of Python objects</A>
								<DT><A HREF="https://x.com/srush_nlp/status/1820910844827357518">Frozen Dataclasses+Optree+Jaxtyping - the rest of Python is a really good programming language.</A>
								<DT><A HREF="https://github.com/astanin/python-tabulate">astanin/python-tabulate: Pretty-print tabular data in Python, a library and a command-line utility. Repository migrated from bitbucket.org/astanin/python-tabulate.</A>
								<DT><A HREF="https://github.com/ezyang/python-template/tree/main">ezyang/python-template: Python template for Codex coding</A>
							</DL><p>
							<DT><H3 FOLDED>Rust</H3>
							<DL><p>
								<DT><H3 FOLDED>rust-installation</H3>
								<DL><p>
									<DT><A HREF="https://www.rust-lang.org/tools/install">Install Rust - Rust Programming Language</A>
									<DT><A HREF="https://forge.rust-lang.org/infra/other-installation-methods.html">Other Installation Methods - Rust Forge</A>
									<DT><A HREF="https://sourabhbajaj.com/mac-setup/Rust/">Rust ¬∑ macOS Setup Guide</A>
								</DL><p>
								<DT><H3 FOLDED>rust-procedural-macros</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=geovSK3wMB8">Procedural Macros in Rust (part 1) - YouTube</A>
									<DT><A HREF="https://github.com/dtolnay/cargo-expand">dtolnay/cargo-expand: Subcommand to show result of macro expansion</A>
									<DT><A HREF="https://github.com/dtolnay/proc-macro-workshop">dtolnay/proc-macro-workshop: Learn to write Rust procedural macros‚ÄÉ‚ÄÉ[Rust Latam conference, Montevideo Uruguay, March 2019]</A>
								</DL><p>
								<DT><H3 FOLDED>rust-python-bindings</H3>
								<DL><p>
									<DT><A HREF="https://github.com/prql/prql/tree/main/prql-python">prql/prql-python at main ¬∑ prql/prql</A>
									<DT><A HREF="https://github.com/PyO3/pyo3">PyO3/pyo3: Rust bindings for the Python interpreter</A>
									<DT><A HREF="https://pyo3.rs/v0.14.5/index.html">Introduction - PyO3 user guide</A>
									<DT><A HREF="https://github.com/google/autocxx">google/autocxx: Tool for safe ergonomic Rust/C++ interop driven from existing C++ headers</A>
									<DT><A HREF="https://github.com/LaurentMazare/hojo">LaurentMazare/hojo: A small python library to run iterators in a separate process</A>
								</DL><p>
								<DT><H3 FOLDED>rust-cpp-interop</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/autocxx">google/autocxx: Tool for safe ergonomic Rust/C++ interop driven from existing C++ headers</A>
									<DT><A HREF="https://github.com/meta-pytorch/monarch/blob/main/nccl-sys/build.rs">monarch/nccl-sys/build.rs at main ¬∑ meta-pytorch/monarch</A>
								</DL><p>
								<DT><H3 FOLDED>rust-logging</H3>
								<DL><p>
									<DT><A HREF="https://users.rust-lang.org/t/unable-to-enable-anything-above-info-logging/27470">Unable to enable anything above INFO logging - help - The Rust Programming Language Forum</A>
									<DT><A HREF="https://rust-lang-nursery.github.io/rust-cookbook/development_tools/debugging/log.html">Log Messages - Rust Cookbook</A>
								</DL><p>
								<DT><H3 FOLDED>rust-async</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=kSQ9-JSl0z4">Rust Live | Asynchronous Rust - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=gkU4NGSe21I">Zed Decoded: Async Rust</A>
								</DL><p>
								<DT><H3 FOLDED>rust-debug</H3>
								<DL><p>
									<DT><A HREF="https://lldb.llvm.org/">LLDB Homepage ‚Äî The LLDB Debugger</A>
									<DT><A HREF="https://www.youtube.com/watch?v=8D74GaBIYI4">Rust: GDB debugging - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>rust-people</H3>
								<DL><p>
									<DT><A HREF="https://github.com/oovm?tab=stars">oovm (SasakiSaki) / Starred</A>
									<DT><A HREF="https://github.com/kykosic">kykosic (Kyle Kosic) (xAI &amp; OpenAI)</A>
									<DT><A HREF="https://github.com/LaurentMazare">LaurentMazare (Laurent Mazare) (Huggingface)</A>
								</DL><p>
								<DT><H3 FOLDED>rust-crates</H3>
								<DL><p>
									<DT><A HREF="https://stackoverflow.com/questions/66915951/rust-use-vs-mod">import - Rust use vs mod?</A>
									<DT><A HREF="https://github.com/rust-itertools/itertools">rust-itertools/itertools: Extra iterator adaptors, iterator methods, free functions, and macros.</A>
								</DL><p>
								<DT><H3 FOLDED>rust-parallel</H3>
								<DL><p>
									<DT><A HREF="https://docs.rs/rayon/1.8.0/rayon/index.html">rayon: Data-parallelism to convert sequential computations into parallel</A>
								</DL><p>
								<DT><H3 FOLDED>rust-internals</H3>
								<DL><p>
									<DT><H3 FOLDED>rustc</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=q2vJ8Faundw">Parallel</A>
									</DL><p>
									<DT><H3 FOLDED>Borrow Checker</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=KVwP6nY4xgA">Rust's borrow rules: but why, really?</A>
										<DT><A HREF="https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html">References and Borrowing</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>cgo</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=KYdlqhb267c&list=LL&index=4">RustConf 2023 - Integrating Rust and Go: Lessons from Github Code Search - YouTube</A>
									<DT><A HREF="https://pkg.go.dev/cmd/cgo">cgo command - cmd/cgo - Go Packages</A>
									<DT><A HREF="https://doc.rust-lang.org/nomicon/ffi.html">FFI - The Rustonomicon</A>
									<DT><A HREF="https://github.com/ollama/ollama/blob/main/llm/ext_server/ext_server.h">ollama/llm/ext_server/ext_server.h extern "C"</A>
								</DL><p>
								<DT><H3 FOLDED>cargo</H3>
								<DL><p>
									<DT><A HREF="https://crates.io/crates/cargo-update">cargo-update - crates.io: Rust Package Registry</A>
									<DT><A HREF="https://stackoverflow.com/questions/60857222/how-do-i-list-all-of-the-packages-ive-installed-globally-with-cargo-install">rust - How do I list all of the packages I've installed globally with cargo install? - Stack Overflow</A>
									<DT><A HREF="https://claude.ai/chat/bf662bfe-7c59-45b5-9667-b6b9fc44e50a">Listing Installed Rust Crates - Claude</A>
								</DL><p>
								<DT><H3 FOLDED>rust-tui</H3>
								<DL><p>
									<DT><H3 FOLDED>codex-rs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/openai/codex">openai/codex: Lightweight coding agent that runs in your terminal</A>
										<DT><A HREF="https://github.com/search?q=repo%3Aopenai%2Fcodex%20Ratatui&type=code">Code search results</A>
									</DL><p>
									<DT><H3 FOLDED>ratatui</H3>
									<DL><p>
										<DT><A HREF="https://ratatui.rs/">Ratatui | Ratatui</A>
										<DT><A HREF="https://github.com/search?q=repo%3Aopenai%2Fcodex%20Ratatui&type=code">Code search results</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://doc.rust-lang.org/stable/rust-by-example/mod/visibility.html">Visibility - Rust By Example</A>
								<DT><A HREF="https://replit.com/@antferdom/rustlings#.replit">rustlings - Replit</A>
								<DT><A HREF="https://doc.rust-lang.org/cargo/commands/cargo-tree.html">cargo-tree - Display a tree visualization of a dependency graph</A>
								<DT><A HREF="https://doc.rust-lang.org/book/ch02-00-guessing-game-tutorial.html">The Rust Programming Language (main)</A>
								<DT><A HREF="https://www.thecodeteacher.com/question/96947/How-do-I-%22use%22-or-import-a-local-Rust-file?">mod: Include internal code</A>
								<DT><A HREF="https://learning-rust.github.io/docs/a4.cargo,crates_and_basic_project_structure.html">Cargo, Crates and Basic Project Structure | Learning Rust</A>
								<DT><A HREF="https://github.com/clap-rs/clap/blob/master/examples/cargo-example.md">clap: command line argparser</A>
								<DT><A HREF="https://www.youtube.com/watch?v=D1NAREuicNs">Flame Graphs and ASM optimizations</A>
								<DT><A HREF="https://dev.to/tangram/writing-the-fastest-gbdt-libary-in-rust-197k">Writing the fastest GBDT libary in Rust - DEV Community</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-h1oa6GYvV8">Rust Memory Ordering (Atomics and Locks Chapter 3) - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=QHjSJC6yrs8&t=20s">Programming in Rust: Enums, Tagged Unions, Memory Layout and Pattern Matching - YouTube</A>
								<DT><A HREF="https://github.com/slawlor/ractor">slawlor/ractor: Rust actor framework</A>
								<DT><A HREF="https://github.com/LaurentMazare/tch-rs">LaurentMazare/tch-rs: Rust bindings for the C++ api of PyTorch.</A>
								<DT><A HREF="https://github.com/kykosic/actix-pytorch-example/tree/master">kykosic/actix-pytorch-example: An example of using Torch rust bindings to serve trained machine learning models via Actix Web</A>
								<DT><A HREF="https://github.com/sxyazi/yazi">sxyazi/yazi: üí• Blazing fast terminal file manager written in Rust, based on async I/O.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=VJsPd24gByY">Episode 006: Zig and Rust - YouTube</A>
								<DT><A HREF="https://github.com/matklad/xshell">matklad/xshell</A>
								<DT><A HREF="https://github.com/dsherret/dax">dsherret/dax: Cross platform shell tools for Deno inspired by zx.</A>
								<DT><A HREF="https://github.com/google/zx">google/zx: A tool for writing better scripts</A>
								<DT><A HREF="https://google.github.io/comprehensive-rust/">Welcome to Comprehensive Rust ü¶Ä - Comprehensive Rust ü¶Ä</A>
								<DT><A HREF="https://github.com/google/zerocopy">google/zerocopy</A>
								<DT><A HREF="https://github.com/google/autocxx">google/autocxx: Tool for safe ergonomic Rust/C++ interop driven from existing C++ headers</A>
								<DT><A HREF="https://doc.rust-lang.org/book/ch09-02-recoverable-errors-with-result.html">Recoverable Errors with Result - The Rust Programming Language</A>
								<DT><A HREF="https://dev.to/chaudharypraveen98/form-validation-in-rust-404l">Form Validation in Rust (Actix-Web) - DEV Community</A>
								<DT><A HREF="https://www.youtube.com/watch?v=KVwP6nY4xgA">Rust's borrow rules: but why, really?</A>
								<DT><A HREF="https://www.youtube.com/watch?v=g6mUtBVESb0">Rust's trait system is a proof engine, let's make it prove us an ABI!</A>
								<DT><A HREF="https://github.com/LukeMathWalker/pavex/tree/main">LukeMathWalker/pavex: An easy-to-use Rust framework for building robust and performant APIs</A>
								<DT><A HREF="https://github.com/nadavrot/compressor">nadavrot/compressor: An educational implementation of a modern compressor in Rust</A>
								<DT><A HREF="https://www.youtube.com/watch?v=fpkjmE-56Gw">Rust Allocators and Memory Management - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Kdpfhj3VM04">Compiler-Driven Development in Rust - YouTube</A>
								<DT><A HREF="https://github.com/google/comprehensive-rust">google/comprehensive-rust: This is the Rust course used by the Android team at Google. It provides you the material to quickly teach Rust.</A>
								<DT><A HREF="https://github.com/flux-rs/flux">flux-rs/flux: Refinement Types for Rust</A>
							</DL><p>
							<DT><H3 FOLDED>javascript</H3>
							<DL><p>
								<DT><H3 FOLDED>nodejs</H3>
								<DL><p>
									<DT><H3 FOLDED>nodejs-installation</H3>
									<DL><p>
										<DT><A HREF="https://nodejs.org/en/download">Node.js ‚Äî Download Node.js¬Æ</A>
									</DL><p>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>cpp</H3>
							<DL><p>
								<DT><H3 FOLDED>cpp-building</H3>
								<DL><p>
									<DT><H3 FOLDED>cpp-installation</H3>
									<DL><p>
										<DT><A HREF="http://www-scf.usc.edu/~csci104/20142/installation/gccmac.html">CSCI 104 ‚Äì Installing G++ on a Mac</A>
										<DT><A HREF="https://www.moncefbelyamani.com/how-to-install-xcode-homebrew-git-rvm-ruby-on-mac/">including M1 Apple Silicon</A>
										<DT><A HREF="https://stackoverflow.com/questions/68880134/gdb-no-bottle-available-gdb-install">macos - gdb: no bottle available-gdb install (ARM not supported)</A>
									</DL><p>
									<DT><H3 FOLDED>bazel-cpp</H3>
									<DL><p>
										<DT><A HREF="https://github.com/run-ai/runai-model-streamer/blob/master/cpp/WORKSPACE">runai-model-streamer/cpp/WORKSPACE at master ¬∑ run-ai/runai-model-streamer</A>
										<DT><A HREF="https://github.com/run-ai/runai-model-streamer/blob/master/cpp/rules.bzl">runai-model-streamer/cpp/rules.bzl at master ¬∑ run-ai/runai-model-streamer</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>cpp-compilation</H3>
								<DL><p>
									<DT><A HREF="https://stackoverflow.com/questions/3178342/compiling-a-c-program-with-gcc">Compiling a C++ program with gcc - Stack Overflow</A>
									<DT><A HREF="https://www.youtube.com/watch?v=iYHVR5NrOYQ&list=LL&index=3&t=1062s">Static Library and Shared Library In C using GCC, Linux, Ubuntu - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-comptime</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=5eneQ9mFbpA">The Superpower of C++ - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-memory-model</H3>
								<DL><p>
									<DT><H3 FOLDED>RAII</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>memory-arenas</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=K1heXXn324Q">Pointers | Arena Allocator in C - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=vHWiDx_l4V0">What's a Memory Allocator Anyway? - Benjamin Feng - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=CulF4YQt6zA">i wrote my own memory allocator in C to prove a point - YouTube</A>
									</DL><p>
									<DT><A HREF="https://medium.com/swlh/writing-c-when-youre-a-java-developer-memory-management-7c42e222645e">Memory Management</A>
									<DT><A HREF="https://isocpp.org/wiki/faq/freestore-mgmt">Memory Management</A>
									<DT><A HREF="https://thenumb.at/rpp/">Oxidizing C++</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-learning</H3>
								<DL><p>
									<DT><A HREF="https://github.com/federico-busato/Modern-CPP-Programming">federico-busato/Modern-CPP-Programming: Modern C++ Programming Course (C++03/11/14/17/20/23/26)</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-libc</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>cpp-standard</H3>
								<DL><p>
									<DT><A HREF="https://google.github.io/styleguide/cppguide.html">Google C++ Style Guide</A>
								</DL><p>
								<DT><H3 FOLDED>stl-algorithms</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=zlJg9mCNfkQ">Thrust and the C++ Standard Algorithms - Conor Hoekstra - GTC 2021 - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=W2tWOdzgXHA">GoingNative 2013 C++ Seasoning</A>
									<DT><A HREF="https://www.youtube.com/watch?v=h4Jl1fk3MkQ">CppCon 2016: Marshall Clow ‚ÄúSTL Algorithms - why you should use them, and how to write your own" - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=2olsGf6JIkU">CppCon 2018: Jonathan Boccara ‚Äú105 STL Algorithms in Less Than an Hour‚Äù - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=48gV1SNm3WA">C++Now 2019: Conor Hoekstra ‚ÄúAlgorithm Intuition‚Äù</A>
									<DT><A HREF="https://github.com/codereport/Content/tree/main/Talks">Content/Talks at main ¬∑ codereport/Content</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-error-handling</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=uj9ozuzZy6g">C++23's std::expected - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-file</H3>
								<DL><p>
									<DT><A HREF="https://github.com/run-ai/runai-model-streamer/blob/master/cpp/utils/temp/file/file.h">runai-model-streamer/cpp/utils/temp/file/file.h at master ¬∑ run-ai/runai-model-streamer</A>
								</DL><p>
								<DT><H3 FOLDED>carbon</H3>
								<DL><p>
									<DT><A HREF="https://github.com/carbon-language/carbon-lang">carbon-language/carbon-lang: Carbon Language's main repository: documents, design, implementation, and related tools. (NOTE: Carbon Language is experimental; see README)</A>
								</DL><p>
								<DT><H3 FOLDED>cosmopolitan</H3>
								<DL><p>
									<DT><A HREF="https://github.com/jart/cosmopolitan">jart/cosmopolitan: build-once run-anywhere c library</A>
								</DL><p>
								<DT><H3 FOLDED>cpp-command-line-parser</H3>
								<DL><p>
									<DT><A HREF="https://github.com/jarro2783/cxxopts/tree/eb787304d67ec22f7c3a184ee8b4c481d04357fd">jarro2783/cxxopts: Lightweight C++ command line option parser</A>
								</DL><p>
								<DT><H3 FOLDED>dlopen</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=tBApLbmAZ6Y">You should read Open Source code - YouTube</A>
									<DT><A HREF="https://man7.org/linux/man-pages/man3/dlopen.3.html">dlopen(3) - Linux manual page</A>
								</DL><p>
								<DT><A HREF="https://medium.com/swlh/writing-c-when-youre-a-java-developer-memory-management-7c42e222645e">Memory Management</A>
								<DT><A HREF="https://isocpp.org/wiki/faq/freestore-mgmt">Memory Management</A>
								<DT><A HREF="https://www.youtube.com/watch?v=BP6NxVxDQIs&t=37s">CppCon 2016: Timur Doumler ‚ÄúWant fast C++? Know your hardware!" - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Qv1Yn-3lvtU">Refactoring to C++23 with GCC 13 - YouTube</A>
								<DT><A HREF="https://github.com/carbon-language/carbon-lang">carbon-language/carbon-lang: Carbon Language's main repository: documents, design, implementation, and related tools. (NOTE: Carbon Language is experimental; see README)</A>
								<DT><A HREF="https://github.com/harrism/cpp11-range/tree/70f844968c5f669ce85f8ce4cbd24a3584c57f4b">harrism/cpp11-range</A>
								<DT><A HREF="https://omairmajid.com/posts/2020-07-08-what-is-glibcxx-error/">2020-07-08-what-is-glibcxx-error</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-erXR6k9TeE">C++Now 2018: Rong Lu ‚ÄúC++ Development with Visual Studio Code‚Äù - YouTube</A>
								<DT><A HREF="https://learn.microsoft.com/en-us/cpp/cpp/object-lifetime-and-resource-management-modern-cpp?view=msvc-170">Object lifetime and resource management (RAII) | Microsoft Learn</A>
								<DT><A HREF="https://learn.microsoft.com/en-us/cpp/cpp/templates-cpp?view=msvc-170&source=recommendations">Templates (C++) | Microsoft Learn</A>
								<DT><A HREF="https://github.com/google/autocxx">google/autocxx: Tool for safe ergonomic Rust/C++ interop driven from existing C++ headers</A>
								<DT><A HREF="https://github.com/google/mosaic">google/mosaic: A C++ bindings generator for Rust.</A>
								<DT><A HREF="https://thenumb.at/rpp/">Oxidizing C++</A>
								<DT><A HREF="https://www.youtube.com/watch?v=FnMfhWiSweo">Low-Latency Trading Systems in C++: Templated Meta-State Machines in HFT - Jason McGuiness - ACCU 23 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=fsIfQqRjc1U">1 Problem, 4 C++'s - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=YBtnqaMTfHg">Glean: Code Indexing at Meta - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=50sQUgBZCIA">{fmt}: The Cool Parts - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=MUISz2qA640&t=19s">Will Ada Replace C/C++? - YouTube</A>
								<DT><A HREF="https://gist.github.com/Chillee/fbd504a65312893df1b402624042a965">Educational implementations</A>
								<DT><A HREF="https://gist.github.com/Chillee/c729ac9d1995665ea9426226c4203ca5">elapsed_time</A>
								<DT><A HREF="https://github.com/mcinglis/c-style">mcinglis/c-style: My favorite C programming practices.</A>
								<DT><A HREF="https://www.geeksforgeeks.org/exit0-vs-exit1-in-c-c-with-examples/">exit(0) vs exit(1) in C/C++ with Examples - GeeksforGeeks</A>
								<DT><A HREF="https://www.youtube.com/watch?v=g7CCaRwRVBQ&list=PL71Y0EmrppR0KyZvQWj63040UEzKQU7n8">Advanced C #1: Function Pointers - YouTube</A>
								<DT><A HREF="https://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html">What Every C Programmer Should Know About Undefined Behavior #1/3 - The LLVM Project Blog</A>
								<DT><A HREF="https://www.youtube.com/watch?v=n7Tl1qJxTew">Uninitialized Uses in Systems C++ Programming: The Bytes Before the C++ Types - JF Bastien - YouTube</A>
								<DT><A HREF="https://github.com/CppOnlineConference/CppOnline2024">CppOnlineConference/CppOnline2024: Slide Repository For CppOnline 2024</A>
								<DT><A HREF="https://github.com/nlohmann/json/tree/bc889afb4c5bf1c0d8ee29ef35eaaf4c8bef8a5d">nlohmann/json: JSON for Modern C++</A>
								<DT><A HREF="https://github.com/drisspg/simple_cpp/tree/main">drisspg/simple_cpp</A>
								<DT><A HREF="https://github.com/federico-busato/Modern-CPP-Programming">federico-busato/Modern-CPP-Programming: Modern C++ Programming Course (C++03/11/14/17/20/23/26)</A>
								<DT><A HREF="https://github.com/p-ranav/argparse">p-ranav/argparse: Argument Parser for Modern C++</A>
								<DT><A HREF="https://leimao.github.io/blog/Static-Library-VS-Shared-Library/">Static Library VS Shared Library - Lei Mao's Log Book</A>
								<DT><A HREF="https://www.youtube.com/watch?v=4KdvcQKNfbQ">Programming Party Tricks - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=95M6V3mZgrI">Dynamic Arrays in C - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=kS_GqDp6IT4">Libraries That Quietly Revolutionized C - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>Zig</H3>
							<DL><p>
								<DT><H3 FOLDED>zig-build-system</H3>
								<DL><p>
									<DT><A HREF="https://ziglearn.org/chapter-3/">Chapter 3 - Build system | ziglearn.org</A>
									<DT><A HREF="https://www.youtube.com/watch?v=-XLSyaJ6m3o&t=902s">WTF is Build.Zig? by Ed Yu - YouTube</A>
									<DT><A HREF="https://github.com/kimmolinna/duckdb-zig-build/">kimmolinna/duckdb-zig-build: DuckDB is an in-process SQL OLAP Database Management System</A>
									<DT><A HREF="https://github.com/akhildevelops/cudaz">akhildevelops/cudaz: A Zig Cuda wrapper</A>
								</DL><p>
								<DT><H3 FOLDED>zig-people</H3>
								<DL><p>
									<DT><A HREF="https://github.com/fengb">fengb (Benjamin Feng)</A>
								</DL><p>
								<DT><H3 FOLDED>zig-http-web-server</H3>
								<DL><p>
									<DT><A HREF="https://github.com/zigzap/zap">zigzap/zap: blazingly fast backends in zig</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=_WccWcx0p4k">Zig overview</A>
								<DT><A HREF="https://www.youtube.com/watch?v=iZFXAN8kpPo">Advanced Hello World in Zig - Loris Cro - YouTube</A>
								<DT><A HREF="https://log2base2.com/c-with-dsa?utm_src=youtube&utm_target=ycwdeug1&gclid=CjwKCAjwt52mBhB5EiwA05YKo4S_xtW1JucfNad8OMbuQj0b_tg5eej5VfMOx5M8PdeFGvIrlEiHeRoCxHkQAvD_BwE">Learn C Programming | Pointers Visualization | Log2Base2</A>
								<DT><A HREF="https://www.youtube.com/watch?v=vHWiDx_l4V0">What's a Memory Allocator Anyway? - Benjamin Feng - YouTube</A>
								<DT><A HREF="https://github.com/fengb/zee_alloc">fengb/zee_alloc: tiny Zig allocator primarily targeting WebAssembly</A>
								<DT><A HREF="https://www.youtube.com/watch?v=CwXixVcliP0">How to Build Software From Source - Andrew Kelley - Software You Can Love Vancouver 2023 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=x1N9JPPPC18&t=4s">Proficient Parallel Programming - King Butcher - Software You Can Love VC 2023 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=8MbREuiLQrM">Zig Compiler Internals - Andrew Kelley - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=1N85yU6RMcY">Ziglibc: Sweeping out the rug from underneath C - Jonathan Marler - Software You Can Love 2022 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=BiYPrMjPU60">Zig Lexer : Finished it!!! - YouTube</A>
								<DT><A HREF="https://github.com/unum-cloud/ucall">unum-cloud/ucall: Remote Procedure Calls - 50x lower latency and 70x higher bandwidth than FastAPI, implementing REST &amp; JSON-RPC over io_uring and SIMDJSON ‚òéÔ∏è</A>
								<DT><A HREF="https://www.youtube.com/watch?v=VJsPd24gByY">Episode 006: Zig and Rust - YouTube</A>
								<DT><A HREF="https://github.com/allyourcodebase/zlib">allyourcodebase/zlib: https://www.zlib.net/</A>
								<DT><A HREF="https://www.youtube.com/watch?v=xIPrwrBAU2c">Zig Data Structure Katas - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=D5XTnYAgIp0">Episode 013: Prepare Repair - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=a--v9mt8ep0">Episode 21: Grid.Write - YouTube</A>
								<DT><A HREF="https://zig.news/edyu/zig-package-manager-wtf-is-zon-2-0110-update-1jo3">Zig Package Manager 2 - WTF is Build.Zig.Zon and Build.Zig (0.11.0 Update) - Zig NEWS</A>
								<DT><A HREF="https://www.youtube.com/watch?v=pnnx1bkFXng">i changed my mind about zig - YouTube</A>
								<DT><A HREF="https://github.com/Meenachinmay/5-million-Txns-in-Tigerbeetle">Meenachinmay/5-million-Txns-in-Tigerbeetle: Trying Tigerbeetle transactional database.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=MWy_mrmE4gs">Episode 034: Prefetching From Disk - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=a--v9mt8ep0&t=247s">Episode 21: Grid.Write - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=NyMRZxcw0Ek&feature=youtu.be">Episode 091: Zig Zag Merge (in Zig ‚ö°) - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>Go</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ollama/ollama/blob/main/llm/ext_server/ext_server.h">ollama/llm/ext_server/ext_server.h extern "C"</A>
								<DT><A HREF="https://github.com/tliron/py4go">tliron/py4go: Tight bidirectional integration between Go and Python</A>
								<DT><A HREF="https://github.com/tliron/py4go/tree/main/examples/hello-world">py4go/examples/hello-world at main ¬∑ tliron/py4go</A>
								<DT><A HREF="https://github.com/bytedance/gopkg?tab=readme-ov-file">bytedance/gopkg: Universal Utilities for Go</A>
								<DT><A HREF="https://github.com/Meenachinmay">Meenachinmay (Chinmay Anand)</A>
								<DT><A HREF="https://www.slideshare.net/slideshow/golang-mobile-app-golang-introduction-of-golang/257575240">[Golang] ‰ª• Mobile App Â∑•Á®ãÂ∏´Ë¶ñËßíÔºåÂ∏∂‰Ω†ÈÄ≤ÂÖ• Golang ÁöÑ‰∏ñÁïå (Introduction of GoLang) | PPT</A>
								<DT><A HREF="https://github.com/bytedance/gopkg">bytedance/gopkg: Universal Utilities for Go</A>
							</DL><p>
							<DT><H3 FOLDED>Java</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=BaUrpq_7KMk">How Netflix Really Uses Java - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>Gleam</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=D88S_RdagP8">Introduction to Gleam's Concurrency Model</A>
								<DT><A HREF="https://www.youtube.com/@lpil">Louis Pilfold - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>array programming</H3>
							<DL><p>
								<DT><H3 FOLDED>parrot</H3>
								<DL><p>
									<DT><A HREF="https://github.com/nvlabs/parrot">NVlabs/parrot: Parrot is a C++ library for fused array operations using CUDA/Thrust. It provides efficient GPU-accelerated operations with lazy evaluation semantics, allowing for chaining of operations without unnecessary intermediate materializations.</A>
									<DT><A HREF="https://nvlabs.github.io/parrot/">Parrot documentation</A>
								</DL><p>
								<DT><A HREF="https://www.brainstobytes.com/hands-on-numpy-universal-functions-and-array-oriented-programming/">Hands-on NumPy(IV): Universal Functions and Array-oriented Programming</A>
								<DT><A HREF="https://link.springer.com/chapter/10.1007/978-3-030-74386-4_1">Tensor Computation | SpringerLink</A>
								<DT><A HREF="https://www.youtube.com/watch?v=aFal9-SJjGY&list=PL_lsbAsL_o2BivkGLiDfHY9VqWlaNoZ2O&index=40">Keynote: The Promise of PyTorch as a General-Purpose Array-Oriented Computational..- Travis Oliphant - YouTube</A>
							</DL><p>
						</DL><p>
						<DT><A HREF="https://research.google/blog/advancements-in-machine-learning-for-machine-learning/">Advancements in machine learning for machine learning (Google AI)</A>
						<DT><A HREF="https://carpedm30.notion.site/AI-Compiler-Study-aaf4cff2c8734e50ad95ac6230dbd80b">‚ôüÔ∏è AI Compiler Study</A>
						<DT><A HREF="https://gist.github.com/sophiawisdom/ccdff5b7ebcd782393dbc5be3f0866f9">shittytransformer.py</A>
						<DT><A HREF="https://www.thonking.ai/p/strangely-matrix-multiplications">Strangely, Matrix Multiplications on GPUs Run Faster When Given "Predictable" Data! [short]</A>
						<DT><A HREF="https://github.com/daadaada/turingas">daadaada/turingas: Assembler for NVIDIA Volta and Turing GPUs</A>
						<DT><A HREF="https://github.com/banach-space/llvm-tutor">banach-space/llvm-tutor: A collection of out-of-tree LLVM passes for teaching and learning</A>
						<DT><A HREF="https://github.com/yzhaiustc/Optimizing-SGEMM-on-NVIDIA-Turing-GPUs">yzhaiustc/Optimizing-SGEMM-on-NVIDIA-Turing-GPUs: Optimizing SGEMM kernel functions on NVIDIA GPUs to a close-to-cuBLAS performance.</A>
						<DT><A HREF="https://twitter.com/cis_female/status/1737448740620013751/photo/1">Sophia: Quantitative Analsysis tokeneconomics cost model</A>
						<DT><A HREF="https://startup.jobs/graph-compiler-engineer-openai-4658227">Graph Compiler Engineer at OpenAI</A>
						<DT><A HREF="https://github.com/IST-DASLab">IST Austria Distributed Algorithms and Systems Lab</A>
						<DT><A HREF="https://www.zhihu.com/people/liang-de-peng">GiantPandaCV (chinese high-proffesional discussions)</A>
						<DT><A HREF="https://github.com/microsoft/Olive">microsoft/Olive: Olive is an easy-to-use hardware-aware model optimization tool that composes industry-leading techniques across model compression, optimization, and compilation.</A>
						<DT><A HREF="https://pytorchtoatoms.substack.com/p/nvidia-quantum-x800-next-generation">NVIDIA Quantum-X800: Next Generation Infiniband 800Gbit/s Network Topology</A>
						<DT><A HREF="https://x.com/PytorchToAtoms">(1) Pytorch To Atoms (@PytorchToAtoms) / X</A>
						<DT><A HREF="https://www.youtube.com/watch?v=XD9DqcZOB3A">Cornell ECE 5545: Guest Lecture: CentML Gennady Pekhimenko - YouTube</A>
						<DT><A HREF="https://github.com/dorjeduck/llm.mojo">dorjeduck/llm.mojo: port of Andrjey Karpathy's llm.c to Mojo</A>
						<DT><A HREF="https://research.colfax-intl.com/tutorial-python-binding-for-cuda-libraries-in-pytorch/">Tutorial: Python bindings for CUDA libraries in PyTorch ‚Äì Colfax Research</A>
						<DT><A HREF="https://twitter.com/cis_female/status/1782576009239560336/photo/1">(1) sophia (chrysanthemum princess) (@cis_female) / X</A>
						<DT><A HREF="https://twitter.com/cis_female/status/1660386176761724928">(1) sophia (chrysanthemum princess) en X: "I implemented the transformer in 30 minutes and 30 lines of python which compiles to 6670 instructions of gpu microcode (lower-level assembly), or ~100kb total (twitter js is ~1000kb). This shitty implementation achieves 40% of the A100's *THEORETICAL MAXIMUM* performance" / X</A>
						<DT><A HREF="https://gist.github.com/sophiawisdom/4b3886a251d0728625dd8d1f76e9eb60">cublas fp16 matmul</A>
						<DT><A HREF="https://gist.github.com/sophiawisdom/b8e63dc8ce6037b6032eeb010b93e446">layernorm</A>
						<DT><A HREF="https://github.com/facebookincubator/dynolog/tree/main?tab=readme-ov-file#gpu-monitoring">facebookincubator/dynolog: Dynolog is a telemetry daemon for performance monitoring and tracing. It exports metrics from different components in the system like the linux kernel, CPU, disks, Intel PT, GPUs etc. Dynolog also integrates with pytorch and can trigger traces for distributed training applications.</A>
						<DT><A HREF="https://www.youtube.com/watch?v=6BiNzPdy6YA">[REFAI Seminar 04/16/24] ML for ML Compilers at Google - YouTube</A>
						<DT><A HREF="https://www.modular.com/blog/how-to-be-confident-in-your-performance-benchmarking">Modular: How to Be Confident in Your Performance Benchmarking</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/IEEE_754">IEEE 754 - Wikipedia</A>
						<DT><A HREF="https://github.com/chengzeyi/yatc">chengzeyi/yatc: A Pure Python Deep Learning Compiler</A>
						<DT><A HREF="https://chsasank.com/sycl-portable-cuda-alternative.html">SYCL: A Portable Alternative to CUDA - Sasank's Blog</A>
						<DT><A HREF="https://github.com/merrymercy/awesome-tensor-compilers">merrymercy/awesome-tensor-compilers: A list of awesome compiler projects and papers for tensor computation and deep learning.</A>
						<DT><A HREF="https://github.com/tensor-fusion/compiler-explorer">tensor-fusion/compiler-explorer: Run compilers interactively from your web browser and interact with the assembly</A>
						<DT><A HREF="https://github.com/run-ai">run:ai</A>
						<DT><A HREF="https://2024resumedropco-design.splashthat.com/">Meta Research AI and Systems Co-Design Resume Drop (PhD New Grad/Intern)</A>
						<DT><A HREF="https://www.youtube.com/watch?v=4HgShra-KnY&t=1022s">ASPLOS Keynote: The Golden Age of Compiler Design in an Era of HW/SW Co-design by Dr. Chris Lattner - YouTube</A>
						<DT><A HREF="https://github.com/hikettei/Caten">hikettei/Caten: [wip] Deep Learning Compiler based on Polyhedral Compiler, Light-weight IRs, and Optimizing Pattern Matcher.</A>
						<DT><A HREF="https://github.com/KnowingNothing/compiler-and-arch">KnowingNothing/compiler-and-arch: A list of tutorials, paper, talks, and open-source projects for emerging compiler and architecture</A>
						<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest">lcy-seso/DLFrameworkTest: My tests and experiments with some popular dl frameworks.</A>
						<DT><A HREF="https://jlebar.com/2024/2/4/completeness.html">"Hardware completeness" in compiler IRs</A>
						<DT><A HREF="https://www.modular.com/blog/democratizing-ai-compute-part-6-what-about-ai-compilers">Modular: What about TVM, XLA, and AI compilers? (Democratizing AI Compute, Part 6)</A>
						<DT><A HREF="https://zhuanlan.zhihu.com/p/1896877524346185101">AI Compiler Preparation</A>
					</DL><p>
					<DT><H3 FOLDED>ML Sys</H3>
					<DL><p>
						<DT><H3 FOLDED>serving</H3>
						<DL><p>
							<DT><H3 FOLDED>sequence-modeling</H3>
							<DL><p>
								<DT><H3 FOLDED>fairseq2</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookresearch/fairseq2">facebookresearch/fairseq2: FAIR Sequence Modeling Toolkit 2</A>
								</DL><p>
								<DT><A HREF="https://github.com/bytedance/lightseq">bytedance/lightseq: LightSeq: A High Performance Library for Sequence Processing and Generation</A>
							</DL><p>
							<DT><H3 FOLDED>serving-kv</H3>
							<DL><p>
								<DT><H3 FOLDED>lmcache</H3>
								<DL><p>
									<DT><A HREF="https://github.com/LMCache/LMCache">LMCache/LMCache: Supercharge Your LLM with the Fastest KV Cache Layer</A>
								</DL><p>
								<DT><H3 FOLDED>ShadowKV</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2410.21465">[2410.21465] ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference</A>
									<DT><A HREF="https://bytedance-seed.github.io/ShadowKV/">ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM inference</A>
									<DT><A HREF="https://github.com/ByteDance-Seed/ShadowKV">ByteDance-Seed/ShadowKV: [ICML 2025 Spotlight] ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>serving-runtime-optimizations</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ggerganov/llama.cpp">ggerganov/llama.cpp: LLM inference in C/C++</A>
								<DT><A HREF="https://github.com/huggingface/candle">huggingface/candle: Minimalist ML framework for Rust</A>
								<DT><A HREF="https://github.com/kykosic/actix-pytorch-example">kykosic/actix-pytorch-example (xAI prototype)</A>
								<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md">llama.cpp/examples/server/README.md at master ¬∑ ggerganov/llama.cpp</A>
							</DL><p>
							<DT><H3 FOLDED>serving-research</H3>
							<DL><p>
								<DT><H3 FOLDED>serving-research-web-server</H3>
								<DL><p>
									<DT><H3 FOLDED>Robyn</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sparckles/Robyn">sparckles/Robyn: Robyn is a Super Fast Async Python Web Framework with a Rust runtime.</A>
									</DL><p>
									<DT><H3 FOLDED>uvicorn</H3>
									<DL><p>
										<DT><H3 FOLDED>uvicorn-logger</H3>
										<DL><p>
											<DT><A HREF="https://github.com/roy-pstr/fastapi-custom-exception-handlers-and-logs/blob/master/logger.py">logger.py</A>
											<DT><A HREF="https://github.com/encode/uvicorn/blob/0efd3835da6dcc713f74aadf7b52779d0d1fa17d/uvicorn/config.py#L357">uvicorn: config.py#L357 (log_config=None)</A>
											<DT><A HREF="https://docs.python.org/3/library/logging.config.html">logging.config ‚Äî Logging configuration ‚Äî Python 3.12.3 documentation</A>
											<DT><A HREF="https://github.com/encode/uvicorn/blob/0efd3835da6dcc713f74aadf7b52779d0d1fa17d/uvicorn/config.py#L32">uviconr: LOG_LEVELS config.py#L32</A>
											<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/9b6ef9e1f0d8acaefd989440b27da9069aa69207/deepspeed/utils/logging.py">DeepSpeed/deepspeed/utils/logging.py</A>
										</DL><p>
										<DT><A HREF="https://github.com/encode/uvicorn">encode/uvicorn: An ASGI web server, for Python. ü¶Ñ</A>
										<DT><A HREF="https://github.com/Lightning-AI/LitServe/blob/ee1a7b53772332a937bdb548277b28cc54ba16e0/src/litserve/server.py#L25">LitServe/src/litserve/server.py</A>
									</DL><p>
									<DT><H3 FOLDED>zap</H3>
									<DL><p>
										<DT><A HREF="https://github.com/zigzap/zap">zigzap/zap: blazingly fast backends in zig</A>
									</DL><p>
									<DT><A HREF="https://github.com/facebook/wangle">facebook/wangle: Wangle is a framework providing a set of common client/server abstractions for building services in a consistent, modular, and composable way.</A>
									<DT><A HREF="https://github.com/Lightning-AI/LitServe?tab=readme-ov-file#implement-a-server">Lightning-AI/LitServe: Deploy AI models at scale. High-throughput serving engine for AI/ML models that uses the latest state-of-the-art model deployment techniques.</A>
									<DT><A HREF="https://github.com/awslabs/aws-c-http">awslabs/aws-c-http: C99 implementation of the HTTP/1.1 and HTTP/2 specifications</A>
									<DT><A HREF="https://github.com/emmett-framework/granian">emmett-framework/granian: A Rust HTTP server for Python applications</A>
								</DL><p>
								<DT><H3 FOLDED>serving-research-rust</H3>
								<DL><p>
									<DT><H3 FOLDED>axum</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=Wnb_n5YktO8&t=30s">Decrusting the axum crate - YouTube</A>
										<DT><A HREF="https://crates.io/crates/axum">axum - crates.io: Rust Package Registry</A>
										<DT><A HREF="https://github.com/tokio-rs/axum">tokio-rs/axum: Ergonomic and modular web framework built with Tokio, Tower, and Hyper</A>
										<DT><A HREF="https://github.com/serde-rs/serde">serde-rs/serde: Serialization framework for Rust</A>
										<DT><A HREF="https://github.com/tokio-rs/tokio">tokio-rs/tokio: A runtime for writing reliable asynchronous applications with Rust. Provides I/O, networking, scheduling, timers, ...</A>
										<DT><A HREF="https://github.com/tokio-rs/tracing">tokio-rs/tracing: Application level tracing for Rust.</A>
										<DT><A HREF="https://crates.io/crates/tracing-subscriber">tracing-subscriber - crates.io: Rust Package Registry</A>
										<DT><A HREF="https://github.com/hyperium/hyper">hyperium/hyper: An HTTP library for Rust (HTTP parser)</A>
										<DT><A HREF="https://github.com/tower-rs/tower">tower-rs/tower: async fn(Request) (Middleware)</A>
										<DT><A HREF="https://docs.rs/matchit/latest/matchit/">matchit (route matching)</A>
										<DT><A HREF="https://docs.rs/hyper/1.2.0/hyper/">hyper - Rust</A>
										<DT><A HREF="https://docs.rs/hyper/0.14.20/hyper/server/struct.Builder.html">Builder in hyper::server - Rust</A>
										<DT><A HREF="https://tokio.rs/blog/2021-05-14-inventing-the-service-trait">Inventing the Service trait | Tokio - An asynchronous Rust runtime</A>
										<DT><A HREF="https://docs.rs/axum/0.6.20/axum/attr.debug_handler.html">debug_handler in axum (FromRequestParts) MAIN</A>
										<DT><A HREF="https://github.com/tokio-rs/axum/blob/2ec68d6c4dab10b83b9195c3acd4ccc7c26d0e8a/axum/src/handler/mod.rs#L206-248">FromRequest -&gt; Handler (macro)</A>
										<DT><A HREF="https://github.com/tokio-rs/axum/blob/2ec68d6c4dab10b83b9195c3acd4ccc7c26d0e8a/axum-core/src/response/into_response.rs#L395">IntoResponse (last arg special)</A>
										<DT><A HREF="https://docs.rs/axum/0.6.20/axum/extract/struct.State.html">extactors::State (impl FromRequestParts)</A>
										<DT><A HREF="https://docs.rs/axum/0.6.20/axum/handler/struct.HandlerService.html">HandlerService in axum::handler</A>
										<DT><A HREF="https://docs.rs/tower/0.4.13/tower/trait.Service.html">tower::Service (Future -&gt; self.state.clone())</A>
										<DT><A HREF="https://crates.io/crates/tokio-blocking">tokio-blocking (inference step)</A>
										<DT><A HREF="https://docs.rs/axum-extra/0.9.2/axum_extra/">axum_extra - (utilities)</A>
									</DL><p>
									<DT><A HREF="https://github.com/kykosic/actix-pytorch-example">kykosic/actix-pytorch-example (xAI prototype)</A>
									<DT><A HREF="https://github.com/kykosic/actix-tensorflow-example">kykosic/actix-tensorflow-example</A>
									<DT><A HREF="https://github.com/hyperium/hyper">hyperium/hyper: An HTTP library for Rust</A>
									<DT><A HREF="https://github.com/hyperium/h2">hyperium/h2: HTTP 2.0 client &amp; server implementation for Rust.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=P-v8xRhpquM">Rust Programming Part 2 HTTP Server Using Result Type &amp; Responding To Client - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Wnb_n5YktO8&t=30s">Decrusting the axum crate - YouTube</A>
									<DT><A HREF="https://blog.hippoml.com/unified-datacenter-local-foundation-model-serving-beyond-docker-way-a929003fa07c">Unified DataCenter &amp; Local Foundation Model Serving: Beyond Docker Way | by HippoML Blog | Jan, 2024 | Medium</A>
								</DL><p>
								<DT><H3 FOLDED>network services</H3>
								<DL><p>
									<DT><A HREF="https://github.com/cloudflare/pingora">cloudflare/pingora: A library for building fast, reliable and evolvable network services.</A>
									<DT><A HREF="https://blog.cloudflare.com/pingora-open-source">Open sourcing Pingora: our Rust framework for building programmable network services</A>
									<DT><A HREF="https://github.com/cloudflare/pingora/blob/main/docs/quick_start.md">pingora/docs/quick_start.md at main ¬∑ cloudflare/pingora</A>
									<DT><A HREF="https://github.com/cloudflare/pingora/blob/main/pingora-proxy/examples/load_balancer.rs">pingora/pingora-proxy/examples/load_balancer.rs at main ¬∑ cloudflare/pingora</A>
									<DT><A HREF="https://github.com/bytedance/g3">bytedance/g3: Enterprise-oriented Generic Proxy Solutions</A>
								</DL><p>
								<DT><H3 FOLDED>Network Messaging Protocol</H3>
								<DL><p>
									<DT><H3 FOLDED>NATS</H3>
									<DL><p>
										<DT><H3 FOLDED>nats-protobuf</H3>
										<DL><p>
											<DT><A HREF="https://natsbyexample.com/examples/messaging/protobuf/go">NATS by Example - Protobuf for Message Payloads (Go)</A>
											<DT><A HREF="https://github.com/savaki/nats-protobuf">savaki/nats-protobuf: write protobuf services with NATS as the transport; service discovery simplified</A>
										</DL><p>
										<DT><H3 FOLDED>nats-client</H3>
										<DL><p>
											<DT><H3 FOLDED>Client Protocol</H3>
											<DL><p>
												<DT><A HREF="https://docs.nats.io/reference/reference-protocols/nats-protocol">Client Protocol | NATS Docs</A>
											</DL><p>
											<DT><A HREF="https://github.com/3kwa/goingnats">Python minimal NATS client (no asyncio)</A>
											<DT><A HREF="https://github.com/nats-io/nats.py">nats-io/nats.py: Python3 client for NATS (asycio)</A>
											<DT><A HREF="https://github.com/nats-io/nats.net.v2">nats-io/nats.net.v2: Full Async C# / .NET client for NATS</A>
											<DT><A HREF="https://github.com/nats-io/nats.zig">nats-io/nats.zig: Zig Client for NATS</A>
											<DT><A HREF="https://github.com/rutgerbrf/zig-nats/blob/master/example/main.zig">zig-nats/example/main.zig at master ¬∑ rutgerbrf/zig-nats</A>
										</DL><p>
										<DT><A HREF="https://github.com/nats-io/nats-server">nats-io/nats-server: High-Performance server for NATS.io, the cloud and edge native messaging system.</A>
										<DT><A HREF="https://nats.io/download/">NATS.io ‚Äì Cloud Native, Open Source, High-performance Messaging</A>
										<DT><A HREF="https://gcoolinfo.medium.com/comparing-nats-nats-streaming-and-nats-jetstream-ec2d9f426dc8">Comparing NATS, NATS Streaming and NATS JetStream | by George Koulouris | Medium</A>
										<DT><A HREF="https://github.com/nats-io/nats.c">nats-io/nats.c: A C client for NATS</A>
										<DT><A HREF="https://github.com/ConnectEverything/nats-by-example/#getting-started">ConnectEverything/nats-by-example: Collection of runnable, reference examples using NATS (https://nats.io)</A>
										<DT><A HREF="https://docs.nats.io/nats-concepts/what-is-nats">What is NATS | NATS Docs</A>
										<DT><A HREF="https://docs.nats.io/nats-concepts/jetstream">JetStream | NATS Docs</A>
										<DT><A HREF="https://www.youtube.com/watch?v=JNQM_aq9pd4">aggregator (multiple backends e.g. /rest/* &amp; /nats/*)</A>
										<DT><A HREF="https://github.com/gcool-info/nats-playground">gcool-info/nats-playground: Playground for a secure, Highly Available NATS Cluster with message persistence (using JetStream)</A>
										<DT><A HREF="https://www.youtube.com/watch?v=SLb4rdI5lIM">NATS for Modern Messaging and Microservices - YouTube</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=kH7P1ZX44DQ&list=LL&index=29">How to Design a Network Messaging Protocol!</A>
								</DL><p>
								<DT><H3 FOLDED>websockets</H3>
								<DL><p>
									<DT><A HREF="https://github.com/kykosic/python-websocket-exmple/blob/master/server.py">python-websocket-exmple/server.py at master ¬∑ kykosic/python-websocket-exmple</A>
									<DT><A HREF="https://www.youtube.com/watch?v=yrzv6o9Pnao">WebSocket Server from Zero by Specs - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>gRPC</H3>
								<DL><p>
									<DT><H3 FOLDED>Protocol Buffers</H3>
									<DL><p>
										<DT><A HREF="https://github.com/protocolbuffers">Protocol Buffers</A>
										<DT><A HREF="https://github.com/protocolbuffers/protobuf">protocolbuffers/protobuf: Protocol Buffers - Google's data interchange format</A>
										<DT><A HREF="https://flatbuffers.dev/">FlatBuffers: FlatBuffers</A>
										<DT><A HREF="https://github.com/google/flatbuffers">google/flatbuffers: FlatBuffers: Memory Efficient Serialization Library</A>
										<DT><A HREF="https://www.infoq.com/news/2023/07/linkedin-protocol-buffers-restli/">LinkedIn Adopts Protocol Buffers for Microservices Integration and Reduces Latency by up to 60%</A>
										<DT><A HREF="https://www.youtube.com/watch?v=9IxE2UQqJCw&t=7s">Reduce Latency By 60% With ProtoBufs!!! | Prime Reacts - YouTube</A>
										<DT><A HREF="https://protobuf.dev/overview/">Overview | Protocol Buffers Documentation</A>
										<DT><A HREF="https://gist.github.com/jambonn/1f5fffc23f97f8413372a438739c1bff">How to Install Protobuf on Ubuntu 20.04</A>
										<DT><A HREF="https://protobuf.dev/overview/#updating-defs">Overview | Protocol Buffers Documentation</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/proto/generate.proto">text-generation-inference/proto/generate.proto at main ¬∑ huggingface/text-generation-inference</A>
									</DL><p>
									<DT><H3 FOLDED>Rust</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=kerKXChDmsE">Tonic makes gRPC in Rust stupidly simple</A>
										<DT><A HREF="https://github.com/hyperium/tonic">hyperium/tonic: A native gRPC client &amp; server implementation with async/await support.</A>
										<DT><A HREF="https://github.com/tokio-rs/prost">tokio-rs/prost: PROST! a Protocol Buffers implementation for the Rust Language</A>
										<DT><A HREF="https://github.com/hyperium/tonic/blob/master/tonic-build/README.md">tonic/tonic-build/README.md at master ¬∑ hyperium/tonic</A>
									</DL><p>
									<DT><H3 FOLDED>client</H3>
									<DL><p>
										<DT><A HREF="https://github.com/fullstorydev/grpcurl">fullstorydev/grpcurl: Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers</A>
									</DL><p>
									<DT><H3 FOLDED>uds: Unix Domain Socket</H3>
									<DL><p>
										<DT><A HREF="https://github.com/grpc/grpc/tree/d68161a64f191b8d8d5afe0507e7a2291f91ff1a/examples/python/uds">uds: Unix Domain Socket Example in gRPC Python</A>
										<DT><A HREF="https://grpc.io/docs/languages/python/quickstart/">Quick start | Python | gRPC</A>
									</DL><p>
									<DT><A HREF="https://github.com/grpc/grpc/blob/d68161a64f191b8d8d5afe0507e7a2291f91ff1a/examples/python/uds/async_greeter_server.py">(EXAMPLE) grpc/examples/python/uds/async_greeter_server.py at d68161a64f191b8d8d5afe0507e7a2291f91ff1a ¬∑ grpc/grpc</A>
									<DT><A HREF="https://www.youtube.com/watch?v=SDnPul2-N9w">Big picture</A>
									<DT><A HREF="https://www.youtube.com/watch?v=uGYZn6xk-hA">Serialization formats: JSON and Protobuf</A>
									<DT><A HREF="https://janhendrikewers.uk/pydantic_vs_protobuf_vs_namedtuple_vs_dataclasses.html">Pydantic vs Protobuf vs Namedtuples vs Dataclasses</A>
									<DT><A HREF="https://github.com/bazelbuild/starlark">bazelbuild/starlark: Starlark Language</A>
									<DT><A HREF="https://github.com/stripe/skycfg">stripe/skycfg: Skycfg is an extension library for the Starlark language that adds support for constructing Protocol Buffer messages.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=kerKXChDmsE">Tonic makes gRPC in Rust stupidly simple</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/7dbaf9e9013060af52024ea1a8b361b107b50a69/router/src/server.rs#L115">text-generation-inference/router/src/server.rs at 7dbaf9e9013060af52024ea1a8b361b107b50a69 ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/fullstorydev/grpcurl">fullstorydev/grpcurl: Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers</A>
									<DT><A HREF="https://github.com/grpc/grpc/tree/master/src/python/grpcio">grpc/src/python/grpcio at master</A>
									<DT><A HREF="https://grpc.github.io/grpc/python/grpc.html">gRPC ‚Äî gRPC Python 1.62.0 documentation</A>
									<DT><A HREF="https://github.com/grpc/grpc/blob/master/doc/python/server_reflection.md">grpc/doc/python/server_reflection.md (reflection)</A>
									<DT><A HREF="https://github.com/d5h-foss/grpc-interceptor">d5h-foss/grpc-interceptor: Simplified Python gRPC interceptors</A>
									<DT><A HREF="https://www.youtube.com/watch?v=M1qt83N3JWg">¬øQu√© es gRPC? - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>WSGI</H3>
								<DL><p>
									<DT><A HREF="https://www.fullstackpython.com/wsgi-servers.html">WSGI Servers - Full Stack Python</A>
								</DL><p>
								<DT><H3 FOLDED>environ</H3>
								<DL><p>
									<DT><A HREF="https://github.com/triton-inference-server/server/blob/ddd6c4b4a286970e0b6c18dcd5c90c7a121d3e48/qa/L0_backend_fastertransformer/test.sh">Triton Inference Server: $TRITON_DIR (fastertransformer backend)</A>
									<DT><A HREF="https://twitter.com/wangzhr4/status/1783772055294329159/photo/1">sensitive information as local env vars</A>
									<DT><A HREF="https://chat.openai.com/c/607f5eb0-ab64-494d-acdb-b1a3f7319695">Exposure of Sensitive Information &amp; Security practices</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/8674f9880e2d8574c2adc759027e0f27dc9b95de/setup.py#L31">setup.py#L31 # cannot import envs directly because it depends on vllm which is not installed yet</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/8674f9880e2d8574c2adc759027e0f27dc9b95de/setup.py#L18">setup.py#L18</A>
								</DL><p>
								<DT><H3 FOLDED>asycio</H3>
								<DL><p>
									<DT><H3 FOLDED>pyInfer</H3>
									<DL><p>
										<DT><A HREF="https://github.com/wangzyon/pyInfer">wangzyon/pyInfer: async inference for machine learning model</A>
										<DT><A HREF="https://github.com/wangzyon/pyInfer/blob/master/pyinfer/utils/common/registry.py">pyInfer/pyinfer/utils/common/registry.py REGISTER ENGINE</A>
									</DL><p>
									<DT><A HREF="https://github.com/facebookincubator/later">facebookincubator/later: A framework for python asyncio with batteries included for people writing services in python asyncio</A>
									<DT><A HREF="https://github.com/wangzyon/pyInfer/blob/master/pyinfer/core/engine/engine.py">pyInfer/pyinfer/core/engine/engine.py at master ¬∑ wangzyon/pyInfer</A>
								</DL><p>
								<DT><H3 FOLDED>serving-research-web-server-max_tokens</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/performance/perf-best-practices.md">max_batch_size * max_input_len * alpha + max_batch_size * max_beam_width * (1 - alpha)</A>
								</DL><p>
								<DT><H3 FOLDED>serving-research-torch.compile</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/commit/78f87d5a0c7d82911a639c397577284868a53c42">Temporary implem of torch.compile on our stuff. ¬∑ huggingface/text-generation-inference@78f87d5</A>
								</DL><p>
								<DT><H3 FOLDED>image-compression</H3>
								<DL><p>
									<DT><H3 FOLDED>PNG-network-transfer</H3>
									<DL><p>
										<DT><H3 FOLDED>cuda-encoding-png</H3>
										<DL><p>
											<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-s51286/">CUDA-Based Acceleration of PNG Image Encoder and Decoder | GTC Digital Spring 2023 | NVIDIA On-Demand</A>
											<DT><A HREF="https://github.com/NVIDIA/DALI">NVIDIA/DALI: A GPU-accelerated library containing highly optimized building blocks and an execution engine for data processing to accelerate deep learning training and inference applications.</A>
											<DT><A HREF="https://github.com/NVIDIA/nvcomp">NVIDIA/nvcomp: Repository for nvCOMP docs and examples. nvCOMP is a library for fast lossless compression/decompression on the GPU that can be downloaded from https://developer.nvidia.com/nvcomp.</A>
											<DT><A HREF="https://github.com/NVIDIA/CUDALibrarySamples/tree/master/nvCOMP">CUDALibrarySamples/nvCOMP at master ¬∑ NVIDIA/CUDALibrarySamples</A>
										</DL><p>
										<DT><H3 FOLDED>fpng</H3>
										<DL><p>
											<DT><H3 FOLDED>fpng-python</H3>
											<DL><p>
												<DT><A HREF="https://github.com/qrmt/fpng-python">qrmt/fpng-python: Python bindings for fpng</A>
											</DL><p>
											<DT><A HREF="https://github.com/richgel999/fpng">richgel999/fpng: Super fast C++ .PNG writer/reader</A>
										</DL><p>
										<DT><H3 FOLDED>opencv-libpng</H3>
										<DL><p>
										</DL><p>
										<DT><H3 FOLDED>mtpng</H3>
										<DL><p>
											<DT><A HREF="https://github.com/bvibber/mtpng?tab=readme-ov-file">bvibber/mtpng: A parallelized PNG encoder in Rust</A>
											<DT><A HREF="https://github.com/pwuertz/pymtpng">pwuertz/pymtpng: Python bindings for MTPNG library.</A>
											<DT><A HREF="https://crates.io/crates/png">png - crates.io: Rust Package Registry</A>
											<DT><A HREF="https://github.com/image-rs/image-png">image-rs/image-png: PNG decoding and encoding library in pure Rust</A>
											<DT><A HREF="https://docs.rs/png/0.17.16/png/">png - Rust</A>
										</DL><p>
										<DT><A HREF="https://grok.com/chat/d47cbdc5-f753-48f1-ad22-1efe35b78179">Optimizing PNG Serialization for Image Generation - Grok</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://github.com/geohot/minikeyvalue/blob/master/src/server.go">minikeyvalue/src/server.go at master ¬∑ geohot/minikeyvalue</A>
								<DT><A HREF="https://github.com/theroyallab/tabbyAPI/blob/main/endpoints/OAI/router.py">tabbyAPI/endpoints/OAI/router.py (good &amp; minimal FastAPI ref impl)</A>
								<DT><A HREF="https://github.com/triton-inference-server/server/blob/ddd6c4b4a286970e0b6c18dcd5c90c7a121d3e48/qa/L0_http/http_test.py">server/qa/L0_http/http_test.py</A>
								<DT><A HREF="https://github.com/triton-inference-server/server/blob/ddd6c4b4a286970e0b6c18dcd5c90c7a121d3e48/qa/L0_http/python_http_aio_test.py">server/qa/L0_http/python_http_aio_test.py (readiness)</A>
								<DT><A HREF="https://github.com/triton-inference-server/client">triton-inference-server/client: Triton Python, C++ and Java client libraries</A>
								<DT><A HREF="https://github.com/triton-inference-server/client/blob/a00b97131ffd46c814ae3c2d4eca98266d19f804/src/python/library/tritonclient/http/_client.py#L434">triton client: model_version API structure _client.py#L434</A>
								<DT><A HREF="https://www.youtube.com/watch?v=BhtxEDwgylU&list=LL&index=10">Use AppMap with VS Code Dev Containers - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=6BiNzPdy6YA">[REFAI Seminar 04/16/24] ML for ML Compilers at Google (AutoFDO)</A>
								<DT><A HREF="https://github.com/facebook/proxygen">facebook/proxygen: A collection of C++ HTTP libraries including an easy to use HTTP server.</A>
								<DT><A HREF="https://engineering.fb.com/2014/11/05/production-engineering/introducing-proxygen-facebook-s-c-http-framework/">Introducing Proxygen, Facebook's C++ HTTP framework - Engineering at Meta</A>
								<DT><A HREF="https://www.youtube.com/watch?v=t08OA4CfRFs">Using Rust to write scalable Python APIs - YouTube</A>
								<DT><A HREF="https://github.com/PaddlePaddle/Serving/blob/v0.9.0/doc/Python_Pipeline/Pipeline_Design_CN.md">Serving/doc/Python_Pipeline/Pipeline_Design_CN.md at v0.9.0 ¬∑ PaddlePaddle/Serving</A>
								<DT><A HREF="https://github.com/pytorch/pytorch/blob/c3ee07c71cef9f085577c5e53dfe5faf8f2b3b4e/benchmarks/inference/server.py#L239">pytorch/benchmarks/inference/server.py</A>
								<DT><A HREF="https://jonathanc.net/blogs/maximizing_pytorch_throughput">Maximizing PyTorch Throughput with FastAPI ‚Äì Jonathan Chang‚Äôs Blog</A>
							</DL><p>
							<DT><H3 FOLDED>serving-inference-engine</H3>
							<DL><p>
								<DT><A HREF="https://github.com/wangzyon/pyInfer/blob/master/pyinfer/core/engine/engine.py">pyInfer/pyinfer/core/engine/engine.py</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/legacy/models/providers/diffusers.py">DeepSpeed-MII/mii/legacy/models/providers/diffusers.py</A>
								<DT><A HREF="https://github.com/zhaochenyang20/ModelServer">zhaochenyang20/ModelServer: Efficient, Flexible, and Highly Fault-Tolerant Model Service Management Based on SGLang</A>
							</DL><p>
							<DT><H3 FOLDED>serving-FastAPI</H3>
							<DL><p>
								<DT><H3 FOLDED>Starlette</H3>
								<DL><p>
									<DT><A HREF="https://github.com/encode/starlette/blob/9f16bf5c25e126200701f6e04330864f4a91a898/docs/server-push.md?plain=1#L30">routes without decorators, but constructors and funcs</A>
									<DT><A HREF="https://github.com/tiangolo/fastapi/blob/38929aae1b6d42848652705e5ca618a675dba0e1/fastapi/routing.py#L651">fastapi/fastapi/routing.py</A>
								</DL><p>
								<DT><H3 FOLDED>FastAPI-lifespan</H3>
								<DL><p>
									<DT><A HREF="https://medium.com/@life-is-short-so-enjoy-it/fastapi-experiment-lifespan-feature-7f87de5601db">FastAPI: experiment lifespan feature | by Life-is-short--so--enjoy-it | Medium</A>
								</DL><p>
								<DT><H3 FOLDED>fastapi-examples</H3>
								<DL><p>
									<DT><H3 FOLDED>llama-agentic-system</H3>
									<DL><p>
										<DT><A HREF="https://github.com/meta-llama/llama-agentic-system">meta-llama/llama-agentic-system: Agentic components of the Llama Stack APIs</A>
										<DT><A HREF="https://github.com/meta-llama/llama-agentic-system/blob/b266c1c62bea3c184a93b1bb295468a41d7b555b/llama_agentic_system/server.py#L44">server.py#L44</A>
									</DL><p>
									<DT><A HREF="https://github.com/Lightning-AI/LitServe/blob/ee1a7b53772332a937bdb548277b28cc54ba16e0/src/litserve/server.py#L25">LitServe/src/litserve/server.py</A>
								</DL><p>
								<DT><A HREF="https://www.techempower.com/benchmarks/?utm_source=pocket_mylist#section=data-r20&hw=ph&test=db">HTTP Servers Benchmarks</A>
								<DT><A HREF="https://github.com/roy-pstr/fastapi-custom-exception-handlers-and-logs/blob/master/main.py">fastapi-custom-exception-handlers-and-logs/main.py at master ¬∑ roy-pstr/fastapi-custom-exception-handlers-and-logs</A>
								<DT><A HREF="https://github.com/tiangolo/fastapi/blob/38929aae1b6d42848652705e5ca618a675dba0e1/fastapi/routing.py#L655C13-L655C23">FastAPI: routes as list is deprecated routing.py#L655C13-L655C23</A>
								<DT><A HREF="https://github.com/tiangolo/fastapi/blob/38929aae1b6d42848652705e5ca618a675dba0e1/tests/test_extra_routes.py#L22">FastAPI: router no decorated test_extra_routes.py#L22</A>
								<DT><A HREF="https://github.com/tiangolo/fastapi/blob/38929aae1b6d42848652705e5ca618a675dba0e1/tests/test_include_route.py">fastapi/tests/test_include_route.py</A>
								<DT><A HREF="https://www.youtube.com/watch?v=t08OA4CfRFs">Using Rust to write scalable Python APIs - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=row-SdNdHFE">Best Practice to Make HTTP Request in FastAPI Application - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=tGD3653BrZ8">How FastAPI Handles Requests Behind the Scenes - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=vkQZe8Idbtg">Fastapi endpoints testing with pytest | Tutorial 1 - YouTube</A>
								<DT><A HREF="https://viktorsapozhok.github.io/fastapi-oauth2-postgres/">Structuring FastAPI application with multiple services using 3-tier design pattern. | Vanilla Ninja</A>
								<DT><A HREF="https://github.com/Lightning-AI/LitServe?tab=readme-ov-file#implement-a-server">Lightning-AI/LitServe: Deploy AI models at scale. High-throughput serving engine for AI/ML models that uses the latest state-of-the-art model deployment techniques.</A>
								<DT><A HREF="https://github.com/Lightning-AI/LitServe/blob/ee1a7b53772332a937bdb548277b28cc54ba16e0/src/litserve/server.py#L25">LitServe/src/litserve/server.py</A>
								<DT><A HREF="https://github.com/meta-llama/llama-agentic-system">meta-llama/llama-agentic-system: Agentic components of the Llama Stack APIs</A>
								<DT><A HREF="https://github.com/pytorch/ao/blob/6b529961bd0b41953d26cdde5851f460839d5cf6/examples/sam2_amg_server/server.py">ao/examples/sam2_amg_server/server.py: sam2</A>
							</DL><p>
							<DT><H3 FOLDED>serving-test</H3>
							<DL><p>
								<DT><H3 FOLDED>serving-test-device</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/dc514df2afad386739bf8471ab351a86d5c5ffc7/torch/testing/_internal/common_cuda.py">pytorch/torch/testing/_internal/common_cuda.py</A>
								</DL><p>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/benchmark_throughput.py#L126">vllm/benchmarks/benchmark_throughput.py</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/benchmark_serving.py">vllm/benchmarks/benchmark_serving.py</A>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/integration-tests/conftest.py#L284">text-generation-inference/integration-tests/conftest.py</A>
								<DT><A HREF="https://github.com/tinygrad/tinygrad/discussions?discussions_q=is%3Aopen+test">tinygrad/tinygrad ¬∑ Discussions ¬∑ GitHub</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/test/test_utils.py#L396">sglang/python/sglang/test/test_utils.py: popen_launch_server</A>
							</DL><p>
							<DT><H3 FOLDED>serving-benchmark</H3>
							<DL><p>
								<DT><H3 FOLDED>serving-test-regression</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>serving-evaluation</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-genai-bench</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/genai-bench">sgl-project/genai-bench: Genai-bench is a powerful benchmark tool designed for comprehensive token-level performance evaluation of large language model (LLM) serving systems.</A>
									</DL><p>
									<DT><A HREF="https://x.com/agrawalamey12/status/1946279095198945642">The bitter lesson of AI infra: The hardest part about building faster LLM inference systems is not designing the systems, but rather it is evaluating if the system is actually faster!</A>
									<DT><A HREF="https://arxiv.org/abs/2507.09019">[2507.09019] On Evaluating Performance of LLM Inference Serving Systems</A>
								</DL><p>
								<DT><H3 FOLDED>HTTP-benchmarking</H3>
								<DL><p>
									<DT><A HREF="https://github.com/hatoo/oha">hatoo/oha: Ohayou(„Åä„ÅØ„Çà„ÅÜ), HTTP load generator, inspired by rakyll/hey with tui animation.</A>
									<DT><A HREF="https://github.com/wg/wrk">wg/wrk: Modern HTTP benchmarking tool</A>
									<DT><A HREF="https://github.com/grafana/k6">grafana/k6: A modern load testing tool, using Go and JavaScript - https://k6.io</A>
									<DT><A HREF="https://github.com/sharkdp/hyperfine">sharkdp/hyperfine: A command-line benchmarking tool</A>
									<DT><A HREF="https://httpd.apache.org/docs/current/programs/ab.html">ab - Apache HTTP server benchmarking tool - Apache HTTP Server Version 2.4</A>
									<DT><A HREF="https://gist.github.com/aliesbelik/840eff7c5bc78a141eab8e36f2f4edf2">Benchmarking &amp; load testing tools</A>
								</DL><p>
								<DT><H3 FOLDED>lmsys</H3>
								<DL><p>
									<DT><A HREF="https://lmsys.org/blog/2024-07-25-sglang-llama3/">Achieving Faster Open-Source Llama3 Serving with SGLang Runtime (vs. TensorRT-LLM, vLLM) | LMSYS Org</A>
								</DL><p>
								<DT><A HREF="https://bentoml.com/blog/benchmarking-llm-inference-backends">Benchmarking LLM Inference Backends</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/bench_serving.py">sglang/python/sglang/bench_serving.py</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/benchmark_throughput.py#L126">vllm/benchmarks/benchmark_throughput.py</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/launch_tgi_server.sh">vllm/benchmarks/launch_tgi_server.sh</A>
								<DT><A HREF="https://www.youtube.com/watch?v=7njmta3SlxE">Hao Zhang - Chatbot Arena (UCSD / LMSys) - YouTube</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/benchmark_serving.py">vllm/benchmarks/benchmark_serving.py</A>
								<DT><A HREF="https://twitter.com/dzhulgakov/status/1737917306565697990?s=46&t=yqOem5ktaowo8FyJ-ilbzQ">(1) Dmytro Dzhulgakov en X: "I‚Äôm all pro open benchmarks, but comparing **public** LLM endpoints just doesn‚Äôt work unless there‚Äôs a confirmed huge user base like OpenAI. In fact, performance may be even anti-correlated with popularityüòâ Here‚Äôs why üßµ" / X</A>
								<DT><A HREF="https://twitter.com/anyscalecompute/status/1737883193720922413">(1) Anyscale en X: "üìàWe‚Äôre excited to introduce the LLMPerf leaderboard: the first public and open source leaderboard for benchmarking performance of various LLM inference providers in the market. Our goal with this leaderboard is to equip users and developers with a clear understanding of the... https://t.co/XGF4fhkaWG" / X</A>
								<DT><A HREF="https://github.com/fw-ai/benchmark">fw-ai/benchmark: Benchmark suite for LLMs from Fireworks.ai</A>
								<DT><A HREF="https://github.com/ray-project/llmperf">ray-project/llmperf: LLMPerf is a library for validating and benchmarking LLMs</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/tree/main/benchmarks">vllm/benchmarks at main</A>
								<DT><A HREF="https://modal.com/llm-almanac/advisor?filters=ttft_p95%3C1%2Ctokens%3D512%3B512%2Cmodel%3DQwen+2.5+7B&best_by=latency">LLM Engineer's Almanac - Advisor | Modal</A>
								<DT><A HREF="https://github.com/AI-Hypercomputer/JetStream/blob/main/benchmarks/benchmark_serving.py">JetStream/benchmarks/benchmark_serving.py at main ¬∑ AI-Hypercomputer/JetStream</A>
							</DL><p>
							<DT><H3 FOLDED>serving-types</H3>
							<DL><p>
								<DT><H3 FOLDED>InferenceRequest</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/ccfeda47cb5ca10ee3c4efd9b78c6bb15c2cd3d2/megatron/core/inference_params.py#L1">Megatron-LM: inference_params.py#L1</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/74a1be88f589bdd53e6b110528ae65dba5a1e9af/examples/mamba.py#L297">Tinygrad: inference_params (mamba.py)#L297</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/advanced/inference-request.md">TensorRT-LLM/docs/source/advanced/inference-request.md</A>
								</DL><p>
								<DT><H3 FOLDED>pydantic</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/clients/python/text_generation/types.py">text-generation-inference/clients/python/text_generation/types.py (pydantic v2)</A>
									<DT><A HREF="https://x.com/samsja19/status/1949795304061944007">(1) samsja en X: "yes and no, dataclass are not good enough. Pydantic model / dataclass are way more expressive and validate the input There is a lib maintain by the @pydantic team that allow for overriding cli and load config via toml, that's all you need https://t.co/GXPC5mcNyr" / X</A>
									<DT><A HREF="https://github.com/pydantic/pydantic-settings/tree/main">pydantic/pydantic-settings: Settings management using pydantic</A>
									<DT><A HREF="https://x.com/mikasenghaas/status/1983654738769146231">(1) Mika Senghaas en X: "this unassuming pydantic construction takes ~200ms for 32k tokens with logprobs yes, this is &amp;gt;10min cpu overhead at 4k batch size https://t.co/2fHfHHIDgf" / X</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>SGLang</H3>
							<DL><p>
								<DT><H3 FOLDED>radixark</H3>
								<DL><p>
									<DT><A HREF="https://www.radixark.ai/career">Hiring at RadixArk</A>
									<DT><A HREF="https://www.radixark.ai/job-details/gpu-kernel-engineer-(cuda-triton-pallas)">GPU Kernel Engineer (CUDA / Triton / Pallas)</A>
									<DT><A HREF="https://www.radixark.ai/job-details/gpu-kernel-engineer-(cuda-triton-pallas)-copy">TPU Systems Engineer (JAX / XLA / Pallas)</A>
									<DT><A HREF="https://www.radixark.ai/job-details/backend-platform-engineer">Backend/Platform Engineer</A>
									<DT><A HREF="https://www.radixark.ai/job-details/generalist-systems-engineer-(multi-stack)">Generalist Systems Engineer (Multi-Stack)</A>
									<DT><A HREF="https://www.radixark.ai/job-details/cluster-infrastructure-engineer">Cluster &amp; Infrastructure Engineer</A>
									<DT><A HREF="https://www.radixark.ai/job-details/rl-systems-engineer">RL Systems Engineer</A>
									<DT><A HREF="https://www.radixark.ai/job-details/ai-infra-resident-(1-year-program)">AI Infra Resident (1-Year Program)</A>
									<DT><A HREF="https://www.radixark.ai/job-details/diffusion-inference-engineer">Diffusion Inference Engineer</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-release-notes</H3>
								<DL><p>
									<DT><H3 FOLDED>sglang-v0.4.3</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/releases/tag/v0.4.3">Release v0.4.3 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><A HREF="https://lmsys.org/blog/2024-07-25-sglang-llama3/">Achieving Faster Open-Source Llama3 Serving with SGLang Runtime (vs. TensorRT-LLM, vLLM) | LMSYS Org</A>
									<DT><A HREF="https://lmsys.org/blog/2024-12-04-sglang-v0-4/">SGLang v0.4: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer, Faster Structured Outputs | LMSYS Org</A>
									<DT><A HREF="https://x.com/lmsysorg/status/1872251875070021831">sglang v0.4.1</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-dev</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-roadmap</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/4042">Development Roadmap (2025 H1) ¬∑ Issue #4042 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/7736">Development Roadmap (2025 H2) ¬∑ Issue #7736 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_sglang_roadmap.pdf">sgl-learning-materials/slides/amd_meetup_sglang_roadmap.pdf at main ¬∑ sgl-project/sgl-learning-materials</A>
										<DT><A HREF="https://docs.google.com/document/d/1A7TI0zP9WioloA0RjqVJ5P6FDyw3HZ9tB3ZuUTaWct8/edit?tab=t.0#heading=h.r84v7rmyfqa3">SGLang RL Rampup - Google Docs</A>
									</DL><p>
									<DT><H3 FOLDED>sglang-docker</H3>
									<DL><p>
										<DT><A HREF="https://hub.docker.com/r/lmsysorg/sglang/tags">lmsysorg/sglang Tags | Docker Hub</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/f39037fffbeb463595a1e31d72c85e53b6e7d355/.github/workflows/release-docker-router.yml#L2">sglang/.github/workflows/release-docker-router.yml</A>
									</DL><p>
									<DT><H3 FOLDED>sglang-reverse</H3>
									<DL><p>
										<DT><A HREF="https://github.com/datacrunch-research/text-generation-inference/blob/a110e2807d4fe42ea78243e3638c1c4b1d487d6a/server/text_generation_server/debug_backend.py">text-generation-inference/server/text_generation_server/debug_backend.py at a110e2807d4fe42ea78243e3638c1c4b1d487d6a ¬∑ datacrunch-research/text-generation-inference</A>
										<DT><A HREF="https://github.com/datacrunch-research/mediagen-evals/blob/main/videogen_eval/test_launch.py">mediagen-evals/videogen_eval/test_launch.py at main ¬∑ datacrunch-research/mediagen-evals</A>
										<DT><A HREF="https://github.com/datacrunch-research/mediagen-evals/blob/main/videogen_eval/launch_server.py">mediagen-evals/videogen_eval/launch_server.py at main ¬∑ datacrunch-research/mediagen-evals</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-core</H3>
									<DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1989802218837278723">A year of first-person perspective involvement in the development of an open-source inference framework</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/docs/developer/development_guide_using_docker.md#h200">sglang/docs/developer/development_guide_using_docker.md at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1939041055208112436">Here are some tips for SGLang development, compilation, and profiling.</A>
									<DT><A HREF="https://x.com/StasBekman/status/1989862347423584613">I can even do performance comparisons using just say 8-16 layers</A>
									<DT><A HREF="https://github.com/stas00/the-art-of-debugging/tree/master/pytorch#2-editing-the-config-object-on-the-fly">the-art-of-debugging/pytorch num_hidden_layers</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-debug</H3>
								<DL><p>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1939041055208112436">Here are some tips for SGLang development, compilation, and profiling.</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1984750078074839122">Immediate Crash CUDA-GDB</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-docs</H3>
								<DL><p>
									<DT><H3 FOLDED>sglang-hyperparameter</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/7d6585b1801213d77051f84c4b68e2f7d6f0e0d5/docs/backend/hyperparameter_tuning.md">sglang/docs/backend/hyperparameter_tuning.md</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-notes</H3>
									<DL><p>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/17186885141">SGLang source code study notes: part 1 - cache, req, and scheduler</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-quantization</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/4c59782e0f3d6bc4373333fbdca83959ccc19392/docs/advanced_features/quantization.md">sglang/docs/advanced_features/quantization.md at 4c59782e0f3d6bc4373333fbdca83959ccc19392 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/NVIDIA/Model-Optimizer">NVIDIA/Model-Optimizer: A unified library of SOTA model optimization techniques like quantization, pruning, distillation, speculative decoding, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM, TensorRT, vLLM, etc. to optimize inference speed.</A>
									</DL><p>
									<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial">zhaochenyang20/Awesome-ML-SYS-Tutorial: My learning notes/codes for ML SYS.</A>
									<DT><A HREF="https://github.com/weishengying/Notes/tree/main/sglang">Notes/sglang at main ¬∑ weishengying/Notes</A>
									<DT><A HREF="https://github.com/sgl-project/sgl-learning-materials">sgl-project/sgl-learning-materials: Materials for learning SGLang</A>
									<DT><A HREF="https://www.youtube.com/watch?v=h8YDst5j5SA&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=7">SGLang: An Efficient Open-Source Framework for Large-Scale LLM Serving - Liangsheng Yin - YouTube</A>
									<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/tree/main/sglang/code-walk-through">Awesome-ML-SYS-Tutorial/sglang/code-walk-through at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=XQylGyG7yp8&t=2162s">Lecture 35: SGLang - YouTube</A>
									<DT><A HREF="https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_dev_day_v2.pdf">sgl-learning-materials/slides/amd_dev_day_v2.pdf at main ¬∑ sgl-project/sgl-learning-materials</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Ny4xxErgFgQ">Efficient LLM Inference with SGLang, Lianmin Zheng, xAI - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XQylGyG7yp8">Lecture 35: SGLang - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=KjH7Gl0_pq0">DeepSeek V3, SGLang, and the state of Open Model Inference in 2025 (Quantization, MoEs, Pricing) - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-benchmarking</H3>
								<DL><p>
									<DT><H3 FOLDED>sglang-benchmarking-deepseek</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3">sglang/benchmark/deepseek_v3 at main ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://x.com/i/bookmarks?post_id=1881267587603890338">DeepSeek R1 one batch decoding benchmark</A>
										<DT><A HREF="https://x.com/lmsysorg/status/1881267587603890338">(1) lmsys.org en X: "Under this command: python3 -m sglang.bench_one_batch --batch-size 1 --input 128 --output 256 --model deepseek-ai/DeepSeek-R1 --tp 8 --trust-remote-code you can check performance on 8 * H200. And here's the serving command: python3 -m sglang.launch_server --model https://t.co/orjYuKSz7D" / X</A>
									</DL><p>
									<DT><H3 FOLDED>genai-bench</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/genai-bench">sgl-project/genai-bench: Genai-bench is a powerful benchmark tool designed for comprehensive token-level performance evaluation of large language model (LLM) serving systems.</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/tree/main/benchmark">text-generation-inference/benchmark at main ¬∑ huggingface/text-generation-inference</A>
										<DT><A HREF="https://www.linkedin.com/posts/zhangj_oracle-genai-genaibench-activity-7350901996620533761-EMJm/">Oracle GenAI</A>
										<DT><A HREF="https://github.com/ai-dynamo/aiperf">ai-dynamo/aiperf: AIPerf is a comprehensive benchmarking tool that measures the performance of generative AI models served by your preferred inference solution.</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-bench_serving</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/10409">[benchmark] refactor bench (part 1) by XucSh ¬∑ Pull Request #10409 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-InferenceMax</H3>
									<DL><p>
										<DT><A HREF="https://github.com/InferenceMAX/InferenceMAX">InferenceMAX/InferenceMAX</A>
										<DT><A HREF="https://inferencemax.semianalysis.com/">DeepSeek R1 0528 B200 SG</A>
										<DT><A HREF="https://github.com/InferenceMAX/InferenceMAX/commit/d27433dffb7b90ffc461ede429d897219e950b8b">Update NVIDIA DeepSeek sglang Docker image from v0.5.5 to v0.5.6 (#276) ¬∑ InferenceMAX/InferenceMAX@d27433d</A>
										<DT><A HREF="https://github.com/ishandhanani/srt-slurm/tree/v0.5.5.post2/recipies/gb300-fp4/128k8k">srt-slurm/recipies/gb300-fp4/128k8k at v0.5.5.post2 ¬∑ ishandhanani/srt-slurm</A>
										<DT><A HREF="https://github.com/InferenceMAX/InferenceMAX/issues/390">gb300 disagg prefill deepseek multinode ¬∑ Issue #390 ¬∑ InferenceMAX/InferenceMAX</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/bench_serving.py">sglang/python/sglang/bench_serving.py at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/benchmark/blog_v0_2">sglang/benchmark/blog_v0_2 at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/2b340adfb1ebf6dee420885479ee92296694078c/docker/compose.yaml#L22">sglang/docker/compose.yaml: model weights loading container</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/test/srt/configs/random_config.yaml">sglang/test/srt/configs/random_config.yaml at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://x.com/lmsysorg/status/1890235303270740454">(1) lmsys.org en X: "üöÄ Big update from the sglang team! We've made significant progress on the highly anticipated deepseek model: üöÄ FlashInfer MLA Attention integration for 4x faster long-context performance ‚ö° torch.compile support, hitting 50 tokens/s for online inference üî• CUTLASS block-wise" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2507.09019">[2507.09019] On Evaluating Performance of LLM Inference Serving Systems</A>
									<DT><A HREF="https://github.com/datacrunch-research/scaling-inference/blob/main/scripts/ac4360.py">scaling-inference/scripts/ac4360.py at main ¬∑ datacrunch-research/scaling-inference</A>
									<DT><A HREF="https://inferencemax.semianalysis.com/">InferenceMAX by SemiAnalysis</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-profiling</H3>
								<DL><p>
									<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/sglang/latency-accelerte-for-weight-updates/readme.md">Awesome-ML-SYS-Tutorial/sglang/latency-accelerte-for-weight-updates/readme.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/issues/9638">[Doc] How to profile SGLang ¬∑ Issue #9638 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://docs.sglang.ai/developer_guide/benchmark_and_profiling.html">Benchmark and Profiling ‚Äî SGLang</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1943463615320555663">SGLang Performance Optimization Tips Record from August 2025</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1939041055208112436">Here are some tips for SGLang development, compilation, and profiling.</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1984750078074839122">Layer-by-layer NVTX Profiling</A>
									<DT><A HREF="https://docs.sglang.io/developer_guide/benchmark_and_profiling.html">Benchmark and Profiling ‚Äî SGLang</A>
								</DL><p>
								<DT><H3 FOLDED>srt</H3>
								<DL><p>
									<DT><H3 FOLDED>multiple-token-generation</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/3634">add mtp unit test by zhyncs ¬∑ Pull Request #3634 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://lmsys.org/blog/2025-07-17-mtp/">Accelerating SGLang with Multiple Token Prediction | LMSYS Org</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-attention</H3>
									<DL><p>
										<DT><H3 FOLDED>srt-fa4</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/9428/files">FA4 by hyhieu ¬∑ Pull Request #9428 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><A HREF="https://hebiao064.github.io/fa3-attn-backend-basic">Implement Flash Attention Backend in SGLang - Basics and KV Cache ¬∑ Biao's Blog</A>
										<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/01a19bec9b67313af394920714111f8b9a21dad3/large-language-model-note/sglang%26lightllm/SGLang%20%E6%94%AF%E6%8C%81Flash%20Attention%20V3%20Backend.md">SGLang ÊîØÊåÅFlash Attention V3 Backend.md</A>
									</DL><p>
									<DT><H3 FOLDED>srt/distributed/device_communicators</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/a1c1ebe9357418ae8cf8ffdf66e3eaec066170e8/python/sglang/srt/distributed/device_communicators/cuda_wrapper.py#L64">sglang/python/sglang/srt/distributed/device_communicators/cuda_wrapper.py comm.py</A>
									</DL><p>
									<DT><H3 FOLDED>srt/model_executor/model_runner.py</H3>
									<DL><p>
										<DT><A HREF="https://github.com/CatherineSue/sglang/blob/a41fcad7d9c53b3045bc8e8e9db3e6ad519b4f9d/python/sglang/srt/model_executor/model_runner.py">sglang/python/sglang/srt/model_executor/model_runner.py at a41fcad7d9c53b3045bc8e8e9db3e6ad519b4f9d ¬∑ CatherineSue/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>srt/mem_cache</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/5fc560c096aa6ef17b6a6a706eb5dae405fb6ad9/python/sglang/srt/mem_cache/gds.py">sglang/python/sglang/srt/mem_cache/gds.py</A>
									</DL><p>
									<DT><H3 FOLDED>srt/utils/common</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/d90f9bfc4e6a1772c4a3e063b6e8433e39dd10dc/python/sglang/srt/utils/common.py#L3730-L3735">get_current_device_stream_fast() to reduce overhead to current_stream = torch.cuda.current_stream()</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15835">[Feature] JIT Fused QK norm + qk norm clean up by DarkSharpness ¬∑ Pull Request #15835 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-models</H3>
									<DL><p>
										<DT><H3 FOLDED>sglang-model-support</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/5092">Add Llama4 support by CatherineSue ¬∑ Pull Request #5092 ¬∑ sgl-project/sglang</A>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/5092/files">Add Llama4 support by CatherineSue ¬∑ Pull Request #5092 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-kimi-k2.5</H3>
										<DL><p>
											<DT><A HREF="https://www.linkedin.com/company/sgl-project/posts/?feedView=all">sglang serve --model-path moonshotai/kimi-k2.5 --tp 8 --trust-remote-code --tool-call-parser kimi_k2 --reassoning-parser kimi_k2</A>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/17789/changes">Support Kimi-K2.5 model by yhyang201 ¬∑ Pull Request #17789 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-glm4.5</H3>
										<DL><p>
											<DT><A HREF="https://x.com/lmsysorg/status/1950996781422223779">(1) LMSYS Org en X: "üö®GLM-4.5 is here ‚Äî now fully supported on SGLang! Unified reasoning, coding, and agentic capabilities with 128k context. Competitive with Claude 4, ahead of Kimi K2, and top-tier on MATH500, SWE-bench, and more. Deploy with a single command: python3 -m sglang.launch_server" / X</A>
											<DT><A HREF="https://lmsys.org/blog/2026-01-21-novita-glm4/">Optimizing GLM4-MoE for Production: 65% Faster TTFT with SGLang | LMSYS Org</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-llama4</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/5092">Add Llama4 support by CatherineSue ¬∑ Pull Request #5092 ¬∑ sgl-project/sglang</A>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/5092/files">Add Llama4 support by CatherineSue ¬∑ Pull Request #5092 ¬∑ sgl-project/sglang</A>
											<DT><A HREF="https://github.com/CatherineSue/sglang/blob/a41fcad7d9c53b3045bc8e8e9db3e6ad519b4f9d/python/sglang/srt/models/mllama4.py">sglang/python/sglang/srt/models/mllama4.py</A>
											<DT><A HREF="https://github.com/vllm-project/vllm/blob/v0.8.3/vllm/model_executor/models/llama4.py">vllm/vllm/model_executor/models/llama4.py at v0.8.3 ¬∑ vllm-project/vllm</A>
											<DT><A HREF="https://ai.meta.com/blog/llama-4-multimodal-intelligence/">The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-oss</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/issues/8833">[Tracking] OpenAI gpt-oss Day 0 Support ¬∑ Issue #8833 ¬∑ sgl-project/sglang</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>srt/layers</H3>
									<DL><p>
										<DT><H3 FOLDED>srt/layers/attention</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/9428">FA4 by hyhieu ¬∑ Pull Request #9428 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>srt-quantization</H3>
										<DL><p>
											<DT><H3 FOLDED>srt-W4AFp8Config</H3>
											<DL><p>
												<DT><A HREF="https://github.com/sgl-project/sglang/blob/f1f4c451ab8ed404ff0662b9970dd484e19d3cc5/python/sglang/srt/layers/quantization/w4afp8.py#L38">sglang/python/sglang/srt/layers/quantization/w4afp8.py at f1f4c451ab8ed404ff0662b9970dd484e19d3cc5 ¬∑ sgl-project/sglang</A>
											</DL><p>
											<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/sglang/quantization/quantization_architecture_en.md">Awesome-ML-SYS-Tutorial/sglang/quantization/quantization_architecture_en.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
											<DT><A HREF="https://www.linkedin.com/pulse/analysis-sglang-frameworks-quantization-design-approach-chenyang-zhao-lsbse/?trackingId=YnJnkpRm3gTLkmtrtyxRcw%3D%3D">(1) An Analysis of SGLang Framework's Quantization Design and Approach | LinkedIn</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/python/sglang/srt/layers">sglang/python/sglang/srt/layers at main ¬∑ sgl-project/sglang</A>
								</DL><p>
								<DT><H3 FOLDED>sglang-turbomind</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang">sgl-project/sglang: SGLang is yet another fast serving framework for large language models and vision language models.</A>
									<DT><A HREF="https://github.com/InternLM/turbomind">InternLM/turbomind</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XQylGyG7yp8&t=2162s">Lecture 35: SGLang - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-dpsk</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-dpsk-v3.2</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/15025">[Roadmap] DeepSeek v3.2 Optimization ¬∑ Issue #15025 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-dsa</H3>
									<DL><p>
										<DT><H3 FOLDED>sgl-dsa-cp</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/12065">(1/n)support context parallel with deepseekv3.2-DSA by lixiaolx ¬∑ Pull Request #12065 ¬∑ sgl-project/sglang</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>sgl-gb300-dpsk</H3>
									<DL><p>
										<DT><H3 FOLDED>sgl-gb300-dpsk-profiling</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ishandhanani/srt-slurm/commit/fa705dc06fb55988ef9398258c58bc64cf9a29ef">support set prefill/decode profiling step separately and agg profiling</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-gb300-dpsk-1p1d</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ishandhanani/srt-slurm/blob/v0.5.5.post2/recipies/gb300-fp4/128k8k/3-mid-curve-pt2.yaml">srt-slurm/recipies/gb300-fp4/128k8k/3-mid-curve-pt2.yaml decode_nodes: 1, prefill_nodes: 1</A>
										</DL><p>
										<DT><A HREF="https://github.com/ishandhanani/srt-slurm/tree/v0.5.5.post2/recipies/gb300-fp4/128k8k">srt-slurm/recipies/gb300-fp4/128k8k at v0.5.5.post2 ¬∑ ishandhanani/srt-slurm</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/10903">Instructions for DeepSeek on GB200 ¬∑ Issue #10903 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>srt-slurm</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ishandhanani/srt-slurm/tree/v0.5.5.post2/recipies/gb300-fp4/128k8k">srt-slurm/recipies/gb300-fp4/128k8k at v0.5.5.post2 ¬∑ ishandhanani/srt-slurm</A>
									</DL><p>
									<DT><H3 FOLDED>dpsk-profiling</H3>
									<DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/profile-data">deepseek-ai/profile-data: Analyze computation-communication overlap in V3/R1.</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/issues/2591">[Feature] DeepSeek V3 optimization ¬∑ Issue #2591 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/pull/2719">DeepSeek V3 FP8 Support by yingcanw ¬∑ Pull Request #2719 ¬∑ NVIDIA/TensorRT-LLM</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/issues/2965">[Feature] remove vllm _custom_ops ¬∑ Issue #2965 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://x.com/lmsysorg/status/1890235303270740454">(1) lmsys.org en X: "üöÄ Big update from the sglang team! We've made significant progress on the highly anticipated deepseek model: üöÄ FlashInfer MLA Attention integration for 4x faster long-context performance ‚ö° torch.compile support, hitting 50 tokens/s for online inference üî• CUTLASS block-wise" / X</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/releases/tag/v0.4.3">Release v0.4.3 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/issues/5514">[Tracker] SGLang v0.4.5.post1 performance on H200 ¬∑ Issue #5514 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://docs.sglang.ai/basic_usage/deepseek_v32.html">DeepSeek V3.2 Usage ‚Äî SGLang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/16660/changes">[CI] Enable dpsk v31 test on nightly H200 by Fridge003 ¬∑ Pull Request #16660 ¬∑ sgl-project/sglang</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-compile</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-jit</H3>
									<DL><p>
										<DT><H3 FOLDED>sgl-jit-example</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/blob/4397cda7dcd66207a4553297b312f33cbadba91d/python/sglang/jit_kernel/tests/test_add_constant.py#L1">sglang/python/sglang/jit_kernel/tests/test_add_constant.py sglang.jit_kernel.add_constant import add_constant</A>
										</DL><p>
										<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/01a19bec9b67313af394920714111f8b9a21dad3/large-language-model-note/sglang%26lightllm/SGLang_JIT_%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3.md">SGLang_JIT_Technical Documentation.md</A>
										<DT><A HREF="https://x.com/lm_zheng/status/1994514462494380235">sgl tvm-ffi jit kernels to reduce binary size</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/4397cda7dcd66207a4553297b312f33cbadba91d/docs/developer_guide/JIT_kernels.md">sglang/docs/developer_guide/JIT_kernels.md</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/4397cda7dcd66207a4553297b312f33cbadba91d/python/sglang/jit_kernel/tests/test_add_constant.py#L1">sglang/python/sglang/jit_kernel/tests/test_add_constant.py</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/16884">[Refactor] Clean up JIT kernel utilites by DarkSharpness ¬∑ Pull Request #16884 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1939041055208112436">Here are some tips for SGLang development, compilation, and profiling.</A>
									<DT><A HREF="https://www.zhihu.com/question/660924854/answer/1979122447296008661">How to learn the technology stack of large model inference platforms?</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/issues/10118">[RFC] SGLang unified kernel fusion and torch compile optimisations ¬∑ Issue #10118 ¬∑ sgl-project/sglang</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-kernels</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-moe</H3>
									<DL><p>
										<DT><H3 FOLDED>deepseek-moe</H3>
										<DL><p>
											<DT><H3 FOLDED>moe-token-based</H3>
											<DL><p>
												<DT><A HREF="https://github.com/radixark/miles/blob/fc798d2c12e2b382cdaf6854a657e038b4eb53de/miles/rollout/modular_rollout/inference_wrapper_generate.py">miles/miles/rollout/modular_rollout/inference_wrapper_generate.py at fc798d2c12e2b382cdaf6854a657e038b4eb53de ¬∑ radixark/miles</A>
											</DL><p>
											<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247493157&idx=1&sn=51c0e27a347dd3fe1ed868d87f667897&chksm=f995f6e7cee27ff1a95d59aefe6bcf4117115343b301dddcc3ea7646dfeb61b582a90d507a16&cur_album_id=3396415517161095170&scene=189&poc_token=HFCN_mejAGWeYB52g6Vft2lx3uMgK8i_wzNqNGnJ">ËØ¶ÁªÜË∞àË∞àDeepSeek MoEÁõ∏ÂÖ≥ÁöÑÊäÄÊúØÂèëÂ±ï</A>
											<DT><A HREF="https://x.com/_xjdr/status/2001438418941940079">xjdr: in a deepseek-shaped moe, the experts dominate memory + compute. so you look at b200 and think: ‚Äúit has absurd fp8 + nvfp4 throughput... why am i doing expert matmuls for training in bf16?</A>
											<DT><A HREF="https://x.com/_xjdr/status/2001436350634168737">(1) xjdr en X: "On RD/EP: in a MoE you have a bunch of mlps (‚Äúexperts‚Äù), and a router that picks a few experts per token (top‚Äëk). you only run those experts. the catch is that the router shatters your batch. instead of one big matmul (what gpus love), you get E little matmuls (one per expert),"</A>
										</DL><p>
										<DT><H3 FOLDED>sglang-ep-moe-W4AFP8</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/7762">feat: support DeepSeek-R1-W4AFP8 model with ep-moe mode by yangsijia-serena ¬∑ Pull Request #7762 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-moe-kimi_k2</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/13374/files">[opt kimi k2 3/n] opt kimi_k2 moe_fused_gate kernel by BBuf ¬∑ Pull Request #13374 ¬∑ sgl-project/sglang</A>
											<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/0939a052893b29e458aad73d91316cf4f2275c5e/large-language-model-note/moe%20align%20block%20size%20kernel%E7%9A%84%E4%BC%98%E5%8C%96%E6%BA%90%E7%A0%81.md">how-to-optim-algorithm-in-cuda/large-language-model-note/moe align block size kernelÁöÑ‰ºòÂåñÊ∫êÁ†Å.md at 0939a052893b29e458aad73d91316cf4f2275c5e ¬∑ BBuf/how-to-optim-algorithm-in-cuda</A>
										</DL><p>
										<DT><H3 FOLDED>MetaShuffling</H3>
										<DL><p>
											<DT><A HREF="https://pytorch.org/blog/metashuffling-accelerating-llama-4-moe-inference/">MetaShuffling: Accelerating Llama 4 MoE Inference ‚Äì PyTorch</A>
										</DL><p>
										<DT><H3 FOLDED>MoMoE</H3>
										<DL><p>
											<DT><A HREF="https://x.com/tilderesearch/status/1948818857214574652">(1) Tilde en X: "Mixture‚Äëof‚ÄëExperts (MoE) powers many frontier models like R1, K2, &amp;amp; Qwen3 ‚ö°Ô∏è To make frontier-scale MoE models accessible to train, we open-source¬†MoMoE, a hyper-performant MoE implementation built for training and inference, outpacing the fastest existing ones by up to: - 70% https://t.co/QXBZTQF4Np" / X</A>
											<DT><A HREF="https://www.tilderesearch.com/blog/momoe">MoMoE: Memory-optimized Mixture of Experts | Tilde</A>
										</DL><p>
										<DT><A HREF="https://github.com/BBuf/tensorrt-llm-moe">BBuf/tensorrt-llm-moe</A>
										<DT><A HREF="https://arxiv.org/abs/2501.08313">[2501.08313] MiniMax-01: Scaling Foundation Models with Lightning Attention</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/2920">[kernel] MiniMax-Text-01 decode lightning_attn with triton by BBuf ¬∑ Pull Request #2920 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/2471#event-15791112196">[Feature] FusedMoE H200 tuning ¬∑ Issue #2471 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/2767">add benchmark_moe_align_blocks by BBuf ¬∑ Pull Request #2767 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://mp.weixin.qq.com/s/WFJxnTF9fGIIXPA7GQ5V2w">ËØ¶ÁªÜË∞àË∞àDeepSeek MoEÁõ∏ÂÖ≥ÁöÑÊäÄÊúØÂèëÂ±ï</A>
										<DT><A HREF="https://github.com/triton-lang/triton/pull/6429">[BENCH] added production kernels and micro-benchmark for mixture-of-experts MLP by ptillet ¬∑ Pull Request #6429 ¬∑ triton-lang/triton</A>
										<DT><A HREF="https://arxiv.org/pdf/2502.19811">Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1914466839750218423">Meta ShufflingÁöÑMoE Grouped GEMM kernel benchmark - Áü•‰πé</A>
										<DT><A HREF="https://cursor.com/blog/kernels">1.5x Faster MoE Training with Custom MXFP8 Kernels | Cursor - The AI Code Editor</A>
										<DT><A HREF="https://pytorch.org/blog/accelerating-moes-with-a-triton-persistent-cache-aware-grouped-gemm-kernel/">Accelerating MoE‚Äôs with a Triton Persistent Cache-Aware Grouped GEMM Kernel ‚Äì PyTorch</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/29264560896">A real-world deployment of a 10,000-GPU cluster has saved millions of GPU hours! MoE communication optimization technology COMET is now open source.</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1985487895319052795">Let's discuss optimization strategies for MoE Group GEMM in TP inference scenarios.</A>
										<DT><A HREF="https://x.com/StasBekman/status/1990608885212983363">Have you ever wondered by how much is your MoE implementation slower than its dense equivalent</A>
										<DT><A HREF="https://lmsys.org/blog/2026-01-21-novita-glm4/">Optimizing GLM4-MoE for Production: 65% Faster TTFT with SGLang | LMSYS Org</A>
										<DT><A HREF="https://github.com/osayamenja/FlashMoE">osayamenja/FlashMoE: Distributed MoE in a Single Kernel [NeurIPS '25]</A>
										<DT><A HREF="https://x.com/_xjdr/status/2010925809452622068">(1) xjdr en X: "this is why i have trust issues https://t.co/IK9IU7IVSW" / X</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-inductor</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/4748">[Feature] beat torch compile ¬∑ Issue #4748 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-blackwell</H3>
									<DL><p>
										<DT><H3 FOLDED>sgl-NVL72</H3>
										<DL><p>
											<DT><H3 FOLDED>sgl-nvl72-setup</H3>
											<DL><p>
												<DT><A HREF="https://docs.nvidia.com/mission-control/docs/rack-bring-up-install/2.0.0/rack-bring-up.html#configure-nmx-c-leader">GB200/GB300 Rack Power On and Bring Up ‚Äî NVIDIA Mission Control Management Plane and Rack Setup with NVIDIA GB200 NVL72 Systems Installation Guide</A>
												<DT><A HREF="https://docs.nvidia.com/dgx/dgxgb200-user-guide/rack-reboot-sequence.html#post-reboot-verification">Rack Reboot Sequence ‚Äî NVIDIA DGX GB200 User Guide</A>
											</DL><p>
											<DT><H3 FOLDED>sgl-gb200-container</H3>
											<DL><p>
												<DT><A HREF="https://hub.docker.com/layers/lmsysorg/sglang/v0.4.9.post6-cu128-gb200/images/sha256-b0aadc8ed6c91572413e8db3c9626b6a88cbdecbd78bc40832ee71db6a10111f">Image Layer Details - lmsysorg/sglang:v0.4.9.post6-cu128-gb200 | Docker Hub</A>
												<DT><A HREF="https://x.com/lmsysorg/status/1950361560997908850">DeepSeek R1 GB200 NVL72 inference container</A>
												<DT><A HREF="https://github.com/sgl-project/sglang/issues/10903">Instructions for DeepSeek on GB200 ¬∑ Issue #10903 ¬∑ sgl-project/sglang</A>
											</DL><p>
											<DT><H3 FOLDED>sgl-gb300-container</H3>
											<DL><p>
												<DT><A HREF="https://hub.docker.com/layers/lmsysorg/sglang/dev-arm64-cu13/images/sha256-e5e79406c48b67a13b24040cb96c08669dcf7f366d7ff94e5e0331f5c1b74f43">Image Layer Details - lmsysorg/sglang:dev-arm64-cu13 | Docker Hub</A>
											</DL><p>
											<DT><A HREF="https://lmsys.org/blog/2025-09-25-gb200-part-2/">Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part II): 3.8x Prefill, 4.8x Decode Throughput | LMSYS Org</A>
											<DT><A HREF="https://lmsys.org/blog/2025-06-16-gb200-part-1/">Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part I): 2.7x Higher Decoding Throughput | LMSYS Org</A>
											<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72503/">LLM Inference Performance and Optimization on NVIDIA GB200 NVL72 | GTC 25 2025 | NVIDIA On-Demand</A>
											<DT><A HREF="https://github.com/deepseek-ai/DeepEP/pull/193/files">Allow multi-node NVLink detection: NVSHMEM_DISABLE_MNNVL = 1</A>
											<DT><A HREF="https://github.com/vllm-project/vllm/blob/6066284914c7984b37dc8bed69ac29bf21f8c49e/vllm/env_override.py#L23">vllm/vllm/env_override.py at NCCL_CUMEM_ENABLE = 0</A>
											<DT><A HREF="https://x.com/SemiAnalysis_/status/1978210309442851270">SemiAnalysis en X: "What ops do GPUs execute when training MoEs, and how does that relate to GB200 NVL72? Keywords: Dispatch / Combine / DP x EP / Large-scale EP Dispatch In each GPU, each token are routed to the corresponding expert(s). The operation is an All-to-All collective because expert https://t.co/9uGJe3EFhY" / X</A>
											<DT><A HREF="https://lmsys.org/blog/2025-10-14-sa-inference-max/">NVIDIA and SGLang Accelerating SemiAnalysis InferenceMAX and GB200 Together | LMSYS Org</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-sm103</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/docker/Dockerfile#L249">sglang/docker/Dockerfile # 12.9.1+ properly supports Blackwell 10.3</A>
										</DL><p>
										<DT><A HREF="https://x.com/SemiAnalysis_/status/1978256694397550688">(1) SemiAnalysis en X: "SGLang team was the first open-source solution to reproduce DeepSeek‚Äôs multi-node inference system and performance (ultra-wide expert parallelism, disaggregated prefill, and DP attention). Looking forward to adding disaggregated prefill and wide EP on InferenceMAX 8-way machines https://t.co/fON6xdMPZO" / X</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-tpu</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/7736">Development Roadmap (2025 H2) ¬∑ Issue #7736 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang-jax">sgl-project/sglang-jax: JAX backend for SGL</A>
										<DT><A HREF="https://github.com/sgl-project/sglang-jax/blob/bce2119fe54400726578caa6913e2df7f4adb7a3/docs/developer_guide/jax_tutorial.md?plain=1#L31">sglang-jax/docs/developer_guide/jax_tutorial.md at bce2119fe54400726578caa6913e2df7f4adb7a3 ¬∑ sgl-project/sglang-jax</A>
										<DT><A HREF="https://github.com/sgl-project/sglang-jax/blob/bce2119fe54400726578caa6913e2df7f4adb7a3/docs/features/attention_backend.md?plain=1#L88">sglang-jax/docs/features/attention_backend.md at bce2119fe54400726578caa6913e2df7f4adb7a3 ¬∑ sgl-project/sglang-jax</A>
										<DT><A HREF="https://github.com/sgl-project/sglang-jax/blob/bce2119fe54400726578caa6913e2df7f4adb7a3/python/sgl_jax/srt/layers/gmm/megablox_gmm_kernel/gmm.py#L11">sglang-jax/python/sgl_jax/srt/layers/gmm/megablox_gmm_kernel/gmm.py at bce2119fe54400726578caa6913e2df7f4adb7a3 ¬∑ sgl-project/sglang-jax</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-DeepGEMM</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/DeepGEMM/commit/1392a4d054b7db5ddee89bf9b261645edf6f5464">Make various updates and fixes: (#164) (#2) ¬∑ sgl-project/DeepGEMM@1392a4d</A>
										<DT><A HREF="https://github.com/sgl-project/DeepGEMM/blob/1392a4d054b7db5ddee89bf9b261645edf6f5464/tests/test_bf16.py">DeepGEMM/tests/test_bf16.py at 1392a4d054b7db5ddee89bf9b261645edf6f5464 ¬∑ sgl-project/DeepGEMM</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/7116">Reproduction commands for decode speed ¬∑ Issue #7116 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-tensort-llm</H3>
									<DL><p>
										<DT><A HREF="https://github.com/BBuf/tensorrt-llm-moe">BBuf/tensorrt-llm-moe</A>
										<DT><A HREF="https://github.com/BBuf/tensorrt-llm-moe/blob/master/cpp/tensorrt_llm/kernels/cutlass_kernels/python/generate_kernels.py">tensorrt-llm-moe/cpp/tensorrt_llm/kernels/cutlass_kernels/python/generate_kernels.py at master ¬∑ BBuf/tensorrt-llm-moe</A>
										<DT><A HREF="https://docs.nvidia.com/deeplearning/tensorrt/latest/installing-tensorrt/installing.html">Installing TensorRT apt-get install tensorrt</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/sgl-kernel">sglang/sgl-kernel at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/issues/2965">[Feature] remove vllm _custom_ops ¬∑ Issue #2965 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/3178">chore: bump 0.0.3 for sgl-kernel by zhyncs ¬∑ Pull Request #3178 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/zhihu/ZhiLight">zhihu/ZhiLight: A highly optimized LLM inference acceleration engine for Llama and its variants.</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/3602">Expert Parallelism (EP) Support for DeepSeek V3 by sleepcoo ¬∑ Pull Request #3602 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/23574608727">SGLang DP MLA ÁâπÊÄßËß£ËØª - Áü•‰πé</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1914466839750218423">Meta ShufflingÁöÑMoE Grouped GEMM kernel benchmark - Áü•‰πé</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/pull/20957">[DP/EP] PPLX&lt;&gt;Triton Debug by robertgshaw2-redhat</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/pull/15835">[Feature] JIT Fused QK norm + qk norm clean up by DarkSharpness ¬∑ Pull Request #15835 ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/01a19bec9b67313af394920714111f8b9a21dad3/large-language-model-note/sglang%26lightllm/SGLang_JIT_%E6%8A%80%E6%9C%AF%E6%96%87%E6%A1%A3.md">SGLang_JIT_Technical Documentation.md</A>
									<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/01a19bec9b67313af394920714111f8b9a21dad3/large-language-model-note/sglang%26lightllm/SGLang%20%E6%94%AF%E6%8C%81Flash%20Attention%20V3%20Backend.md">SGLang ÊîØÊåÅFlash Attention V3 Backend.md</A>
									<DT><A HREF="https://github.com/Tencent/hpc-ops">Tencent/hpc-ops: High Performance LLM Inference Operator Library</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-server</H3>
								<DL><p>
									<DT><H3 FOLDED>sglang-backend</H3>
									<DL><p>
										<DT><H3 FOLDED>sglang-OpenAI-API</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/blob/16267d4fa721b3e8c11e9b3d41f5d53fa8bedaf1/docs/backend/openai_api_completions.ipynb">sglang/docs/backend/openai_api_completions.ipynb at 16267d4fa721b3e8c11e9b3d41f5d53fa8bedaf1 ¬∑ sgl-project/sglang</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>sgl-scheduler</H3>
									<DL><p>
										<DT><A HREF="https://www.linkedin.com/pulse/from-kv-cache-zero-overhead-scheduling-understanding-sglangs-zhao-oc7nc/?trackingId=wlicrjAXQeqfi4QfYebjvw%3D%3D">(6) From KV Cache to Zero Overhead Scheduling: Understanding SGLang's Scheduling Ingenuity | LinkedIn</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-reasoning</H3>
									<DL><p>
										<DT><H3 FOLDED>sglang-dynamic-reassoning</H3>
										<DL><p>
											<DT><A HREF="https://www.linkedin.com/pulse/think-less-more-dynamic-reasoning-sglang-ai-agents-yudi-xue-j11hc/">Think Less, Think More: Dynamic Reasoning with SGLang for Ultra-Efficient AI Agents</A>
										</DL><p>
										<DT><A HREF="https://veitner.bearblog.dev/how-to-use-reasoning-models-with-sglang/">How to use reasoning models with SGLang | simons blog</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/9a405274e287ce370a7788c6c70c4d40b06b688b/test/srt/test_enable_thinking.py#L41">sglang/test/srt/test_enable_thinking.py: --reasoning-parser</A>
									</DL><p>
									<DT><H3 FOLDED>sglang-vlm</H3>
									<DL><p>
										<DT><A HREF="https://lmsys.org/blog/2025-07-16-nvila/">How to support new VLMs into SGLang: A Case Study with NVILA</A>
										<DT><A HREF="https://x.com/lmsysorg/status/1945558596718399648">(1) LMSYS Org en X: "üöÄSummer Fest Day 4: Turbocharging Vision-Language Models with SGLang + NVILA 4.4√ó throughput, 2.2√ó faster response time! We've integrated NVILA into SGLang, enabling high-performance, scalable serving of vision-language models. This unlocks a 4.4√ó TPS boost and significantly https://t.co/GRNkXkTB5C" / X</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-server-profiling</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/10804">[Feature] Sglang Tracing: Fine-Grained Tracking for Request Latency - Part 2 by sufeng-buaa ¬∑ Pull Request #10804 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-instrument</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/11074/files">[metrics] instrument fastapi for tracing by lun-4 ¬∑ Pull Request #11074 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-tracing</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/13152">Sglang Tracing: Add trace-level, trace-module, and unify tracing/request-stage-metrics by sufeng-buaa ¬∑ Pull Request #13152 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-weights</H3>
									<DL><p>
										<DT><H3 FOLDED>Tensor R-Fork</H3>
										<DL><p>
											<DT><A HREF="https://lmsys.org/blog/2025-12-10-rfork/">Let Tensors Fly ‚Äî Accelerating Large Model Weight Loading with R-Fork | LMSYS Org</A>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/8215">Support loading weights from remote instance by amysaq2023 ¬∑ Pull Request #8215 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-s3</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/11865">Fix model loading from S3 buckets by ganochenkodg ¬∑ Pull Request #11865 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-rdma-model-weights</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/8215">Support loading weights from remote instance by amysaq2023 ¬∑ Pull Request #8215 ¬∑ sgl-project/sglang</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/lm-sys/FastChat/tree/main">lm-sys/FastChat: An open platform for training, serving, and evaluating large language models. Release repo for Vicuna and Chatbot Arena.</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/python/sglang/srt/managers">sglang/python/sglang/srt/managers at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/205d5cb407f7860c79df870b3f045d74b8292f77/python/sglang/launch_server.py#L13">sglang/python/sglang/launch_server.py ServerArgs</A>
								</DL><p>
								<DT><H3 FOLDED>disaggregating-prefill-decoding</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-pd-disaggregation</H3>
									<DL><p>
										<DT><H3 FOLDED>sgl-deepEP</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/pull/17289/changes">Overlap shared experts with deepep dispatch for single batch overlap on Blackwell by Fridge003 ¬∑ Pull Request #17289 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>pd-ratio</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/compare/main...doc-pd-ratio">[doc] add doc about how to tune pd ratio #7865</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-pd-trace</H3>
										<DL><p>
											<DT><H3 FOLDED>sgl-request-tracing</H3>
											<DL><p>
												<DT><A HREF="https://github.com/sgl-project/sglang/pull/10804">[Feature] Sglang Tracing: Fine-Grained Tracking for Request Latency - Part 2 by sufeng-buaa ¬∑ Pull Request #10804 ¬∑ sgl-project/sglang</A>
											</DL><p>
											<DT><H3 FOLDED>sgl-pd-metrics</H3>
											<DL><p>
												<DT><A HREF="https://github.com/sgl-project/sglang/pull/8710">[PD metrics] Add latency Histogram metrics of each stage for generate requests by acelyc111 ¬∑ Pull Request #8710 ¬∑ sgl-project/sglang</A>
												<DT><A HREF="https://github.com/sgl-project/sglang/pull/6225">Support incremental streaming of logprob/token_ids between scheduler and detokenizer by merrymercy ¬∑ Pull Request #6225 ¬∑ sgl-project/sglang</A>
												<DT><A HREF="https://github.com/sgl-project/sglang/pull/10815">[PD] TimeStats for PD disaggregation by LJL36 ¬∑ Pull Request #10815 ¬∑ sgl-project/sglang</A>
											</DL><p>
											<DT><H3 FOLDED>sgl-TimeState</H3>
											<DL><p>
											</DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/issues/10916">[Feature] Propose Unified Observability Interface for Request Tracing, PD Metric, and TimeStat Log ¬∑ Issue #10916 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-1P1D</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ishandhanani/srt-slurm/blob/v0.5.5.post2/recipies/gb300-fp4/128k8k/1-top-of-curve.yaml">srt-slurm/recipies/gb300-fp4/128k8k/1-top-of-curve.yaml</A>
											<DT><A HREF="https://github.com/InferenceMAX/InferenceMAX/issues/390">gb300 disagg prefill deepseek multinode ¬∑ Issue #390 ¬∑ InferenceMAX/InferenceMAX</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-pd-profilling</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ishandhanani/srt-slurm/commit/fa705dc06fb55988ef9398258c58bc64cf9a29ef">support set prefill/decode profiling step separately and agg profilin</A>
										</DL><p>
										<DT><H3 FOLDED>sgl-pd-deployments</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/issues/10903">Instructions for DeepSeek on GB200 ¬∑ Issue #10903 ¬∑ sgl-project/sglang</A>
										</DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/issues/4655">[Roadmap] Prefill and Decoding Disaggregation ¬∑ Issue #4655 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://lmsys.org/blog/2025-05-05-large-scale-ep/">Deploying DeepSeek with PD Disaggregation and Large-scale Expert Parallelism on 96 H100 GPUs | LMSYS Org</A>
										<DT><A HREF="https://lmsys.org/blog/2025-06-16-gb200-part-1/">Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part I): 2.7x Higher Decoding Throughput | LMSYS Org</A>
										<DT><A HREF="https://x.com/lmsysorg/status/1919465296966123721">(2) LMSYS Org en X: "üöÄ Breaking: SGLang provides the first open-source implementation to serve @deepseek_ai V3/R1 models with large-scale expert parallelism and prefill-decode disaggregation on 96 GPUs. It nearly matches the throughput reported by the official DeepSeek blog, achieving 52.3K input https://t.co/HJ5FM8RZWI" / X</A>
										<DT><A HREF="https://github.com/infinigence/Semi-PD">infinigence/Semi-PD: A prefill &amp; decode disaggregated LLM serving framework with shared GPU memory and fine-grained compute isolation.</A>
										<DT><A HREF="https://github.com/sgl-project/ome/blob/90a66560d8fff0d83c576481b2e1991fe9cf31b9/config/runtimes/srt/kimi-k2-pd-rt.yaml">ome/config/runtimes/srt/kimi-k2-pd-rt.yaml prefill decode router commands</A>
										<DT><A HREF="https://developer.nvidia.com/blog/accelerated-inference-for-large-transformer-models-using-nvidia-fastertransformer-and-nvidia-triton-inference-server/">(Q*K^T) * V computation process with caching</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-pd-benchmarking</H3>
									<DL><p>
										<DT><H3 FOLDED>srt-slurm</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ishandhanani/srt-slurm">ishandhanani/srt-slurm: Collection of SLURM deployment scripts for various hardware + sglang disaggregation variants</A>
											<DT><A HREF="https://github.com/ishandhanani/srt-slurm/pull/19">Add tagging system for benchmark runs by ishandhanani ¬∑ Pull Request #19 ¬∑ ishandhanani/srt-slurm</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>sgl-dynamo</H3>
									<DL><p>
										<DT><H3 FOLDED>pd-dynamo-configs</H3>
										<DL><p>
											<DT><A HREF="https://www.youtube.com/watch?v=3C-6STonTLU&t=4383s">Introducing NVIDIA Dynamo: Low-Latency Distributed Inference for Scaling Reasoning LLMs - YouTube</A>
										</DL><p>
										<DT><A HREF="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo: A Datacenter Scale Distributed Inference Serving Framework</A>
										<DT><A HREF="https://hub.docker.com/r/ishandhanani/sglang/tags">ishandhanani/sglang - Docker Image</A>
									</DL><p>
									<DT><H3 FOLDED>MoonCake</H3>
									<DL><p>
										<DT><H3 FOLDED>mooncacke-benchmarking</H3>
										<DL><p>
											<DT><H3 FOLDED>mooncaake-aiperf</H3>
											<DL><p>
												<DT><A HREF="https://github.com/ishandhanani/srt-slurm/pull/70/files">This benchmark tests KV-aware routing performance using the Mooncake conversation trace dataset from the FAST25 paper</A>
												<DT><A HREF="https://github.com/ai-dynamo/aiperf">ai-dynamo/aiperf: AIPerf is a comprehensive benchmarking tool that measures the performance of generative AI models served by your preferred inference solution.</A>
											</DL><p>
										</DL><p>
										<DT><A HREF="https://arxiv.org/abs/2407.00079">[2407.00079] Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving</A>
										<DT><A HREF="https://github.com/kvcache-ai/Mooncake?tab=readme-ov-file">kvcache-ai/Mooncake: Mooncake is the serving platform for Kimi, a leading LLM service provided by Moonshot AI.</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/705754254">Mooncake (1): Âú®Êúà‰πãÊöóÈù¢ÂÅöÊúàÈ•ºÔºåKimi ‰ª• KVCache ‰∏∫‰∏≠ÂøÉÁöÑÂàÜÁ¶ªÂºèÊé®ÁêÜÊû∂ÊûÑ - Áü•‰πé</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/705910725">ÂÖ≥‰∫é Mooncake ÁöÑÁ¢éÁ¢éÂøµ - Áü•‰πé</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/706204757">Mooncake (2)ÔºöKimi ‚ÄúÊ≥ºÂ§©ÁöÑÊµÅÈáè‚ÄùÊÄé‰πàÊé•ÔºåÂàÜÁ¶ªÊû∂ÊûÑ‰∏ãÂü∫‰∫éÈ¢ÑÊµãÁöÑË∞ÉÂ∫¶Á≠ñÁï• - Áü•‰πé</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/707997501">Mooncake (3): ÂºÄÊ∫êÊï∞ÊçÆÈõÜÔºÅ‰ª•Âèä‰∏Ä‰∫õÊÑüË∞¢ÂíåÁ¢éÁ¢éÂøµ - Áü•‰πé</A>
									</DL><p>
									<DT><H3 FOLDED>sglang-DeepEP</H3>
									<DL><p>
										<DT><A HREF="https://github.com/deepseek-ai/DeepEP/pull/239">Support displaying separate send and recv time by fzyzcjy ¬∑ Pull Request #239 ¬∑ deepseek-ai/DeepEP</A>
									</DL><p>
									<DT><H3 FOLDED>sglang-kimi-k2</H3>
									<DL><p>
										<DT><A HREF="https://lmsys.org/blog/2025-07-20-k2-large-scale-ep/">Deploying Kimi K2 with PD Disaggregation and Large-Scale Expert Parallelism on 128 H200 GPUs | LMSYS Org</A>
										<DT><A HREF="https://x.com/lmsysorg/status/1946875484585029678">(1) LMSYS Org en X: "üö®SGLang Summer Fest Bonus Dropüö® Proud to share a joint effort from Mooncake by @Kimi_Moonshot, @Oracle , and SGLang: Kimi K2 trillion-scale deployment‚Äîrunning on 128 H200 GPUs sponsored by @NVIDIAAIDev DGX Cloud. OME + SGLang = MoE inference at production scale.üëá https://t.co/N5dKtPa27Z" / X</A>
										<DT><A HREF="https://x.com/zhyncs42/status/1943795393177039176">(1) zhyncs en X: "@Kimi_Moonshot K2 shares the same architecture as @deepseek_ai R1, with experts increased from 256 to 384‚Äîso all SGLang optimizations work out of the box. PD disaggregation + large-scale EP was validated on 100+ H200s by MoonCake Team before release. Always trust SGLang! üöÄ" / X</A>
										<DT><A HREF="https://x.com/lmsysorg/status/1943793859798216846">(1) LMSYS Org en X: "Kimi @Kimi_Moonshot K2 on SGLang: As a trillion-parameter model, long context on 1‚Äì2 H200/B200 nodes struggles. Use SGLang‚Äôs PD disaggregation + large-scale EP‚Äîvalidated on 100+ H200s by MoonCake Team. New SOTA is here‚Äîstart using it! https://t.co/SdiQWPraHH" / X</A>
									</DL><p>
									<DT><H3 FOLDED>pd-disaggregation-notes</H3>
									<DL><p>
										<DT><A HREF="https://x.com/haoailab/status/1985753711344316648">(1) Hao AI Lab en X: "üî• New Blog: ‚ÄúDisaggregated Inference: 18 Months Later‚Äù 18 months in LLM inference feels like a new Moore‚Äôs Law cycle ‚Äì but this time not just 2x per year: üí∏ Serving cost ‚Üì10‚Äì100x üöÄ Throughput ‚Üë10x ‚ö° Latency ‚Üì5x A big reason? Disaggregated Inference. From DistServe, our" / X</A>
										<DT><A HREF="https://hao-ai-lab.github.io/blogs/distserve-retro/">Disaggregated Inference: 18 Months Later | Hao AI Lab @ UCSD</A>
									</DL><p>
									<DT><H3 FOLDED>pd-people</H3>
									<DL><p>
										<DT><A HREF="https://gindachen.github.io/">Junda Chen</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2311.18677">[2311.18677] Splitwise: Efficient generative LLM inference using phase splitting</A>
									<DT><A HREF="https://arxiv.org/abs/2401.09670">[2401.09670] DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving</A>
									<DT><A HREF="https://arxiv.org/abs/2504.02263">[2504.02263] MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism</A>
									<DT><A HREF="https://github.com/ppl-ai/pplx-kernels">ppl-ai/pplx-kernels: Perplexity GPU Kernels</A>
									<DT><A HREF="https://github.com/infinigence/Semi-PD">infinigence/Semi-PD: A prefill &amp; decode disaggregated LLM serving framework with shared GPU memory and fine-grained compute isolation.</A>
									<DT><A HREF="https://www.perplexity.ai/hub/blog/disaggregated-prefill-and-decode">Disaggregated Prefill and Decode</A>
									<DT><A HREF="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">Large Transformer Model Inference Optimization | Lil'Log</A>
									<DT><A HREF="https://hao-ai-lab.github.io/blogs/distserve-retro/">Disaggregated Inference: 18 Months Later | Hao AI Lab @ UCSD</A>
									<DT><A HREF="https://github.com/IBM/vllm/blob/6ff59f09ee84fb2db453fc7f2ba3fc8ad4d80572/docs/design/p2p_nccl_connector.md">vllm/docs/design/p2p_nccl_connector.md 2P3D diagram</A>
								</DL><p>
								<DT><H3 FOLDED>sglang-router</H3>
								<DL><p>
									<DT><H3 FOLDED>sglang-router-docker</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/f39037fffbeb463595a1e31d72c85e53b6e7d355/.github/workflows/release-docker-router.yml#L2">sglang/.github/workflows/release-docker-router.yml at f39037fffbeb463595a1e31d72c85e53b6e7d355 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/rust">sglang/rust at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://x.com/hsu_byron/status/1864449841239347341">(1) Byron Hsu en X: "(1/n) Introducing SGLang Router: a cache-aware router for LLM Inference in SGLang v0.4! Prefix Caching has been an effective technique to speed up LLM inference. However, when it comes to data parallelism, the load balancer substantially degrades cache hit rates because naive https://t.co/TjxeKyoUMe" / X</A>
									<DT><A HREF="https://arxiv.org/abs/2407.00023">[2407.00023] Preble: Efficient Distributed Prompt Scheduling for LLM Serving</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-tensorrt</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/tensorrt-demo">sgl-project/tensorrt-demo</A>
								</DL><p>
								<DT><H3 FOLDED>sglang-constrained-decoding</H3>
								<DL><p>
									<DT><A HREF="https://arxiv.org/abs/2312.07104">[2312.07104] SGLang: Efficient Execution of Structured Language Model Programs</A>
									<DT><A HREF="https://arxiv.org/html/2312.07104v2">SGLang: Efficient Execution of Structured Language Model Programs</A>
									<DT><A HREF="https://www.aidancooper.co.uk/constrained-decoding/">A Guide to Structured Outputs Using Constrained Decoding</A>
								</DL><p>
								<DT><H3 FOLDED>lightllm</H3>
								<DL><p>
									<DT><H3 FOLDED>lightllm-deepseek</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ModelTC/lightllm/pull/783">DeepseekV3 support deepep, deepgemm, PD, DP TP SP Mix mode. by hiworldwzj ¬∑ Pull Request #783 ¬∑ ModelTC/lightllm</A>
									</DL><p>
									<DT><A HREF="https://github.com/ModelTC/lightllm">ModelTC/lightllm: LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance.</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1910048095816877891">LightLLM‰∏≠DeepSeek V3/R1 Two MicroBatch Overlap ÂÆûÁé∞Ëß£Êûê - Áü•‰πé</A>
								</DL><p>
								<DT><H3 FOLDED>sglang-kubernetes</H3>
								<DL><p>
									<DT><H3 FOLDED>ome</H3>
									<DL><p>
										<DT><H3 FOLDED>ome-installation</H3>
										<DL><p>
											<DT><H3 FOLDED>ome-LeaderWorkerSet</H3>
											<DL><p>
												<DT><A HREF="https://github.com/kubernetes-sigs/lws">kubernetes-sigs/lws: LeaderWorkerSet: An API for deploying a group of pods as a unit of replication</A>
												<DT><A HREF="https://docs.google.com/document/d/1C0wgkOdDov8fEsBNZF3wPwYv1njRuWBs2-BueymXyfM/edit?tab=t.0">The LeaderWorkerSet API - Google Docs</A>
											</DL><p>
											<DT><A HREF="https://docs.sglang.ai/ome/docs/installation/">Installation | OME</A>
										</DL><p>
										<DT><H3 FOLDED>ome-0.1.3</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/ome/releases/tag/v0.1.3">Release OME v.0.1.3 ¬∑ sgl-project/ome</A>
										</DL><p>
										<DT><H3 FOLDED>ome-instance_type</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/ome/pull/177/files#diff-7d0416602be335d36eb5e700cfaed75c6d0d10a7efd46d89d365b38d562d8b6e">[utils] Add CoreWeave H200 shape configuration by abatilo ¬∑ Pull Request #177 ¬∑ sgl-project/ome</A>
										</DL><p>
										<DT><H3 FOLDED>ome-storage</H3>
										<DL><p>
										</DL><p>
										<DT><A HREF="https://github.com/sgl-project/ome">sgl-project/ome: OME is a Kubernetes operator for enterprise-grade management and serving of Large Language Models (LLMs)</A>
										<DT><A HREF="https://lmsys.org/blog/2025-07-08-ome/">OME: Revolutionizing LLM Infrastructure with Model-Driven Architecture | LMSYS Org</A>
										<DT><A HREF="https://github.com/AlibabaPAI/llumnix">AlibabaPAI/llumnix: Efficient and easy multi-instance LLM serving</A>
										<DT><A HREF="https://gemini.google.com/u/3/app/cfed837647f6df3c">OME reverse-engineer, high-level concepts and gradually dividing into code impl</A>
									</DL><p>
									<DT><A HREF="https://lmsys.org/blog/2025-07-20-k2-large-scale-ep/">Deploying Kimi K2 with PD Disaggregation and Large-Scale Expert Parallelism on 128 H200 GPUs</A>
									<DT><A HREF="https://lmsys.org/blog/2025-05-05-large-scale-ep/">Deploying DeepSeek with PD Disaggregation and Large-Scale Expert Parallelism on 96 H100 GPUs | LMSYS Org</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-people</H3>
								<DL><p>
									<DT><A HREF="https://zhyncs.com/">Yineng Zhang</A>
									<DT><A HREF="https://github.com/DarkSharpness">DarkSharpness (DarkSharpness) main sgl-mini author</A>
									<DT><A HREF="http://www.lsyin.me/">Liangsheng Yin</A>
									<DT><A HREF="https://github.com/Fridge003">Fridge003 (Baizhou Zhang)</A>
									<DT><A HREF="https://github.com/ishandhanani">ishandhanani</A>
									<DT><A HREF="https://github.com/Conless">Conless (Yi Pan) initial PyTorch implementation of C++ NCCL communicator</A>
									<DT><A HREF="https://github.com/MisakaVan">MisakaVan (MisakaVan) testing docs</A>
									<DT><A HREF="https://peterzheng98.github.io/">About Me - Wenxin Zheng</A>
									<DT><A HREF="https://acm.sjtu.edu.cn/~xzy2022/">Ziyi Xu | ÂæêÂ≠êÁªé</A>
								</DL><p>
								<DT><H3 FOLDED>megascale-infer</H3>
								<DL><p>
									<DT><H3 FOLDED>Attention-FFN-disaggregation</H3>
									<DL><p>
										<DT><A HREF="https://x.com/eric_haibin_lin/status/1948943463564935407">Great to see StepFun acknowledges the idea of Attention-FFN disaggregation from our Megascale-infer work and take to the next level üöÄüöÄüöÄ</A>
										<DT><A HREF="https://github.com/stepfun-ai/Step3">stepfun-ai/Step3</A>
										<DT><A HREF="https://x.com/vllm_project/status/1948917913895010751">This amazing Attention-FFN disaggregation implementation vLLM StepFun</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1932920900203807997">Step-3 Reasoning System: From PD Separation to AF Separation (AFD)</A>
									</DL><p>
									<DT><A HREF="https://arxiv.org/abs/2504.02263">[2504.02263] MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism</A>
								</DL><p>
								<DT><H3 FOLDED>reasoning-efficiency</H3>
								<DL><p>
									<DT><A HREF="https://x.com/i/jobs/1948828300585172994">Member of Technical Staff - Reasoning Efficiency: The Reasoning Efficiency team at xAI focuses on pushing the boundaries of cost-efficient intelligence</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-wheels</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/sgl-whl">sgl-project/sgl-whl: SGLang wheels for multiple platforms</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-kvcache</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-gds</H3>
									<DL><p>
										<DT><H3 FOLDED>nixl</H3>
										<DL><p>
											<DT><A HREF="https://github.com/ai-dynamo/nixl">ai-dynamo/nixl: NVIDIA Inference Xfer Library (NIXL)</A>
											<DT><A HREF="https://engineers.ntt.com/entry/202505-nixl/entry">LLMÊé®Ë´ñ„ÇíÊîØ„Åà„ÇãÊäΩË±°ÂåñËª¢ÈÄÅ„É©„Ç§„Éñ„É©„É™ NVIDIA Inference Xfer Library (NIXL) „Å´„Å§„ÅÑ„Å¶ - NTT docomo Business Engineers' Blog</A>
											<DT><A HREF="https://github.com/ai-dynamo/nixl/blob/main/benchmark/kvbench/README.md">nixl/benchmark/kvbench/README.md at main ¬∑ ai-dynamo/nixl</A>
											<DT><A HREF="https://www.youtube.com/watch?v=87T-irSjXfE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=139">Scaling KV Caches for LLMs: How LMCache + NIXL Handle Network and Storage...- J. Jiang &amp; M. Khazraee - YouTube</A>
										</DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/7896/files">Add GDS alternative for hierarchical kv cache by didoteebin ¬∑ Pull Request #7896 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>kvcached</H3>
									<DL><p>
										<DT><A HREF="https://x.com/adityastomar_/status/1958048129275805867">(1) Aditya Tomar en X: "Can we break the memory wall for LLM inference via KV cache rematerialization? üö® Introducing XQuant, which leverages underutilized compute units to eliminate the memory bottleneck for LLM inference! ‚Ä¢ 10‚Äì12.5x memory savings vs. FP16 ‚Ä¢ Near-zero accuracy loss ‚Ä¢ Beats https://t.co/9qMcV0ubaK" / X</A>
										<DT><A HREF="https://x.com/yifandotqiao/status/1980667591418081426">(1) Yifan Qiao en X: "üöÄ End the GPU Cost Crisis Today!!! Headache with LLMs lock a whole GPU but leave capacity idle? Frustrated by your cluster's low utilization? We launch kvcached, the first library for elastic GPU sharing across LLMs. üîó https://t.co/3BC7B6s2EX üßµüëá Why it matters: https://t.co/jdIg1gyyOS" / X</A>
										<DT><A HREF="https://yifanqiao.notion.site/Solve-the-GPU-Cost-Crisis-with-kvcached-289da9d1f4d68034b17bf2774201b141">Solve the GPU Cost Crisis with kvcached</A>
										<DT><A HREF="https://arxiv.org/pdf/2508.08448">Towards Efficient and Practical GPU Multitasking in the Era of LLM</A>
										<DT><A HREF="https://github.com/ovg-project/kvcached">ovg-project/kvcached: Virtualized Elastic KV Cache for Dynamic GPU Sharing and Beyond</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=2CBnAwM09VM">Rethinking AI Infrastructure for Agents: KV Cache Saturation and the Rise of Agentic Cache - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-tuning</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/awesome-sglang">sgl-project/awesome-sglang: Make SGLang go brrr</A>
									<DT><A HREF="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">Large Transformer Model Inference Optimization | Lil'Log</A>
									<DT><A HREF="https://www.tensoreconomics.com/p/moe-inference-economics-from-first">MoE Inference Economics from First Principles</A>
									<DT><A HREF="https://www.bentoml.com/llm-perf/">LLM Benchmark and Optimization Explorer</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1943463615320555663">SGLang Performance Optimization Tips Record from August 2025</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-scaling-inference</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-long-context</H3>
									<DL><p>
										<DT><H3 FOLDED>Chunked pipeline</H3>
										<DL><p>
											<DT><A HREF="https://x.com/lm_zheng/status/2012069688122003890">(2) Lianmin Zheng en X: "Chunked pipeline parallelism is arguably the most general and scalable system technique for accelerating super-long-context inference. It remains underrated today, largely because there still isn‚Äôt a strong, high-quality open-source implementation. The SGLang team recently fully" / X</A>
											<DT><A HREF="https://lmsys.org/blog/2026-01-15-chunked-pipeline/">Pipeline Parallelism in SGLang: Scaling to Million-Token Contexts and Beyond | LMSYS Org</A>
										</DL><p>
										<DT><A HREF="https://x.com/lmsysorg/status/2011869695482249680">: The highest-performance open-source PP implementation for 1M+ token contexts</A>
										<DT><A HREF="https://x.com/RYANHINGSHING/status/2010803805269737483">(1) Ryan Leung Ê¢ÅËààÁõõ, CFA en X: "This reminds me of Huawei‚Äôs three-level KV cache storage structure for long memory context inference, which was announced 5 months ago. Since Huawei and DeepSeek have been cooperating, I suspect that DS had already tested the hierarchical concept at least half a year earlierü§î https://t.co/TUIC0sPELQ" / X</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_sglang_ep.pdf">sgl-learning-materials/slides/amd_meetup_sglang_ep.pdf at main ¬∑ sgl-project/sgl-learning-materials</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-test</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/efb94e0d3db6aba9d464bc9a2f83191146203152/server/tests/models/test_seq2seq_lm.py">text-generation-inference/server/tests/models/test_seq2seq_lm.py per batch memory allocation grpc</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-vlm</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=zZUYA18OQqs">SGLang Office Hour Recap: Vision-Language Models (VLM) ‚Äî Dec 29, 2025 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-diffusion</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-diffusion-profiling</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/python/sglang/multimodal_gen/runtime/utils/profiler.py">sglang/python/sglang/multimodal_gen/runtime/utils/profiler.py at main ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1987623785982076436">How to systematically locate and analyze performance bottlenecks in PyTorch model inference?</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15812">[Diffusion] Improve qwen image edit performace to align with LightX2V by BBuf ¬∑ Pull Request #15812 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15397">[Diffusion] Fix `sglang generate --perf-dump-path` to include per-denoising-step timings by BBuf ¬∑ Pull Request #15397 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-diffusion-compile</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/e0963a6cb1eaa0d83283c672b86ac2882a05e0e6/python/sglang/multimodal_gen/runtime/pipelines_core/stages/denoising.py#L65">sglang/python/sglang/multimodal_gen/runtime/pipelines_core/stages/denoising.py at e0963a6cb1eaa0d83283c672b86ac2882a05e0e6 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-diffusion-attention</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/e0963a6cb1eaa0d83283c672b86ac2882a05e0e6/python/sglang/multimodal_gen/runtime/pipelines_core/stages/denoising.py#L132C1-L133C1">denoising.py#L132C1-L133C1 STA, VIDEO_SPARSE_ATTN, VMOBA, FA, SDPA, SAGE_ATTEN_3</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15408/files">[Diffusion] Add diffusion attention backends doc by BBuf ¬∑ Pull Request #15408 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-diffusion-notes</H3>
									<DL><p>
										<DT><A HREF="https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/sglang/code-walk-through/sgl_diffusion_en.md">Awesome-ML-SYS-Tutorial/sglang/code-walk-through/sgl_diffusion_en.md at main ¬∑ zhaochenyang20/Awesome-ML-SYS-Tutorial</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1970665571243761676">A Brief Analysis of SGLang-Diffusion</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1980440469520529217">SGLang Diffusion Learning Notes</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-diffusion-tp</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15666/files">[Diffusion] Flux.1.dev support Tensor Parallel by BBuf ¬∑ Pull Request #15666 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-USPAttention</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15163/files">[Diffusion] Cache dit support parallel by BBuf ¬∑ Pull Request #15163 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/15163">[Diffusion] Cache dit support parallel by BBuf ¬∑ Pull Request #15163 ¬∑ sgl-project/sglang</A>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/16532">[Diffusion] Fix Ulysses/Ring process group construction under TP to enable correct Wan2.2 tensor parallelism by BBuf ¬∑ Pull Request #16532 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-diffusion-wan</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/6afe3963997014f656e613602693769aece88b27/python/sglang/multimodal_gen/runtime/models/dits/causal_wanvideo.py">sglang/python/sglang/multimodal_gen/runtime/models/dits/causal_wanvideo.py at 6afe3963997014f656e613602693769aece88b27 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>sgl-diffusion-glm-image</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/pull/16894">[diffusion] model: GLM-Image by yhyang201 ¬∑ Pull Request #16894 ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/f35b5da521bffa72404f45ad4a9e85727f12456b/python/sglang/multimodal_gen/runtime/layers/attention/layer.py#L289">USPAttention: Ulysses Sequence Parallelism with Ring Attention</A>
									<DT><A HREF="https://x.com/lmsysorg/status/1986886665496084877?s=20">(1) LMSYS Org en X: "üöÄ Introducing SGLang Diffusion ‚Äî bringing SGLang‚Äôs high-performance serving to diffusion models. ‚ö°Ô∏è Up to 5.9√ó faster inference üß© Supports major open-source models: Wan, Hunyuan, Qwen-Image, Qwen-Image-Edit, Flux üß∞ Easy to use via OpenAI-compatible API, CLI &amp;amp; Python API https://t.co/DU7EdG7Chb" / X</A>
									<DT><A HREF="https://lmsys.org/blog/2025-11-07-sglang-diffusion/">SGLang Diffusion: Accelerating Video and Image Generation | LMSYS Org</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/python/sglang/multimodal_gen">sglang/python/sglang/multimodal_gen at main ¬∑ sgl-project/sglang</A>
									<DT><A HREF="https://x.com/haoailab/status/1986896503185809667">Hao AI Lab en X: "Exciting to partner with SGL (@lmsysorg ). FastVideo + SGL = the future open source ecosystem for diffusion! ü•≥ü•≥" / X</A>
									<DT><A HREF="https://www.linkedin.com/pulse/sglang-diffusion-code-walk-through-chenyang-zhao-hd7gc/?trackingId=w0V4CiHjuWDxKjmIftLAZA%3D%3D">SGLang Diffusion Code Walk Through | LinkedIn</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1986157623695922659">SGLang Diffusion WAN2.2 inference speed is accelerated by 60% through zero-overhead layer-by-layer weight offloading technology.</A>
									<DT><A HREF="https://www.youtube.com/watch?v=YwNrdtoYJnc">SGLang Diffusion: Open-Source High-Performance Inference for Image &amp; Video Generation - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-speculative-decoding</H3>
								<DL><p>
									<DT><H3 FOLDED>sgl-eagle</H3>
									<DL><p>
										<DT><A HREF="https://lmsys.org/blog/2025-12-01-eagle3-vertex/">From research to production: Accelerate OSS LLM with EAGLE-3 on Vertex | LMSYS Org</A>
									</DL><p>
									<DT><A HREF="https://jiajunli-guapisolo.notion.site/Power-Up-Speculative-Decoding-In-Reinforcement-Learning-2ae2d24a293b80918847e99c6804ae52">Power Up Speculative Decoding In Reinforcement Learning</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-mini</H3>
								<DL><p>
									<DT><A HREF="https://github.com/sgl-project/mini-sglang">sgl-project/mini-sglang</A>
									<DT><A HREF="https://x.com/lmsysorg/status/2001356624855023669">(1) LMSYS Org en X: "How long have you been "planning to understand" how modern LLM inference works? We just gave you a readable version of SGLang you can finish over the weekend. Introducing mini-SGLang ‚ö° We distilled SGLang from 300K into 5,000 lines. Kept the core design, cut the complexity. https://t.co/41aJxJQNRn" / X</A>
									<DT><A HREF="https://lmsys.org/blog/2025-12-17-minisgl/">Mini-SGLang: Efficient Inference Engine in a Nutshell | LMSYS Org</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-opt</H3>
								<DL><p>
									<DT><A HREF="https://lmsys.org/blog/2025-12-02-modelopt-quantization/">Boost SGLang Inference: Native NVIDIA Model Optimizer Integration for Seamless Quantization and Deployment | LMSYS Org</A>
									<DT><A HREF="https://github.com/NVIDIA/Model-Optimizer">NVIDIA/Model-Optimizer: A unified library of SOTA model optimization techniques like quantization, pruning, distillation, speculative decoding, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM, TensorRT, vLLM, etc. to optimize inference speed.</A>
								</DL><p>
								<DT><H3 FOLDED>sgl-deployments</H3>
								<DL><p>
									<DT><A HREF="https://cookbook-sg-lang.vercel.app/docs/intro">SGLang Cookbook</A>
									<DT><A HREF="https://github.com/sgl-project/sgl-cookbook">sgl-project/sgl-cookbook: Cookbook of SGLang - Recipe</A>
									<DT><A HREF="https://github.com/sgl-project/sgl-cookbook/blob/main/docs/models/DeepSeek/DeepSeek-V3_2.md">sgl-cookbook/docs/models/DeepSeek/DeepSeek-V3_2.md at main ¬∑ sgl-project/sgl-cookbook</A>
								</DL><p>
								<DT><A HREF="https://docs.google.com/document/d/1xEow4eIM152xNcRxqZz9VEcOiTQo8-CEuuQ5qTmkt-E/edit?tab=t.0#heading=h.kyti36ufipru">SGL community meeting - Google Docs</A>
								<DT><A HREF="https://github.com/sgl-project/sglang">sgl-project/sglang: SGLang is yet another fast serving framework for large language models and vision language models.</A>
								<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/benchmark/blog_v0_2">sglang/benchmark/blog_v0_2 at main ¬∑ sgl-project/sglang</A>
								<DT><A HREF="https://github.com/microsoft/sarathi-serve">microsoft/sarathi-serve: A low-latency &amp; high-throughput serving engine for LLMs</A>
								<DT><A HREF="https://github.com/microsoft/vattention?tab=readme-ov-file">microsoft/vattention: Dynamic Memory Management for Serving LLMs without PagedAttention</A>
								<DT><A HREF="https://github.com/AlibabaPAI/FLASHNN/blob/528a9301587f5fb135b25d973a87ba0a40a703a7/flashnn/kernel_backend.py#L44">FLASHNN/flashnn/kernel_backend.py at 528a9301587f5fb135b25d973a87ba0a40a703a7 ¬∑ AlibabaPAI/FLASHNN</A>
								<DT><A HREF="https://github.com/sgl-project/sgl-learning-materials/tree/main">sgl-project/sgl-learning-materials: Materials for learning SGLang</A>
								<DT><A HREF="https://github.com/zhaochenyang20/ModelServer">zhaochenyang20/ModelServer: Efficient, Flexible, and Highly Fault-Tolerant Model Service Management Based on SGLang</A>
								<DT><A HREF="https://x.com/ibab/status/1827047684714463603">(1) ibab en X: "Grok 2 mini is now 2x faster than it was yesterday. In the last three days @lm_zheng and @MalekiSaeed rewrote our inference stack from scratch using SGLang (https://t.co/M1M8BlXosH). This has also allowed us to serve the big Grok 2 model, which requires multi-host inference, at a https://t.co/G9iXTV8o0z" / X</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Ny4xxErgFgQ">Efficient LLM Inference with SGLang, Lianmin Zheng, xAI - YouTube</A>
								<DT><A HREF="https://github.com/interestingLSY/swiftLLM">interestingLSY/swiftLLM: A tiny yet powerful LLM inference system tailored for researching purpose. vLLM-equivalent performance with only 2k lines of code (2% of vLLM).</A>
								<DT><A HREF="https://aflah02.substack.com/p/multi-node-llm-inference-with-sglang">Multi-Node LLM Inference with SGLang on SLURM-Enabled Clusters</A>
								<DT><A HREF="https://github.com/xjdr-alt/entropix">xjdr-alt/entropix: Entropy Based Sampling and Parallel CoT Decoding</A>
								<DT><A HREF="https://www.tensoreconomics.com/p/moe-inference-economics-from-first">MoE Inference Economics from First Principles</A>
								<DT><A HREF="https://x.com/lmsysorg/status/1981103763441250387">(1) LMSYS Org en X: "We're excited to announce the collaboration between KTransformers and SGLang! KTransformers has been a killer for local AI inference with its system-algorithm co-design, often showing 5x - 10x speedup. This integration equips SGLang with KTransformers‚Äô inference strategy and https://t.co/RpSBUnbT2b" / X</A>
								<DT><A HREF="https://www.linkedin.com/pulse/vinegar-dumplings-how-ant-group-pr-sparked-six-month-sglang-zhao-jgite/?trackingId=JHi86AldwmHiFBBbmGxJfw%3D%3D">The Vinegar and the Dumplings: How an Ant Group PR Sparked a Six-Month SGLang Community Effort: sgl logprobs</A>
								<DT><A HREF="https://x.com/GenAI_is_real/status/2009142311574454636">(1) Chayenne Zhao en X: "The era of "simple" inference is dead. If you aren't building for Zero-Overhead scheduling and Radix-based prefix sharing, you‚Äôre just wasting H100 cycles. I‚Äôm seeing a lot of "vibe-based" optimization at the big labs, but the real war is being won in the scheduler. OpenAI and https://t.co/z2hhQDjz0K" / X</A>
							</DL><p>
							<DT><H3 FOLDED>vLLM</H3>
							<DL><p>
								<DT><H3 FOLDED>vllm-roadmap</H3>
								<DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/issues/26376">[Roadmap] vLLM Roadmap Q4 2025 ¬∑ Issue #26376 ¬∑ vllm-project/vllm</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-docs</H3>
								<DL><p>
									<DT><A HREF="https://www.aleksagordic.com/blog/vllm">Inside vLLM: Anatomy of a High-Throughput LLM Inference System - Aleksa Gordiƒá</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-dev</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-memory-leaks</H3>
									<DL><p>
										<DT><A HREF="https://mistral.ai/news/debugging-memory-leak-in-vllm">Heaps do lie: debugging a memory leak in vLLM. | Mistral AI</A>
										<DT><A HREF="https://x.com/matthewjgunton/status/2014714734017163349">(1) Matthew Gunton en X: "This is a really excellent blog showing low-level debugging required to find memory leaks. In the end, UCX was creating too many RSS allocations as part of its InfiniBand memory optimizations. Let's see how each tool helped them figured this out" / X</A>
										<DT><A HREF="https://x.com/vllm_project/status/2014630499231412477">The hunt went from Python profilers ‚Üí pmap ‚Üí BPFtrace ‚Üí GDB, finally tracing it to UCX's mmap hooks.</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/32181">nixl_connector: export UCX_MEM_MMAP_HOOK_MODE=none to avoid a UCX memory leak by hasB4K ¬∑ Pull Request #32181 ¬∑ vllm-project/vllm</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>vllm-mini</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Wenyueh/MinivLLM/blob/main/HowToApproachvLLM.md">MinivLLM/HowToApproachvLLM.md at main ¬∑ Wenyueh/MinivLLM</A>
									<DT><A HREF="https://jonathanc.net/blog/vllm-flex-attention-from-scratch">vLLM from scratch with FlexAttention ‚Äì Jonathan Chang‚Äôs Blog</A>
								</DL><p>
								<DT><H3 FOLDED>AIBrix</H3>
								<DL><p>
									<DT><A HREF="https://x.com/mcraddock/status/1893337828693586318?s=12">(1) Mark üá∫üá≥ en X: "ByteDance released their full AI stack: AIBrix, an open-source initiative designed to provide essential building blocks to construct scalable GenAI inference infrastructure. AIBrix delivers a cloud-native solution optimised for deploying, managing, and scaling LLMs https://t.co/JLYXy1EGtM" / X</A>
									<DT><A HREF="https://github.com/vllm-project/aibrix">vllm-project/aibrix: Cost-efficient and pluggable Infrastructure components for GenAI inference</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-omni</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-omni-glm-image</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm-omni/pull/763">[Model][Rebase] Add GLM-Image Model and Partial Rebase to v0.14.0 (Support AR Offiline) by tzhouam ¬∑ Pull Request #763 ¬∑ vllm-project/vllm-omni</A>
									</DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm-omni">vllm-project/vllm-omni: A framework for efficient model inference with omni-modality models</A>
									<DT><A HREF="https://docs.vllm.ai/projects/vllm-omni/en/latest/">vLLM-Omni</A>
									<DT><A HREF="https://zhuanlan.zhihu.com/p/1982525738998588869">[Notes] RDMA Basics</A>
									<DT><A HREF="https://blog.vllm.ai/2025/12/19/vllm-omni-diffusion-cache-acceleration.html">vLLM-Omni Diffusion Cache Acceleration | vLLM Blog</A>
									<DT><A HREF="https://docs.vllm.ai/projects/vllm-omni/en/latest/user_guide/diffusion_acceleration/">Overview - vLLM-Omni</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-meetings</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/presentation/d/1iJ8o7V2bQEi0BFEljLTwc5G1S10_Rhv3beed5oB0NJ4/edit#slide=id.g2650ce3df47_0_0">vLLM @ Fourth Meetup (Public) - Google Slides</A>
									<DT><A HREF="https://docs.google.com/presentation/d/1OF6GBbxDNwlgwmyYiCyN98W3t2HNfFlhpFJlqJgp_aI/mobilepresent?slide=id.g273594aa4df_1_6">vLLM @ Fourth Meetup (Public) - Google Slides (Neural Magic)</A>
								</DL><p>
								<DT><H3 FOLDED>nm-vllm</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-fp8</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/collections/neuralmagic/fp8-llms-for-vllm-666742ed2b78b7ac8df13127">FP8 LLMs for vLLM - a neuralmagic Collection</A>
									</DL><p>
									<DT><A HREF="https://github.com/neuralmagic/nm-vllm">neuralmagic/nm-vllm (fork)</A>
									<DT><A HREF="https://github.com/neuralmagic/nm-vllm/blob/788b4e526d379aa6b910cb1932a756d17cbcc997/vllm/model_executor/weight_utils.py#L81">weight_utils.py#L81 convert_bin_to_safetensor_file (checkpoint format conversion procedure)</A>
									<DT><A HREF="https://github.com/datacrunch-research/transmogrifier/blob/main/transmogrifier/convert.py#L156">transmogrifier/transmogrifier/convert.py at main ¬∑ datacrunch-research/transmogrifier</A>
									<DT><A HREF="https://github.com/neuralmagic/AutoFP8">neuralmagic/AutoFP8</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fp6/03-05-2024">DeepSpeed/blogs/deepspeed-fp6/03-05-2024 at master ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://github.com/neuralmagic/compressed-tensors">neuralmagic/compressed-tensors: A safetensors extension to efficiently store sparse quantized tensors on disk</A>
									<DT><A HREF="https://github.com/neuralmagic/guidellm/tree/main">neuralmagic/guidellm</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-engine</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-v1.0</H3>
									<DL><p>
										<DT><A HREF="https://blog.vllm.ai/2025/12/17/large-scale-serving.html">vLLM Large Scale Serving: DeepSeek @ 2.2k tok/s/H200 with Wide-EP | vLLM Blog</A>
									</DL><p>
									<DT><H3 FOLDED>vllm-design</H3>
									<DL><p>
										<DT><H3 FOLDED>vllm-p2p_nccl_connector</H3>
										<DL><p>
											<DT><A HREF="https://github.com/IBM/vllm/blob/6ff59f09ee84fb2db453fc7f2ba3fc8ad4d80572/docs/design/p2p_nccl_connector.md">vllm/docs/design/p2p_nccl_connector.md</A>
											<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/blob/0939a052893b29e458aad73d91316cf4f2275c5e/large-language-model-note/vllm-p2p_nccl_connector_zh.md">how-to-optim-algorithm-in-cuda/large-language-model-note/vllm-p2p_nccl_connector_zh.md at 0939a052893b29e458aad73d91316cf4f2275c5e ¬∑ BBuf/how-to-optim-algorithm-in-cuda</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://blog.vllm.ai/2026/01/08/kv-offloading-connector.html">--kv_offloading_backend native --kv_offloading_size &lt;size_in_GB&gt;</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-deterministic</H3>
								<DL><p>
									<DT><A HREF="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Defeating Nondeterminism in LLM Inference - Thinking Machines Lab</A>
									<DT><A HREF="https://github.com/thinking-machines-lab/batch_invariant_ops">thinking-machines-lab/batch_invariant_ops</A>
									<DT><A HREF="https://x.com/vllm_project/status/2013627585947734399">VLLM_BATCH_INVARIANT=1</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-server</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-engine-client</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/b942c094e3ab905aeb16f4136353f378e17159e8/vllm/entrypoints/openai/api_server.py#L124">vllm/vllm/entrypoints/openai/api_server.py</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/vllm/engine/protocol.py#L27">vllm/vllm/engine/protocol.py at main ¬∑ vllm-project/vllm</A>
										<DT><A HREF="https://x.com/EmbeddedLLM/status/1942556855324270610">(1) EmbeddedLLM en X: "Pro-tip for vLLM power-users: free ‚âà 90 % of your GPU VRAM in seconds‚Äîno restarts requiredüöÄ üö© Why you‚Äôll want this ‚Ä¢ Hot-swap new checkpoints on the same card ‚Ä¢ Rotate multiple LLMs on one GPU (batch jobs, micro-services, A/B tests) ‚Ä¢ Stage-based pipelines that call https://t.co/WAzdiZWL6u" / X</A>
									</DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/b942c094e3ab905aeb16f4136353f378e17159e8/vllm/entrypoints/openai/api_server.py#L124">vllm/vllm/entrypoints/openai/api_server.py</A>
									<DT><A HREF="https://www.youtube.com/watch?v=qpjJ8d4ly_M&list=PL_lsbAsL_o2B2ZOK4Lb2V03-O9YlHFJgY&index=4">vLLM: Easy, Fast, and Cheap LLM Serving for Everyone - Kaichao You, Tsinghua University - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-kernels</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-blackwell</H3>
									<DL><p>
										<DT><H3 FOLDED>vllm-sm103</H3>
										<DL><p>
											<DT><A HREF="https://github.com/vllm-project/vllm/pull/30484">[Feature] Add SM103 (Blackwell Ultra) Support to vLLM by LopezCastroRoberto ¬∑ Pull Request #30484 ¬∑ vllm-project/vllm</A>
											<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/2303">[Perf][Feature] Add SM103-specific schedulers for NVFP4 CUTLASS kernels by LopezCastroRoberto ¬∑ Pull Request #2303 ¬∑ flashinfer-ai/flashinfer</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>vllm-DeepGEMM</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/19820">[Feature] Integrate new deepgemm by yewentao256 ¬∑ Pull Request #19820 ¬∑ vllm-project/vllm</A>
										<DT><A HREF="https://github.com/neuralmagic/nm-vllm/blob/bd52201be0bf804f3627d4605699eb4d055fd6a4/vllm/model_executor/layers/quantization/deepgemm.py">nm-vllm/vllm/model_executor/layers/quantization/deepgemm.py at bd52201be0bf804f3627d4605699eb4d055fd6a4 ¬∑ neuralmagic/nm-vllm</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>vllm-compile</H3>
								<DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/03c4c4aa9deb2ad09a95c7997d2e5578c8db68d6/vllm/compilation/backends.py">vllm/vllm/compilation/backends.py</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/03c4c4aa9deb2ad09a95c7997d2e5578c8db68d6/vllm/compilation/fx_utils.py">vllm/vllm/compilation/fx_utils.py at 03c4c4aa9deb2ad09a95c7997d2e5578c8db68d6 ¬∑ vllm-project/vllm</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/03c4c4aa9deb2ad09a95c7997d2e5578c8db68d6/vllm/compilation/compiler_interface.py">vllm/vllm/compilation/compiler_interface.py</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XdORM2pkyH8&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=83">Keynote: PyTorch Technical Deep Dive - Alban Desmaison, Peng Wu, Mark Saroufim &amp; Edward Yang, Meta - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=1aEFHpF69Lc">[vLLM Office Hours #26] Intro to torch.compile and how it works with vLLM - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-deepseek</H3>
								<DL><p>
									<DT><A HREF="https://blog.vllm.ai/2025/12/17/large-scale-serving.html">vLLM Large Scale Serving: DeepSeek @ 2.2k tok/s/H200 with Wide-EP | vLLM Blog</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-pd-dissagregation</H3>
								<DL><p>
									<DT><A HREF="https://blog.vllm.ai/2025/12/17/large-scale-serving.html">vLLM Large Scale Serving: DeepSeek @ 2.2k tok/s/H200 with Wide-EP | vLLM Blog</A>
									<DT><A HREF="https://www.youtube.com/watch?v=6m6ZE6yVEDI&t=4381s">[vLLM Office Hours #36] LIVE from Z√ºrich vLLM Meetup - November 6, 2025 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-splitwise</H3>
								<DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/pull/2809">Add Splitwise implementation to vLLM</A>
									<DT><A HREF="https://www.microsoft.com/en-us/research/blog/splitwise-improves-gpu-usage-by-splitting-llm-inference-phases/">Splitwise improves GPU usage by splitting LLM inference phases - Microsoft Research</A>
									<DT><A HREF="https://arxiv.org/abs/2311.18677">[2311.18677] Splitwise: Efficient generative LLM inference using phase splitting</A>
									<DT><A HREF="https://github.com/Mutinifni/splitwise-sim">Mutinifni/splitwise-sim: LLM serving cluster simulator</A>
									<DT><A HREF="https://www.youtube.com/watch?v=WwJvecXOeUA">OSDI '24 - DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language... - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-benchmark</H3>
								<DL><p>
									<DT><H3 FOLDED>guidellm</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/guidellm">vllm-project/guidellm: Evaluate and Enhance Your LLM Deployments for Real-World Inference Needs</A>
									</DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/launch_tgi_server.sh#L4">vllm/benchmarks/launch_tgi_server.sh</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/fa32207842f1ed5a966372ed0513914bff8426c4/benchmarks/benchmark_throughput.py#L200">vllm/benchmarks/benchmark_throughput.py</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-profiling</H3>
								<DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/compare/main...FrzNo1:rllm:main">Comparing vllm-project:main...FrzNo1:main ¬∑ vllm-project/vllm</A>
									<DT><A HREF="https://github.com/vllm-project/vllm/pull/25091">[Core] Add MFU tracking to GPU model execution by bwasti ¬∑ Pull Request #25091 ¬∑ vllm-project/vllm</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-tensorize</H3>
								<DL><p>
									<DT><A HREF="https://docs.vllm.ai/en/latest/getting_started/examples/tensorize_vllm_model.html">Tensorize vLLM Model ‚Äî vLLM</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-models</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-llama</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/vllm/model_executor/models/llama.py">vllm/vllm/model_executor/models/llama.py at main ¬∑ vllm-project/vllm</A>
									</DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/issues/6265">[New Model]: CogVlm2 - SOTA Vision Large Language Model for Document Understanding ¬∑ Issue #6265 ¬∑ vllm-project/vllm</A>
									<DT><A HREF="https://docs.vllm.ai/en/latest/models/supported_models.html">Supported Models ‚Äî vLLM</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-chat</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-ChatInterface</H3>
									<DL><p>
										<DT><A HREF="https://www.gradio.app/docs/gradio/chatinterface#demos">Gradio ChatInterface Docs</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/examples/online_serving/openai_chat_completion_with_reasoning.py">vllm/examples/online_serving/openai_chat_completion_with_reasoning.py at main ¬∑ vllm-project/vllm</A>
									</DL><p>
									<DT><H3 FOLDED>librechat</H3>
									<DL><p>
										<DT><A HREF="https://www.librechat.ai/docs/quick_start/custom_endpoints">https://www.librechat.ai/docs/quick_start/custom_endpoints</A>
										<DT><A HREF="https://github.com/danny-avila/LibreChat">danny-avila/LibreChat: Enhanced ChatGPT Clone: Features Agents, DeepSeek, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active project.</A>
										<DT><A HREF="https://grok.com/chat/a34b32ce-ac6c-4086-b1e2-49263a08d816">LibreChat Docker Network Configuration Issue: host.docker.internal and 0.0.0.0 binding to all interfaces SGLang consumption</A>
									</DL><p>
									<DT><H3 FOLDED>chat-ui</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/chat-ui">huggingface/chat-ui: Open source codebase powering the HuggingChat app</A>
										<DT><A HREF="https://huggingface.co/chat/">HuggingChat</A>
										<DT><A HREF="https://huggingface.co/docs/transformers/main/chat_templating">Templates for Chat Models</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/1082">Support for HF Chat templates? ¬∑ Issue #1082 ¬∑ huggingface/text-generation-inference</A>
									</DL><p>
									<DT><H3 FOLDED>chat-TUI</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/chat/91f1a976-479b-4504-9a86-1a16ba45d557">Persistent Chat Session with Language Models - Grok</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/52e8b69d9868597a01292c1e0cce17f8d963a50e/examples/coder.py#L33">tinygrad/examples/coder.py tinygrad Chat TUI</A>
										<DT><A HREF="https://github.com/datacrunch-research/mediagen-evals/blob/main/chat/chat_terminal.py">mediagen-evals/chat/chat_terminal.py at main ¬∑ datacrunch-research/mediagen-evals</A>
									</DL><p>
									<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/examples/online_serving/gradio_openai_chatbot_webserver.py">vllm/examples/online_serving/gradio_openai_chatbot_webserver.py at main ¬∑ vllm-project/vllm</A>
									<DT><A HREF="https://github.com/danny-avila/LibreChat?utm_source=chatgpt.com">danny-avila/LibreChat: Enhanced ChatGPT Clone: Features Agents, DeepSeek, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active project.</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-checkpoint</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-model-streamer</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/9941">[Core]Add New Run:ai Streamer Load format. by pandyamarut ¬∑ Pull Request #9941 ¬∑ vllm-project/vllm</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/10192">[Core] Loading model from S3 using RunAI Model Streamer as optional loader by omer-dayan ¬∑ Pull Request #10192 ¬∑ vllm-project/vllm</A>
									</DL><p>
									<DT><H3 FOLDED>vllm-s3</H3>
									<DL><p>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/main/vllm/transformers_utils/s3_utils.py#L57">vllm/vllm/transformers_utils/s3_utils.py at main ¬∑ vllm-project/vllm</A>
									</DL><p>
									<DT><H3 FOLDED>vllm-sleep</H3>
									<DL><p>
										<DT><A HREF="https://x.com/EmbeddedLLM/status/1942556855324270610">(1) EmbeddedLLM en X: "Pro-tip for vLLM power-users: free ‚âà 90 % of your GPU VRAM in seconds‚Äîno restarts requiredüöÄ üö© Why you‚Äôll want this ‚Ä¢ Hot-swap new checkpoints on the same card ‚Ä¢ Rotate multiple LLMs on one GPU (batch jobs, micro-services, A/B tests) ‚Ä¢ Stage-based pipelines that call https://t.co/WAzdiZWL6u" / X</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/b942c094e3ab905aeb16f4136353f378e17159e8/vllm/entrypoints/openai/api_server.py#L1006">vllm/vllm/entrypoints/openai/api_server.py</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/blob/b942c094e3ab905aeb16f4136353f378e17159e8/vllm/entrypoints/openai/api_server.py#L418">vllm/vllm/entrypoints/openai/api_server.py at b942c094e3ab905aeb16f4136353f378e17159e8 ¬∑ vllm-project/vllm</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>vllm-long-context</H3>
								<DL><p>
									<DT><H3 FOLDED>vllm-MiniMax-M1</H3>
									<DL><p>
										<DT><A HREF="https://blog.vllm.ai/2025/06/30/minimax-m1.html">MiniMax-M1 Hybrid Architecture Meets vLLM: Long Context, Fast Inference | vLLM Blog</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>vllm-dcp</H3>
								<DL><p>
									<DT><A HREF="https://x.com/vllm_project/status/1970814441718755685">(2) vLLM en X: "Pro Tipüí°Fast and simple way to deploy DeepSeek-V3.1-Terminus with vLLM ‚ö°Ô∏è Run it with: vllm serve deepseek-ai/DeepSeek-V3.1-Terminus -tp 8 -dcp 8 (as simple as appending -dcp 8 after -tp 8) Thanks to the @Kimi_Moonshot team, vLLM 0.10.2 adds Decode Context Parallel (DCP) https://t.co/NjuJTpC1xR" / X</A>
									<DT><A HREF="https://docs.vllm.ai/en/v0.10.2/api/vllm/config/parallel.html">parallel - vLLM</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-semantic-router</H3>
								<DL><p>
									<DT><A HREF="https://vllm-semantic-router.com/">vLLM Semantic Router</A>
									<DT><A HREF="https://www.linkedin.com/posts/xia-ben-hu-78923724_gpt-5s-secret-ingredient-for-efficiency-activity-7363620745706393602-fPdd/">GPT-5‚Äôs secret ingredient for efficiency: the real-time router</A>
									<DT><A HREF="https://blog.vllm.ai/2025/09/11/semantic-router.html">vLLM Semantic Router: Next Phase in LLM inference | vLLM Blog</A>
									<DT><A HREF="https://blog.vllm.ai/2025/11/19/signal-decision.html">Signal-Decision Driven Architecture: Reshaping Semantic Routing at Scale | vLLM Blog</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-router</H3>
								<DL><p>
									<DT><A HREF="https://x.com/vllm_project/status/2000882750010876179?s=12">(1) vLLM en X: "When you serve vLLM at scale, request distribution is not a stateless problem. KV cache locality matters for conversational traffic, and prefill/decode (P/D) disaggregation introduces two specialized worker pools with very different bottlenecks. Generic load balancers typically https://t.co/tERzEjtqTD" / X</A>
									<DT><A HREF="https://blog.vllm.ai/2025/12/13/vllm-router-release.html">vLLM Router: A High-Performance and Prefill/Decode Aware Load Balancer for Large-scale Serving | vLLM Blog</A>
									<DT><A HREF="https://github.com/vllm-project/router">vllm-project/router: A high-performance and light-weight router for vLLM large scale deployment</A>
								</DL><p>
								<DT><H3 FOLDED>vllm-tpu</H3>
								<DL><p>
									<DT><A HREF="https://blog.vllm.ai/2025/10/16/vllm-tpu.html">vLLM TPU: A New Unified Backend Supporting PyTorch and JAX on TPU | vLLM Blog</A>
									<DT><A HREF="https://github.com/vllm-project/tpu-inference">vllm-project/tpu-inference: TPU inference for vLLM, with unified JAX and PyTorch support.</A>
									<DT><A HREF="https://github.com/AI-Hypercomputer/tpu-recipes/tree/main/inference/trillium/vLLM">tpu-recipes/inference/trillium/vLLM at main ¬∑ AI-Hypercomputer/tpu-recipes</A>
								</DL><p>
								<DT><A HREF="https://github.com/vllm-project/vllm">vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs</A>
								<DT><A HREF="https://vllm.ai/">vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention</A>
								<DT><A HREF="https://twitter.com/edacih/status/1671885000030191616">Continuous batching &amp; PagedAttention (TW thread)</A>
								<DT><A HREF="https://www.anyscale.com/blog/continuous-batching-llm-inference">Continuous batching &amp; PagedAttention</A>
								<DT><A HREF="https://github.com/EmbeddedLLM/vllm-rocm">EmbeddedLLM/vllm-rocm: ROCm-enabled vLLM: A high-throughput and memory-efficient inference and serving engine for LLMs</A>
								<DT><A HREF="https://github.com/microsoft/aici/blob/main/rllm/rllm-cuda/src/llm/paged/cache_engine.rs">aici/rllm/rllm-cuda/src/llm/paged/cache_engine.rs</A>
								<DT><A HREF="https://github.com/triton-inference-server/tutorials/blob/main/Quick_Deploy/vLLM/README.md#deploying-a-vllm-model-in-triton">tutorials/Quick_Deploy/vLLM/README.md</A>
								<DT><A HREF="https://www.youtube.com/watch?v=xPvjwqX1m_I">vLLM and Neural Magic Office Hours - June 5, 2024 - YouTube</A>
								<DT><A HREF="https://github.com/vllm-project/vllm/blob/4a6769053ab2616f7f490e6ec5b8241e76ef0c2a/vllm/envs.py#L4">vllm/vllm/envs.py</A>
								<DT><A HREF="https://github.com/microsoft/sarathi-serve">microsoft/sarathi-serve: A low-latency &amp; high-throughput serving engine for LLMs</A>
								<DT><A HREF="https://x.com/vllm_project/status/1981088861506982041">(1) vLLM en X: "üöÄ Excited to share our work on batch-invariant inference in vLLM! Now you can get identical results regardless of batch size with just one flag: VLLM_BATCH_INVARIANT=1 No more subtle differences between bs=1 and bs=N (including prefill!). Let's dive into how we built this üßµüëá https://t.co/NkDPVc1vTb" / X</A>
								<DT><A HREF="https://x.com/robertnishihara/status/1981112722361372924">(1) Robert Nishihara en X: "I enjoyed speaking at #PyTorchCon today. Wanted to share one slide from my talk about open source AI infra. This is about how Ray and vLLM work together. LLM inference is growing more and more complex, and doing a good job with LLM inference means working across layers and https://t.co/1e5tUtKxm3" / X</A>
								<DT><A HREF="https://blog.vllm.ai/2025/10/28/Kimi-K2-Accuracy.html">Chasing 100% Accuracy: A Deep Dive into Debugging Kimi K2‚Äôs Tool-Calling on vLLM | vLLM Blog</A>
							</DL><p>
							<DT><H3 FOLDED>MLCEngine</H3>
							<DL><p>
								<DT><A HREF="https://blog.mlc.ai/2024/10/10/optimizing-and-characterizing-high-throughput-low-latency-llm-inference">MLC | Optimizing and Characterizing High-Throughput Low-Latency LLM Inference in MLCEngine</A>
								<DT><A HREF="https://blog.mlc.ai/">MLC | Home</A>
								<DT><A HREF="https://github.com/mlc-ai/mlc-llm">mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML Compilation</A>
							</DL><p>
							<DT><H3 FOLDED>MoonshotAI</H3>
							<DL><p>
								<DT><H3 FOLDED>ktransformers</H3>
								<DL><p>
									<DT><A HREF="https://github.com/kvcache-ai/ktransformers">kvcache-ai/ktransformers: A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations</A>
								</DL><p>
								<DT><A HREF="https://github.com/MoonshotAI">Moonshot AI</A>
							</DL><p>
							<DT><H3 FOLDED>lmdeploy</H3>
							<DL><p>
								<DT><H3 FOLDED>lmdeploy-docs</H3>
								<DL><p>
									<DT><A HREF="https://lmdeploy.readthedocs.io/en/latest/">Welcome to LMDeploy‚Äôs tutorials! ‚Äî lmdeploy</A>
									<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/main/docs/en/installation.md">lmdeploy/docs/en/installation.md at main</A>
								</DL><p>
								<DT><H3 FOLDED>lmdeploy-multi-modal</H3>
								<DL><p>
									<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/main/docs/en/multi_modal/cogvlm.md">lmdeploy/docs/en/multi_modal/cogvlm.md at main ¬∑ InternLM/lmdeploy</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/5ddb6bf218ed16a2dcf0058f20c59a247e180fd2/examples/multimodal/run.py#L920">run.py#L920 -&gt; image_path</A>
									<DT><A HREF="https://github.com/THUDM/CogVLM2/blob/main/basic_demo/requirements.txt">CogVLM2/basic_demo/requirements.txt at main ¬∑ THUDM/CogVLM2</A>
								</DL><p>
								<DT><H3 FOLDED>lmdeploy-container</H3>
								<DL><p>
									<DT><H3 FOLDED>lmdeploy-container-example</H3>
									<DL><p>
										<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">neuralmagic/tensorrt-demo</A>
										<DT><A HREF="https://hub.docker.com/layers/openmmlab/lmdeploy/latest/images/sha256-77e3080cdc32839a39dc245770c42183162f9d787ef4fc4b3d4f11ddfaacb092?context=explore">Image Layer Details - openmmlab/lmdeploy:latest | Docker Hub</A>
										<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/02077a7d03b6bdaf905ba32e8bdd755d41d77401/docs/en/multi_modal/vl_pipeline.md">lmdeploy/docs/en/multi_modal/vl_pipeline.md at 02077a7d03b6bdaf905ba32e8bdd755d41d77401 ¬∑ InternLM/lmdeploy</A>
										<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/40fdc777688d4830b92ae8b5c5380686dc0de97f/docs/en/serving/api_server_vl.md">lmdeploy/docs/en/serving/api_server_vl.md at 40fdc777688d4830b92ae8b5c5380686dc0de97f ¬∑ InternLM/lmdeploy</A>
										<DT><A HREF="https://github.com/InternLM/lmdeploy/tree/40fdc777688d4830b92ae8b5c5380686dc0de97f">InternLM/lmdeploy at 40fdc777688d4830b92ae8b5c5380686dc0de97f</A>
										<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/02077a7d03b6bdaf905ba32e8bdd755d41d77401/docs/en/supported_models/supported_models.md#L4">lmdeploy/docs/en/supported_models/supported_models.md at 02077a7d03b6bdaf905ba32e8bdd755d41d77401 ¬∑ InternLM/lmdeploy</A>
										<DT><A HREF="https://aistudio.google.com/app/prompts/1KnqPc-9ZNiYGbWD-sO3I0ro5touxoTU0?pli=1">Docker build | Google AI Studio</A>
										<DT><A HREF="https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B">THUDM/cogvlm2-llama3-chat-19B ¬∑ Hugging Face</A>
										<DT><A HREF="https://github.com/THUDM/CogVLM2/blob/main/basic_demo/requirements.txt">CogVLM2/basic_demo/requirements.txt at main ¬∑ THUDM/CogVLM2</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/f565d16acbeea9c6c222349bdd32e4c6e0854d24/Dockerfile#L4">pytorch/Dockerfile at f565d16acbeea9c6c222349bdd32e4c6e0854d24 ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://x.com/home">(1) Inicio / X</A>
									</DL><p>
									<DT><A HREF="https://hub.docker.com/r/openmmlab/lmdeploy">openmmlab/lmdeploy - Docker Image | Docker Hub</A>
									<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/40fdc777688d4830b92ae8b5c5380686dc0de97f/docs/en/serving/api_server_vl.md">lmdeploy/docs/en/serving/api_server_vl.md: Each model may require specific dependencies not included in the Docker image.</A>
								</DL><p>
								<DT><H3 FOLDED>lmdeploy-serving</H3>
								<DL><p>
									<DT><H3 FOLDED>lmdeploy-benchmarking</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/blob/c8e9fed87a85241180cb83230c8407d5d96c5f85/python/sglang/benchmarks/bench_serving.py#L243">sglang: bench_serving.py#L243 "lmdeploy": async_request_openai_completions,</A>
										<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">neuralmagic/tensorrt-demo</A>
									</DL><p>
									<DT><H3 FOLDED>openai-protocol-vision</H3>
									<DL><p>
										<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/ebae7d28d9dcf2b62dab926770d97089764e69da/docs/en/get_started.md">lmdeploy/docs/en/get_started.md at ebae7d28d9dcf2b62dab926770d97089764e69da ¬∑ InternLM/lmdeploy</A>
										<DT><A HREF="https://platform.openai.com/docs/guides/vision?lang=curl">Vision - OpenAI API: type: image_url | image_url: url</A>
									</DL><p>
									<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/40fdc777688d4830b92ae8b5c5380686dc0de97f/docs/en/serving/api_server_vl.md">lmdeploy/docs/en/serving/api_server_vl.md: Each model may require specific dependencies not included in the Docker image.</A>
									<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/85daad96ec4832e47678066ff07f6d6cc69697d0/lmdeploy/serve/openai/api_server.py#L371">lmdeploy/lmdeploy/serve/openai/api_server.py: /v1/chat/completions -&gt; image interaction</A>
									<DT><A HREF="https://github.com/InternLM/lmdeploy/blob/ebae7d28d9dcf2b62dab926770d97089764e69da/lmdeploy/serve/openai/protocol.py#L104">lmdeploy/lmdeploy/serve/openai/protocol.py: ignore_eos</A>
								</DL><p>
								<DT><H3 FOLDED>turbomind</H3>
								<DL><p>
									<DT><A HREF="https://github.com/InternLM/turbomind">InternLM/turbomind</A>
									<DT><A HREF="https://www.youtube.com/watch?v=XQylGyG7yp8&t=2162s">Lecture 35: SGLang - YouTube</A>
									<DT><A HREF="https://github.com/mobiusml/gemlite">mobiusml/gemlite: Simple and fast low-bit matmul kernels in CUDA / Triton</A>
									<DT><A HREF="https://x.com/Mobius_Labs/status/1907450136696856910">GemLite</A>
								</DL><p>
								<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">neuralmagic/tensorrt-demo</A>
								<DT><A HREF="https://github.com/InternLM/lmdeploy">InternLM/lmdeploy: LMDeploy is a toolkit for compressing, deploying, and serving LLMs.</A>
								<DT><A HREF="https://github.com/ModelTC/lightllm/tree/main">ModelTC/lightllm: LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance.</A>
								<DT><A HREF="https://github.com/InternLM/turbomind">InternLM/turbomind</A>
								<DT><A HREF="https://github.com/InternLM/InternLM">InternLM/InternLM: Official release of InternLM2.5 base and chat models. 1M context support</A>
								<DT><A HREF="https://github.com/zhihu/ZhiLight">zhihu/ZhiLight: A highly optimized LLM inference acceleration engine for Llama and its variants.</A>
							</DL><p>
							<DT><H3 FOLDED>ZhiLight</H3>
							<DL><p>
								<DT><A HREF="https://github.com/zhihu/ZhiLight">zhihu/ZhiLight: A highly optimized LLM inference acceleration engine for Llama and its variants.</A>
							</DL><p>
							<DT><H3 FOLDED>jetstream</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google/JetStream/tree/main">google/JetStream: A throughput and memory optimized engine for LLM inference on TPUs!</A>
								<DT><A HREF="https://github.com/AI-Hypercomputer/JetStream/blob/29329e8e73820993f77cfc8efe34eb2a73f5de98/jetstream/engine/engine_api.py#L161">JetStream/jetstream/engine/engine_api.py</A>
								<DT><A HREF="https://github.com/tensorflow/serving">tensorflow/serving: A flexible, high-performance serving system for machine learning models</A>
								<DT><A HREF="https://cloud.google.com/blog/products/compute/ai-hypercomputer-inference-updates-for-google-cloud-tpu-and-gpu">AI Hypercomputer inference updates for Google Cloud TPU and GPU | Google Cloud Blog</A>
							</DL><p>
							<DT><H3 FOLDED>chitu</H3>
							<DL><p>
								<DT><A HREF="https://github.com/thu-pacman/chitu/tree/public-main">thu-pacman/chitu: High-performance inference framework for large language models, focusing on efficiency, flexibility, and availability.</A>
							</DL><p>
							<DT><H3 FOLDED>bytedn-volcengine</H3>
							<DL><p>
								<DT><H3 FOLDED>volcengine-openAI</H3>
								<DL><p>
									<DT><A HREF="https://www.volcengine.com/docs/82379/1330626">ÂÖºÂÆπOpenAI API--ÁÅ´Â±±ÊñπËàüÂ§ßÊ®°ÂûãÊúçÂä°Âπ≥Âè∞-ÁÅ´Â±±ÂºïÊìé</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>Triton Inference Server</H3>
							<DL><p>
								<DT><H3 FOLDED>tis-releases</H3>
								<DL><p>
									<DT><H3 FOLDED>tis-release-24.05</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/deeplearning/triton-inference-server/release-notes/rel-24-05.html">Release Notes :: NVIDIA Deep Learning Triton Inference Server Documentation</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/releases/tag/v0.11.0">Release TensorRT-LLM 0.11.0 Release ¬∑ NVIDIA/TensorRT-LLM</A>
										<DT><A HREF="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver">Triton Inference Server | NVIDIA NGC</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>triton-remote-caching</H3>
								<DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62531/">Deploying, Optimizing, and Benchmarking Large Language Models With Triton Inference Server | NVIDIA On-Demand</A>
								</DL><p>
								<DT><H3 FOLDED>tis-client</H3>
								<DL><p>
									<DT><A HREF="https://github.com/triton-inference-server/client">triton-inference-server/client</A>
								</DL><p>
								<DT><H3 FOLDED>tis-server</H3>
								<DL><p>
									<DT><H3 FOLDED>dynamic batching</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sgl-project/sglang/tree/main/python/sglang/srt/managers">sglang/python/sglang/srt/managers at main ¬∑ sgl-project/sglang</A>
									</DL><p>
									<DT><H3 FOLDED>concurrent model execution</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>tis-examples</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=JgP2WgNIq_w">How to Deploy HuggingFace‚Äôs Stable Diffusion Pipeline with Triton Inference Server</A>
										<DT><A HREF="https://docs.coreweave.com/compass/examples/triton-inference-server-fastertransformer">Triton Inference Server - FasterTransformer GPT-J and GPT-NeoX 20B - CoreWeave</A>
										<DT><A HREF="https://docs.coreweave.com/machine-learning-and-ai/inference/examples/triton-inference/triton-inference-server-fastertransformer#gpt-neox-20b">FasterTransformer GPT-J and GPT: NeoX 20B - CoreWeave</A>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-S52370/?ncid=em-even-124008-vt33">Inference of Large Language Models with NVIDIA Triton Inference Server (Presented by CoreWeave) | NVIDIA On-Demand</A>
										<DT><A HREF="https://developer.nvidia.com/blog/accelerated-inference-for-large-transformer-models-using-nvidia-fastertransformer-and-nvidia-triton-inference-server/?nvid=nv-int-txtad-664399-vt27#cid=an01_nv-int-txtad_en-us">Accelerated Inference for Large Transformer Models Using NVIDIA Triton Inference Server | NVIDIA Technical Blog</A>
										<DT><A HREF="https://developer.nvidia.com/blog/deploying-gpt-j-and-t5-with-fastertransformer-and-triton-inference-server/">Deploying GPT-J and T5 with NVIDIA Triton Inference Server | NVIDIA Technical Blog</A>
										<DT><A HREF="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/LanguageModeling/BERT/triton">Deploying the BERT model on Triton Inference Server</A>
										<DT><A HREF="https://www.youtube.com/watch?v=NR_iUl2Ooc0">NVIDIA Triton Inference Server and its use in Netflix's Model Scoring Service: model ensemble (pipeline)</A>
									</DL><p>
									<DT><H3 FOLDED>tis-dtypes</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html">TYPE_BF16</A>
										<DT><A HREF="https://github.com/triton-inference-server/server/blob/e1816629dd8bc1b05748450739420639543bcb11/qa/python_models/identity_bf16/config.pbtxt#L33">server/qa/python_models/identity_bf16/config.pbtxt</A>
									</DL><p>
									<DT><H3 FOLDED>tis-ensemble</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=NR_iUl2Ooc0">NVIDIA Triton Inference Server and its use in Netflix's Model Scoring Service: model ensemble (pipeline)</A>
									</DL><p>
									<DT><A HREF="https://github.com/triton-inference-server/server">server</A>
									<DT><A HREF="https://github.com/triton-inference-server/server">triton-inference-server/server: The Triton Inference Server provides an optimized cloud and edge inferencing solution.</A>
									<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend/blob/main/scripts/launch_triton_server.py">tensorrtllm_backend/scripts/launch_triton_server.py at main ¬∑ triton-inference-server/tensorrtllm_backend</A>
								</DL><p>
								<DT><H3 FOLDED>TensorRT-LLM</H3>
								<DL><p>
									<DT><H3 FOLDED>tensorrt-llm-build</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/5d8ca2faf74c494f220c8f71130340b513eea9a9/docs/source/installation/build-from-source-linux.md">TensorRT-LLM/docs/source/installation/build-from-source-linux.md at 5d8ca2faf74c494f220c8f71130340b513eea9a9 ¬∑ NVIDIA/TensorRT-LLM</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-lectures</H3>
									<DL><p>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62031/">Speeding up LLM Inference With TensorRT-LLM | NVIDIA On-Demand</A>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62531/">Deploying, Optimizing, and Benchmarking Large Language Models With Triton Inference Server | NVIDIA On-Demand</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-docs</H3>
									<DL><p>
										<DT><A HREF="https://nvidia.github.io/TensorRT-LLM/">Welcome to TensorRT-LLM‚Äôs Documentation! ‚Äî tensorrt_llm documentation</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/main/docs/source">TensorRT-LLM/docs/source at main ¬∑ NVIDIA/TensorRT-LLM</A>
										<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">neuralmagic/tensorrt-demo</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-dpsk</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/blogs/tech_blog/blog15_Optimizing_DeepSeek_V32_on_NVIDIA_Blackwell_GPUs.md#how-to-reproduce">TensorRT-LLM/docs/source/blogs/tech_blog/blog15_Optimizing_DeepSeek_V32_on_NVIDIA_Blackwell_GPUs.md at main ¬∑ NVIDIA/TensorRT-LLM</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-triton-kernels</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/openai_triton/README.md">TensorRT-LLM/examples/openai_triton/README.md</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/openai_triton/manual_plugin">TensorRT-LLM/examples/openai_triton/manual_plugin</A>
										<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo">neuralmagic/tensorrt-demo</A>
										<DT><A HREF="https://github.com/BBuf/tensorrt-llm-moe">BBuf/tensorrt-llm-moe</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-multimodal</H3>
									<DL><p>
										<DT><H3 FOLDED>multimodal-session</H3>
										<DL><p>
											<DT><A HREF="https://zhuanlan.zhihu.com/p/700214123?utm_psn=1779287628619632640">https://zhuanlan.zhihu.com/p/700214123?utm_psn=1779287628619632640</A>
											<DT><A HREF="https://madsys.cs.tsinghua.edu.cn/">https://madsys.cs.tsinghua.edu.cn/</A>
											<DT><A HREF="https://claude.ai/chat/21a90660-5bf8-4d48-87a7-da590e138e30">https://claude.ai/chat/21a90660-5bf8-4d48-87a7-da590e138e30</A>
											<DT><A HREF="https://lmsys.org/blog/2024-07-25-sglang-llama3/">https://lmsys.org/blog/2024-07-25-sglang-llama3/</A>
											<DT><A HREF="https://github.com/sgl-project/sglang/blob/c8e9fed87a85241180cb83230c8407d5d96c5f85/python/sglang/benchmarks/bench_serving.py#L4">https://github.com/sgl-project/sglang/blob/c8e9fed87a85241180cb83230c8407d5d96c5f85/python/sglang/benchmarks/bench_serving.py#L4</A>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/llama#llama-v3-updates">https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/llama#llama-v3-updates</A>
											<DT><A HREF="https://docs.google.com/document/d/1QYl7Yvy5nGvXlzWFenxIpovGTkgxjvfRKzt1ecMd1GM/edit">triton server using tensorrt-llm llama 3 - Google Docs</A>
											<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">https://github.com/neuralmagic/tensorrt-demo/tree/main</A>
											<DT><A HREF="https://github.com/datacrunch-research/tensorrt-demo/blob/main/docs/multimodal.md">https://github.com/datacrunch-research/tensorrt-demo/blob/main/docs/multimodal.md</A>
											<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend/blob/b25d578a48422db3b2d5bd89b16c235dd85c4300/inflight_batcher_llm/src/utils.cc#L92">https://github.com/triton-inference-server/tensorrtllm_backend/blob/b25d578a48422db3b2d5bd89b16c235dd85c4300/inflight_batcher_llm/src/utils.cc#L92</A>
											<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend/tree/main?tab=readme-ov-file">https://github.com/triton-inference-server/tensorrtllm_backend/tree/main?tab=readme-ov-file</A>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/a681853d3803ee5893307e812530b5e7004bb6e1/examples/multimodal#cogvlm">https://github.com/NVIDIA/TensorRT-LLM/tree/a681853d3803ee5893307e812530b5e7004bb6e1/examples/multimodal#cogvlm</A>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/releases/tag/v0.11.0">Release TensorRT-LLM 0.11.0 Release ¬∑ NVIDIA/TensorRT-LLM</A>
											<DT><A HREF="https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html">https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/model_configuration.html</A>
											<DT><A HREF="https://github.com/triton-inference-server/server/blob/e1816629dd8bc1b05748450739420639543bcb11/qa/python_models/identity_bf16/config.pbtxt#L33">server/qa/python_models/identity_bf16/config.pbtxt at e1816629dd8bc1b05748450739420639543bcb11 ¬∑ triton-inference-server/server</A>
											<DT><A HREF="https://jax.readthedocs.io/en/latest/autodidax.html#part-2-jaxprs">Autodidax: JAX core from scratch ‚Äî JAX documentation</A>
											<DT><A HREF="https://outlook.office.com/mail/inbox/id/AAQkADNiMWRmMjMwLTQ0MzItNDhjOS1iOGFjLTk3NzQyNjY1Y2RhMQAQACFINjNdKRpGiAD0qfgsu54%3D">Email - Antonio Dominguez - Outlook</A>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/a681853d3803ee5893307e812530b5e7004bb6e1/examples/dit/README.md">TensorRT-LLM/examples/dit/README.md at a681853d3803ee5893307e812530b5e7004bb6e1 ¬∑ NVIDIA/TensorRT-LLM</A>
											<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/a681853d3803ee5893307e812530b5e7004bb6e1/tensorrt_llm/models/dit/model.py">TensorRT-LLM/tensorrt_llm/models/dit/model.py at a681853d3803ee5893307e812530b5e7004bb6e1 ¬∑ NVIDIA/TensorRT-LLM</A>
											<DT><A HREF="https://github.com/black-forest-labs/flux/blob/main/src/flux/modules/layers.py#L11">flux/src/flux/modules/layers.py at main ¬∑ black-forest-labs/flux</A>
										</DL><p>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/5ddb6bf218ed16a2dcf0058f20c59a247e180fd2/examples/multimodal/README.md#cogvlm">TensorRT-LLM/examples/multimodal/README.md</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-llama-3</H3>
									<DL><p>
										<DT><A HREF="https://docs.google.com/document/d/1QYl7Yvy5nGvXlzWFenxIpovGTkgxjvfRKzt1ecMd1GM/edit">Untitled document - Google Docs</A>
										<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/blob/main/README.md?plain=1">tensorrt-demo/README.md at main ¬∑ neuralmagic/tensorrt-demo</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/llama#llama-v3-updates">TensorRT-LLM/examples/llama at main ¬∑ NVIDIA/TensorRT-LLM</A>
										<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend/blob/main/docs/llama.md?plain=1">tensorrtllm_backend/docs/llama.md at main ¬∑ triton-inference-server/tensorrtllm_backend</A>
										<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend/blob/main/scripts/launch_triton_server.py">tensorrtllm_backend/scripts/launch_triton_server.py at main ¬∑ triton-inference-server/tensorrtllm_backend</A>
										<DT><A HREF="https://huggingface.co/docs/transformers/main/en/model_doc/llama">LLaMA</A>
										<DT><A HREF="https://www.notion.so/dl-compiler-26c51f0aaa4842c381f710a9b5496116">dl-compiler</A>
										<DT><A HREF="https://chatgpt.com/c/c01100b8-e432-437c-b167-c7d9598c3922">ChatGPT</A>
										<DT><A HREF="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct">meta-llama/Meta-Llama-3-8B-Instruct ¬∑ Hugging Face</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-dit</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chengzeyi/piflux/blob/main/src/piflux/patch.py#L6">piflux/src/piflux/patch.py at main ¬∑ chengzeyi/piflux</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/dit">TensorRT-LLM/examples/dit</A>
										<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/tensorrt_llm/models/dit/model.py">TensorRT-LLM/tensorrt_llm/models/dit/model.py</A>
										<DT><A HREF="https://github.com/chengzeyi/piflux">chengzeyi/piflux: (WIP) Parallel inference for black-forest-labs' FLUX model.</A>
									</DL><p>
									<DT><H3 FOLDED>tensorrt-llm-custom-model</H3>
									<DL><p>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc24-s62031/">Speeding up LLM Inference With TensorRT-LLM | NVIDIA On-Demand</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/tree/release/0.5.0">TensorRT-LLM</A>
									<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend">triton-inference-server/tensorrtllm_backend: The Triton TensorRT-LLM Backend</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/issues/2014">failed to use TensorRT-LLM/examples/apps/fastapi_server.py ¬∑ Issue #2014 ¬∑ NVIDIA/TensorRT-LLM</A>
									<DT><A HREF="https://github.com/triton-inference-server/tensorrtllm_backend/blob/main/docs/llama.md">tensorrtllm_backend/docs/llama.md at main</A>
									<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">neuralmagic/tensorrt-demo</A>
									<DT><A HREF="https://github.com/zhyncs/TensorRT-LLM-Hacks">zhyncs/TensorRT-LLM-Hacks: TensorRT LLM Hacks</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/40274aac39f2542483906d92ec3b8014faf62912/benchmarks/Suite.md?plain=1#L6">TensorRT-LLM/benchmarks/Suite.md: trt-bench</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-Model-Optimizer">NVIDIA/TensorRT-Model-Optimizer: nvidia-modelopt is a unified library of state-of-the-art model optimization techniques like quantization, pruning, distillation, speculative decoding, etc. It compresses deep learning models for downstream deployment frameworks like TensorRT-LLM or TensorRT to optimize inference speed.</A>
								</DL><p>
								<DT><H3 FOLDED>FasterTransformer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/triton-inference-server/fastertransformer_backend">triton-inference-server/fastertransformer_backend</A>
									<DT><A HREF="https://github.com/NVIDIA/FasterTransformer/blob/main/docs/t5_guide.md">FasterTransformer/docs/t5_guide.md at main ¬∑ NVIDIA/FasterTransformer</A>
									<DT><A HREF="https://github.com/triton-inference-server/fastertransformer_backend#run-inter-node-t-x-p--gpus-per-node-models">triton-inference-server/fastertransformer_backend</A>
									<DT><A HREF="https://www.youtube.com/watch?v=MDqNwSTLimU">[NVIDIA] Faster Transformer</A>
									<DT><A HREF="https://github.com/OpenNMT/OpenNMT-tf">DecoderTransformer: OpenNMT/OpenNMT-tf</A>
									<DT><A HREF="https://github.com/NVIDIA/FasterTransformer">NVIDIA/FasterTransformer: Transformer related optimization, including BERT, GPT</A>
									<DT><A HREF="https://carper.ai/diff-models-a-new-way-to-edit-code/">Diff Models ‚Äì A New Way to Edit Code | CarperAI</A>
									<DT><A HREF="https://github.com/pytorch/serve/tree/master/examples/FasterTransformer_HuggingFace_Bert">serve/examples/FasterTransformer_HuggingFace_Bert</A>
								</DL><p>
								<DT><A HREF="https://github.com/triton-inference-server/fastertransformer_backend">triton-inference-server/fastertransformer_backend</A>
								<DT><A HREF="https://github.com/triton-inference-server/backend/blob/main/docs/backend_platform_support_matrix.md">backend/backend_platform_support_matrix.md</A>
								<DT><A HREF="https://developer.nvidia.com/blog/power-your-ai-inference-with-new-nvidia-triton-and-nvidia-tensorrt-features/?ncid=so-link-726143&=&linkId=100000196119468#cid=dl05_so-link_en-us">PyTriton</A>
								<DT><A HREF="https://medium.com/nvidia-ai/how-to-deploy-almost-any-hugging-face-model-on-nvidia-triton-inference-server-with-an-8ee7ec0e6fc4">Big Picture: Example showcase demo</A>
								<DT><A HREF="https://github.com/ELS-RD/transformer-deploy">Transformer Deployment</A>
								<DT><A HREF="https://github.com/triton-inference-server/python_backend?tab=readme-ov-file#decoupled-mode">triton-inference-server/python_backend: Triton backend that enables pre-process, post-processing and other logic to be implemented in Python.</A>
							</DL><p>
							<DT><H3 FOLDED>Torch Serve</H3>
							<DL><p>
								<DT><A HREF="https://github.com/pytorch/serve">pytorch/serve: Serve, optimize and scale PyTorch models in production</A>
								<DT><A HREF="https://dev-discuss.pytorch.org/t/the-future-of-c-model-deployment/1282">The future of C++ model deployment</A>
								<DT><A HREF="https://github.com/BBuf/how-to-optim-algorithm-in-cuda/commit/fec7d0015b9c3b0d4ca5ca77072aec57d59c8d38">add Deploying LLMs with TorchServe + vLLM.md ¬∑ BBuf/how-to-optim-algorithm-in-cuda@fec7d00</A>
							</DL><p>
							<DT><H3 FOLDED>jax-serving</H3>
							<DL><p>
								<DT><H3 FOLDED>Saxml</H3>
								<DL><p>
									<DT><H3 FOLDED>serving-alpa</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/zhuohan123/status/1629007867834695681">AlpaServe: model parallelism</A>
										<DT><A HREF="https://www.youtube.com/watch?v=qzYoMldlyoA&t=13s">Trends Driving Big Models</A>
										<DT><A HREF="https://www.youtube.com/watch?v=LGYYRRKxCjE">Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning - YouTube</A>
									</DL><p>
									<DT><A HREF="https://github.com/Google/saxml">google/saxml</A>
									<DT><A HREF="https://cloud.google.com/kubernetes-engine/docs/tutorials/tpu-multihost-saxml#load_the_model">Serve an LLM using multi-host TPUs on GKE with Saxml ¬†|¬† Kubernetes Engine ¬†|¬† Google Cloud</A>
									<DT><A HREF="https://github.com/google/saxml/blob/e060b11a7c2de1cca75370a8cddd8f89d6f4664c/saxml/server/pax/lm/servable_lm_model_test.py#L279">saxml/saxml/server/pax/lm/servable_lm_model_test.py</A>
									<DT><A HREF="https://github.com/google/JetStream/tree/main">google/JetStream: A throughput and memory optimized engine for LLM inference on TPUs!</A>
								</DL><p>
								<DT><A HREF="https://github.com/google/jax/blob/main/jax/experimental/jax2tf/examples/serving/README.md">jax2tf: serving examples</A>
								<DT><A HREF="https://alpa.ai/tutorials/opt_serving.html#launch-a-web-server-to-serve-the-opt-models">Serving OPT-175B, BLOOM-176B and CodeGen-16B using Alpa ‚Äî Alpa 0.2.3.dev17 documentation</A>
								<DT><A HREF="https://github.com/alpa-projects/alpa">alpa-projects/alpa: Training and serving large-scale neural networks with auto parallelization.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=e85Ceq2g5z0&t=1s">(Day 1 - Breakout Session) StableHLO &amp; PJRT - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-XyysbKrShk">PyTorch üíô XLA - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>Deepspeed-MII</H3>
							<DL><p>
								<DT><H3 FOLDED>Deepspeed-MII-engine</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/docs/_tutorials/inference-tutorial.md">DeepSpeed/inference-tutorial.md at master ¬∑ microsoft/DeepSpeed ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeedExamples">microsoft/DeepSpeedExamples: Example models using DeepSpeed</A>
									<DT><A HREF="https://github.com/huggingface/accelerate/blob/55691b14c21748319bc7004f09d2ea6019e71a25/benchmarks/big_model_inference.py#L100">accelerate/big_model_inference.py at 55691b14c21748319bc7004f09d2ea6019e71a25 ¬∑ huggingface/accelerate</A>
									<DT><A HREF="https://lightning.ai/pages/community/serve-stable-diffusion-three-times-faster/">Stable Diffusion kernel injection</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/pull/4604">DeepSpeed-FastGen by cmikeh2 ¬∑ Pull Request #4604 ¬∑ microsoft/DeepSpeed</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/4828d71d076b9a5cbe7ef48007cc5b51907c3319/blogs/deepspeed-fastgen/README.md">DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference</A>
								</DL><p>
								<DT><H3 FOLDED>Deepspeed-MII-architecture</H3>
								<DL><p>
									<DT><A HREF="https://github.com/antferdom/infrastructure/blob/master/rest_server/server.py">infrastructure/server.py at master ¬∑ antferdom/infrastructure ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/pythonprofilers/memory_profiler">pythonprofilers/memory_profiler: Monitor Memory usage of Python code</A>
									<DT><A HREF="https://github.com/huggingface/accelerate/blob/3cb9d5fd9c78c1da9fbc3127d6e63679a2475c6a/src/accelerate/utils/modeling.py#L443">accelerate/modeling.py at 3cb9d5fd9c78c1da9fbc3127d6e63679a2475c6a ¬∑ huggingface/accelerate</A>
									<DT><A HREF="https://github.com/huggingface/accelerate/blob/5e6351502aa2117d9f73da4c001e9baa87c65b67/tests/test_big_modeling.py#L600">accelerate/test_big_modeling.py at 5e6351502aa2117d9f73da4c001e9baa87c65b67 ¬∑ huggingface/accelerate</A>
									<DT><A HREF="https://github.com/huggingface/accelerate/blob/55691b14c21748319bc7004f09d2ea6019e71a25/benchmarks/big_model_inference.py#L100">accelerate/big_model_inference.py at 55691b14c21748319bc7004f09d2ea6019e71a25 ¬∑ huggingface/accelerate</A>
									<DT><A HREF="https://github.com/huggingface/transformers/blob/370f0ca18c8e4577357df59936e790acdecef4ac/tests/models/t5/test_modeling_tf_t5.py#L551">transformers/test_modeling_tf_t5.py at 370f0ca18c8e4577357df59936e790acdecef4ac ¬∑ huggingface/transformers</A>
									<DT><A HREF="https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.TableQuestionAnsweringPipeline">Pipelines</A>
									<DT><A HREF="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline">Pipelines</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeedExamples">microsoft/DeepSpeedExamples: Example models using DeepSpeed</A>
									<DT><A HREF="https://arxiv.org/pdf/2207.00032.pdf">https://arxiv.org/pdf/2207.00032.pdf</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/docs/_tutorials/inference-tutorial.md">DeepSpeed/inference-tutorial.md at master ¬∑ microsoft/DeepSpeed ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/server.py">DeepSpeed-MII/server.py at main ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/mallorbc/Finetune_LLMs/blob/main/inference/query.py">Finetune_LLMs/query.py at main ¬∑ mallorbc/Finetune_LLMs ¬∑ GitHub</A>
								</DL><p>
								<DT><H3 FOLDED>Deepspeed-MII-deployment-stack-trace</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/9527eb5d39fc93ede11c4761abbc13fe7e644795/mii/deployment.py#LL128C1-L129C1">DeepSpeed-MII/deployment.py at 9527eb5d39fc93ede11c4761abbc13fe7e644795 ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/models/score/generate.py">DeepSpeed-MII/generate.py at main ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/models/score/generate.py#L12">DeepSpeed-MII/generate.py at main ¬∑ microsoft/DeepSpeed-MII</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/main/mii/models/score/score_template.py">DeepSpeed-MII/score_template.py at main ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/9527eb5d39fc93ede11c4761abbc13fe7e644795/mii/deployment.py#L147">DeepSpeed-MII/deployment.py at 9527eb5d39fc93ede11c4761abbc13fe7e644795 ¬∑ microsoft/DeepSpeed-MII</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/9527eb5d39fc93ede11c4761abbc13fe7e644795/mii/utils.py#L155">DeepSpeed-MII/utils.py at 9527eb5d39fc93ede11c4761abbc13fe7e644795 ¬∑ microsoft/DeepSpeed-MII</A>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/9527eb5d39fc93ede11c4761abbc13fe7e644795/mii/server.py">DeepSpeed-MII/server.py at 9527eb5d39fc93ede11c4761abbc13fe7e644795 ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
								</DL><p>
								<DT><H3 FOLDED>Deepspeed-MII-benchmarking</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/issues/204">Issue #204: Benchmarking MII performance</A>
								</DL><p>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII#getting-started-with-mii">microsoft/DeepSpeed-MII: MII makes low-latency and high-throughput inference possible, powered by DeepSpeed.</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/9527eb5d39fc93ede11c4761abbc13fe7e644795/examples/local/text-generation-zero-example.py#L24">DeepSpeed-MII/text-generation-zero-example.py at 9527eb5d39fc93ede11c4761abbc13fe7e644795 ¬∑ microsoft/DeepSpeed-MII</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/9527eb5d39fc93ede11c4761abbc13fe7e644795/mii/models/load_models.py">DeepSpeed-MII/load_models.py at 9527eb5d39fc93ede11c4761abbc13fe7e644795 ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed-MII/blob/main/examples/benchmark/txt2img/baseline-sd.py">DeepSpeed-MII/baseline-sd.py at main ¬∑ microsoft/DeepSpeed-MII ¬∑ GitHub</A>
								<DT><A HREF="https://github.com/huggingface/diffusers/blob/v0.7.1/examples/text_to_image/train_text_to_image.py#L603">diffusers/train_text_to_image.py at v0.7.1 ¬∑ huggingface/diffusers ¬∑ GitHub</A>
								<DT><A HREF="https://github.com/huggingface/diffusers/blob/d2285f51589bbee18673272611b709d306e7f911/examples/research_projects/intel_opts/textual_inversion_dfq/text2images.py#L68">diffusers/text2images.py at d2285f51589bbee18673272611b709d306e7f911 ¬∑ huggingface/diffusers</A>
								<DT><A HREF="https://github.com/pytorch/serve">pytorch/serve: Serve, optimize and scale PyTorch models in production</A>
								<DT><A HREF="https://docs.python.org/3/library/inspect.html">inspect ‚Äî Inspect live objects ‚Äî Python 3.11.3 documentation</A>
								<DT><A HREF="https://www.deepspeed.ai/2022/09/09/zero-inference.html">ZeRO-Inference: Democratizing massive model inference - DeepSpeed</A>
								<DT><A HREF="https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/welcoming-mistral-phi-jais-code-llama-nvidia-nemotron-and-more/ba-p/3982699#:~:text=Today,%20we%20are%20also%20pleased,API%20endpoint%20to%20their%20applications.">Azure AI: Model as a Service</A>
								<DT><A HREF="https://github.com/Azure/azure-sdk-for-python">Azure/azure-sdk-for-python: This repository is for active development of the Azure SDK for Python. For consumers of the SDK we recommend visiting our public developer docs at https://docs.microsoft.com/python/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-python.</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen">FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference</A>
								<DT><A HREF="https://www.youtube.com/watch?v=fkHYRWMmTmM">[short] DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference - YouTube</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen">DeepSpeed/blogs/deepspeed-fastgen at master ¬∑ microsoft/DeepSpeed</A>
							</DL><p>
							<DT><H3 FOLDED>Text Generation Inference (TGI)</H3>
							<DL><p>
								<DT><H3 FOLDED>tgi-release-notes</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/docs/text-generation-inference/conceptual/chunking">TGI v3 overview</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-lectures</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=6OozhhI6U4g&t=3483s">Open Assistant Inference Backend Development (Hands-On Coding) - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=jlMAX2Oaht0">Text-generation-inference (TGI) deployment optimization and benchmarking - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=jKbbvy-xB4w&t=1894s">HuggingFace: Text Generation Inference: Part 1 - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-client</H3>
								<DL><p>
									<DT><A HREF="https://superfastpython.com/asyncio-gather/">How to Use asyncio.gather() in Python</A>
									<DT><A HREF="https://stackoverflow.com/questions/2785954/creating-a-list-in-python-with-multiple-copies-of-a-given-object-in-a-single-lin">Creating a list in Python with multiple copies of a given object in a single line - Stack Overflow</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-launcher</H3>
								<DL><p>
									<DT><H3 FOLDED>PyTorch checkpointing</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/safetensors/blob/96061e97bb7fc4ea6cdd1f79f58701efc4710d22/docs/source/index.mdx#L41">safetensors/docs/source/index.mdx at 96061e97bb7fc4ea6cdd1f79f58701efc4710d22 ¬∑ huggingface/safetensors</A>
										<DT><A HREF="https://github.com/huggingface/safetensors/blob/96061e97bb7fc4ea6cdd1f79f58701efc4710d22/bindings/python/tests/test_pt_comparison.py#L194">safetensors/bindings/python/tests/test_pt_comparison.py at 96061e97bb7fc4ea6cdd1f79f58701efc4710d22 ¬∑ huggingface/safetensors</A>
										<DT><A HREF="https://chat.openai.com/c/ac65640c-ae35-4308-bc9e-208baf30a139">Optimizing PyTorch Distributed Launch</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/228b31047858eda15d58a8bc03831f197e4c2120/extra/utils.py#L37">tinygrad/extra/utils.py at 228b31047858eda15d58a8bc03831f197e4c2120 ¬∑ tinygrad/tinygrad</A>
										<DT><A HREF="https://github.com/facebookresearch/llama-recipes/blob/373000b2ac13f3e52b5df11cec79ed5f2e5b9cbe/src/llama_recipes/inference/model_utils.py#L8">llama-recipes/src/llama_recipes/inference/model_utils.py at 373000b2ac13f3e52b5df11cec79ed5f2e5b9cbe ¬∑ facebookresearch/llama-recipes</A>
										<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/c8d6a1f34ab6f1b6bd468d256e535a61f98f114c/convert.py#L1016">llama.cpp/convert.py at c8d6a1f34ab6f1b6bd468d256e535a61f98f114c ¬∑ ggerganov/llama.cpp</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/serialization.py#L866">pytorch/torch/serialization.py at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/96a982ad8fc232479384476b1596a880697cc1d0/Makefile">text-generation-inference/Makefile at 96a982ad8fc232479384476b1596a880697cc1d0 ¬∑ huggingface/text-generation-inference</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/96a982ad8fc232479384476b1596a880697cc1d0/server/text_generation_server/utils/weights.py">text-generation-inference/server/text_generation_server/utils/weights.py at 96a982ad8fc232479384476b1596a880697cc1d0 ¬∑ huggingface/text-generation-inference</A>
										<DT><A HREF="https://pytorch.org/docs/stable/elastic/run.html">torchrun (Elastic Launch) ‚Äî PyTorch 2.1 documentation</A>
										<DT><A HREF="https://huggingface.co/bigscience/bloom-560m/blob/main/config.json">config.json ¬∑ bigscience/bloom-560m at main</A>
										<DT><A HREF="https://pytorch.org/torchx/latest/cli.html">CLI ‚Äî PyTorch/TorchX main documentation</A>
										<DT><A HREF="https://github.githistory.xyz/huggingface/text-generation-inference/blob/main/Makefile">Git History - Makefile</A>
										<DT><A HREF="https://github.com/grpc/grpc/tree/d68161a64f191b8d8d5afe0507e7a2291f91ff1a/examples/python/uds">grpc/examples/python/uds at d68161a64f191b8d8d5afe0507e7a2291f91ff1a ¬∑ grpc/grpc</A>
										<DT><A HREF="https://github.com/facebookexperimental/protoquant">facebookexperimental/protoquant: Prototype routines for GPU quantization written using PyTorch.</A>
										<DT><A HREF="https://github.com/datacrunch-research/text-generation-inference/commit/fbf28546706038db51870bd53684ceb528affe6b">(COMPLETE): minimal working PyTorch checkpointing in launcher ¬∑ datacrunch-research/text-generation-inference@fbf2854</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>tgi-shardmanager</H3>
								<DL><p>
									<DT><A HREF="https://engineering.fb.com/2020/08/24/production-engineering/scaling-services-with-shard-manager/">Scaling services with Shard Manager - Engineering at Meta</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-router (serving system)</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/tree/main/router">README</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/469">FastTokenizer: heuristics for the scheduler</A>
									<DT><A HREF="https://www.usenix.org/conference/osdi22/presentation/yu">Orca: A Distributed Serving System for Transformer-Based Generative Models | USENIX</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/pull/210">feat(router): Dynamic batch sizing</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/pull/210">Dynamic batch sizing</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/main/docs/source/advanced/batch-manager.md">TensorRT-LLM/docs/source/advanced/batch-manager.md</A>
									<DT><A HREF="https://github.com/IBM/text-generation-router">IBM/text-generation-router: Routing proxy for TGIS</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-inference-engine</H3>
								<DL><p>
									<DT><H3 FOLDED>tgi-quantization</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/pull/438">Inference support for GPTQ (llama + falcon tested) + Quantization script by Narsil ¬∑ Pull Request #438 ¬∑ huggingface/text-generation-inference</A>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/455">SPQR discussion (Meta AI)</A>
									</DL><p>
									<DT><H3 FOLDED>tgi-vlm</H3>
									<DL><p>
										<DT><A HREF="https://github.com/leizhao1234/cogvlm2">leizhao1234/cogvlm2: Add cogVLM v2 to TGI (MAIN)</A>
									</DL><p>
									<DT><H3 FOLDED>tgi-model-loading</H3>
									<DL><p>
										<DT><A HREF="https://github.com/search?q=repo%3Ahuggingface%2Ftext-generation-inference%20language_model&type=code">language_model</A>
										<DT><A HREF="https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B-tgi">THUDM/cogvlm2-llama3-chat-19B-tgi ¬∑ Hugging Face</A>
									</DL><p>
									<DT><H3 FOLDED>tgi-format-model</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B-tgi">THUDM/cogvlm2-llama3-chat-19B-tgi ¬∑ Hugging Face</A>
										<DT><A HREF="https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B/blob/main/model.safetensors.index.json">model.safetensors.index.json ¬∑ THUDM/cogvlm2-llama3-chat-19B at main</A>
										<DT><A HREF="https://huggingface.co/THUDM/cogvlm2-llama3-chat-19B-tgi/blob/main/pytorch_model.bin.index.json">pytorch_model.bin.index.json ¬∑ THUDM/cogvlm2-llama3-chat-19B-tgi at main</A>
									</DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/376">Improve inference speed of Santacoder and Starcoder (and others) ¬∑ Issue #376 ¬∑ huggingface/text-generation-inference</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-inference-container</H3>
								<DL><p>
									<DT><H3 FOLDED>tgi-dockerfile</H3>
									<DL><p>
										<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/Dockerfile">text-generation-inference/Dockerfile at main ¬∑ huggingface/text-generation-inference ¬∑ GitHub</A>
										<DT><A HREF="https://github.com/awslabs/llm-hosting-container/blob/main/docs/huggingface/tgi-0.9.3.md">HuggingFace TGI Container Environemnt Variables</A>
										<DT><A HREF="https://github.com/awslabs/llm-hosting-container/blob/main/huggingface/pytorch/tgi/docker/2.2.0/Dockerfile">llm-hosting-container/huggingface/pytorch/tgi/docker/2.2.0/Dockerfile at main ¬∑ awslabs/llm-hosting-container</A>
										<DT><A HREF="https://github.com/danieldk/tgi-nix">danieldk/tgi-nix</A>
										<DT><A HREF="https://github.com/datacrunch-research/hosting-container">datacrunch-research/hosting-container: Large Language Model Hosting Container</A>
									</DL><p>
									<DT><A HREF="https://github.com/awslabs/llm-hosting-container">awslabs/llm-hosting-container: Large Language Model Hosting Container</A>
									<DT><A HREF="https://github.com/aws/sagemaker-python-sdk">aws/sagemaker-python-sdk: A library for training and deploying machine learning models on Amazon SageMaker</A>
									<DT><A HREF="https://github.com/aws/deep-learning-containers/blob/master/pytorch/inference/buildspec.yml">deep-learning-containers/buildspec.yml at master ¬∑ aws/deep-learning-containers ¬∑ GitHub</A>
									<DT><A HREF="https://github.com/sgl-project/sglang/blob/5d0d40d0eb8c347d8b3598f0a375696728df66c4/scripts/playground/launch_tgi.sh#L4">sglang/scripts/playground/launch_tgi.sh at 5d0d40d0eb8c347d8b3598f0a375696728df66c4 ¬∑ sgl-project/sglang</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-benchmark</H3>
								<DL><p>
									<DT><A HREF="https://github.com/bigcode-project/bigcode-inference-benchmark/blob/main/scripts/run_grid.sh">bigcode-inference-benchmark: run_grid.sh</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-profiling</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/1014">Profile TGI with nsys launch/start/stop lead to Error: ShardCannotStart ¬∑ Issue #1014 ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/1129">multi-gpu</A>
									<DT><A HREF="https://developer.nvidia.com/nsight-systems">Nsight Systems | NVIDIA Developer | NVIDIA Developer</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/863">NCCL nsight-systems</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-fork</H3>
								<DL><p>
									<DT><H3 FOLDED>IBM</H3>
									<DL><p>
										<DT><A HREF="https://github.com/IBM/text-generation-inference/blob/main/integration_tests/text_generation_tests/test_server.py">integration_tests: test_server.py</A>
										<DT><A HREF="https://twitter.com/YiTayML/status/1714315484357857766">The Effiency Misnomer</A>
										<DT><A HREF="https://github.com/foundation-model-stack/foundation-model-stack">foundation-model-stack/foundation-model-stack</A>
										<DT><A HREF="https://github.com/IBM/text-generation-inference">IBM/text-generation-inference: IBM development fork</A>
										<DT><A HREF="https://github.com/caikit/caikit-nlp">caikit/caikit-nlp</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>tgi-embeddings</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/199">[Feature] Return embeddings ¬∑ Issue #199 ¬∑ huggingface/text-generation-inference</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-billing</H3>
								<DL><p>
									<DT><A HREF="https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#example-response-2">OpenAI GPT Response: usage</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/pull/578">enh: Adding additional response header X-Total-Tokens by brightsparc ¬∑ Pull Request #578 ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/637">Return total tokens generated as an http response header ¬∑ Issue #637 ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/435">Request a new api endpoint to check and retrieve token length for given text/prompt ¬∑ Issue #435 ¬∑ huggingface/text-generation-inference</A>
								</DL><p>
								<DT><H3 FOLDED>tgi-discussion</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/1819">Planned/Potential of significant work #1819</A>
								</DL><p>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference">huggingface/text-generation-inference</A>
								<DT><A HREF="https://huggingface.co/inference-endpoints">Inference Endpoints - Hugging Face</A>
								<DT><A HREF="https://huggingface.co/docs/transformers/v4.28.1/en/pipeline_webserver">Using pipelines for a webserver</A>
								<DT><A HREF="https://huggingface.co/bigscience/mt0-xxl-mt">bigscience/mt0-xxl-mt ¬∑ Hugging Face</A>
								<DT><A HREF="https://github.com/google-research/multilingual-t5">google-research/multilingual-t5</A>
								<DT><A HREF="https://huggingface.github.io/text-generation-inference/">Text Generation Inference API</A>
								<DT><A HREF="https://twitter.com/yacineMTB/status/1691208981698498560">HF Transformers Software Complexity</A>
								<DT><A HREF="https://towardsdatascience.com/hugging-face-transformer-inference-under-1-millisecond-latency-e1be0057a51c">Hugging Face Transformer Inference Under 1 Millisecond Latency</A>
							</DL><p>
							<DT><H3 FOLDED>skypilot</H3>
							<DL><p>
								<DT><A HREF="https://nebius.com/blog/posts/serving-qwen3-skypilot-sglang">Serving Qwen3 models on Nebius AI Cloud by using SkyPilot and SGLang</A>
								<DT><A HREF="https://x.com/SemiAnalysis_/status/1984051218688204827">(1) SemiAnalysis en X: "BREAKING: A couple months ago, NeoClouds were scared that NVIDIA‚Äôs DGX Lepton was going to commoditize their margins. This is no longer the case as NVIDIA is already on a path to ruin DGX Lepton. We will break it down below üëá The premise of why DGX Lepton was could potentially https://t.co/sMid5bnqfR" / X</A>
							</DL><p>
							<DT><H3 FOLDED>gpt-fast</H3>
							<DL><p>
								<DT><A HREF="https://pytorch.org/blog/accelerating-generative-ai-2/">Accelerating Generative AI with PyTorch II: GPT, Fast | PyTorch</A>
								<DT><A HREF="https://github.com/pytorch-labs/gpt-fast/blob/main/tp.py">gpt-fast/tp.py at main ¬∑ pytorch-labs/gpt-fast</A>
								<DT><A HREF="https://github.com/MDK8888/GPTFast">MDK8888/GPTFast: Accelerate your Hugging Face Transformers 7.6-9x. Native to Hugging Face and PyTorch.</A>
							</DL><p>
							<DT><H3 FOLDED>nanoflow</H3>
							<DL><p>
								<DT><A HREF="https://github.com/efeslab/Nanoflow">efeslab/Nanoflow: A throughput-oriented high-performance serving framework for LLMs</A>
								<DT><A HREF="https://x.com/bariskasikci/status/1828167529585672504">(1) Baris Kasikci en X: "We present Nanoflow, an LLM serving framework with close-to-optimal throughput. Nanoflow aggressively overlaps compute, memory, network operations yielding 1.91x more throughput on Splitwise, Lmsys and ShareGPT datasets wrt the best baseline, Tensor RT LLM (~69% of optimal tput) https://t.co/zqYcs9bMay" / X</A>
							</DL><p>
							<DT><H3 FOLDED>fal</H3>
							<DL><p>
								<DT><H3 FOLDED>fal-people</H3>
								<DL><p>
									<DT><A HREF="https://x.com/gorkemyurt">(1) Gorkem Yurtseven (@gorkemyurt) / X</A>
									<DT><A HREF="https://x.com/isidentical">batuhan taskaya (@isidentical) / X</A>
									<DT><A HREF="https://x.com/cloneofsimo">Simo Ryu (@cloneofsimo) / X</A>
									<DT><A HREF="https://x.com/drochetti">Daniel Rochetti (@drochetti) / X</A>
									<DT><A HREF="https://x.com/jfischoff">Jonathan Fischoff (@jfischoff) / X</A>
									<DT><A HREF="https://x.com/chamini2">Matteo Ferrando (@chamini2) / X</A>
									<DT><A HREF="https://x.com/gokayfem">gokaygokay (@gokayfem) / X</A>
									<DT><A HREF="https://x.com/aykutkardas">Aykut (@aykutkardas) / X</A>
									<DT><A HREF="https://x.com/rkuprieiev">Ruslan Kuprieiev üá∫üá¶ (@rkuprieiev) / X</A>
									<DT><A HREF="https://x.com/fp8e4m3fn">Vedat Baday (@fp8e4m3fn) / X</A>
									<DT><A HREF="https://x.com/_yatharthg">Yatharth Gupta (@_yatharthg) / X</A>
									<DT><A HREF="https://x.com/Gothos03">(1) Vishnu Jaddipal (@Gothos03) / X</A>
									<DT><A HREF="https://x.com/chengzeyi">Cheng (@chengzeyi) -&gt;  stable-fast.</A>
								</DL><p>
								<DT><A HREF="https://github.com/fal-ai/fal">fal-ai/fal: ‚ö° Fastest way to serve open source ML models to millions</A>
							</DL><p>
							<DT><H3 FOLDED>awslabs-LISA</H3>
							<DL><p>
								<DT><H3 FOLDED>AWS DJL</H3>
								<DL><p>
									<DT><A HREF="https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-tutorials-fastertransformer.html">Large model inference with FasterTransformer and DJL Serving - Amazon SageMaker</A>
									<DT><A HREF="https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/llm-workshop/lab5-flan-t5-xxl/flan-xxl-sagemaker-fastertransformer-s5cmd.ipynb">amazon-sagemaker-examples/inference/generativeai/llm-workshop/lab5-flan-t5-xxl/flan-xxl-sagemaker-fastertransformer-s5cmd.ipynb at main ¬∑ aws/amazon-sagemaker-examples</A>
									<DT><A HREF="https://github.com/deepjavalibrary/djl-serving">deepjavalibrary/djl-serving: A universal scalable machine learning model deployment solution</A>
									<DT><A HREF="https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/optimizations/aitemplate/lmi-aitemplate-stablediff.ipynb">amazon-sagemaker-examples/inference/generativeai/optimizations/aitemplate/lmi-aitemplate-stablediff.ipynb at main ¬∑ aws/amazon-sagemaker-examples</A>
								</DL><p>
								<DT><A HREF="https://github.com/awslabs/LISA">awslabs/LISA: LLM inference solution for Amazon Dedicated Cloud (LISA).</A>
							</DL><p>
							<DT><H3 FOLDED>serving-coreweave</H3>
							<DL><p>
								<DT><A HREF="https://docs.coreweave.com/coreweave-machine-learning-and-ai/inference">Inference | CoreWeave</A>
								<DT><A HREF="https://docs.coreweave.com/">CoreWeave Cloud - CoreWeave</A>
								<DT><A HREF="https://github.com/kserve/kserve">kserve/kserve: Standardized Serverless ML Inference Platform on Kubernetes</A>
								<DT><A HREF="https://github.com/huggingface/text-generation-inference">huggingface/text-generation-inference: Large Language Model Text Generation Inference</A>
								<DT><A HREF="https://docs.coreweave.com/compass/examples/triton-inference-server-fastertransformer">https://docs.coreweave.com/compass/examples/triton-inference-server-fastertransformer</A>
							</DL><p>
							<DT><H3 FOLDED>serving-modal</H3>
							<DL><p>
								<DT><A HREF="https://modal.com/docs/examples/trtllm_llama">Serverless TensorRT-LLM (LLaMA 3 8B) | Modal Docs</A>
								<DT><A HREF="https://github.com/modal-labs">Modal Labs</A>
								<DT><A HREF="https://github.com/modal-labs/serverless-queuing-theory-model">modal-labs/serverless-queuing-theory-model: Implementation of a serverless queuing theory model to explore optimal policies and tradeoffs between latency &amp; utilization</A>
								<DT><A HREF="https://github.com/modal-labs/mountpoint-s3">modal-labs/mountpoint-s3: A simple, high-throughput file client for mounting an Amazon S3 bucket as a local file system.</A>
								<DT><A HREF="https://github.com/modal-labs/modal-examples/blob/main/07_web_endpoints/basic_web.py">modal-examples/07_web_endpoints/basic_web.py at main ¬∑ modal-labs/modal-examples</A>
							</DL><p>
							<DT><H3 FOLDED>serving-checkpointing</H3>
							<DL><p>
								<DT><H3 FOLDED>nm-compressed-tensors</H3>
								<DL><p>
									<DT><A HREF="https://github.com/neuralmagic/compressed-tensors">neuralmagic/compressed-tensors: A safetensors extension to efficiently store sparse quantized tensors on disk</A>
								</DL><p>
								<DT><H3 FOLDED>hf_transfer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/hf_transfer/blob/main/src/lib.rs#L38">hf_transfer/src/lib.rs at main ¬∑ huggingface/hf_transfer</A>
									<DT><A HREF="https://github.com/huggingface/hf_transfer">os.environ["HF_HUB_ENABLE_HF_TRANSFER"] = "1"</A>
									<DT><A HREF="https://github.com/rishiraj/firerequests">rishiraj/firerequests: High-performance, asynchronous Python HTTP client library designed for faster file transfers using concurrency, semaphores, and fault-tolerant features.</A>
								</DL><p>
								<DT><H3 FOLDED>buffers</H3>
								<DL><p>
									<DT><A HREF="https://www.tutorialspoint.com/How-an-entire-file-is-read-into-buffer-and-returned-as-a-string-in-Python">How an entire file is read into buffer and returned as a string in Python?</A>
									<DT><A HREF="https://stackoverflow.com/questions/59026110/python-read-data-from-buffer">Python read data from Buffer - Stack Overflow</A>
									<DT><A HREF="https://docs.python.org/3/library/os.html">os.read</A>
									<DT><A HREF="https://docs.python.org/3/library/io.html">io: readinto</A>
									<DT><A HREF="https://www.youtube.com/watch?v=THWDx_RyZ6A">Episode 011: Let's Go to the Disk! - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>safetensors</H3>
								<DL><p>
									<DT><H3 FOLDED>convert-safetensors</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/c/55ba3e16-1efd-4659-9c7a-f575b92f7fd9?rid=0b7ae2e2-af9e-475c-b95d-509955e3c700">Model Weight Conversion to bfloat16 - Grok</A>
										<DT><A HREF="https://github.com/datacrunch-research/cortex/blob/wan22/extra/utils/convert_weights_to_bf16.py">cortex/extra/utils/convert_weights_to_bf16.py at wan22 ¬∑ datacrunch-research/cortex</A>
									</DL><p>
									<DT><H3 FOLDED>model-streamer</H3>
									<DL><p>
										<DT><A HREF="https://github.com/run-ai/runai-model-streamer">run-ai/runai-model-streamer</A>
										<DT><A HREF="https://github.com/vllm-project/vllm/pull/9941">[Core]Add New Run:ai Streamer Load format. by pandyamarut ¬∑ Pull Request #9941 ¬∑ vllm-project/vllm</A>
										<DT><A HREF="https://www.run.ai/blog/accelerating-model-loading-with-run-ai-model-streamer">From Storage to GPU‚Äîbut Faster: Accelerating Model Loading with Run:ai Model Streamer</A>
										<DT><A HREF="https://pages.run.ai/hubfs/PDFs/White%20Papers/Model-Streamer-Performance-Benchmarks.pdf">Ruan:ai research model streamer performance benchmarks</A>
										<DT><A HREF="https://github.com/meta-llama/llama-models/blob/0e0b8c519242d5833d8c11bffc1232b77ad7f301/models/cli/download.py#L38">llama-models/models/cli/download.py at 0e0b8c519242d5833d8c11bffc1232b77ad7f301 ¬∑ meta-llama/llama-models</A>
									</DL><p>
									<DT><A HREF="https://github.com/huggingface/safetensors/issues/200">equivalent of torch.load from io stream to gpu</A>
									<DT><A HREF="https://github.com/vladmandic/sd-loader/blob/main/bench.py">sd-loader/bench.py at main ¬∑ vladmandic/sd-loader</A>
									<DT><A HREF="https://github.com/huggingface/safetensors/issues/200">using fp16 or fp32 (load times)</A>
									<DT><A HREF="https://github.com/huggingface/safetensors/issues/18">Some clarification about PyTorch format</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/text_generation_server/models/flash_llama.py#L216-L311">(TGI): Safetensors lazy_loading (flash_llama.py)</A>
									<DT><A HREF="https://huggingface.co/docs/safetensors/speed#gpu-benchmark">Speed Comparison</A>
									<DT><A HREF="https://github.com/huggingface/safetensors/issues/67">Support for model streaming (disk -&gt; VRAM)? ¬∑ Issue #67</A>
									<DT><A HREF="https://github.com/huggingface/safetensors/pull/189/files">Adding memmap example to read from file</A>
									<DT><A HREF="https://github.com/huggingface/safetensors/issues/242">tensorstore</A>
									<DT><A HREF="https://github.com/foundation-model-stack/fastsafetensors/tree/main/examples">fastsafetensors/examples at main ¬∑ foundation-model-stack/fastsafetensors</A>
								</DL><p>
								<DT><H3 FOLDED>torch-checkpointing</H3>
								<DL><p>
									<DT><H3 FOLDED>torch-checkpointing-distributed</H3>
									<DL><p>
										<DT><A HREF="https://pytorch.org/blog/performant-distributed-checkpointing/?utm_content=258825622&utm_medium=social&utm_source=linkedin&hss_channel=lcp-78618366">PyTorch Distributed checkpointing in Production</A>
										<DT><A HREF="https://www.youtube.com/watch?v=ldBmHNva_Fw&t=31s">Distributed Checkpoint - Iris Zhang &amp; Chien-Chin Huang, Meta - YouTube</A>
										<DT><A HREF="https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP)</A>
									</DL><p>
									<DT><H3 FOLDED>skipping initialization of module parameters</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/29523">Option to skip random weight initialization at module instance creation</A>
										<DT><A HREF="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to_empty">meta device + added a to_empty function 2 from the meta device</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/nn/utils/init.py#L5">nn/utils/init.py at main Added device/dtype kwargs to all nn.Modules</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/96161">[torchdistx] Future of the large model initialization META device</A>
										<DT><A HREF="https://pytorch.org/torchdistx/latest/fake_tensor.html">Fake Tensor ‚Äî torchdistX 0.2.0 documentation</A>
										<DT><H3 FOLDED>problems: not solve 2x model parameters being in memory</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/90465">[FSDP] Revisit meta device initialization ¬∑ Issue #90465 ¬∑ pytorch/pytorch</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>loading parameters</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/nn/modules/module.py#L1941">pytorch/torch/nn/modules/module.py at main ¬∑ pytorch/pytorch</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/103405">(PROFILING) load model on infer so much memory on GPU and CPU ¬∑ Issue #103405</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/64601">Reuse tensors from state_dict in load_state_dict ¬∑ Issue #64601</A>
										<DT><A HREF="https://github.com/stas00/transformers/blob/main/src/transformers/modeling_utils.py#L2968">transformers/src/transformers/modeling_utils.py (reuse_tensor)</A>
										<DT><H3 FOLDED>state_dict</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/97196">Sequential/Partial unpickling and loading of models ¬∑ Issue #97196</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/75242">(stass) torch.load: that loads one submodule at a time</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/issues/64327">RFC: multi-part `torch.load`/`torch.save` to support huge models and/or low CPU memory</A>
											<DT><A HREF="https://areu01or00.github.io/Tensor-Slayer.github.io/ai/research/tensor-manipulation/2025/07/19/tensor-slayer-framework.html">https://areu01or00.github.io/Tensor-Slayer.github.io/ai/research/tensor-manipulation/2025/07/19/tensor-slayer-framework.html</A>
										</DL><p>
										<DT><H3 FOLDED>spliting</H3>
										<DL><p>
											<DT><A HREF="https://github.com/huggingface/transformers/issues/13548">RFC: split checkpoint load/save for huge models ¬∑ Issue #13548 ¬∑ huggingface/transformers</A>
											<DT><A HREF="https://github.com/finetunej/transformers/blob/ca5d90ac1965982db122a649c2c9c902bde74a03/src/transformers/modeling_utils.py#L417-L443">transformers/src/transformers/modeling_utils.py</A>
											<DT><A HREF="https://github.com/huggingface/transformers/blob/c030fc891395d11249046e36b9e0219685b33399/src/transformers/modeling_utils.py#L1045">floating_point_ops</A>
										</DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/issues/87033">Saving and loading from physical storage ¬∑ Issue #87033</A>
										<DT><H3 FOLDED>mmap</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/619ae87a1d1ae086f59a64d3b71dbfe4af8b804a/torch/serialization.py#L1010">serialization.py: mmap</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/619ae87a1d1ae086f59a64d3b71dbfe4af8b804a/test/test_serialization.py">test_serialization_mmap_loading</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/pull/101446">[WIP] Let torch.load load memory-mapped tensors</A>
											<DT><A HREF="https://github.com/nadavrot/memset_benchmark?tab=readme-ov-file">nadavrot/memset_benchmark: This repository contains high-performance implementations of memset and memcpy in assembly.</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>ByteCheckpoint</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ByteDance-Seed/ByteCheckpoint">ByteDance-Seed/ByteCheckpoint: ByteCheckpoint: An Unified Checkpointing Library for LFMs</A>
										<DT><A HREF="https://arxiv.org/abs/2407.20143">[2407.20143] ByteCheckpoint: A Unified Checkpointing System for Large Foundation Model Development</A>
									</DL><p>
									<DT><H3 FOLDED>torch-rdma</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/compare/main...mikaylagawarecki:pytorch:gds#diff-6c848cacbf0ee6cb3ace89d0e3a8b407b61f31543e5bf4ba70f149bc4b6585c7">Comparing pytorch:main...mikaylagawarecki:gds ¬∑ pytorch/pytorch: Torch load/save gds</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/compare/main...mikaylagawarecki:pytorch:gds-new-3">Comparing pytorch:main...mikaylagawarecki:gds-new-3 ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><H3 FOLDED>torch-checkpointing-offlload</H3>
									<DL><p>
										<DT><A HREF="https://x.com/StasBekman/status/1946261847373717848">extend torch.util.checkpoint to support offload to cpu/nvme #158657</A>
									</DL><p>
									<DT><H3 FOLDED>zip</H3>
									<DL><p>
										<DT><A HREF="https://x.com/cloud11665/status/1987219921810739393">(1) cloud en X: "Finally someone gets it. A fun fact that you might have not known is torch\.save() is also a zip(64) - though an uncompressed one. It has one main data.pkl entry inside that describes the tensors (or whole classes and functions if you save with unsafe mode) and then binary blob https://t.co/w9F6v3aDUw" / X</A>
									</DL><p>
									<DT><A HREF="https://dev-discuss.pytorch.org/t/state-of-model-creation-initialization-seralization-in-pytorch-core/1240">State of model creation/initialization/seralization in PyTorch Core</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/csrc/jit/docs/serialization.md">TorchScript serialization</A>
									<DT><A HREF="https://pytorch-dev-podcast.simplecast.com/episodes/serialization">Serialization | PyTorch Developer Podcast</A>
									<DT><A HREF="https://github.com/msaroufim/cpuoffload/tree/main">msaroufim/cpuoffload</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/db53e9d5ae262d15d8c8cfb9e5c67d620f66f54c/generate_new_checkpoint.py">pytorch/generate_new_checkpoint.py at db53e9d5ae262d15d8c8cfb9e5c67d620f66f54c ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/MoonshotAI/checkpoint-engine">MoonshotAI/checkpoint-engine: Checkpoint-engine is a simple middleware to update model weights in LLM inference engines</A>
								</DL><p>
								<DT><H3 FOLDED>serving-checkpointing-deepspeed</H3>
								<DL><p>
									<DT><A HREF="https://github.com/microsoft/DeepSpeed/issues/2379">DeepSpeed: Pre-sharding</A>
								</DL><p>
								<DT><H3 FOLDED>transmogrifier</H3>
								<DL><p>
									<DT><A HREF="https://mail.google.com/mail/u/0/#inbox?compose=CllgCKCFShQFztGvfWXCdvvFKVPMZgRSNlMlmGFlhSNBPphbqHsjpFVWTxZZBRhfsPrlVtnVXWL">Inbox - antonio.jfdominguez@gmail.com - Gmail</A>
									<DT><A HREF="https://github.com/huggingface/safetensors/blob/main/bindings/python/convert.py#L158">safetensors/bindings/python/convert.py at main ¬∑ huggingface/safetensors</A>
									<DT><A HREF="https://github.com/huggingface/huggingface_hub/blob/ef48c7f7311c0717db98f1b555c8e61d76fc1870/src/huggingface_hub/hf_api.py#L4225">https://github.com/huggingface/huggingface_hub/blob/ef48c7f7311c0717db98f1b555c8e61d76fc1870/src/huggingface_hub/hf_api.py#L4225</A>
									<DT><A HREF="https://chat.openai.com/c/3e8059da-4190-4d44-996e-38c5f08b0fb6">Argparse Args Programmatically</A>
									<DT><A HREF="https://github.com/datacrunch-research/transmogrifier/blob/main/transmogrifier/convert.py">transmogrifier/transmogrifier/convert.py at main ¬∑ datacrunch-research/transmogrifier</A>
									<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/228b31047858eda15d58a8bc03831f197e4c2120/extra/utils.py#L37">https://github.com/tinygrad/tinygrad/blob/228b31047858eda15d58a8bc03831f197e4c2120/extra/utils.py#L37</A>
									<DT><A HREF="https://github.com/openai/triton/blob/96b04493f11a72bf4f2fcc746259ce84b10cc730/python/triton/testing.py#L160">https://github.com/openai/triton/blob/96b04493f11a72bf4f2fcc746259ce84b10cc730/python/triton/testing.py#L160</A>
									<DT><A HREF="https://github.com/facebookresearch/llama-recipes/blob/373000b2ac13f3e52b5df11cec79ed5f2e5b9cbe/src/llama_recipes/inference/model_utils.py#L8">llama-recipes/src/llama_recipes/inference/model_utils.py at 373000b2ac13f3e52b5df11cec79ed5f2e5b9cbe ¬∑ facebookresearch/llama-recipes</A>
									<DT><A HREF="https://www.notion.so/datacrunchio/model-transmogrifier-27445d5b11134f7d9745039fd66dbda8">https://www.notion.so/datacrunchio/model-transmogrifier-27445d5b11134f7d9745039fd66dbda8</A>
									<DT><A HREF="https://github.com/huggingface/hf_transfer">huggingface/hf_transfer</A>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/blob/c8d6a1f34ab6f1b6bd468d256e535a61f98f114c/convert.py#L1016">llama.cpp/convert.py at c8d6a1f34ab6f1b6bd468d256e535a61f98f114c ¬∑ ggerganov/llama.cpp</A>
									<DT><A HREF="https://github.com/ggerganov/llama.cpp/tree/34b2a5e1ee4fe6295fb4420eb91131d743694c65">ggerganov/llama.cpp at 34b2a5e1ee4fe6295fb4420eb91131d743694c65</A>
									<DT><A HREF="https://github.com/huggingface/text-generation-inference/blob/main/server/text_generation_server/utils/gptq/exllama.py#L40">text-generation-inference/server/text_generation_server/utils/gptq/exllama.py at main ¬∑ huggingface/text-generation-inference</A>
									<DT><A HREF="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main">stabilityai/stable-diffusion-xl-base-1.0 at main</A>
									<DT><A HREF="https://huggingface.co/meta-llama/Llama-2-13b-hf/tree/main">meta-llama/Llama-2-13b-hf at main</A>
									<DT><A HREF="https://github.com/huggingface/huggingface_hub/blob/ef48c7f7311c0717db98f1b555c8e61d76fc1870/src/huggingface_hub/hf_api.py#L2956">huggingface_hub/src/huggingface_hub/hf_api.py at ef48c7f7311c0717db98f1b555c8e61d76fc1870 ¬∑ huggingface/huggingface_hub</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/torch/serialization.py#L866">pytorch/torch/serialization.py at main ¬∑ pytorch/pytorch</A>
									<DT><A HREF="https://github.com/allenai/cached_path">allenai/cached_path: A file utility for accessing both local and remote files through a unified interface.</A>
								</DL><p>
								<DT><H3 FOLDED>checkpointing-gds</H3>
								<DL><p>
									<DT><H3 FOLDED>cuFile</H3>
									<DL><p>
										<DT><H3 FOLDED>kvikio</H3>
										<DL><p>
											<DT><A HREF="https://github.com/rapidsai/kvikio/blob/branch-24.04/python/tests/test_defaults.py">kvikio/python/tests/test_defaults.py (compat_mode)</A>
											<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/topics/cufile-compatibility.html">cuFile Compatibility Mode - NVIDIA Docs</A>
											<DT><A HREF="https://docs.rapids.ai/api/libkvikio/nightly/">Compatibility Mode (KVIKIO_COMPAT_MODE)</A>
										</DL><p>
										<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html">cuFile API Reference Guide - NVIDIA Docs</A>
										<DT><A HREF="https://github.com/rapidsai/kvikio">rapidsai/kvikio</A>
										<DT><A HREF="https://github.com/rapidsai/kvikio/pull/135">Overload `numpy.fromfile()` and `cupy.fromfile()` by madsbk ¬∑ Pull Request #135 ¬∑ rapidsai/kvikio</A>
										<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py">alpa/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py at main ¬∑ alpa-projects/alpa</A>
										<DT><A HREF="https://github.com/pfnet/pytorch-pfn-extras/blob/f6b127063ec910b71788db2ae6ef96a3d89832b1/tests/pytorch_pfn_extras_tests/cuda_tests/test_allocator.py">pytorch-pfn-extras/tests/pytorch_pfn_extras_tests/cuda_tests/test_allocator.py at f6b127063ec910b71788db2ae6ef96a3d89832b1 ¬∑ pfnet/pytorch-pfn-extras</A>
										<DT><A HREF="https://pytorch-pfn-extras.readthedocs.io/en/latest/user_guide/cuda.html">CUDA (CuPy Interoperability) ‚Äî pytorch-pfn-extras documentation</A>
										<DT><A HREF="https://github.com/NVIDIA/apex/blob/810ffae374a2b9cb4b5c5e28eaeca7d7998fca0c/apex/contrib/csrc/gpu_direct_storage/gds.cpp">apex/apex/contrib/csrc/gpu_direct_storage/gds.cpp</A>
										<DT><A HREF="https://github.com/NVIDIA/MagnumIO/blob/main/gds/samples/cufile_sample_022.cc">cuFile Batch APIs</A>
										<DT><A HREF="https://chat.openai.com/c/61bb588b-35a7-42a6-90e9-c2355e5646a9">Identify Disk Storage Type</A>
									</DL><p>
									<DT><A HREF="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html">NVIDIA GPUDirect Storage Overview Guide - NVIDIA Docs</A>
									<DT><A HREF="https://ieeexplore.ieee.org/document/7973709">Offloading Communication Control Logic in GPU</A>
									<DT><A HREF="https://github.com/Mellanox/gpu_direct_rdma_access">Mellanox/gpu_direct_rdma_access: example code for using DC QP for providing RDMA READ and WRITE operations to remote GPU memory</A>
									<DT><A HREF="https://github.com/NVIDIA/gdrcopy">NVIDIA/gdrcopy: A fast GPU memory copy library based on NVIDIA GPUDirect RDMA technology</A>
									<DT><A HREF="https://github.com/NVIDIA/gds-nvidia-fs">NVIDIA/gds-nvidia-fs: NVIDIA GPUDirect Storage Driver</A>
									<DT><A HREF="https://github.com/lw?tab=stars">lw (Luca Wehrstedt)</A>
									<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py">alpa/examples/llm_serving/scripts/step_3_convert_to_numpy_weights.py</A>
									<DT><A HREF="https://github.com/pytorch/pytorch/compare/main...mikaylagawarecki:pytorch:gds">Comparing pytorch:main...mikaylagawarecki:gds ¬∑ pytorch/pytorch</A>
								</DL><p>
								<DT><H3 FOLDED>serving-checkpointing-serialization</H3>
								<DL><p>
									<DT><H3 FOLDED>json</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ijl/orjson">ijl/orjson: Fast, correct Python JSON library supporting dataclasses, datetimes, and numpy</A>
										<DT><A HREF="https://github.com/bytedance/sonic">bytedance/sonic: A blazingly fast JSON serializing &amp; deserializing library</A>
									</DL><p>
									<DT><A HREF="https://github.com/huggingface/safetensors/issues/358">checkpoint quantized weights (bitsandbyres.nf4, SpQR etc)</A>
									<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/checkpoints">ml-engineering/checkpoint</A>
									<DT><A HREF="https://github.com/alpa-projects/alpa/blob/824f2ffd5124d24935811bc738ed903796ab13ac/alpa/serialization.py#L54">(JAX) Alpa: serialization.py</A>
								</DL><p>
								<DT><H3 FOLDED>checkpointing-tinygrad</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=2QO3vzwHXhg&t=3551s">converting to float16 slowing down</A>
								</DL><p>
								<DT><H3 FOLDED>container-cold-start-times</H3>
								<DL><p>
									<DT><A HREF="https://scale.com/blog/reduce-cold-start-time-llm-inference">How To Reduce Cold Start Times For LLM Inference (Scale AI)</A>
									<DT><A HREF="https://www.amplifypartners.com/blog-posts/how-modal-built-a-data-cloud-from-the-ground-up">How Modal built a data cloud from the ground up | Amplify Partners</A>
								</DL><p>
								<DT><A HREF="https://github.com/xai-org/grok-1/blob/main/checkpoint.py">grok-1/checkpoint.py at main</A>
								<DT><A HREF="https://scale.com/blog/reduce-cold-start-time-llm-inference">How To Reduce Cold Start Times For LLM Inference (Scale AI)</A>
								<DT><A HREF="https://github.com/facebookresearch/HolisticTraceAnalysis">facebookresearch/HolisticTraceAnalysis</A>
								<DT><A HREF="https://github.com/huggingface/hf_transfer">huggingface/hf_transfer</A>
								<DT><A HREF="https://docs.ffcv.io/bottleneck_doctor.html">The Bottleneck Doctor ‚Äî FFCV documentation</A>
								<DT><A HREF="https://github.com/coreweave/tensorizer">coreweave/tensorizer: Module, Model, and Tensor Serialization/Deserialization</A>
								<DT><A HREF="https://github.com/allenai/cached_path">allenai/cached_path: A file utility for accessing both local and remote files through a unified interface.</A>
								<DT><A HREF="https://openai.com/index/scaling-kubernetes-to-7500-nodes/">Scaling Kubernetes to 7,500 nodes | OpenAI -&gt; CPU &amp; GPU balloons</A>
								<DT><A HREF="https://www.usenix.org/conference/osdi20/presentation/gujarati">Serving DNNs like Clockwork: Performance Predictability from the Bottom Up | USENIX</A>
								<DT><A HREF="https://www.outerport.com/blog/fast-flux-load">How fast can you load a FLUX (LoRA) model?</A>
							</DL><p>
							<DT><H3 FOLDED>serving-miscellaneous</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cloudflare/quiche">cloudflare/quiche: ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3</A>
								<DT><A HREF="https://cloudflare-quic.com/">QUIC | Cloudflare</A>
								<DT><A HREF="https://www.youtube.com/watch?v=FqljO9B5grM">Impeccable API Design: What you MUST CONSIDER before deploying APIs to production</A>
								<DT><A HREF="https://github.com/w3c/webtransport/blob/main/explainer.md">webtransport/explainer.md at main ¬∑ w3c/webtransport</A>
								<DT><A HREF="https://github.com/Motsepe-Jr/AI-research-papers-pseudo-code/blob/main/Distributed%20Inference%20Papers/Fast_Distributed_Inference_Serving_for_Large_Language_Models.ipynb">AI-research-papers-pseudo-code/Distributed Inference Papers/Fast_Distributed_Inference_Serving_for_Large_Language_Models.ipynb at main ¬∑ Motsepe-Jr/AI-research-papers-pseudo-code ¬∑ GitHub</A>
								<DT><A HREF="https://www.flickr.com/photos/neurollero/sets/366106/with/51970885/">neuro | Flickr</A>
								<DT><A HREF="https://jina.ai/news/inference-how-can-jina-ai-offer-the-best-in-class-model-as-a-service-so-affordably/">Jina: The Science of Model Deployment</A>
								<DT><A HREF="https://docs.cerebras.net/en/latest/wsc/getting-started/csctl.html#csctl">csctl: CLI tool for job monitoring ‚Äî Cerebras Developer Documentation</A>
								<DT><A HREF="https://github.com/alibaba/hiactor">alibaba/hiactor: Hiactor is a distributed C++ actor framework.</A>
								<DT><A HREF="https://github.com/hpcaitech/EnergonAI">hpcaitech/EnergonAI: Large-scale model inference.</A>
								<DT><A HREF="https://github.com/mosaicml/llm-foundry/blob/main/scripts/eval/local_data/EVAL_GAUNTLET.md">llm-foundry/scripts/eval/local_data/EVAL_GAUNTLET.md at main ¬∑ mosaicml/llm-foundry</A>
							</DL><p>
							<DT><H3 FOLDED>serving-hosting-container</H3>
							<DL><p>
								<DT><A HREF="https://github.com/awslabs/llm-hosting-container">awslabs/llm-hosting-container: Large Language Model Hosting Container</A>
							</DL><p>
							<DT><H3 FOLDED>serving-diffusion</H3>
							<DL><p>
								<DT><H3 FOLDED>alibaba-diffusers-api</H3>
								<DL><p>
									<DT><A HREF="https://github.com/alibaba/diffusers-api">alibaba/diffusers-api</A>
									<DT><A HREF="https://github.com/alibaba/diffusers-api/blob/main/diffusers/app.py#L28">diffusers-api/diffusers/app.py at main ¬∑ alibaba/diffusers-api</A>
									<DT><A HREF="https://github.com/alibaba/diffusers-api/blob/main/diffusers/utils/image_process.py#L156">diffusers-api/diffusers/utils/image_process.py: computer vision algorithms</A>
								</DL><p>
								<DT><H3 FOLDED>DeepCache</H3>
								<DL><p>
									<DT><H3 FOLDED>tmp</H3>
									<DL><p>
										<DT><A HREF="https://medium.com/swlh/writing-c-when-youre-a-java-developer-memory-management-7c42e222645e">Writing C++ When You‚Äôre a Java Developer: Memory Management | by Alexandre Lombard | The Startup | Medium</A>
										<DT><A HREF="https://mypy.readthedocs.io/en/stable/protocols.html">Protocols and structural subtyping - mypy 1.9.0 documentation</A>
										<DT><A HREF="https://colab.research.google.com/github/google/seqio/blob/main/seqio/notebooks/Basics_Task_and_Mixtures.ipynb#scrollTo=QTyxusscJgwO">[seqio basics] Task and Mixtures.ipynb - Colab</A>
										<DT><A HREF="https://github.com/google-research-datasets/natural-questions">google-research-datasets/natural-questions: Natural Questions (NQ) contains real user questions issued to Google search, and answers found from Wikipedia by annotators. NQ is designed for the training and evaluation of automatic question answering systems.</A>
										<DT><A HREF="https://twitter.com/i/bookmarks?post_id=1778234586599727285">https://twitter.com/i/bookmarks?post_id=1778234586599727285</A>
										<DT><A HREF="https://arxiv.org/abs/2404.07143">[2404.07143] Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</A>
										<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-4-kv-caching-a-deeper-look-4ba9a77746c8">LLM Inference Series: 4. KV caching, a deeper look | by Pierre Lienhart | Medium</A>
										<DT><A HREF="https://github.com/openai/triton/blob/main/python/triton/testing.py">triton/python/triton/testing.py at main ¬∑ openai/triton</A>
										<DT><A HREF="https://github.com/horseee/DeepCache/blob/master/stable_diffusion.py#L29">DeepCache/stable_diffusion.py at master ¬∑ horseee/DeepCache</A>
										<DT><A HREF="https://huggingface.co/docs/diffusers/main/en/optimization/deepcache">DeepCache</A>
										<DT><A HREF="https://arxiv.org/pdf/2312.00858.pdf">https://arxiv.org/pdf/2312.00858.pdf</A>
									</DL><p>
									<DT><A HREF="https://github.com/horseee/DeepCache">horseee/DeepCache: [CVPR 2024] DeepCache: Accelerating Diffusion Models for Free</A>
									<DT><A HREF="https://huggingface.co/docs/diffusers/main/en/optimization/deepcache">DeepCache</A>
									<DT><A HREF="https://github.com/dbolya/tomesd">dbolya/tomesd: Speed up Stable Diffusion with this one simple trick!</A>
									<DT><A HREF="https://github.com/chengzeyi/stable-fast/issues/110">Support for DeepCache ¬∑ Issue #110 ¬∑ chengzeyi/stable-fast</A>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-h200-tensor-core-gpus-and-nvidia-tensorrt-llm-set-mlperf-llm-inference-records/">NVIDIA H200 Tensor Core GPUs and NVIDIA TensorRT-LLM Set MLPerf LLM Inference Records | NVIDIA Technical Blog</A>
									<DT><A HREF="https://blogs.nvidia.com/blog/tensorrt-llm-inference-mlperf/">NVIDIA Hopper Leaps Ahead in Generative AI at MLPerf | NVIDIA Blog</A>
									<DT><A HREF="https://arxiv.org/abs/2312.00858">[2312.00858] DeepCache: Accelerating Diffusion Models for Free</A>
									<DT><A HREF="https://developer.nvidia.com/blog/nvidia-h200-tensor-core-gpus-and-nvidia-tensorrt-llm-set-mlperf-llm-inference-records/">NVIDIA H200 Tensor Core GPUs and NVIDIA TensorRT-LLM</A>
									<DT><A HREF="https://blogs.nvidia.com/blog/tensorrt-llm-inference-mlperf/">NVIDIA Hopper Leaps Ahead in Generative AI at MLPerf</A>
								</DL><p>
								<DT><H3 FOLDED>diffusers</H3>
								<DL><p>
									<DT><H3 FOLDED>diffusers-imports</H3>
									<DL><p>
										<DT><A HREF="https://github.com/optuna/optuna/blob/master/optuna/integration/__init__.py">optuna/optuna/integration/__init__.py at master</A>
										<DT><A HREF="https://github.com/huggingface/diffusers/blob/42cae93b942ec904ead46c26c42be24422adc92c/src/diffusers/utils/import_utils.py#L760">diffusers/src/diffusers/utils/import_utils.py</A>
										<DT><A HREF="https://github.com/huggingface/diffusers/blob/67bef2027cc461af5bbe73b3c0f35bb1350f5aa8/src/diffusers/pipelines/consistency_models/__init__.py">diffusers/src/diffusers/pipelines/consistency_models/__init__.py</A>
									</DL><p>
									<DT><A HREF="https://github.com/huggingface/diffusers/blob/fe5f035f797a5fa663a98030c9d0ec2f982cd09d/docs/source/en/using-diffusers/custom_pipeline_overview.md">diffusers/docs/source/en/using-diffusers/custom_pipeline_overview.md</A>
								</DL><p>
								<DT><H3 FOLDED>image-process</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/controlnet_aux">huggingface/controlnet_aux</A>
								</DL><p>
								<DT><H3 FOLDED>diffusion-generation-server</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/diffusers/tree/main/examples/server">diffusers/examples/server at main ¬∑ huggingface/diffusers</A>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=JgP2WgNIq_w">How to Deploy HuggingFace‚Äôs Stable Diffusion Pipeline with Triton Inference Server</A>
								<DT><A HREF="https://developer.nvidia.com/blog/nvidia-h200-tensor-core-gpus-and-nvidia-tensorrt-llm-set-mlperf-llm-inference-records/">NVIDIA H200 Tensor Core GPUs and NVIDIA TensorRT-LLM Set MLPerf LLM</A>
								<DT><A HREF="https://mlcommons.org/benchmarks/inference-datacenter/">Benchmark MLPerf Inference: Datacenter | MLCommons V3.1</A>
								<DT><A HREF="https://huggingface.co/ByteDance/SDXL-Lightning">ByteDance/SDXL-Lightning ¬∑ Hugging Face</A>
								<DT><A HREF="https://github.com/huggingface/diffusers/blob/fe5f035f797a5fa663a98030c9d0ec2f982cd09d/docs/source/en/using-diffusers/custom_pipeline_overview.md">diffusers/docs/source/en/using-diffusers/custom_pipeline_overview.md</A>
								<DT><A HREF="https://www.baseten.co/blog/40-faster-stable-diffusion-xl-inference-with-nvidia-tensorrt/">diffusion-benchmarking</A>
							</DL><p>
							<DT><H3 FOLDED>serving-cache</H3>
							<DL><p>
								<DT><A HREF="https://x.com/i/bookmarks?post_id=1819358570766643223">DeepSeek: context caching on disk</A>
								<DT><A HREF="https://www.eecs.harvard.edu/~michaelm/postscripts/esa2008full.pdf">More Robust Hashing: Cuckoo Hashing with a Stash‚àó</A>
								<DT><A HREF="https://www.youtube.com/watch?app=desktop&v=VTqVnhL1ClU&list=PL9eL-xg48OM3pnVqFSRyBFleHtBBw-nmZ&index=37&pp=iAQB">Episode 036: A Cache That Always Hits - YouTube</A>
								<DT><A HREF="https://github.com/HazyResearch/cartridges">HazyResearch/cartridges: Storing long contexts in tiny caches with self-study</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2211.05102">[2211.05102] Efficiently Scaling Transformer Inference</A>
							<DT><A HREF="https://fastagi.substack.com/p/25-must-know-projects-for-aillm-serving?utm_campaign=post&triedRedirect=true">25 Must-Know Projects for AI/LLM Serving</A>
							<DT><A HREF="https://www.usenix.org/conference/osdi22/presentation/yu">Orca: A Distributed Serving System for Transformer-Based Generative Models | USENIX</A>
							<DT><A HREF="https://arxiv.org/abs/2404.16283">Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services</A>
							<DT><A HREF="https://www.run.ai/">Run:ai - AI Optimization and Orchestration</A>
							<DT><A HREF="https://x.com/haoailab/status/1805307696297689119">(1) Hao AI Lab en X: "Multiple LLM serving has emerged as a crucial and costly demand. Want to co-serve multiple LLMs with better utilization? Introducing MuxServe - flexible spatial-temporal multiplexing - up to 1.8x higher throughput Blog: https://t.co/Pep94vUFTw Paper: https://t.co/X1Jhov3QOY https://t.co/mXrHMSLPS1" / X</A>
							<DT><A HREF="https://github.com/Lightning-AI/LitServe">Lightning-AI/LitServe: Deploy AI models at scale. High-throughput serving engine for AI/ML models that uses the latest state-of-the-art model deployment techniques.</A>
							<DT><A HREF="https://github.com/microsoft/ParrotServe">microsoft/ParrotServe: [OSDI'24] Serving LLM-based Applications Efficiently with Semantic Variable</A>
							<DT><A HREF="https://docs.databricks.com/en/machine-learning/model-serving/index.html">Model serving with Databricks | Databricks on AWS</A>
							<DT><A HREF="https://github.com/kvcache-ai/Mooncake">kvcache-ai/Mooncake: Mooncake is the serving platform for Kimi, a leading LLM service provided by Moonshot AI.</A>
							<DT><A HREF="https://github.com/replicate/cog">replicate/cog: Containers for machine learning</A>
							<DT><A HREF="https://github.com/AI-Hypercomputer/JetStream">AI-Hypercomputer/JetStream: JetStream is a throughput and memory optimized engine for LLM inference on XLA devices, starting with TPUs (and GPUs in future -- PRs welcome).</A>
							<DT><A HREF="https://github.com/xjdr-alt/entropix/tree/server">xjdr-alt/entropix at server</A>
							<DT><A HREF="https://www.run.ai/blog/serving-large-language-models">What it means to serve an LLM and which serving technology to choose from</A>
							<DT><A HREF="https://github.com/microsoft/sarathi-serve">microsoft/sarathi-serve: A low-latency &amp; high-throughput serving engine for LLMs</A>
							<DT><A HREF="https://x.com/elliotarledge/status/1970417395476111809">3 kinds of inference we will need to optimize for</A>
							<DT><A HREF="https://x.com/ZhihuFrontier/status/2012080310981374428">(2) Zhihu Frontier en X: "üöÄ2025 Year in Review: 4 Trends, 5 Breakthroughs in LLM Inference Systems From Huawei researcher &amp;amp; Zhihu contributor Â∑¶ÈπèÈ£û ‚Äî a deep dive into why 2025 became the "Year of Inference Explosion." Here is the part oneüëá If training was the arms race of the past, then 2025 is when https://t.co/yPlJTzjv4P" / X</A>
							<DT><A HREF="https://github.com/bytedance-iaas">bytedance-iaas</A>
							<DT><A HREF="https://arxiv.org/abs/2601.05047">[2601.05047] Challenges and Research Directions for Large Language Model Inference Hardware</A>
							<DT><A HREF="https://github.com/zartbot/blog/issues/6">Challenges and Research Directions for Large Language Model Inference Hardware ¬∑ Issue #6 ¬∑ zartbot/blog</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-quantization</H3>
						<DL><p>
							<DT><H3 FOLDED>mlsys-post-training-quantization</H3>
							<DL><p>
								<DT><H3 FOLDED>LLM.int8()</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/joaoalvarenga/bloom-8bit">bloom-8bit</A>
									<DT><A HREF="https://huggingface.co/blog/hf-bitsandbytes-integration">A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes</A>
									<DT><A HREF="https://colab.research.google.com/drive/1ft6wQU0BhqG5PRlwgaZJv2VukKKjU4Es">GPT-J 8-bit compression</A>
								</DL><p>
								<DT><H3 FOLDED>int4</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/NolanoOrg/status/1635409631530057728">LLaMa int4</A>
									<DT><A HREF="https://github.com/openai/triton/issues/675">int4 support ¬∑ Issue #675 ¬∑ openai/triton</A>
								</DL><p>
								<DT><A HREF="https://pytorch.org/docs/stable/quantization.html">Quantization ‚Äî PyTorch 2.0 documentation</A>
								<DT><A HREF="https://www.philschmid.de/static-quantization-optimum">Static Quantization with HF Optimum</A>
								<DT><A HREF="https://www.philschmid.de/bert-deepspeed-inference">Accelerate BERT inference with DeepSpeed-Inference on GPUs</A>
								<DT><A HREF="https://blog.speechmatics.com/gpu-quantisation">Fast and Accurate GPU Quantization for Transformers</A>
							</DL><p>
							<DT><H3 FOLDED>mlsys-te</H3>
							<DL><p>
								<DT><A HREF="https://github.com/cchan/nanoGPT-fp8">cchan/nanoGPT-fp8</A>
								<DT><A HREF="https://twitter.com/itsclivetime/status/1655515089506820097">(1) Clive Chan en Twitter: "WIP FP8 training on consumer graphics cards - üßµ/4 I hacked nanoGPT to use TransformerEngine on RTX 4090 and ran a few iterations of GPT-2 training: - nanoGPT Block (+flashattn) =&amp;gt; TE TransformerLayer (both BF16): 15% faster - BF16 =&amp;gt; FP8: additional +18% https://t.co/cJNWehoGeu" / Twitter</A>
								<DT><A HREF="https://blogs.bing.com/Engineering-Blog/october-2021/Bing-delivers-more-contextualized-search-using-quantized-transformer-inference-on-NVIDIA-GPUs-in-Azu">Microsoft's Bing example</A>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/transformer-engine/user-guide/index.html">Transformer Engine documentation ‚Äî Transformer Engine 0.7.0 documentation</A>
							</DL><p>
							<DT><H3 FOLDED>mlsys-activation-quantization</H3>
							<DL><p>
								<DT><A HREF="https://github.com/mit-han-lab/llm-awq">mit-han-lab/llm-awq: AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</A>
								<DT><A HREF="https://twitter.com/jilin_14/status/1683377972840124417">TinyChat (RTX4090)</A>
							</DL><p>
							<DT><H3 FOLDED>IST-DASLab-quant</H3>
							<DL><p>
								<DT><A HREF="https://github.com/IST-DASLab/gptq">IST-DASLab/gptq: Code for the ICLR 2023 paper "GPTQ: Accurate Post-training Quantization of Generative Pretrained Transformers".</A>
								<DT><A HREF="https://github.com/IST-DASLab/marlin">IST-DASLab/marlin: FP16xINT4 LLM inference kernel that can achieve near-ideal ~4x speedups up to medium batchsizes of 16-32 tokens.</A>
								<DT><A HREF="https://github.com/IST-DASLab/QUIK">IST-DASLab/QUIK: Repository for the QUIK project, enabling the use of 4bit kernels for generative inference</A>
							</DL><p>
							<DT><H3 FOLDED>smoothQuant</H3>
							<DL><p>
								<DT><A HREF="https://github.com/mit-han-lab/qserve">mit-han-lab/qserve: QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving</A>
								<DT><A HREF="https://github.com/mit-han-lab/smoothquant">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models</A>
							</DL><p>
							<DT><H3 FOLDED>protoquant</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookexperimental/protoquant">facebookexperimental/protoquant: Prototype routines for GPU quantization written using PyTorch.</A>
							</DL><p>
							<DT><H3 FOLDED>hf-quantization</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/docs/transformers/main_classes/quantization#fp4-quantization">Quantize ü§ó Transformers models</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/pdf/2004.09602.pdf">Integer Quantization For Deep Learing Inference: Principles and Evaluation</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-inference-sparsity</H3>
						<DL><p>
							<DT><H3 FOLDED>DeepSpeed-sparsity</H3>
							<DL><p>
								<DT><A HREF="https://www.deepspeed.ai/tutorials/sparse-attention/#how-to-config-sparsity-structures">DeepSpeed Sparse Attention</A>
							</DL><p>
							<DT><H3 FOLDED>IST-DASLab-sparsity</H3>
							<DL><p>
								<DT><A HREF="https://github.com/IST-DASLab/SparseFinetuning">IST-DASLab/SparseFinetuning: Repository for Sparse Finetuning of LLMs via modified version of the MosaicML llmfoundry</A>
							</DL><p>
							<DT><H3 FOLDED>torch-blocksparse</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ptillet/torch-blocksparse">ptillet/torch-blocksparse: Block-sparse primitives for PyTorch</A>
							</DL><p>
							<DT><A HREF="https://github.com/EleutherAI/gpt-neox/blob/main/configs/sparse.yml">gpt-neox/sparse.yml at main ¬∑ EleutherAI/gpt-neox ¬∑ GitHub</A>
							<DT><A HREF="https://docs.cerebras.net/en/latest/wsc/how_to_guides/sparsity.html#id1">Train a model with weight sparsity (Beta) ‚Äî Cerebras Developer Documentation</A>
							<DT><A HREF="https://www.youtube.com/watch?v=4gKYE9-YtP0">MICRO'23 TorchSparse++: Efficient Training and Inference Framework for Sparse Convolution on GPUs - YouTube</A>
							<DT><A HREF="https://github.com/AlibabaResearch/flash-llm">AlibabaResearch/flash-llm: Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-pruning</H3>
						<DL><p>
						</DL><p>
						<DT><H3 FOLDED>mlsys-architectural-optimization</H3>
						<DL><p>
							<DT><H3 FOLDED>Adaptive Computation</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2207.07061.pdf">Confident Adaptive Language Modeling (CALM)</A>
								<DT><A HREF="https://github.com/hao-ai-lab/LookaheadDecoding">hao-ai-lab/LookaheadDecoding</A>
								<DT><A HREF="https://arxiv.org/pdf/2305.10427.pdf">Accelerating Transformer Inference for Translation via Parallel Decoding</A>
							</DL><p>
							<DT><H3 FOLDED>FasterTransformer</H3>
							<DL><p>
								<DT><A HREF="https://fast-transformers.github.io/">Fast Transformers for PyTorch</A>
								<DT><A HREF="https://fast-transformers.github.io/#research">Fast Transformers for PyTorch</A>
								<DT><A HREF="https://github.com/NVIDIA/FasterTransformer">NVIDIA/FasterTransformer: Transformer related optimization, including BERT, GPT</A>
								<DT><A HREF="https://gist.github.com/moyix/7896575befbe1b99162ccfec8d135566">How to convert the SalesForce CodeGen models to GPT-J</A>
								<DT><A HREF="https://developer.nvidia.com/blog/increasing-inference-acceleration-of-kogpt-with-fastertransformer/">Increasing Inference Acceleration of KoGPT with NVIDIA FasterTransformer | NVIDIA Technical Blog</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-CWES52119/?ncid=em-even-124008-vt33">Connect with the Experts: GPU Performance Analysis and Optimization | NVIDIA On-Demand</A>
								<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtcspring23-S51196/?ncid=em-even-124008-vt33">FP8</A>
								<DT><A HREF="https://github.com/NVIDIA/FasterTransformer/tree/6ea1c77c7fabf1a046463eceddce1839efc63e60">NVIDIA/FasterTransformer at 6ea1c77c7fabf1a046463eceddce1839efc63e60</A>
								<DT><A HREF="https://github.com/NVIDIA/FasterTransformer/blob/6ea1c77c7fabf1a046463eceddce1839efc63e60/examples/pytorch/gpt/gpt_example.py#L237">FasterTransformer/examples/pytorch/gpt/gpt_example.py at 6ea1c77c7fabf1a046463eceddce1839efc63e60 ¬∑ NVIDIA/FasterTransformer</A>
							</DL><p>
							<DT><A HREF="https://github.com/google/automl/tree/master/lion#language-modeling">Google AutoML: Lion Optimizer over Adam</A>
							<DT><A HREF="https://github.com/triton-inference-server/model_analyzer">triton-inference-server/model_analyzer: Triton Model Analyzer is a CLI tool to help with better understanding of the compute and memory requirements of the Triton Inference Server models.</A>
							<DT><A HREF="https://developer.nvidia.com/blog/increasing-inference-acceleration-of-kogpt-with-fastertransformer/">General Optimizations List</A>
							<DT><A HREF="https://github.com/feifeibear/LLMSpeculativeSampling">Speculative Decoding</A>
							<DT><A HREF="https://github.com/tomaarsen/attention_sinks">tomaarsen/attention_sinks: Extend existing LLMs way beyond the original training length with constant memory usage, and without retraining</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-distillation</H3>
						<DL><p>
						</DL><p>
						<DT><H3 FOLDED>inference-profiling</H3>
						<DL><p>
							<DT><A HREF="https://github.com/DataCrunch-io/large_transformer_training_playbook/blob/main/transformers.ipynb">Transformers.ipynb: Megatron-LM &amp; DeepSpeed &amp; HF Transformers</A>
							<DT><A HREF="https://github.com/pythonprofilers/memory_profiler">pythonprofilers/memory_profiler: Monitor Memory usage of Python code</A>
							<DT><A HREF="https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras">TensorFlow Profiler: Profile model performance ¬†|¬† TensorBoard</A>
							<DT><A HREF="https://unix.stackexchange.com/questions/125429/tracking-down-where-disk-space-has-gone-on-linux">du</A>
							<DT><A HREF="https://docs.contrastsecurity.com/en/python-middleware.html">Configure middleware</A>
							<DT><A HREF="https://www.cyberciti.biz/open-source/install-ncdu-on-linux-unix-ncurses-disk-usage/">ncdu</A>
							<DT><A HREF="https://github.com/Syllo/nvtop">Syllo/nvtop: GPUs process monitoring for AMD, Intel and NVIDIA</A>
							<DT><A HREF="https://github.com/gperftools/gperftools">gperftools/gperftools: Main gperftools repository</A>
						</DL><p>
						<DT><H3 FOLDED>transformer-parallelism</H3>
						<DL><p>
							<DT><A HREF="https://github.com/stas00/tinypar">TP/PP/DP implementation of llama using apex blocks</A>
							<DT><A HREF="https://github.com/bytedance/flux">bytedance/flux: A fast communication-overlapping library for tensor parallelism on GPUs.</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-inference-notebooks</H3>
						<DL><p>
							<DT><A HREF="https://github.com/bigcode-project/Megatron-LM/blob/raymond-notebooks/notebooks/transformer_parameter_count.ipynb">Megatron-LM/transformer_parameter_count.ipynb</A>
							<DT><A HREF="https://www.philschmid.de/gptj-deepspeed-inference#3-optimize-gpt-j-for-gpu-using-deepspeeds-inferenceengine">Accelerate GPT-J inference with DeepSpeed-Inference on GPUs</A>
							<DT><A HREF="https://www.philschmid.de/static-quantization-optimum">Static Quantization with Hugging Face `optimum` for ~3x latency improvements</A>
							<DT><A HREF="https://www.philschmid.de/fine-tune-flan-t5-deepspeed">Fine-tune FLAN-T5 XL/XXL using DeepSpeed &amp; Hugging Face Transformers</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-inference-benchmark</H3>
						<DL><p>
							<DT><A HREF="https://github.com/huggingface/text-generation-inference">https://github.com/huggingface/text-generation-inference</A>
							<DT><A HREF="https://huggingface.co/docs/transformers/benchmarks">https://huggingface.co/docs/transformers/benchmarks</A>
							<DT><A HREF="https://github.com/huggingface/notebooks/blob/main/examples/benchmark.ipynb">notebooks/benchmark.ipynb at main ¬∑ huggingface/notebooks ¬∑ GitHub</A>
							<DT><A HREF="https://github.com/huggingface/transformers/blob/main/tests/benchmark/test_benchmark.py">transformers/test_benchmark.py at main ¬∑ huggingface/transformers ¬∑ GitHub</A>
							<DT><A HREF="https://github.com/huggingface/transformers/blob/c256bc6d104b1e85a138f3cf0e5f9f85d1197a25/src/transformers/benchmark/benchmark_utils.py#L633">transformers/benchmark_utils.py at c256bc6d104b1e85a138f3cf0e5f9f85d1197a25 ¬∑ huggingface/transformers</A>
							<DT><A HREF="https://colab.research.google.com/drive/17tla0i10y2fsQF0FNy_yuV6hxqPjqS6h#scrollTo=19ec9a99">transformers.ipynb - Colaboratory</A>
							<DT><A HREF="https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm.py">https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm.py</A>
							<DT><A HREF="https://pytorch.org/docs/stable/benchmark_utils.html">https://pytorch.org/docs/stable/benchmark_utils.html</A>
							<DT><A HREF="https://github.com/pytorch/pytorch/blob/master/torch/utils/benchmark/examples/compare.py">https://github.com/pytorch/pytorch/blob/master/torch/utils/benchmark/examples/compare.py</A>
							<DT><A HREF="https://github.com/mli/transformers-benchmarks">https://github.com/mli/transformers-benchmarks</A>
							<DT><A HREF="https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling">https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling</A>
							<DT><A HREF="https://github.com/huggingface/transformers-bloom-inference">transformers-bloom-inference</A>
							<DT><A HREF="https://github.com/bigcode-project/Megatron-LM/issues/20">Benchmarking Memory Consumption of Optimizers Adam v.s. Adan</A>
							<DT><A HREF="https://github.com/huggingface/blog/blob/main/bloom-inference-pytorch-scripts.md">Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate</A>
							<DT><A HREF="https://github.com/microsoft/DeepSpeed/tree/master/examples">DeepSpeed/examples</A>
							<DT><A HREF="https://github.com/microsoft/DeepSpeedExamples/blob/master/inference/huggingface/text-generation/inference-test.py">DeepSpeedExamples/inference-test.py</A>
							<DT><A HREF="https://huggingface.co/blog/bloom-inference-pytorch-scripts">Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate</A>
							<DT><A HREF="https://github.com/huggingface/transformers-bloom-inference/blob/main/bloom-inference-scripts/bloom-accelerate-inference.py#L46">transformers-bloom-inference/bloom-accelerate-inference.py</A>
							<DT><A HREF="https://github.com/huggingface/text-generation-inference">https://github.com/huggingface/text-generation-inference/tree/main/benchmark</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-inference-lectures</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=IGu7ivuy1Ag&t=590s">How a Transformer works at inference vs training time - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=7P6wllBoHwU">SparseGPT : Get Rid of 100 Billion Parameters - YouTube</A>
							<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f">LLM Inference Series: 5. Dissecting model performance</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-research-groups</H3>
						<DL><p>
							<DT><H3 FOLDED>MadSys Research Group</H3>
							<DL><p>
							</DL><p>
							<DT><A HREF="https://github.com/madsys-dev">MadSys Research Group</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-lectures</H3>
						<DL><p>
							<DT><H3 FOLDED>CS336-Language Modeling from Scratch</H3>
							<DL><p>
								<DT><A HREF="https://x.com/damekdavis/status/1952219480094118218">cs336-assignment2-systems</A>
							</DL><p>
							<DT><A HREF="https://tridao.me/cos597a/">Princeton COS 597A: Efficient Systems for Foundation Models (Fall 2025) | Tri Dao</A>
						</DL><p>
						<DT><H3 FOLDED>mlsys-people</H3>
						<DL><p>
							<DT><A HREF="https://github.com/Paran0idy">Paran0idy (Jiaxing Ding)</A>
						</DL><p>
						<DT><H3 FOLDED>Web</H3>
						<DL><p>
							<DT><H3 FOLDED>HTTP</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=FknTw9bJsXM">From TCP to HTTP | Full Course by ‚Ä™@ThePrimeagen‚Ä¨ - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>TCP</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=FknTw9bJsXM">From TCP to HTTP | Full Course by ‚Ä™@ThePrimeagen‚Ä¨ - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=bzja9fQWzdA&t=5617s">Implementing TCP in Rust (part 1) - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=e2G56bxcl4M">Implementing TCP in Rust part 1 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=OCpt1I0MWXE">Implementing TCP in Rust (part 2) - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>web scrapping</H3>
							<DL><p>
								<DT><A HREF="https://www.selenium.dev/documentation/webdriver/locating_elements/">Locating elements | Selenium</A>
								<DT><A HREF="https://stackoverflow.com/questions/61308799/unable-to-locate-elements-in-selenium-python">Unable to locate elements in Selenium (Python)</A>
								<DT><A HREF="https://www.guru99.com/accessing-forms-in-webdriver.html#2">Selenium Form WebElement: TextBox, Button, sendkeys(), click()</A>
								<DT><A HREF="https://www.selenium.dev/documentation/webdriver/keyboard/">Keyboard | Selenium</A>
								<DT><A HREF="https://www.w3.org/TR/webdriver/#keyboard-actions">WebDriver</A>
								<DT><A HREF="https://stackoverflow.com/questions/2632677/python-integer-incrementing-with">i++</A>
								<DT><A HREF="https://towardsdatascience.com/web-automation-nightmares-6-tricks-to-overcome-them-4241089953e3">Web Automation Nightmares: 6 Tricks to Overcome Them | by Aw Khai Sheng | Towards Data Science</A>
								<DT><A HREF="https://stackoverflow.com/questions/33225947/can-a-website-detect-when-you-are-using-selenium-with-chromedriver/33403473#33403473">selenium fingerprint</A>
								<DT><A HREF="https://www.youtube.com/watch?v=UZGYkH2vAS4">Interact with any website without a browser - Parse - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>architecture</H3>
							<DL><p>
								<DT><A HREF="https://orkhanscience.medium.com/software-architecture-patterns-5-mins-read-e9e3c8eb47d2">Software Architecture Patterns: 4 minute read</A>
								<DT><A HREF="https://www.infoq.com/">InfoQ: Software Development News, Trends &amp; Best Practices</A>
								<DT><A HREF="https://en.wikipedia.org/wiki/Pattern-Oriented_Software_Architecture">Pattern-Oriented Software Architecture - Wikipedia</A>
								<DT><A HREF="https://www.amazon.com/Pattern-Oriented-Software-Architecture-System-Patterns/dp/0471958697">Pattern-Oriented Software Architecture Volume 1: A System of Patterns: Buschmann, Frank, Meunier, Regine, Rohnert, Hans, Sommerlad, Peter, Stal, Michael, Michael Stal</A>
								<DT><A HREF="https://www.amazon.com/Principles-Computer-System-Design-Introduction/dp/0123749573">Principles of Computer System Design: An Introduction: Saltzer, Jerome, Kaashoek, M. Frans: 9780123749574: Amazon.com: Books</A>
								<DT><A HREF="https://medium.com/@olgamitroshyna/software-architecture-i-wish-i-had-known-about-this-earlier-4df43eae57db">Software Architecture: I wish I had known about this earlier...</A>
							</DL><p>
							<DT><H3 FOLDED>dynamic-web-page</H3>
							<DL><p>
								<DT><H3 FOLDED>JavaScript</H3>
								<DL><p>
									<DT><A HREF="https://www.awwwards.com/websites/">Website Design Inspiration</A>
									<DT><A HREF="https://github.com/nhn/tui.image-editor#powerful-filter-function">Full-featured photo image editor using canvas</A>
									<DT><A HREF="http://vanilla-js.com/">Vanilla JS</A>
									<DT><A HREF="https://create.editorx.com/html/editor/web/renderer/new?metaSiteId=0c39fce3-65b4-4514-a1f0-81618914e347&siteId=2dd00095-350d-41e3-8997-5af977b6a6b2">Editor X</A>
									<DT><A HREF="https://getbootstrap.com/">Bootstrap</A>
									<DT><A HREF="https://css-tricks.com/seamless-responsive-photo-grid/">https://css-tricks.com/seamless-responsive-photo-grid/</A>
									<DT><A HREF="https://codepen.io/ibrahima92/full/zYYqqbZ">Image gallery</A>
									<DT><A HREF="https://codepen.io/marcobiedermann/full/vYYyVzK">CSS Grid Gallery</A>
									<DT><A HREF="https://www.freecodecamp.org/news/how-to-deploy-a-static-website-for-free-in-only-3-minutes-with-google-drive/">How to deploy a static website</A>
									<DT><A HREF="https://codepen.io/topics/gsap">CodePen Topics</A>
								</DL><p>
								<DT><H3 FOLDED>Maven</H3>
								<DL><p>
									<DT><A HREF="https://maven.apache.org/run.html">Maven ‚Äì Running Apache Maven</A>
									<DT><A HREF="https://maven.apache.org/pom.html#Dependency_Management">POM Reference</A>
									<DT><A HREF="http://maven.apache.org/guides/mini/guide-3rd-party-jars-local.html">Guide to installing 3rd party JARs</A>
									<DT><A HREF="https://www.pegaxchange.com/2017/10/19/setup-maven-java-project-macos/">Setting up Maven on Mac OS and Creating Java Project</A>
								</DL><p>
								<DT><H3 FOLDED>Spring</H3>
								<DL><p>
									<DT><H3 FOLDED>jsp</H3>
									<DL><p>
										<DT><A HREF="https://stackoverflow.com/questions/2148658/iterate-over-elements-of-list-and-map-using-jstl-cforeach-tag">Iterate over elements of List and Map</A>
										<DT><A HREF="https://docs.oracle.com/cd/E17802_01/products/products/jsp/jstl/1.1/docs/tlddocs/index.html">All Tags / Functions</A>
										<DT><A HREF="http://www.w3big.com/jsp/jstl-core-foreach-tag.html">C: forEach</A>
									</DL><p>
									<DT><A HREF="https://start.spring.io/">Spring Initializr</A>
									<DT><A HREF="https://docs.spring.io/spring-boot/docs/current/maven-plugin/reference/html/#repackage">Spring Boot Maven Plugin Documentation</A>
									<DT><A HREF="https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#boot-features-spring-mvc-template-engines">Spring Boot Reference Documentation</A>
									<DT><A HREF="https://spring.io/guides/gs/spring-boot/">Building an Application with Spring Boot</A>
									<DT><A HREF="https://spring.io/guides/gs/serving-web-content/">Serving Web Content with Spring MVC</A>
									<DT><A HREF="https://stackoverflow.com/questions/36697663/circular-view-path-error-spring-boot/41918545">Circular View path error Spring boot</A>
									<DT><A HREF="https://spring.io/guides/tutorials/rest/">Building REST services with Spring</A>
									<DT><A HREF="https://docs.spring.io/spring-data/jpa/docs/current/reference/html/#repositories">Spring Data JPA - Reference Documentation</A>
									<DT><A HREF="https://spring.io/projects/spring-hateoas">Spring HATEOAS</A>
									<DT><A HREF="http://keenformatics.blogspot.com/2013/08/how-to-solve-json-infinite-recursion.html">How To Solve JSON infinite recursion Stackoverflow</A>
									<DT><A HREF="https://docs.spring.io/spring-boot/docs/2.1.5.RELEASE/reference/html/boot-features-testing.html">46.¬†Testing</A>
									<DT><A HREF="https://www.javadoc.io/doc/org.mockito/mockito-core/2.23.4/org/mockito/Mockito.html">Mockito (Mockito 2.23.4 API)</A>
									<DT><A HREF="https://www.callicoder.com/hibernate-spring-boot-jpa-one-to-many-mapping-example/">JPA / Hibernate One to Many Mapping Example</A>
									<DT><A HREF="https://openclassrooms.com/en/courses/5684146-create-web-applications-efficiently-with-the-spring-boot-mvc-framework/6157116-make-services-unit-testable-using-dependency-injection">services unit testable using dependency injection</A>
									<DT><A HREF="https://www.baeldung.com/get-user-in-spring-security">Retrieve User Information in Spring Security</A>
									<DT><A HREF="https://petstore.swagger.io/#/">Swagger UI</A>
									<DT><A HREF="https://octoperf.com/blog/2018/03/08/securing-rest-api-spring-security/#testing-the-application-1">Securing a Rest API with Spring Security</A>
									<DT><A HREF="https://docs.spring.io/spring-hateoas/docs/current/api/org/springframework/hateoas/EntityModel.html">EntityModel (Spring HATEOAS 1.3.0 API)</A>
								</DL><p>
								<DT><A HREF="https://tools.ietf.org/html/rfc8288#section-1">RFC 8288 - Web Linking</A>
								<DT><A HREF="https://tools.ietf.org/html/rfc3986">RFC 3986 - Uniform Resource Identifier (URI)</A>
								<DT><A HREF="https://tools.ietf.org/html/rfc7807">RFC 7807 - Problem Details for HTTP APIs</A>
								<DT><A HREF="http://stateless.co/hal_specification.html">The Hypertext Application Language</A>
								<DT><A HREF="https://fetch.spec.whatwg.org/#origin-header">Fetch Standard</A>
								<DT><A HREF="https://www.objectdb.com/java/jpa/query/jpql/expression">JPA Query Language (JPQL / Criteria) Expression Syntax</A>
								<DT><A HREF="https://stackoverflow.com/questions/6842289/jpa-multiple-select-query">JPA multiple select query</A>
								<DT><A HREF="https://en.wikibooks.org/wiki/Java_Persistence/Querying#Query_Results">Java Persistence/Querying</A>
							</DL><p>
							<DT><H3 FOLDED>static-web-page</H3>
							<DL><p>
								<DT><A HREF="https://pages.github.com/">GitHub Pages | Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.</A>
							</DL><p>
							<DT><A HREF="https://cloud.google.com/blog/products/application-development/rest-vs-rpc-what-problems-are-you-trying-to-solve-with-your-apis">REST vs. RPC: what problems are you trying to solve with your APIs? | Google Cloud Blog</A>
							<DT><A HREF="https://twitter.com/bibryam/status/1531316906581495811">2021 State of the API design - a visual report</A>
							<DT><A HREF="https://x.com/_chenglou/status/1986583136369844608">bun</A>
						</DL><p>
						<DT><A HREF="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/#distillation">Large Transformer Model Inference Optimization | Lil'Log</A>
						<DT><A HREF="https://www.zhihu.com/people/liang-de-peng">GiantPandaCV (chinese high-proffesional discussions)</A>
						<DT><A HREF="https://websites.umich.edu/~amberljc/file/LLM-Systems-Basics.pdf">LLM-Systems-Basics (Jiachen Liu)</A>
						<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f">LLM Inference Series: 5. Dissecting model performance</A>
						<DT><A HREF="https://github.com/antferdom/tuning_playbook/blob/main/language_models/Resources.md">tuning_playbook</A>
						<DT><A HREF="https://github.com/NVIDIA/DeepLearningExamples">NVIDIA/DeepLearningExamples</A>
						<DT><A HREF="https://arxiv.org/pdf/2302.14017.pdf">Full Stack Optimization of Transformer Inference: a Survey</A>
						<DT><A HREF="https://huggingface.co/docs/transformers/perf_infer_gpu_one">Efficient Inference on a Single GPU</A>
						<DT><A HREF="https://nat.dev/compare">OpenPlayground</A>
						<DT><A HREF="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/Dev_Guide.md">Transformer Model Optimization Tool Dev Guide</A>
						<DT><A HREF="https://excalidraw.com/">Excalidraw | Hand-drawn look &amp; feel ‚Ä¢ Collaborative ‚Ä¢ Secure</A>
						<DT><A HREF="https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices">LLM Inference Performance Engineering: Best Practices | Databricks Blog</A>
						<DT><A HREF="https://rahulschand.github.io/gpu_poor/">Tokens/s simulation</A>
						<DT><A HREF="https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f">LLM Inference Series: 5. Dissecting model performance (2024 main)</A>
						<DT><A HREF="https://developer.nvidia.com/blog/mastering-llm-techniques-inference-optimization/">Mastering LLM Techniques: Inference Optimization | NVIDIA Technical Blog</A>
						<DT><A HREF="https://www.modular.com/blog/how-to-be-confident-in-your-performance-benchmarking">Modular: How to Be Confident in Your Performance Benchmarking</A>
						<DT><A HREF="https://github.com/xjdr-alt/mla_blog_translation">DeepSeek-V2 High-performance Inference Optimization Notes: MLA Optimization</A>
						<DT><A HREF="https://github.com/DefTruth/Awesome-LLM-Inference">DefTruth/Awesome-LLM-Inference: üìñA curated list of Awesome LLM Inference Paper with codes, TensorRT-LLM, vLLM, streaming-llm, AWQ, SmoothQuant, WINT8/4, Continuous Batching, FlashAttention, PagedAttention etc.</A>
						<DT><A HREF="https://github.com/drisspg/transformer_nuggets">drisspg/transformer_nuggets: A place to store reusable transformer components of my own creation or found on the interwebs</A>
						<DT><A HREF="https://github.com/feifeibear/LLMRoofline">feifeibear/LLMRoofline: Compare different hardware platforms via the Roofline Model for LLM inference tasks.</A>
						<DT><A HREF="https://github.com/byungsoo-oh/ml-systems-papers">byungsoo-oh/ml-systems-papers: Curated collection of papers in machine learning systems</A>
						<DT><A HREF="https://tullo.ch/articles/pytorch-gpu-inference-performance/">Improving PyTorch inference performance on GPUs with a few simple tricks ‚ÄîAndrew Tulloch</A>
						<DT><A HREF="https://newsletter.semianalysis.com/p/inferencemax-open-source-inference">InferenceMAX‚Ñ¢: Open Source Inference Benchmarking</A>
						<DT><A HREF="https://abseil.io/fast/hints.html">abseil / Performance Hints</A>
						<DT><A HREF="https://j1129290218.substack.com/p/memory-is-the-new-bottleneck-why?utm_campaign=post&triedRedirect=true">Memory Is the New Bottleneck: Why Memory Hierarchy Optimization Will Be the Rarest Engineering Skill in the Next 3‚Äì5 Years</A>
						<DT><A HREF="https://www.youtube.com/watch?v=4_UdAR_5jqk">A Taxonomy of ML for Systems Problems - Martin Maas | Stanford MLSys #81 - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>Supercomputing</H3>
					<DL><p>
						<DT><H3 FOLDED>Operating Systems</H3>
						<DL><p>
							<DT><H3 FOLDED>os-configuration</H3>
							<DL><p>
								<DT><H3 FOLDED>bootstrap</H3>
								<DL><p>
									<DT><A HREF="https://www.ventoy.net/en/index.html">Ventoy</A>
								</DL><p>
								<DT><H3 FOLDED>.dotfiles</H3>
								<DL><p>
									<DT><H3 FOLDED>.dotfiles-docs</H3>
									<DL><p>
										<DT><A HREF="https://wiki.archlinux.org/title/Dotfiles">Dotfiles - ArchWiki</A>
										<DT><A HREF="https://dotfiles.github.io/">GitHub does dotfiles - dotfiles.github.io</A>
										<DT><A HREF="https://www.anishathalye.com/2014/08/03/managing-your-dotfiles/">Managing Your Dotfiles</A>
										<DT><A HREF="https://www.youtube.com/watch?v=r_MpUP6aKiQ&t=540s">~/.dotfiles in 100 Seconds</A>
									</DL><p>
									<DT><H3 FOLDED>.vim_runtime</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chengzeyi/.vim_runtime">chengzeyi/.vim_runtime: Yet a highly customized universal vim/neovim configuration.</A>
									</DL><p>
									<DT><A HREF="https://github.com/geohot/configuration">geohot/configuration: Like some files bro</A>
									<DT><A HREF="https://superuser.com/questions/886132/where-is-the-zshrc-file-on-mac">Where is the .zshrc file</A>
									<DT><A HREF="https://tldp.org/LDP/abs/html/sample-bashrc.html">Sample .bashrc and .bash_profile Files</A>
									<DT><A HREF="https://www.atlassian.com/git/tutorials/dotfiles">How to store dotfiles</A>
									<DT><A HREF="https://news.ycombinator.com/item?id=11070797">Ask HN: What do you use to manage dotfiles?</A>
									<DT><A HREF="https://superuser.com/questions/39751/add-directory-to-path-if-its-not-already-there/753948#753948">bash - Add directory to $PATH if it's not already there</A>
									<DT><A HREF="https://github.com/eieioxyz/Beyond-Dotfiles-in-100-Seconds">eieioxyz/Beyond-Dotfiles-in-100-Seconds</A>
								</DL><p>
								<DT><A HREF="https://github.com/fastai/fastsetup">fastai/fastsetup: Setup all the things</A>
								<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/5d8ca2faf74c494f220c8f71130340b513eea9a9/docker/common/install_pytorch.sh">TensorRT-LLM/docker/common/install_pytorch.sh</A>
								<DT><H3 FOLDED>os-setup</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tinygrad/tinyos">tinygrad/tinyos</A>
								</DL><p>
								<DT><A HREF="https://github.com/tinygrad/tinyos">tinygrad/tinyos</A>
							</DL><p>
							<DT><H3 FOLDED>version control</H3>
							<DL><p>
								<DT><H3 FOLDED>git</H3>
								<DL><p>
									<DT><H3 FOLDED>pre-commit</H3>
									<DL><p>
										<DT><A HREF="https://pre-commit.ci/">pre-commit.ci</A>
										<DT><A HREF="https://pre-commit.com/">pre-commit</A>
										<DT><A HREF="https://github.com/pre-commit/pre-commit">pre-commit/pre-commit: A framework for managing and maintaining multi-language pre-commit hooks.</A>
										<DT><A HREF="https://github.com/flashinfer-ai/flashinfer/pull/1160">feat: nvshmem python bindings by yzh119 ¬∑ Pull Request #1160 ¬∑ flashinfer-ai/flashinfer</A>
									</DL><p>
									<DT><H3 FOLDED>monorepo</H3>
									<DL><p>
										<DT><H3 FOLDED>git-subtrees</H3>
										<DL><p>
											<DT><A HREF="https://claude.ai/chat/ccf1d431-fadc-4eae-b3e1-7689cf13dbcc">monorepo modifications methodology</A>
											<DT><A HREF="https://gist.github.com/SKempin/b7857a6ff6bddb05717cc17a44091202">Git Subtree basics</A>
										</DL><p>
										<DT><A HREF="https://github.com/web3infra-foundation/mega?tab=readme-ov-file">mega: unofficial open source implementation of Google Piper</A>
										<DT><A HREF="https://cacm.acm.org/research/why-google-stores-billions-of-lines-of-code-in-a-single-repository/">Why Google Stores Billions of Lines of Code in a Single Repository</A>
									</DL><p>
									<DT><H3 FOLDED>gitignore</H3>
									<DL><p>
										<DT><A HREF="https://stackoverflow.com/questions/2545602/how-can-i-git-ignore-subfolders-subdirectories#:~:text=*%2F*%20ignores%20all%20subdirectories%20but,%2F*%20all%20work%20for%20me.">git rm -r --cached .</A>
									</DL><p>
									<DT><H3 FOLDED>git-submodules</H3>
									<DL><p>
										<DT><A HREF="https://git-scm.com/book/en/v2/Git-Tools-Submodules">Git - Submodules</A>
										<DT><A HREF="https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes">Git - Working with Remotes</A>
										<DT><A HREF="https://github.blog/2016-02-01-working-with-submodules/">Working with submodules - The GitHub Blog</A>
										<DT><A HREF="https://claude.ai/chat/d2720f8d-0434-4654-80be-fdbd77a7ff7f">Troubleshooting Git Submodule Setup - Claude</A>
									</DL><p>
									<DT><H3 FOLDED>git-remote</H3>
									<DL><p>
										<DT><A HREF="https://twitter.com/JI/status/1546948817462800384">No more "--set-upstream origin"</A>
										<DT><A HREF="https://claude.ai/chat/538dd4e6-f241-47ce-93f4-7bcbd2095129">Updating Git Remote to Push Local Changes to Fork - Claude</A>
									</DL><p>
									<DT><H3 FOLDED>git-patches</H3>
									<DL><p>
										<DT><A HREF="https://www.specbee.com/blogs/how-create-and-apply-patch-git-diff-and-git-apply-commands-your-drupal-website">git patches</A>
									</DL><p>
									<DT><H3 FOLDED>py-git-install</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/issues/4310">install Python module via git commit: example -&gt; pytorch-triton                     3.0.0+a9bc1a3647</A>
									</DL><p>
									<DT><H3 FOLDED>git-lfs</H3>
									<DL><p>
										<DT><A HREF="https://gemini.google.com/u/3/app/c34d79b9de25ed00">Configure Git LFS to track wheel files</A>
										<DT><A HREF="https://git-lfs.com/">Git Large File Storage | Git Large File Storage (LFS) replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git, while storing the file contents on a remote server like GitHub.com or GitHub Enterprise.</A>
									</DL><p>
									<DT><H3 FOLDED>git-diff</H3>
									<DL><p>
										<DT><A HREF="https://github.com/dandavison/delta">dandavison/delta: A syntax-highlighting pager for git, diff, grep, and blame output</A>
									</DL><p>
									<DT><H3 FOLDED>git-clone</H3>
									<DL><p>
										<DT><A HREF="https://git-scm.com/docs/git-clone">git clone --branch &lt;branch-name&gt; --single-branch &lt;repo-url&gt;</A>
									</DL><p>
									<DT><H3 FOLDED>pip-git-install</H3>
									<DL><p>
										<DT><A HREF="https://github.com/triton-lang/triton/issues/4310">install Python module via git commit: example -&gt; pytorch-triton                     3.0.0+a9bc1a3647</A>
									</DL><p>
									<DT><H3 FOLDED>git-log</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/c/28806e4a-6093-44c2-8b46-7a80ceb55de2">Git Log Grep Search Techniques - Grok</A>
									</DL><p>
									<DT><A HREF="https://github.com/web3infra-foundation/mega">web3infra-foundation/mega: Mega is an unofficial open source implementation of Google Piper.</A>
									<DT><A HREF="https://git-scm.com/docs/git-diff">git-diff</A>
									<DT><A HREF="https://git-scm.com/docs/git-commit">commit</A>
									<DT><A HREF="https://chris.beams.io/posts/git-commit/">How to Write a Git Commit Message</A>
									<DT><A HREF="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh">Connecting to GitHub with SSH - GitHub Docs</A>
									<DT><A HREF="https://git-scm.com/book/en/v2/Git-Basics-Viewing-the-Commit-History">Viewing the Commit History</A>
									<DT><A HREF="https://git-scm.com/book/en/v2/Git-Branching-Rebasing">Rebasing</A>
									<DT><A HREF="https://git-scm.com/book/en/v2/Git-Tools-Reset-Demystified">Reset Demystified</A>
									<DT><A HREF="https://stackoverflow.com/questions/448919/how-can-i-remove-a-commit-on-github">How can I remove a commit on GitHub?</A>
									<DT><A HREF="https://stackoverflow.com/questions/3701404/how-can-i-list-all-commits-that-changed-a-specific-file">follow file</A>
									<DT><A HREF="https://stackoverflow.com/questions/2505096/cloning-a-private-github-repo">Cloning a private Github repo</A>
									<DT><A HREF="https://stackoverflow.com/questions/68775869/support-for-password-authentication-was-removed-please-use-a-personal-access-to">Support for password authentication was removed</A>
									<DT><A HREF="https://stackoverflow.com/questions/11188801/connect-local-repo-with-remote-repo">connect local repo with remote repo</A>
									<DT><A HREF="https://docs.github.com/en/account-and-profile/setting-up-and-managing-your-github-user-account/managing-email-preferences/setting-your-commit-email-address">Setting your commit email address</A>
									<DT><A HREF="https://git-scm.com/book/en/v2/Git-Tools-Submodules">Git - Submodules</A>
									<DT><A HREF="https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes">Git - Working with Remotes</A>
									<DT><A HREF="https://github.blog/2016-02-01-working-with-submodules/">Working with submodules - The GitHub Blog</A>
									<DT><A HREF="https://gist.github.com/myusuf3/7f645819ded92bda6677">How effectively delete a git submodule.</A>
									<DT><A HREF="https://www.leshenko.net/p/ugit/#read-tree-to-index">Git Internals - Learn by Building Your Own Git</A>
									<DT><A HREF="https://www.conventionalcommits.org/en/v1.0.0/">Conventional Commits</A>
									<DT><A HREF="https://www.youtube.com/watch?v=iuIdBfjL62s">bare repo local ssh</A>
								</DL><p>
								<DT><H3 FOLDED>Github</H3>
								<DL><p>
									<DT><A HREF="https://docs.github.com/en/rest/reference/users#get-a-user">Users - GitHub Docs</A>
									<DT><A HREF="https://cli.github.com/">GitHub CLI | Take GitHub to the command line</A>
									<DT><A HREF="https://education.github.com/discount_requests/teacher_application">Request a discount - GitHub Education</A>
								</DL><p>
								<DT><H3 FOLDED>Trunk-based development</H3>
								<DL><p>
									<DT><A HREF="https://www.atlassian.com/continuous-delivery/continuous-integration/trunk-based-development">Trunk-based Development | Atlassian</A>
									<DT><A HREF="https://trunkbaseddevelopment.com/">Introduction</A>
									<DT><A HREF="https://github.com/ezyang/ghstack">ezyang/ghstack: Submit stacked diffs to GitHub on the command line</A>
								</DL><p>
								<DT><H3 FOLDED>Stacking change</H3>
								<DL><p>
									<DT><A HREF="https://graphite.dev/blog/post/DThX8ffP1gmxWJChEv0y">Graphite - Stacking changes</A>
									<DT><A HREF="https://jg.gg/2018/09/29/stacked-diffs-versus-pull-requests/">Stacked Diffs Versus Pull Requests | Jackson Gabbard's Blog</A>
									<DT><A HREF="https://kurtisnusbaum.medium.com/stacked-diffs-keeping-phabricator-diffs-small-d9964f4dcfa6">Stacked Diffs: Keeping Phabricator Diffs Small | by Kurtis Nusbaum | Medium</A>
									<DT><A HREF="https://news.ycombinator.com/item?id=26922633">Stacked Diffs versus Pull Requests (2018) | Hacker News</A>
									<DT><A HREF="https://newsletter.pragmaticengineer.com/p/stacked-diffs">Stacked Diffs (and why you should know about them)</A>
									<DT><A HREF="https://github.com/ezyang/ghstack">ezyang/ghstack: Submit stacked diffs to GitHub on the command line</A>
									<DT><A HREF="https://github.com/modular/stack-pr">modular/stack-pr: A tool for working with stacked PRs on github.</A>
								</DL><p>
								<DT><A HREF="https://pre-commit.ci/">pre-commit.ci</A>
							</DL><p>
							<DT><H3 FOLDED>package manager</H3>
							<DL><p>
								<DT><H3 FOLDED>Brew</H3>
								<DL><p>
									<DT><H3 FOLDED>tap</H3>
									<DL><p>
										<DT><A HREF="https://docs.brew.sh/Taps">Taps (Third-Party Repositories)</A>
									</DL><p>
									<DT><H3 FOLDED>leaves</H3>
									<DL><p>
										<DT><A HREF="https://thoughtbot.com/blog/brew-leaves">brew leaves</A>
									</DL><p>
									<DT><H3 FOLDED>casks</H3>
									<DL><p>
										<DT><A HREF="https://formulae.brew.sh/cask/">homebrew-cask</A>
										<DT><A HREF="https://github.com/Homebrew/homebrew-cask">CLI workflow for the administration of applications as bin</A>
									</DL><p>
									<DT><A HREF="https://brew.sh/">The Missing Package Manager for macOS (or Linux)</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Symbolic_link">Symbolic link</A>
									<DT><A HREF="https://clubmate.fi/make-a-symlink-in-linux-or-mac-os-x/">Make a symlink</A>
									<DT><A HREF="https://formulae.brew.sh/">Formulae</A>
									<DT><A HREF="https://zanshin.net/2014/02/03/how-to-list-brew-dependencies/">List Brew Dependencies</A>
									<DT><A HREF="https://rick.cogley.info/post/use-homebrew-zsh-instead-of-the-osx-default/">Use Homebrew zsh Instead of the OS X Default</A>
									<DT><A HREF="https://stackoverflow.com/questions/55732972/curl-56-libressl-ssl-read-ssl-error-syscall-errno-54/55735219">curl: (56) LibreSSL SSL_read: SSL_ERROR_SYSCALL, errno 54</A>
									<DT><A HREF="https://www.unix.com/os-x-apple-/161123-what-directory-brew-prefix-homebrew.html">directory "$(brew --prefix)"?</A>
									<DT><A HREF="https://docs.brew.sh/Formula-Cookbook">Formula Cookbook ‚Äî Homebrew Documentation</A>
									<DT><A HREF="https://docs.brew.sh/FAQ">FAQ ‚Äî Homebrew Documentation</A>
									<DT><A HREF="https://apple.stackexchange.com/questions/373411/how-to-install-a-specific-version-of-ocaml-on-macos">install a specific version</A>
									<DT><A HREF="https://stackoverflow.com/questions/13477363/how-can-i-brew-link-a-specific-version">How can I brew link a specific version?</A>
									<DT><A HREF="https://docs.brew.sh/Tips-N%27-Tricks">Tips and Tricks ‚Äî Homebrew Documentation</A>
									<DT><A HREF="https://remarkablemark.org/blog/2017/02/03/install-brew-package-version/">How to install an older homebrew package</A>
									<DT><A HREF="https://devhints.io/homebrew">Homebrew cheatsheet</A>
									<DT><A HREF="https://docs.w3cub.com/homebrew/manpage">Brew - Homebrew - W3cubDocs</A>
									<DT><A HREF="https://stackoverflow.com/questions/16246352/how-do-i-specify-ldflags-and-cppflags-for-configure">LDFLAGS and CPPFLAGS</A>
									<DT><A HREF="https://stackoverflow.com/questions/65502748/why-does-brew-cleanup-or-brew-cleanup-n-dont-show-any-output">cleanup</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>windows manager</H3>
							<DL><p>
								<DT><A HREF="https://en.wikipedia.org/wiki/X_Window_System">X Window System</A>
								<DT><A HREF="https://wiki.haskell.org/Xmonad/General_xmonad.hs_config_tips">Xmonad/General xmonad.hs config tips</A>
							</DL><p>
							<DT><H3 FOLDED>Docker</H3>
							<DL><p>
								<DT><H3 FOLDED>docker-installation</H3>
								<DL><p>
									<DT><H3 FOLDED>docker-post-installation</H3>
									<DL><p>
										<DT><A HREF="https://docs.docker.com/engine/install/linux-postinstall/">Post-installation steps | Docker Docs</A>
									</DL><p>
									<DT><A HREF="https://docs.docker.com/engine/install/ubuntu/">Ubuntu | Docker Docs</A>
									<DT><A HREF="https://github.com/docker/docker-install">docker/docker-install: Docker installation script</A>
								</DL><p>
								<DT><H3 FOLDED>docker-run</H3>
								<DL><p>
									<DT><A HREF="https://chatgpt.com/c/681b2a35-f05c-800c-987b-a78521972e23">Get docker run command</A>
								</DL><p>
								<DT><H3 FOLDED>docker-inspect</H3>
								<DL><p>
									<DT><H3 FOLDED>runlike</H3>
									<DL><p>
										<DT><A HREF="https://stackoverflow.com/questions/32758793/how-to-show-the-run-command-of-a-docker-container">How to show the run command of a docker container - Stack Overflow runlike</A>
										<DT><A HREF="https://chatgpt.com/c/681b2a35-f05c-800c-987b-a78521972e23">Get docker run command (runlike)</A>
										<DT><A HREF="https://pypi.org/project/runlike/">runlike ¬∑ PyPI</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>docker-examples</H3>
								<DL><p>
									<DT><A HREF="https://github.com/docker/docker-rust-hello">docker/docker-rust-hello: A simple Rust application</A>
									<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">neuralmagic/tensorrt-demo</A>
									<DT><A HREF="https://github.com/alihassanijr/PyTorch-CUDA12">alihassanijr/PyTorch-CUDA12: Nightly PyTorch + CUDA 12 Dockerfile</A>
									<DT><A HREF="https://hub.docker.com/r/xzhao9/gcp-a100-runner-dind">xzhao9/gcp-a100-runner-dind: Tritonbench base enviroment</A>
									<DT><A HREF="https://github.com/xdit-project/HunyuanVideo/blob/main/docker/Dockerfile_xDiT">HunyuanVideo/docker/Dockerfile_xDiT at main: Install Miniconda</A>
									<DT><A HREF="https://github.com/lcy-seso/DevDockerFiles/tree/master/dev_env">DevDockerFiles/dev_env at master ¬∑ lcy-seso/DevDockerFiles</A>
								</DL><p>
								<DT><H3 FOLDED>docker-image</H3>
								<DL><p>
									<DT><H3 FOLDED>Dockerfile</H3>
									<DL><p>
										<DT><H3 FOLDED>dockerfile-python</H3>
										<DL><p>
											<DT><A HREF="https://github.com/docker-library/python/blob/bf5951cfa2b2f6c3dabf428549c9dca658ecee81/3.12/bullseye/Dockerfile">python/3.12/bullseye/Dockerfile</A>
											<DT><A HREF="http://dockerfile.github.io/#/python">Python Dockerfile</A>
										</DL><p>
										<DT><H3 FOLDED>dockerfile-ENV</H3>
										<DL><p>
											<DT><A HREF="https://grok.com/chat/e6d885da-d411-4cc2-8911-bc09c38eb46d">Dockerfile Environment Persistence - Grok</A>
										</DL><p>
										<DT><H3 FOLDED>dockerfile-suffix</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sgl-project/sglang/blob/main/docker/Dockerfile.sagemaker">sglang/docker/Dockerfile.sagemaker at main ¬∑ sgl-project/sglang</A>
											<DT><A HREF="https://github.com/DataCrunch-io/xelerate-inferno/blob/main/docker/xelerate-inferno-dev.dockerfile">xelerate-inferno/docker/xelerate-inferno-dev.dockerfile at main ¬∑ DataCrunch-io/xelerate-inferno</A>
											<DT><A HREF="https://github.com/chengzeyi/model-deploy/blob/c30e1c444a512a30fac682f4eec55b6ab0dac457/runpod/mystic_upscaler/Dockerfile.cu128">model-deploy/runpod/mystic_upscaler/Dockerfile.cu128</A>
										</DL><p>
										<DT><H3 FOLDED>dockerfile-secrets</H3>
										<DL><p>
											<DT><A HREF="https://docs.docker.com/build/building/secrets/">Secrets | Docker Docs</A>
										</DL><p>
										<DT><A HREF="http://dockerfile.github.io/">Dockerfile Project - Trusted Automated Docker Builds</A>
										<DT><A HREF="https://docs.docker.com/build/dockerfile/frontend/#stable-channel">Custom Dockerfile syntax | Docker Docs</A>
										<DT><A HREF="https://docs.docker.com/reference/dockerfile/">Dockerfile reference | Docker Docs</A>
										<DT><A HREF="https://github.com/tinygrad/tinygrad/blob/d49d4324a3340609126e64b10f979507636fe5ed/test/Dockerfile#L2">tinygrad/test/Dockerfile (minimal python example)</A>
										<DT><A HREF="https://github.com/docker-library/python/blob/875ce40a1ae98c7c37b1652e65f76376ac93a911/apply-templates.sh#L22">python/apply-templates.sh</A>
									</DL><p>
									<DT><H3 FOLDED>docker-image-optimization</H3>
									<DL><p>
										<DT><A HREF="https://rodneyosodo.medium.com/minimizing-python-docker-images-cf99f4468d39">Minimizing python docker images. During the transition to a micro</A>
									</DL><p>
									<DT><H3 FOLDED>docker-devel</H3>
									<DL><p>
										<DT><A HREF="https://hub.docker.com/r/chengzeyi/ubuntu-desktop">chengzeyi/ubuntu-desktop - Docker Image | Docker Hub</A>
										<DT><A HREF="https://hub.docker.com/layers/nvidia/cuda/12.9.1-cudnn-devel-ubuntu22.04/images/sha256-426d35b8a3e4d806ead3878407dbbc2927a26b797c878e8e439525f635cfda5c">Image Layer Details - nvidia/cuda:12.9.1-cudnn-devel-ubuntu22.04 | Docker Hub</A>
									</DL><p>
									<DT><A HREF="https://github.com/docker-library">Docker Official Images</A>
									<DT><A HREF="https://registry.hub.docker.com/">Docker Hub Container Image Library | App Containerization</A>
									<DT><A HREF="https://hub.docker.com/r/wavespeed/pytorch-cuda">wavespeed/pytorch-cuda - Docker Image | Docker Hub</A>
								</DL><p>
								<DT><H3 FOLDED>docker-container</H3>
								<DL><p>
									<DT><H3 FOLDED>NGC</H3>
									<DL><p>
										<DT><A HREF="https://www.nvidia.com/pt-br/gpu-cloud1/containers/">NGC Containers | NVIDIA</A>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/Dockerfile">pytorch/Dockerfile</A>
										<DT><A HREF="https://catalog.ngc.nvidia.com/containers?filters=platform%7CPyTorch%7Cpltfm_pytorch&orderBy=weightPopularDESC&query=&page=&pageSize=">Pytorch container</A>
										<DT><A HREF="https://github.com/psaboia/devcontainer-nvidia-base">psaboia/devcontainer-nvidia-base: Example of how to setup a NVIDIA DevContainer with GPU Support for Tensorflow/Keras, that follows the page https://alankrantas.medium.com/setup-a-nvidia-devcontainer-with-gpu-support-for-tensorflow-keras-on-windows-d00e6e204630</A>
										<DT><A HREF="https://hub.docker.com/layers/nvidia/cuda/11.8.0-devel-ubuntu22.04/images/sha256-60eda04ab6790aa76d73bf0df245b361eabc6d8f7b6f6cf9846c70f399b9a1eb">Image Layer Details - nvidia/cuda:11.8.0-devel-ubuntu22.04 | Docker Hub</A>
										<DT><A HREF="https://hub.docker.com/r/nvidia/cuda/tags">nvidia/cuda Tags | Docker Hub</A>
										<DT><A HREF="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver">Triton Inference Server | NVIDIA NGC</A>
										<DT><A HREF="https://github.com/sgl-project/tensorrt-demo">sgl-project/tensorrt-demo: prerequisite -&gt; nvidia-container-toolkit</A>
									</DL><p>
									<DT><H3 FOLDED>docker-container-checkpointing</H3>
									<DL><p>
										<DT><A HREF="https://github.com/checkpoint-restore/checkpointctl">checkpoint-restore/checkpointctl: A tool for in-depth analysis of container checkpoints</A>
									</DL><p>
									<DT><H3 FOLDED>container-performance</H3>
									<DL><p>
										<DT><H3 FOLDED>cpuset-cpus</H3>
										<DL><p>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://docs.docker.com/reference/cli/docker/container/rm/">docker container rm | Docker Docs</A>
								</DL><p>
								<DT><H3 FOLDED>docker-debug</H3>
								<DL><p>
									<DT><H3 FOLDED>docker-run</H3>
									<DL><p>
										<DT><H3 FOLDED>docker-exec</H3>
										<DL><p>
											<DT><A HREF="https://grok.com/c/7a00486c-da69-4f12-9bb3-d391b09c214a">Docker Exec Command Quoting Issue - Grok</A>
										</DL><p>
										<DT><A HREF="https://docs.docker.com/reference/cli/docker/container/run/">docker run | Docker Docs</A>
										<DT><A HREF="https://stackoverflow.com/questions/47831774/docker-run-with-volume">docker run with --volume</A>
										<DT><A HREF="https://chat.openai.com/c/05357f44-c5ed-4a6d-bce7-5545860507cd">docker run -ti -p 3000:3000 -v $inferno_dir:/source/inferno &lt;image&gt;</A>
									</DL><p>
									<DT><H3 FOLDED>docker-interactive</H3>
									<DL><p>
										<DT><A HREF="https://claude.ai/chat/cbc3a3dc-bdfa-40ff-aeac-ba722f2b3652">docker run interactive session: decompose full command</A>
										<DT><A HREF="https://github.com/neuralmagic/tensorrt-demo/tree/main">docker run -it -d --net host --shm-size=2g --ulimit memlock=-1 --ulimit stack=67108864 --runtime=nvidia --gpus all -v ${tensorrtllm_backend_dir}:/tensorrtllm_backend  -v $HOME/models:/models -v ${tensorrt_demo_dir}:/root/tensorrt-demo --name triton_server nvcr.io/nvidia/tritonserver:24.04-trtllm-python-py3 bash</A>
										<DT><A HREF="https://datacrunch.io/blog/deepseek-v3-llm-nvidia-h200-gpu-inference-benchmarking">docker run -v &lt;models_dir&gt;:/root/.cache/huggingface \</A>
										<DT><A HREF="https://github.com/datacrunch-research/tensorrt-demo">docker exec -it triton_server /bin/bash</A>
										<DT><A HREF="https://claude.ai/chat/4d385901-e1fb-45c8-9c7b-d7be6a5cc32c">Executing Commands in a Running Docker Container - Claude</A>
										<DT><A HREF="https://docs.docker.com/storage/volumes/">Volumes | Docker Docs</A>
										<DT><A HREF="https://github.com/mlcommons/inference/blob/master/language/deepseek-r1/docker/launch_scripts/launch_sglang.sh">inference/language/deepseek-r1/docker/launch_scripts/launch_sglang.sh</A>
									</DL><p>
									<DT><H3 FOLDED>dev-container</H3>
									<DL><p>
										<DT><H3 FOLDED>dev-container-examples</H3>
										<DL><p>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/acc466751b2723eb913fd3148b4f054189bbf1ab/.devcontainer/README.md">pytorch/.devcontainer/README.md</A>
											<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/.devcontainer/Dockerfile">pytorch/.devcontainer/Dockerfile</A>
											<DT><A HREF="https://github.com/psaboia/devcontainer-nvidia-base">psaboia/devcontainer-nvidia-base</A>
											<DT><A HREF="https://github.com/devcontainers/images/tree/main/src/base-ubuntu">images/src/base-ubuntu at main ¬∑ devcontainers/images</A>
										</DL><p>
										<DT><H3 FOLDED>dev-container-template</H3>
										<DL><p>
											<DT><A HREF="https://github.com/devcontainers/template-starter">devcontainers/template-starter: A template explaining how to author custom dev container Templates</A>
											<DT><A HREF="https://containers.dev/templates">Available Dev Container Templates</A>
										</DL><p>
										<DT><H3 FOLDED>dev-container-devcontainer.json</H3>
										<DL><p>
											<DT><A HREF="https://github.com/devcontainers/images">devcontainers/images: Repository for pre-built dev container images published under mcr.microsoft.com/devcontainers</A>
											<DT><A HREF="https://containers.dev/implementors/json_reference/#image-specific">Dev Container metadata reference</A>
										</DL><p>
										<DT><H3 FOLDED>dev-container-nvidia</H3>
										<DL><p>
											<DT><A HREF="https://github.com/psaboia/devcontainer-nvidia-base">psaboia/devcontainer-nvidia-base: Example of how to setup a NVIDIA DevContainer with GPU Support for Tensorflow/Keras, that follows the page https://alankrantas.medium.com/setup-a-nvidia-devcontainer-with-gpu-support-for-tensorflow-keras-on-windows-d00e6e204630</A>
										</DL><p>
										<DT><A HREF="https://containers.dev/implementors/json_reference/">Dev Container metadata reference</A>
										<DT><A HREF="https://github.com/devcontainers">devcontainers</A>
										<DT><A HREF="https://code.visualstudio.com/docs/devcontainers/containers#_create-a-devcontainerjson-file">dev containers &amp; VS code</A>
										<DT><A HREF="https://code.visualstudio.com/docs/devcontainers/containers">Developing inside a Container using Visual Studio Code Remote Development</A>
										<DT><A HREF="https://code.visualstudio.com/docs/devcontainers/create-dev-container">Rebuild: postCreateCommand</A>
										<DT><A HREF="https://code.visualstudio.com/docs/devcontainers/containers#_getting-started">Developing inside a Container using Visual Studio Code Remote Development</A>
										<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#docker">Installing the NVIDIA Container Toolkit</A>
										<DT><A HREF="https://www.youtube.com/watch?v=p9L7YFqHGk4">Customize Dev Containers in VS Code with Dockerfiles and Docker Compose</A>
										<DT><A HREF="https://www.youtube.com/watch?v=BhtxEDwgylU">Use AppMap with VS Code Dev Containers - YouTube</A>
										<DT><A HREF="https://github.com/devcontainers/images/tree/main/src/base-ubuntu">images/src/base-ubuntu at main ¬∑ devcontainers/images</A>
										<DT><A HREF="https://docs.github.com/en/codespaces/setting-up-your-project-for-codespaces/adding-a-dev-container-configuration/introduction-to-dev-containers">Introduction to dev containers - GitHub Docs</A>
										<DT><A HREF="https://containers.dev/guide/dockerfile">Using Images, Dockerfiles, and Docker Compose</A>
										<DT><A HREF="https://containers.dev/">Development containers</A>
									</DL><p>
									<DT><H3 FOLDED>docker-logs</H3>
									<DL><p>
										<DT><A HREF="https://forums.docker.com/t/capture-ouput-of-docker-build-into-a-log-file/123178">Capture ouput of docker build into a log file?</A>
									</DL><p>
									<DT><A HREF="https://github.com/wagoodman/dive">wagoodman/dive: A tool for exploring each layer in a docker image</A>
								</DL><p>
								<DT><H3 FOLDED>docker-nvidia</H3>
								<DL><p>
									<DT><H3 FOLDED>docker-nvidia-installation</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide">Installation Guide ‚Äî NVIDIA drivers</A>
										<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/sample-workload.html">Running a Sample Workload ‚Äî NVIDIA Container Toolkit 1.16.0 documentation</A>
									</DL><p>
									<DT><A HREF="https://medium.datadriveninvestor.com/setting-up-carla-simulator-for-the-self-driving-cars-specialization-d38d4f6a0486">Setting up CARLA Simulator for the Self-Driving Cars Specialization | by Viridiana Romero Martinez | DataDrivenInvestor</A>
									<DT><A HREF="https://awesomeopensource.com/project/Amin-Tgz/awesome-CARLA">Awesome Carla</A>
									<DT><A HREF="https://hub.docker.com/layers/nvidia/cuda/11.8.0-devel-ubuntu22.04/images/sha256-60eda04ab6790aa76d73bf0df245b361eabc6d8f7b6f6cf9846c70f399b9a1eb">Image Layer Details - nvidia/cuda:11.8.0-devel-ubuntu22.04 | Docker Hub</A>
									<DT><A HREF="https://hub.docker.com/r/nvidia/cuda/tags">nvidia/cuda Tags | Docker Hub</A>
									<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html">Specialized Configurations with Docker ‚Äî NVIDIA Container Toolkit 1.16.0 documentation</A>
									<DT><A HREF="https://forums.developer.nvidia.com/t/whats-difference-between-gpus-and-runtime-nvidia-for-the-docker-container/283468/3">To put it simply, use --gpus on x86 and --runtime=nvidia on jetson/ARM SBSA system.</A>
									<DT><A HREF="https://hub.docker.com/u/wavespeed">wavespeed/pytorch-cuda</A>
									<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/sample-workload.html">Running a Sample Workload ‚Äî NVIDIA Container Toolkit</A>
								</DL><p>
								<DT><H3 FOLDED>docker-build</H3>
								<DL><p>
									<DT><H3 FOLDED>docker-build-examples</H3>
									<DL><p>
										<DT><A HREF="https://docs.anjuna.io/sgx/latest/getting_started/tutorial_anjuna_in_docker/build_an_image.html">Build a Docker image :: Getting Started</A>
									</DL><p>
									<DT><H3 FOLDED>buildx</H3>
									<DL><p>
										<DT><A HREF="https://docs.docker.com/reference/cli/docker/buildx/">docker buildx | Docker Docs</A>
										<DT><A HREF="https://github.com/docker/buildx">docker/buildx: Docker CLI plugin for extended build capabilities with BuildKit</A>
									</DL><p>
									<DT><A HREF="https://github.com/docker/buildx">docker/buildx: Docker CLI plugin for extended build capabilities with BuildKit</A>
									<DT><A HREF="https://docs.docker.com/build/">Overview of Docker Build | Docker Docs</A>
									<DT><A HREF="https://docs.docker.com/build/guide/intro/">Introduction | Docker Docs</A>
									<DT><A HREF="https://docs.docker.com/reference/cli/docker/buildx/build/">docker buildx build | Docker Docs</A>
									<DT><A HREF="https://aistudio.google.com/app/prompts/1KnqPc-9ZNiYGbWD-sO3I0ro5touxoTU0?pli=1">Docker build | Google AI Studio</A>
									<DT><A HREF="https://docs.docker.com/build/building/variables/">Variables: --build-arg</A>
								</DL><p>
								<DT><H3 FOLDED>linux-namespaces</H3>
								<DL><p>
									<DT><A HREF="https://blog.lizzie.io/linux-containers-in-500-loc.html">Linux containers in 500 lines of code</A>
									<DT><A HREF="https://www.youtube.com/watch?v=-YnMr1lj4Z8&t=174s">How Docker Works - Intro to Namespaces - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=cPGZMt4cJ0I">Introduction to Docker for CTFs - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>docker-footprint</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookincubator/senpai">facebookincubator/senpai: Senpai is an automated memory sizing tool for container applications.</A>
								</DL><p>
								<DT><H3 FOLDED>testcontainers</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=sNg0bnMF_qY">Testcontainers have forever changed the way I write tests - YouTube</A>
									<DT><A HREF="https://testcontainers.com/">Testcontainers</A>
									<DT><A HREF="https://www.youtube.com/watch?v=sNg0bnMF_qY">Testcontainers have forever changed the way I write tests</A>
								</DL><p>
								<DT><H3 FOLDED>docker-registry</H3>
								<DL><p>
									<DT><H3 FOLDED>docker-mirror</H3>
									<DL><p>
										<DT><A HREF="https://github.com/regclient/regclient/blob/main/docs/regsync.md">regclient/docs/regsync.md at main ¬∑ regclient/regclient</A>
									</DL><p>
									<DT><H3 FOLDED>docker-hub-private</H3>
									<DL><p>
										<DT><A HREF="https://claude.ai/chat/cbc3a3dc-bdfa-40ff-aeac-ba722f2b3652">docker pull: Pulling a Private Docker Image - Claude</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>docker-normal-init</H3>
								<DL><p>
									<DT><A HREF="https://github.com/Yelp/dumb-init">Yelp/dumb-init: A minimal init system for Linux containers</A>
								</DL><p>
								<DT><H3 FOLDED>docker-isolation</H3>
								<DL><p>
									<DT><H3 FOLDED>docker-rootless</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/chat/b8a21c4c-6425-42a3-9879-db5751e2b06c">Isolating Docker Environments for Researchers - Grok</A>
										<DT><A HREF="https://docs.docker.com/engine/security/rootless/">Rootless mode | Docker Docs</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>gvisor</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/gvisor">google/gvisor: Application Kernel for Containers</A>
									<DT><A HREF="https://gvisor.dev/">The Container Security Platform - gVisor</A>
								</DL><p>
								<DT><A HREF="https://blog.lizzie.io/linux-containers-in-500-loc.html">Linux containers in 500 lines of code</A>
								<DT><A HREF="https://github.com/wagoodman/dive">wagoodman/dive: A tool for exploring each layer in a docker image</A>
								<DT><A HREF="https://www.youtube.com/watch?v=rIrNIzy6U_g&t=247s">100+ Docker Concepts you Need to Know</A>
								<DT><A HREF="https://gist.github.com/anupambhatnagar/07ebff374bc45e4b63eb42893cca7e87">Commonly used Docker commands</A>
								<DT><A HREF="https://stackoverflow.com/questions/48957195/how-to-fix-docker-got-permission-denied-issue">How to fix docker: Got permission denied issue</A>
								<DT><A HREF="https://stackoverflow.com/questions/51188657/image-is-being-used-by-stopped-container/51189547">image is being used by stopped container</A>
								<DT><A HREF="https://gist.github.com/biera/fa4fcca8a3150dfa2438">remove all docker containers</A>
								<DT><A HREF="https://docs.docker.com/engine/install/linux-postinstall/">Post-installation steps for Linux | NON-ROOT USER</A>
								<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide">Installation Guide ‚Äî NVIDIA drivers</A>
								<DT><A HREF="https://www.youtube.com/watch?v=J0NuOlA2xDc&t=5s">Never install locally</A>
								<DT><A HREF="https://github.com/docker/buildx">docker/buildx: Docker CLI plugin for extended build capabilities with BuildKit</A>
								<DT><A HREF="https://github.com/facebookincubator/senpai">facebookincubator/senpai: Senpai is an automated memory sizing tool for container applications.</A>
								<DT><A HREF="https://av.tib.eu/media/46137">Senpai - Automatic memory sizing for containers - TIB AV-Portal</A>
								<DT><A HREF="https://gist.github.com/cloneofsimo/e4226f63443bf6386df846b06ff8d420">dockersetup.md</A>
								<DT><A HREF="https://github.com/goldmann/docker-squash">goldmann/docker-squash: Docker image squashing tool</A>
								<DT><A HREF="https://claude.ai/chat/4d385901-e1fb-45c8-9c7b-d7be6a5cc32c">Executing Commands in a Running Docker Container - Claude</A>
								<DT><A HREF="https://www.youtube.com/watch?v=iPoL03tFBtU">Docker Was Too Slow, So We Replaced It: Nix in Production - YouTube</A>
								<DT><A HREF="https://stackoverflow.com/questions/75603687/how-to-restart-dockerd">docker - How to restart dockerd?: sudo systemctl restart docker</A>
								<DT><A HREF="https://github.com/StuartSul/gpu-experiments/blob/103279e0c6a79c4ea94badb7dfdd530485b383c1/hopper/scripts/run-14.sh">gpu-experiments/hopper/scripts/run-14.sh: sudo $NSYS_PATH profile</A>
								<DT><A HREF="https://netflixtechblog.medium.com/mount-mayhem-at-netflix-scaling-containers-on-modern-cpus-f3b09b68beac">Mount Mayhem at Netflix: Scaling Containers on Modern CPUs | by Netflix Technology Blog | Nov, 2025 | Medium</A>
							</DL><p>
							<DT><H3 FOLDED>Linux</H3>
							<DL><p>
								<DT><H3 FOLDED>linux-distros</H3>
								<DL><p>
									<DT><H3 FOLDED>ubuntu</H3>
									<DL><p>
										<DT><A HREF="https://askubuntu.com/questions/1162491/how-can-you-tell-the-version-of-ubuntu-on-a-system-in-a-sh-bash-script">print system version</A>
										<DT><A HREF="https://help.ubuntu.com/community/EnvironmentVariables#File-location_related_variables">EnvironmentVariables - Community Help Wiki</A>
										<DT><A HREF="https://x.com/__tinygrad__/status/1869238988877492671/photo/1">Installing Ubuntu, media boost</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>linux-users</H3>
								<DL><p>
									<DT><H3 FOLDED>linux-users-sudo</H3>
									<DL><p>
										<DT><A HREF="https://askubuntu.com/questions/2214/how-do-i-add-a-user-to-the-sudo-group">How do I add a user to the "sudo" group? - Ask Ubuntu</A>
									</DL><p>
									<DT><A HREF="https://manpages.ubuntu.com/manpages/bionic/man8/useradd.8.html">Ubuntu Manpage: useradd - create a new user or update default new user information</A>
									<DT><A HREF="https://learnubuntu.com/list-users/">How to List Users in Ubuntu Command Line</A>
									<DT><A HREF="https://www.cyberciti.biz/faq/create-a-user-account-on-ubuntu-linux/">How to create a user account on Ubuntu Linux - nixCraft</A>
									<DT><A HREF="https://www.geeksforgeeks.org/id-command-in-linux-with-examples/">id command in Linux with examples - GeeksforGeeks</A>
									<DT><A HREF="https://unix.stackexchange.com/questions/3568/how-to-switch-between-users-on-one-terminal">How to switch between users on one terminal?</A>
									<DT><A HREF="https://www.cyberciti.biz/faq/linux-list-users-command/">Linux List All Users In The System Command - nixCraft</A>
									<DT><A HREF="https://chatgpt.com/c/54a41702-74ee-4dc6-a049-4637eb63c617">Create and Switch Users</A>
									<DT><A HREF="https://chatgpt.com/c/67583c20-e1b4-800c-9d82-a189909a793b">Shared Model Weights Setup: Create or Modify users for a shared volume environment using CEPH</A>
								</DL><p>
								<DT><H3 FOLDED>linux-package manager</H3>
								<DL><p>
									<DT><H3 FOLDED>apt-get</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>apt</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>update &amp; upgrade</H3>
									<DL><p>
										<DT><H3 FOLDED>debfoster</H3>
										<DL><p>
											<DT><A HREF="https://manpages.ubuntu.com/manpages/trusty/man8/debfoster.8.html#name">Ubuntu Manpage: debfoster ‚Äî weed unnecessary Debian packages</A>
											<DT><A HREF="https://ubunlog.com/en/debfoster-clean-maintenance-ubuntu/">Debfoster, clean your system and keep only the important packages | Ubunlog</A>
											<DT><A HREF="https://ubuntuforums.org/showthread.php?t=24403">HOWTO: using debfoster in practice</A>
										</DL><p>
										<DT><A HREF="https://chat.openai.com/c/51c6dd70-1f39-4bf7-843e-837d48b6f0e4">apt-rdepends</A>
										<DT><A HREF="https://askubuntu.com/questions/44122/how-to-upgrade-a-single-package-using-apt-get">apt-get install --only-upgrade &lt;packagename&gt; (unitary upgrade)</A>
									</DL><p>
									<DT><H3 FOLDED>/var/lib/apt/lists</H3>
									<DL><p>
										<DT><A HREF="https://askubuntu.com/questions/179955/var-lib-apt-lists-is-huge">package management - /var/lib/apt/lists is huge - Ask Ubuntu</A>
										<DT><A HREF="https://github.com/devcontainers/images/blob/main/docs/TIPS.md/#why-do-dockerfiles-in-this-repository-use-run-statements-with-commands-separated-by">images/docs/TIPS.md at main ¬∑ devcontainers/images</A>
									</DL><p>
									<DT><A HREF="https://unix.stackexchange.com/questions/20979/how-do-i-list-all-installed-programs">application - How do I list all installed programs?</A>
									<DT><A HREF="https://unix.stackexchange.com/questions/561263/how-to-get-a-list-of-which-packages-were-installed-with-apt-get-by-a-user-and-no">How to get a list of which packages were installed with apt-get by a user and not by dependencies?</A>
									<DT><A HREF="https://chat.openai.com/c/51c6dd70-1f39-4bf7-843e-837d48b6f0e4">apt &amp; apt-get: /etc/apt/sources.list and other .list files in /etc/apt/sources.list.d/</A>
								</DL><p>
								<DT><H3 FOLDED>linux-configuration</H3>
								<DL><p>
									<DT><A HREF="https://www.omgubuntu.co.uk/2010/05/transfer-your-packages-to-a-clean-install">Transfer your packages to a clean install</A>
									<DT><A HREF="https://launchpad.net/oneconf">OneConf in Launchpad</A>
									<DT><A HREF="https://wiki.ubuntu.com/OneConf">OneConf - Ubuntu Wiki</A>
									<DT><A HREF="https://github.com/NVIDIA/TensorRT-LLM/blob/5d8ca2faf74c494f220c8f71130340b513eea9a9/docker/common/install_pytorch.sh">TensorRT-LLM/docker/common/install_pytorch.sh</A>
								</DL><p>
								<DT><H3 FOLDED>editors</H3>
								<DL><p>
									<DT><H3 FOLDED>VS Code</H3>
									<DL><p>
										<DT><A HREF="https://vscode-docs.readthedocs.io/en/latest/customization/themes/">Themes - vscode-docs</A>
										<DT><A HREF="https://code.visualstudio.com/docs/getstarted/settings">Workspace Settings</A>
									</DL><p>
									<DT><H3 FOLDED>vim</H3>
									<DL><p>
										<DT><H3 FOLDED>configuration</H3>
										<DL><p>
											<DT><A HREF="http://cream.sourceforge.net/home.html">Cream :: a modern configuration</A>
											<DT><A HREF="https://stackoverflow.com/questions/40576522/enable-vi-mouse-wheel-scrolling-using-bash-on-ubuntu-on-windows-10/40715383">Set mouse</A>
										</DL><p>
										<DT><H3 FOLDED>syntax highlighting</H3>
										<DL><p>
											<DT><A HREF="https://vim.fandom.com/wiki/Forcing_Syntax_Coloring_for_files_with_odd_extensions">Forcing Syntax Coloring</A>
											<DT><A HREF="https://www.cyberciti.biz/faq/turn-on-or-off-color-syntax-highlighting-in-vi-or-vim/">Turn On or Off Color Syntax Highlighting</A>
											<DT><A HREF="http://vimdoc.sourceforge.net/htmldoc/syntax.html">Huge Vim documentation: syntax</A>
											<DT><A HREF="https://vi.stackexchange.com/questions/5780/list-known-filetypes">List known filetypes</A>
										</DL><p>
										<DT><H3 FOLDED>shortcuts</H3>
										<DL><p>
											<DT><A HREF="http://www.keyxl.com/aaa8263/290/VIM-keyboard-shortcuts.htm">78 Keyboard Shortcuts for VIM</A>
										</DL><p>
										<DT><H3 FOLDED>cheatsheet</H3>
										<DL><p>
											<DT><A HREF="https://www.worldtimzone.com/res/vi.html">Short cheatsheet</A>
											<DT><A HREF="https://vim.rtorr.com/">Medium Vim Cheat Sheet</A>
										</DL><p>
										<DT><A HREF="http://vimdoc.sourceforge.net/htmldoc/help.html">Vim documentation: help</A>
										<DT><A HREF="https://unix.stackexchange.com/questions/161821/how-can-i-delete-all-lines-in-a-file-using-vi">Delete all lines frong a given file</A>
										<DT><H3 FOLDED>vim-configuration</H3>
										<DL><p>
											<DT><A HREF="http://cream.sourceforge.net/home.html">Cream :: a modern configuration</A>
											<DT><A HREF="https://stackoverflow.com/questions/40576522/enable-vi-mouse-wheel-scrolling-using-bash-on-ubuntu-on-windows-10/40715383">Set mouse</A>
										</DL><p>
										<DT><H3 FOLDED>vim-syntax-highlighting</H3>
										<DL><p>
											<DT><A HREF="https://vim.fandom.com/wiki/Forcing_Syntax_Coloring_for_files_with_odd_extensions">Forcing Syntax Coloring</A>
											<DT><A HREF="https://www.cyberciti.biz/faq/turn-on-or-off-color-syntax-highlighting-in-vi-or-vim/">Turn On or Off Color Syntax Highlighting</A>
											<DT><A HREF="http://vimdoc.sourceforge.net/htmldoc/syntax.html">Huge Vim documentation: syntax</A>
											<DT><A HREF="https://vi.stackexchange.com/questions/5780/list-known-filetypes">List known filetypes</A>
										</DL><p>
										<DT><H3 FOLDED>vim-shortcuts</H3>
										<DL><p>
											<DT><A HREF="http://www.keyxl.com/aaa8263/290/VIM-keyboard-shortcuts.htm">78 Keyboard Shortcuts for VIM</A>
										</DL><p>
										<DT><H3 FOLDED>vim-cheatsheet</H3>
										<DL><p>
											<DT><A HREF="https://www.worldtimzone.com/res/vi.html">Short cheatsheet</A>
											<DT><A HREF="https://vim.rtorr.com/">Medium Vim Cheat Sheet</A>
										</DL><p>
										<DT><A HREF="https://claude.ai/chat/75d86b26-32c0-4611-b699-83ee66028f69">Configuring Yazi to show hidden and underscore directories - Claude</A>
									</DL><p>
									<DT><H3 FOLDED>neovim</H3>
									<DL><p>
										<DT><H3 FOLDED>config</H3>
										<DL><p>
											<DT><A HREF="https://medium.com/life-at-moka/step-up-your-game-with-neovim-62ba814166d7">Step Up Your Game with Neovim</A>
											<DT><A HREF="https://github.com/tpope/vim-fugitive">A Git wrapper</A>
											<DT><A HREF="https://github.com/preservim/nerdtree">A tree explorer plugin</A>
											<DT><A HREF="https://vi.stackexchange.com/questions/514/how-do-i-change-the-current-splits-width-and-height">change the current split's width and height</A>
											<DT><A HREF="https://www.youtube.com/watch?v=ZEFXeRIFvN0&t=404s">Command Line: Neovim Installation and Configuration</A>
											<DT><A HREF="https://github.com/junegunn/vim-plug">junegunn/vim-plug: Minimalist Vim Plugin Manager</A>
											<DT><A HREF="https://github.com/morhetz/gruvbox">morhetz/gruvbox: Retro groove color scheme for Vim</A>
											<DT><A HREF="https://www.youtube.com/watch?v=iagjeLuxnMs">My Entire Neovim + Tmux Workflow As A DevOps Engineer On MacOS - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>installation</H3>
										<DL><p>
											<DT><A HREF="https://github.com/neovim/neovim">neovim/neovim: Vim-fork focused on extensibility and usability</A>
											<DT><A HREF="https://formulae.brew.sh/formula/neovim#default">neovim ‚Äî Homebrew Formulae</A>
										</DL><p>
										<DT><H3 FOLDED>neovim-config</H3>
										<DL><p>
											<DT><A HREF="https://medium.com/life-at-moka/step-up-your-game-with-neovim-62ba814166d7">Step Up Your Game with Neovim</A>
											<DT><A HREF="https://github.com/tpope/vim-fugitive">A Git wrapper</A>
											<DT><A HREF="https://github.com/preservim/nerdtree">A tree explorer plugin</A>
											<DT><A HREF="https://vi.stackexchange.com/questions/514/how-do-i-change-the-current-splits-width-and-height">change the current split's width and height</A>
											<DT><A HREF="https://www.youtube.com/watch?v=ZEFXeRIFvN0&t=404s">Command Line: Neovim Installation and Configuration</A>
											<DT><A HREF="https://github.com/junegunn/vim-plug">junegunn/vim-plug: Minimalist Vim Plugin Manager</A>
											<DT><A HREF="https://github.com/morhetz/gruvbox">morhetz/gruvbox: Retro groove color scheme for Vim</A>
											<DT><A HREF="https://www.youtube.com/watch?v=iagjeLuxnMs">My Entire Neovim + Tmux Workflow As A DevOps Engineer On MacOS - YouTube</A>
										</DL><p>
										<DT><H3 FOLDED>neovim-installation</H3>
										<DL><p>
											<DT><A HREF="https://github.com/neovim/neovim">neovim/neovim: Vim-fork focused on extensibility and usability</A>
											<DT><A HREF="https://formulae.brew.sh/formula/neovim#default">neovim ‚Äî Homebrew Formulae</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>sublime text</H3>
									<DL><p>
										<DT><A HREF="https://packagecontrol.io/installation">Installation - Package Control</A>
										<DT><A HREF="https://packagecontrol.io/docs/usage">Usage - Package Control</A>
									</DL><p>
									<DT><A HREF="https://support.typora.io/Spellcheck/">Spellcheck - Typora Support</A>
									<DT><A HREF="https://support.typora.io/Line-Break/">Whitespace and Line Breaks - Typora Support</A>
								</DL><p>
								<DT><H3 FOLDED>linux-disk</H3>
								<DL><p>
									<DT><A HREF="https://man7.org/linux/man-pages/man8/lsblk.8.html">lsblk(8) - Linux manual page</A>
								</DL><p>
								<DT><H3 FOLDED>linux-filesystem</H3>
								<DL><p>
									<DT><H3 FOLDED>distributed-filesystem</H3>
									<DL><p>
										<DT><H3 FOLDED>lustre</H3>
										<DL><p>
											<DT><A HREF="https://www.lustre.org/">Lustre: distributed filesystem</A>
										</DL><p>
										<DT><H3 FOLDED>CEPH</H3>
										<DL><p>
											<DT><A HREF="https://claude.ai/chat/afe41c86-8070-4868-86f3-bef7cecdb346">Optimizing Conda Environments in Multi-Node GPU Clusters - Claude</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>/dev/shm</H3>
									<DL><p>
										<DT><A HREF="https://chatgpt.com/c/67eac713-14fc-800c-bd41-3794b8d7df63">/dev/shm vs Ceph for IO</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>linux-memory</H3>
								<DL><p>
									<DT><H3 FOLDED>LWN.net: What every programmer should know about memory</H3>
									<DL><p>
										<DT><A HREF="https://lwn.net/Articles/250967/">1. Introduction</A>
										<DT><A HREF="https://lwn.net/Articles/252125/">2. CPU caches</A>
										<DT><A HREF="https://lwn.net/Articles/253361/">3. Virtual Memory</A>
										<DT><A HREF="https://lwn.net/Articles/254445/">4. NUMA support</A>
										<DT><A HREF="https://lwn.net/Articles/255364/">5. What programmers can do - cache optimization</A>
										<DT><A HREF="https://lwn.net/Articles/256433/">6. What programmers can do - multi-threaded optimizations</A>
										<DT><A HREF="https://lwn.net/Articles/257209/">7. Memory performance tools</A>
										<DT><A HREF="https://lwn.net/Articles/258154/">8. Future technologies</A>
										<DT><A HREF="https://lwn.net/Articles/258188/">9. Examples and Benchmark Programs: matmul</A>
									</DL><p>
									<DT><H3 FOLDED>memory-mountain</H3>
									<DL><p>
										<DT><A HREF="https://x.com/giffmana/status/1951010266386153563">Strided reads from anywhere but L1 suck ass. But you knew that already</A>
									</DL><p>
									<DT><H3 FOLDED>lshw</H3>
									<DL><p>
										<DT><A HREF="https://x.com/tetsuoai/status/1989908769002983754">(1) TŒûTSU√ò en X: "New systems running. RAM SUMMARY ============ Total usable: 1.7 TiB (DDR5) Modules: 8 √ó 128 GiB Speed: 6400 MHz STORAGE SUMMARY =============== Total raw capacity: 32 TB Modules: 4 x 8 TiB NVMe Total theoretical bandwidth: 31.6 GB/s https://t.co/IaizP4Kq8n" / X</A>
										<DT><A HREF="https://linux.die.net/man/1/lshw">lshw(1): hardware - Linux man page</A>
									</DL><p>
									<DT><H3 FOLDED>lsblk</H3>
									<DL><p>
										<DT><A HREF="https://www.man7.org/linux/man-pages/man8/lsblk.8.html">lsblk(8) - Linux manual page</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=L79vSP8yV2g">Base [4]: Memory Management - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=vHWiDx_l4V0&t=2436s">What's a Memory Allocator Anyway? - Benjamin Feng - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=Sxx0TDPT0t8">üåø Week 17 Hobby Kernel Dev in C, x86: Physical memory allocator pt2 üåø - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=OFo5FPt7KYA">ZRAM | A Misunderstood Linux Tool... - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>linux-networking</H3>
								<DL><p>
									<DT><H3 FOLDED>VPN</H3>
									<DL><p>
										<DT><H3 FOLDED>tailscale</H3>
										<DL><p>
											<DT><A HREF="https://tailscale.com/">Tailscale ¬∑ Best VPN Service for Secure Networks</A>
											<DT><A HREF="https://github.com/artis3n/ansible-role-tailscale">artis3n/ansible-role-tailscale: Ansible role to install and configure a Tailscale node.</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://www.net.in.tum.de/fileadmin/TUM/NET/NET-2024-04-1/NET-2024-04-1_16.pdf">The Path of a Packet Through the Linux Kernel</A>
									<DT><A HREF="https://www.youtube.com/watch?v=ck4WvYM9V4c">Linux Networking: How The Kernel Handles A TCP Connection - YouTube</A>
									<DT><A HREF="https://chatgpt.com/c/e57a5ce7-00de-486a-a8c2-c95db90cf417">non-blocking flat tree</A>
									<DT><A HREF="https://www.geeksforgeeks.org/iotop-command-in-linux-with-examples/">Comando iotop en Linux con ejemplos - GeeksforGeeks</A>
								</DL><p>
								<DT><H3 FOLDED>dkms</H3>
								<DL><p>
									<DT><A HREF="https://askubuntu.com/questions/408605/what-does-dkms-do-how-do-i-use-it">What does DKMS do? How do I use it? - Ask Ubuntu</A>
									<DT><A HREF="https://github.com/dell/dkms">dell/dkms: Dynamic Kernel Module Support</A>
								</DL><p>
								<DT><H3 FOLDED>shell</H3>
								<DL><p>
									<DT><H3 FOLDED>shell-languages</H3>
									<DL><p>
										<DT><H3 FOLDED>Bash</H3>
										<DL><p>
											<DT><H3 FOLDED>bash-error-handling</H3>
											<DL><p>
												<DT><A HREF="https://chatgpt.com/c/73e6a395-5da9-448f-b956-56c47bc98735">set -Eeuo</A>
											</DL><p>
											<DT><H3 FOLDED>bash-set</H3>
											<DL><p>
												<DT><A HREF="https://www.gnu.org/software/bash/manual/html_node/The-Set-Builtin.html">The Set Builtin (Bash Reference Manual)</A>
											</DL><p>
											<DT><H3 FOLDED>bash-completions</H3>
											<DL><p>
												<DT><A HREF="https://itnext.io/programmable-completion-for-bash-on-macos-f81a0103080b">Programmable Completion for Bash</A>
												<DT><A HREF="https://www.gnu.org/software/bash/manual/html_node/Programmable-Completion.html">Programmable Completion (Bash Manual)</A>
											</DL><p>
											<DT><H3 FOLDED>bash-colors</H3>
											<DL><p>
												<DT><A HREF="https://www.cyberciti.biz/faq/how-to-turn-on-or-off-colors-in-bash/">How To Turn On/Off Colors For ls Command</A>
												<DT><A HREF="https://linoxide.com/how-tos/change-linux-shell-prompt-with-different-colors/">How to Change Bash Shell Prompt Colorful</A>
												<DT><A HREF="https://www.cyberciti.biz/faq/apple-mac-osx-terminal-color-ls-output-option/">How to enable colorized output for ls command</A>
											</DL><p>
											<DT><H3 FOLDED>os-automatization</H3>
											<DL><p>
												<DT><A HREF="https://github.com/AnswerDotAI/fastsetup/blob/master/setup-conda.sh">fastsetup/setup-conda.sh at master ¬∑ AnswerDotAI/fastsetup</A>
												<DT><A HREF="https://github.com/albanD/pytorch_dev_env_setup">albanD/pytorch_dev_env_setup</A>
											</DL><p>
											<DT><H3 FOLDED>bash-script</H3>
											<DL><p>
												<DT><A HREF="https://linuxize.com/post/bash-comments/">Writing Comments</A>
												<DT><A HREF="https://stackoverflow.com/questions/17066250/create-timestamp-variable-in-bash-script">Create timestamp variable in bash script - Stack Overflow</A>
											</DL><p>
											<DT><A HREF="https://itnext.io/programmable-completion-for-bash-on-macos-f81a0103080b">Programmable Completion for Bash</A>
											<DT><A HREF="https://itnext.io/upgrading-bash-on-macos-7138bd1066ba">Upgrading</A>
											<DT><A HREF="https://www.gnu.org/software/bash/manual/html_node/Programmable-Completion.html">Programmable Completion (Bash Manual)</A>
											<DT><A HREF="https://www.cyberciti.biz/faq/how-to-turn-on-or-off-colors-in-bash/">How To Turn On/Off Colors For ls Command</A>
											<DT><A HREF="https://linoxide.com/how-tos/change-linux-shell-prompt-with-different-colors/">How to Change Bash Shell Prompt Colorful</A>
											<DT><A HREF="https://tldp.org/LDP/abs/html/">Advanced Bash-Scripting Guide</A>
											<DT><A HREF="https://stackoverflow.com/questions/589149/bash-script-to-cd-to-directory-with-spaces-in-pathname">cd to directory with WHITESPACES in pathname</A>
											<DT><A HREF="https://stackoverflow.com/questions/5130968/how-can-i-copy-the-output-of-a-command-directly-into-my-clipboard">copy the output of a command into clipboard</A>
											<DT><A HREF="https://www.cyberciti.biz/faq/apple-mac-osx-terminal-color-ls-output-option/">How to enable colorized output for ls command</A>
											<DT><A HREF="https://linuxize.com/post/bash-comments/">Writing Comments</A>
											<DT><A HREF="https://stackoverflow.com/questions/17066250/create-timestamp-variable-in-bash-script">Create timestamp variable in bash script - Stack Overflow</A>
											<DT><A HREF="https://github.com/dylanaraps/pure-bash-bible">dylanaraps/pure-bash-bible: üìñ A collection of pure bash alternatives to external processes.</A>
											<DT><A HREF="https://github.com/dylanaraps/pure-bash-bible">dylanaraps/pure-bash-bible</A>
											<DT><A HREF="https://www.gnu.org/software/bash/manual/html_node/">Top (Bash Reference Manual)</A>
											<DT><A HREF="https://stackoverflow.com/questions/44222883/run-a-shell-script-and-immediately-background-it-however-keep-the-ability-to-in">&amp; - Run a shell script and immediately background</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>shell-editors</H3>
									<DL><p>
										<DT><H3 FOLDED>VS Code</H3>
										<DL><p>
											<DT><A HREF="https://vscode-docs.readthedocs.io/en/latest/customization/themes/">Themes - vscode-docs</A>
										</DL><p>
										<DT><H3 FOLDED>vim</H3>
										<DL><p>
											<DT><H3 FOLDED>configuration</H3>
											<DL><p>
												<DT><A HREF="http://cream.sourceforge.net/home.html">Cream :: a modern configuration</A>
												<DT><A HREF="https://stackoverflow.com/questions/40576522/enable-vi-mouse-wheel-scrolling-using-bash-on-ubuntu-on-windows-10/40715383">Set mouse</A>
											</DL><p>
											<DT><H3 FOLDED>syntax highlighting</H3>
											<DL><p>
												<DT><A HREF="https://vim.fandom.com/wiki/Forcing_Syntax_Coloring_for_files_with_odd_extensions">Forcing Syntax Coloring</A>
												<DT><A HREF="https://www.cyberciti.biz/faq/turn-on-or-off-color-syntax-highlighting-in-vi-or-vim/">Turn On or Off Color Syntax Highlighting</A>
												<DT><A HREF="http://vimdoc.sourceforge.net/htmldoc/syntax.html">Huge Vim documentation: syntax</A>
												<DT><A HREF="https://vi.stackexchange.com/questions/5780/list-known-filetypes">List known filetypes</A>
											</DL><p>
											<DT><H3 FOLDED>shortcuts</H3>
											<DL><p>
												<DT><A HREF="http://www.keyxl.com/aaa8263/290/VIM-keyboard-shortcuts.htm">78 Keyboard Shortcuts for VIM</A>
											</DL><p>
											<DT><H3 FOLDED>cheatsheet</H3>
											<DL><p>
												<DT><A HREF="https://www.worldtimzone.com/res/vi.html">Short cheatsheet</A>
												<DT><A HREF="https://vim.rtorr.com/">Medium Vim Cheat Sheet</A>
											</DL><p>
											<DT><A HREF="http://vimdoc.sourceforge.net/htmldoc/help.html">Vim documentation: help</A>
											<DT><A HREF="https://unix.stackexchange.com/questions/161821/how-can-i-delete-all-lines-in-a-file-using-vi">Delete all lines frong a given file</A>
										</DL><p>
										<DT><H3 FOLDED>neovim</H3>
										<DL><p>
											<DT><H3 FOLDED>config</H3>
											<DL><p>
												<DT><A HREF="https://medium.com/life-at-moka/step-up-your-game-with-neovim-62ba814166d7">Step Up Your Game with Neovim</A>
												<DT><A HREF="https://github.com/tpope/vim-fugitive">A Git wrapper</A>
												<DT><A HREF="https://github.com/preservim/nerdtree">A tree explorer plugin</A>
												<DT><A HREF="https://vi.stackexchange.com/questions/514/how-do-i-change-the-current-splits-width-and-height">change the current split's width and height</A>
												<DT><A HREF="https://www.youtube.com/watch?v=ZEFXeRIFvN0&t=404s">Command Line: Neovim Installation and Configuration</A>
												<DT><A HREF="https://github.com/junegunn/vim-plug">junegunn/vim-plug: Minimalist Vim Plugin Manager</A>
												<DT><A HREF="https://github.com/morhetz/gruvbox">morhetz/gruvbox: Retro groove color scheme for Vim</A>
												<DT><A HREF="https://www.youtube.com/watch?v=iagjeLuxnMs">My Entire Neovim + Tmux Workflow As A DevOps Engineer On MacOS - YouTube</A>
											</DL><p>
											<DT><H3 FOLDED>installation</H3>
											<DL><p>
												<DT><A HREF="https://github.com/neovim/neovim">neovim/neovim: Vim-fork focused on extensibility and usability</A>
												<DT><A HREF="https://formulae.brew.sh/formula/neovim#default">neovim ‚Äî Homebrew Formulae</A>
											</DL><p>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>tmux</H3>
									<DL><p>
										<DT><H3 FOLDED>tmux.conf</H3>
										<DL><p>
											<DT><A HREF="https://github.com/geohot/configuration/blob/master/.tmux.conf">configuration/.tmux.conf at master ¬∑ geohot/configuration</A>
											<DT><A HREF="https://mutelight.org/practical-tmux">Practical Tmux ‚Äî mutelight.org</A>
										</DL><p>
										<DT><H3 FOLDED>zellij</H3>
										<DL><p>
											<DT><A HREF="https://github.com/zellij-org/zellij">zellij-org/zellij: A terminal workspace with batteries included</A>
										</DL><p>
										<DT><H3 FOLDED>tmux-man</H3>
										<DL><p>
											<DT><A HREF="https://github.com/tmux/tmux/wiki/Getting-Started">Getting Started ¬∑ tmux/tmux Wiki</A>
										</DL><p>
										<DT><A HREF="https://wiki.archlinux.org/index.php/Tmux#256_colors">tmux - ArchWiki</A>
										<DT><A HREF="https://stackoverflow.com/questions/18760281/how-to-increase-scrollback-buffer-size-in-tmux">scroll - How to increase scrollback buffer size?</A>
										<DT><A HREF="https://mutelight.org/practical-tmux">Practical Tmux</A>
										<DT><A HREF="https://www.runrails.com/tmux/scrolling-in-tmux/#:~:text=2%20%2D%20With%20keyboard%20shortcuts,around%20with%20the%20arrow%20keys.&text=Just%20as%20with%20the%20mouse,to%20add%20them%20to%20your%20.&text=Note%20that%20you%20have%20to,bound%20as%20the%20command%20key.">How to scroll back in Tmux</A>
										<DT><A HREF="https://github.com/tmux/tmux/wiki/Installing">Installing ¬∑ tmux/tmux Wiki</A>
									</DL><p>
									<DT><H3 FOLDED>fuzzy finder</H3>
									<DL><p>
										<DT><A HREF="https://github.com/junegunn/fzf#using-homebrew">junegunn/fzf: A command-line fuzzy finder</A>
										<DT><A HREF="https://www.youtube.com/watch?v=qgG5Jhi_Els">Vim universe. fzf - command line fuzzy finder - YouTube</A>
										<DT><A HREF="https://www.youtube.com/watch?v=hJzqEAf2U4I">I made the greatest tool ever! | tmux &amp; cht.sh &amp; fzf - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>shell-profiles</H3>
									<DL><p>
										<DT><A HREF="https://unix.stackexchange.com/questions/476593/when-should-i-use-bashrc-and-when-profile">When should I use .bashrc and when .profile?</A>
									</DL><p>
									<DT><H3 FOLDED>grep</H3>
									<DL><p>
										<DT><H3 FOLDED>ripgrep</H3>
										<DL><p>
											<DT><A HREF="https://github.com/BurntSushi/ripgrep">ripgrep: ripgrep recursively searches directories for a regex pattern</A>
											<DT><A HREF="https://github.com/BurntSushi/ripgrep/blob/master/GUIDE.md">ripgrep/GUIDE.md</A>
											<DT><A HREF="https://github.com/BurntSushi/ripgrep/issues/623">hidden files to be searched by default ¬∑ Issue #623 ¬∑ BurntSushi/ripgrep</A>
											<DT><A HREF="https://grok.com/chat/19fe88ac-62ea-4b2f-96a2-c0887816ddb0">Ripgrep Multi-Word Pattern Matching: rg 'triton' | rg 'tests'</A>
											<DT><A HREF="https://claude.ai/chat/49175938-1da4-4d35-a6a5-3c6f53fe9e99">Git Grep vs Grep in PyTorch - Claude</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>man &amp; info &amp; help</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=vnBCnd2L0dY">Linux Experts Read 'info' Pages (NOT 'man' pages) - YouTube</A>
										<DT><A HREF="https://man7.org/linux/man-pages/man1/ldd.1.html">ldd - print shared object dependencies</A>
									</DL><p>
									<DT><H3 FOLDED>file manager</H3>
									<DL><p>
										<DT><H3 FOLDED>yazi</H3>
										<DL><p>
											<DT><A HREF="https://github.com/sxyazi/yazi">sxyazi/yazi: üí• Blazing fast terminal file manager written in Rust, based on async I/O.</A>
											<DT><A HREF="https://yazi-rs.github.io/docs/configuration/overview">Configuration | Yazi</A>
											<DT><A HREF="https://yazi-rs.github.io/docs/quick-start/">shell wrapper: change dir</A>
											<DT><A HREF="https://github.com/sxyazi/yazi/issues/801">yazi-adaptor not compiling ¬∑ Issue #801 ¬∑ sxyazi/yazi</A>
											<DT><A HREF="https://claude.ai/chat/75d86b26-32c0-4611-b699-83ee66028f69">Configuring Yazi to show hidden and underscore directories - Claude</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>shell-pipes</H3>
									<DL><p>
										<DT><A HREF="https://github.com/akavel/up">akavel/up: Ultimate Plumber is a tool for writing Linux pipes with instant live preview</A>
									</DL><p>
									<DT><H3 FOLDED>shell-trash</H3>
									<DL><p>
										<DT><A HREF="https://github.com/andreafrancia/trash-cli">andreafrancia/trash-cli: Command line interface to the freedesktop.org trashcan.</A>
									</DL><p>
									<DT><H3 FOLDED>std-out-err</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tiangolo/typer/blob/04eba6b70203287176d2823753513226bf778872/docs/tutorial/printing.md#standard-output-and-standard-error">Standard Output and Standard Error</A>
									</DL><p>
									<DT><H3 FOLDED>shell-automation</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=9KAp_zWeI34">Automating Everything in Linux with ENTR! - YouTube</A>
										<DT><A HREF="https://eradman.com/entrproject/">entr(1)</A>
										<DT><A HREF="https://github.com/tinygrad/tinyos">tinygrad/tinyos</A>
										<DT><A HREF="https://chatgpt.com/c/680124f5-a5e0-800c-9234-85f56e6b9876">Docker permission denied fix</A>
									</DL><p>
									<DT><H3 FOLDED>linux-monitoring</H3>
									<DL><p>
										<DT><H3 FOLDED>disk-usage</H3>
										<DL><p>
											<DT><A HREF="https://github.com/Canop/dysk">Canop/dysk: A linux utility to get information on filesystems, like df but better</A>
											<DT><A HREF="https://github.com/Byron/dua-cli">Byron/dua-cli: View disk space usage and delete unwanted data, fast.</A>
											<DT><A HREF="https://github.com/KSXGitHub/parallel-disk-usage">KSXGitHub/parallel-disk-usage: Highly parallelized, blazing fast directory tree analyzer</A>
											<DT><A HREF="https://github.com/bootandy/dust">bootandy/dust: A more intuitive version of du in rust</A>
										</DL><p>
										<DT><H3 FOLDED>htop</H3>
										<DL><p>
											<DT><H3 FOLDED>glances</H3>
											<DL><p>
												<DT><A HREF="https://github.com/nicolargo/glances">nicolargo/glances: Glances an Eye on your system. A top/htop alternative for GNU/Linux, BSD, Mac OS and Windows operating systems.</A>
											</DL><p>
											<DT><A HREF="https://github.com/htop-dev/htop">htop-dev/htop: htop - an interactive process viewer</A>
										</DL><p>
										<DT><A HREF="https://github.com/aristocratos/btop">aristocratos/btop: A monitor of resources</A>
										<DT><A HREF="https://github.com/Syllo/nvtop">Syllo/nvtop: GPU &amp; Accelerator process monitoring for AMD, Apple, Huawei, Intel, NVIDIA and Qualcomm</A>
										<DT><A HREF="https://github.com/XuehaiPan/nvitop">XuehaiPan/nvitop: An interactive NVIDIA-GPU process viewer and beyond, the one-stop solution for GPU process management.</A>
										<DT><A HREF="https://github.com/htop-dev/htop">htop-dev/htop: htop - an interactive process viewer</A>
										<DT><A HREF="https://github.com/ClementTsang/bottom">ClementTsang/bottom: Yet another cross-platform graphical process/system monitor.</A>
										<DT><A HREF="https://netflixtechblog.com/tagged/observability">Observability ‚Äì Netflix TechBlog</A>
										<DT><A HREF="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">Linux Performance Analysis in 60,000 Milliseconds | by Netflix Technology Blog | Netflix TechBlog</A>
										<DT><A HREF="https://github.com/nicolargo/glances">nicolargo/glances: Glances an Eye on your system. A top/htop alternative for GNU/Linux, BSD, Mac OS and Windows operating systems.</A>
									</DL><p>
									<DT><H3 FOLDED>jq</H3>
									<DL><p>
										<DT><A HREF="https://jqlang.github.io/jq/">jq</A>
										<DT><A HREF="https://jqlang.org/">jq</A>
										<DT><A HREF="https://www.youtube.com/watch?v=n8sOmEe2SDg">The BEST CLI Tool - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>pdsh</H3>
									<DL><p>
										<DT><A HREF="https://linux.die.net/man/1/pdsh">pdsh(1) - Linux man page</A>
										<DT><A HREF="https://github.com/chaos/pdsh">chaos/pdsh: A high performance, parallel remote shell utility</A>
										<DT><A HREF="https://grok.com/chat/211ddb08-e905-4bb0-8933-4bb16d651120">pdsh -a -x storage-test-jumphost hostname (-x exclude)</A>
									</DL><p>
									<DT><H3 FOLDED>sed</H3>
									<DL><p>
										<DT><A HREF="https://linux.die.net/man/1/sed">sed(1) - Linux man page</A>
									</DL><p>
									<DT><H3 FOLDED>find</H3>
									<DL><p>
										<DT><A HREF="https://github.com/sharkdp/fd">sharkdp/fd: A simple, fast and user-friendly alternative to 'find'</A>
									</DL><p>
									<DT><H3 FOLDED>util-linux</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/chat/0a5b6b93-fc34-4433-a833-b09505fff39a">shell # dpkg -L util-linux  | grep bin</A>
									</DL><p>
									<DT><H3 FOLDED>shell-data-movement</H3>
									<DL><p>
										<DT><H3 FOLDED>rclone</H3>
										<DL><p>
											<DT><A HREF="https://grok.com/c/4463f02e-c704-43ad-81f4-dd0188760c3e">Rclone for GPU Data Transfer Optimization - Grok</A>
											<DT><A HREF="https://github.com/rclone/rclone?tab=readme-ov-file">rclone/rclone: "rsync for cloud storage" - Google Drive, S3, Dropbox, Backblaze B2, One Drive, Swift, Hubic, Wasabi, Google Cloud Storage, Azure Blob, Azure Files, Yandex Files</A>
											<DT><A HREF="https://jott.live/markdown/mfu">MFU is Poorly Approximating Billions of Dollars in Compute</A>
										</DL><p>
									</DL><p>
									<DT><H3 FOLDED>jq</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>ls</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ogham/exa">ogham/exa: A modern replacement for ‚Äòls‚Äô.</A>
									</DL><p>
									<DT><H3 FOLDED>cd</H3>
									<DL><p>
										<DT><A HREF="https://github.com/ajeetdsouza/zoxide">ajeetdsouza/zoxide: A smarter cd command. Supports all major shells.</A>
									</DL><p>
									<DT><H3 FOLDED>http-client</H3>
									<DL><p>
										<DT><A HREF="https://github.com/httpie/cli">httpie/cli: ü•ß HTTPie CLI ‚Äî modern, user-friendly command-line HTTP client for the API era. JSON support, colors, sessions, downloads, plugins &amp; more.</A>
									</DL><p>
									<DT><A HREF="https://ss64.com/osx/">An A-Z Index of the Apple macOS command line</A>
									<DT><A HREF="https://jqlang.github.io/jq/">jq</A>
									<DT><A HREF="https://gist.github.com/sts10/daadbc2f403bdffad1b6d33aff016c0a">A curated list of command-line utilities written in Rust</A>
									<DT><A HREF="https://github.com/sharkdp/bat">bat: A cat(1) clone with wings.</A>
									<DT><A HREF="https://github.com/sxyazi/yazi">sxyazi/yazi: üí• Blazing fast terminal file manager written in Rust, based on async I/O.</A>
									<DT><A HREF="https://github.com/Byron/dua-cli">Byron/dua-cli: View disk space usage and delete unwanted data, fast.</A>
									<DT><A HREF="https://github.com/sharkdp/fd">sharkdp/fd: A simple, fast and user-friendly alternative to 'find'</A>
									<DT><A HREF="https://github.com/Canop/dysk">Canop/dysk: A linux utility to get information on filesystems, like df but better</A>
									<DT><A HREF="https://github.com/Syllo/nvtop">Syllo/nvtop: GPU &amp; Accelerator process monitoring for AMD, Apple, Huawei, Intel, NVIDIA and Qualcomm</A>
									<DT><A HREF="https://github.com/Xfennec/progress">Xfennec/progress: Linux tool to show progress for cp, mv, dd, ... (formerly known as cv)</A>
									<DT><A HREF="https://github.com/atuinsh/atuin">atuinsh/atuin: ‚ú® Magical shell history</A>
									<DT><A HREF="https://github.com/facebookarchive/pcicrawler">facebookarchive/pcicrawler: pcicrawler is a Python based command line interface tool which can be used to display, filter and export information about PCI (Peripheral Component Interconnect) or PCIe buses and devices, as well as PCI topology.</A>
									<DT><A HREF="http://www.faqs.org/faqs/unix-faq/shell/shell-differences/">UNIX shell differences and how to change your shell</A>
									<DT><A HREF="https://johndjameson.com/blog/updating-your-shell-with-homebrew/">Updating Your Shell with Homebrew</A>
									<DT><A HREF="https://unix.stackexchange.com/questions/167631/finding-the-original-file-of-a-symbolic-link/167632">readlink - Finding the original file of a symbolic link</A>
									<DT><A HREF="https://ss64.com/osx/ln.html">ln Man Page - Symbolic links</A>
									<DT><A HREF="https://www.baeldung.com/linux/head-tail-commands">Head &amp; Tail</A>
									<DT><A HREF="https://explainshell.com/explain?cmd=tr+%22%3A%22+%22%5Cn%22+%3C%3C%3C%22%24PATH%22">explainshell.com - tr ":" "\n" &lt;&lt;&lt;"$PATH"</A>
									<DT><A HREF="https://explainshell.com/">explainshell.com - match command-line arguments to their help text</A>
									<DT><A HREF="https://github.com/BurntSushi/ripgrep">BurntSushi/ripgrep: ripgrep recursively searches directories for a regex pattern while respecting your gitignore</A>
									<DT><A HREF="https://github.com/chubin/cheat.sh">chubin/cheat.sh: the only cheat sheet you need</A>
									<DT><A HREF="https://man7.org/linux/man-pages/man1/dmesg.1.html">dmesg: print or control the kernel ring buffer</A>
									<DT><A HREF="https://explainshell.com/">explainshell.com</A>
									<DT><A HREF="https://github.com/Xfennec/progress">Xfennec/progress: Linux tool to show progress for cp, mv, dd</A>
									<DT><A HREF="https://jqlang.github.io/jq/">jq: JSON processor</A>
									<DT><A HREF="https://man7.org/linux/man-pages/man1/du.1.html">du(1) - Linux manual page (du -sh &lt;dir&gt;)</A>
									<DT><A HREF="https://man7.org/linux/man-pages/man1/ldd.1.html">ldd - print shared object dependencies</A>
									<DT><A HREF="https://github.com/facebookincubator/below">facebookincubator/below: A time traveling resource monitor for modern Linux systems</A>
									<DT><A HREF="https://github.com/aristocratos/btop">aristocratos/btop: A monitor of resources</A>
									<DT><A HREF="https://github.com/robbmcleod/cpufeature">robbmcleod/cpufeature: Python module for detection of CPU features</A>
									<DT><A HREF="https://github.com/ClementTsang/bottom">ClementTsang/bottom: Yet another cross-platform graphical process/system monitor.</A>
									<DT><A HREF="https://github.com/zellij-org/zellij">zellij-org/zellij: A terminal workspace with batteries included</A>
									<DT><A HREF="https://github.com/Orange-OpenSource/hurl">Orange-OpenSource/hurl: Hurl, run and test HTTP requests with plain text.</A>
									<DT><A HREF="https://www.geeksforgeeks.org/linux-unix/tree-command-unixlinux/">tree Command in Linux with Examples - GeeksforGeeks</A>
									<DT><A HREF="https://x.com/kregenrek/status/1984354511461499297">(1) Kevin Kern en X: "If you're setting up your Coding CLI, here are some tools worth adding. I've found fd, ripgrep, and ast-grep especially useful when working with codex. https://t.co/qS6HcBNiVq" / X</A>
								</DL><p>
								<DT><H3 FOLDED>std-out-err</H3>
								<DL><p>
									<DT><A HREF="https://github.com/tiangolo/typer/blob/04eba6b70203287176d2823753513226bf778872/docs/tutorial/printing.md#standard-output-and-standard-error">Standard Output and Standard Error</A>
									<DT><A HREF="https://claude.ai/chat/cd7e2733-9ef6-4c56-88d9-6b486ca88af2">Linux Shell Output Redirection - Claude</A>
								</DL><p>
								<DT><H3 FOLDED>UNIX</H3>
								<DL><p>
									<DT><H3 FOLDED>learning</H3>
									<DL><p>
										<DT><H3 FOLDED>$PATH</H3>
										<DL><p>
											<DT><A HREF="https://askubuntu.com/questions/600018/how-to-display-path-as-one-directory-per-line">How to display $PATH as one directory per line?</A>
											<DT><A HREF="https://kb.iu.edu/d/acar">Set or modify a path in Unix</A>
										</DL><p>
										<DT><A HREF="https://kb.iu.edu/d/acmq">current values of all environment variables and functions</A>
										<DT><A HREF="https://tldp.org/LDP/Linux-Filesystem-Hierarchy/html/usr.html">/usr</A>
										<DT><A HREF="https://refspecs.linuxfoundation.org/FHS_3.0/fhs/ch04s09.html">4.9.¬†/usr/local : Local hierarchy</A>
										<DT><A HREF="https://blog.balthazar-rouberol.com/text-processing-in-the-shell">Text processing in the shell</A>
									</DL><p>
									<DT><H3 FOLDED>building</H3>
									<DL><p>
										<DT><A HREF="http://www.lemis.com/grog/Documentation/Lions/book.pdf">Book: Commentary on the sixth edition</A>
									</DL><p>
									<DT><A HREF="https://kb.iu.edu/d/affo">What do some common Unix file extensions mean?</A>
								</DL><p>
								<DT><H3 FOLDED>GNU</H3>
								<DL><p>
									<DT><A HREF="https://melpa.org/#/">MELPA</A>
									<DT><A HREF="https://www.gnu.org/software/emacs/download.html#nonfree">Emacs download</A>
									<DT><A HREF="https://www.gnu.org/software/emacs/refcards/pdf/refcard.pdf">GNU Emacs Reference Card</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/GNU_Autotools">GNU Autotools - Wikipedia</A>
									<DT><A HREF="https://www.gnu.org/software/bash/manual/html_node/">Top (Bash Reference Manual)</A>
								</DL><p>
								<DT><H3 FOLDED>ssh</H3>
								<DL><p>
									<DT><H3 FOLDED>clusterssh</H3>
									<DL><p>
										<DT><A HREF="https://github.com/duncs/clusterssh">duncs/clusterssh: Cluster SSH - Cluster Admin Via SSH</A>
										<DT><A HREF="https://www.hackplayers.com/2016/11/clusterssh-o-como-manejar-varios-ssh.html">ClusterSSH o c√≥mo manejar varias sesiones SSH de forma concurrente</A>
									</DL><p>
									<DT><H3 FOLDED>ssh-keygen</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chadmayfield/scriptlets/blob/master/fixssh.py">ssh-keygen -R &lt;hostname&gt; fixssh.py</A>
										<DT><A HREF="https://docs.docker.com/engine/containers/resource_constraints/">Resource constraints: --cpuset-cpus=0-7</A>
										<DT><A HREF="https://www.ssh.com/academy/ssh/keygen">ssh-keygen -t ed25519</A>
									</DL><p>
									<DT><H3 FOLDED>ssh-add</H3>
									<DL><p>
										<DT><A HREF="https://claude.ai/chat/99118603-933e-4048-a3d4-e0cc427eecfd">SSH -A agent forwarding explained: ssh-add -l</A>
										<DT><A HREF="https://linux.die.net/man/1/ssh-add">ssh-add(1) - Linux man page</A>
									</DL><p>
									<DT><A HREF="https://docs.digitalocean.com/products/droplets/how-to/add-ssh-keys/create-with-openssh/">How to Create SSH Keys with OpenSSH on MacOS or Linux :: DigitalOcean Documentation</A>
									<DT><A HREF="https://docs.digitalocean.com/products/droplets/how-to/connect-with-ssh/">How to Connect to Droplets with SSH :: DigitalOcean Documentation</A>
									<DT><A HREF="https://linuxize.com/post/using-the-ssh-config-file/">Using the SSH Config File | Linuxize</A>
									<DT><A HREF="https://www.openssh.com/">OpenSSH</A>
									<DT><A HREF="https://www.ssh.com/academy/ssh/keygen">What is ssh-keygen &amp; How to Use It to Generate a New SSH Key?</A>
									<DT><A HREF="https://www.ssh.com/academy/ssh/copy-id">What is ssh-copy-id? How ssh-copy-id works?</A>
									<DT><A HREF="https://aistudio.google.com/app/prompts/1v0BYzOpN_R8BUbFEIYQsoqZV1QWHRE1c?pli=1">torch.distributed torchrun | Google AI Studio</A>
									<DT><A HREF="https://grok.com/chat/8625fbd9-dd3d-44ad-9239-fd2dd3c39538">SSH Key Management: known_hosts new IP same DNS mapping</A>
								</DL><p>
								<DT><H3 FOLDED>linux-checkpoint</H3>
								<DL><p>
									<DT><H3 FOLDED>wasm-containers</H3>
									<DL><p>
										<DT><H3 FOLDED>Hyperlight</H3>
										<DL><p>
											<DT><A HREF="https://opensource.microsoft.com/blog/2025/03/26/hyperlight-wasm-fast-secure-and-os-free/">Hyperlight Wasm: Fast, secure, and OS-free - Microsoft Open Source Blog</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/checkpoint-restore/criu">checkpoint-restore/criu: Checkpoint/Restore tool</A>
									<DT><A HREF="https://github.com/checkpoint-restore/checkpointctl">checkpoint-restore/checkpointctl: A tool for in-depth analysis of container checkpoints</A>
									<DT><A HREF="https://criu.org/Docker">Docker - CRIU</A>
								</DL><p>
								<DT><H3 FOLDED>linux-kernel-versions</H3>
								<DL><p>
									<DT><H3 FOLDED>linux-kernel-6.10</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=mphUtoCD5SU">Kernel 6.10 | Locked &amp; Optimized - YouTube</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>linux-storage</H3>
								<DL><p>
									<DT><H3 FOLDED>s3</H3>
									<DL><p>
										<DT><H3 FOLDED>boto3</H3>
										<DL><p>
											<DT><A HREF="https://github.com/chengzeyi/model-deploy/commit/0466b871e3d5808f5080063a87f176661ac5a293">enable boto3 debug logging ¬∑ chengzeyi/model-deploy@0466b87</A>
											<DT><A HREF="https://grok.com/chat/a9b1d4fb-d40e-44f7-8d36-6cf4815f2e91">Making Boto3 S3 Work with Google Cloud Storage - Grok</A>
										</DL><p>
										<DT><H3 FOLDED>s5cmd</H3>
										<DL><p>
											<DT><A HREF="https://github.com/peak/s5cmd">peak/s5cmd: Parallel S3 and local filesystem execution tool.</A>
											<DT><A HREF="https://github.com/trojblue/s5cmd-python">trojblue/s5cmd-python: python binding for using s5cmd to download and upload files to s3 efficiently</A>
										</DL><p>
										<DT><H3 FOLDED>minio</H3>
										<DL><p>
											<DT><A HREF="https://github.com/minio/minio">minio/minio: MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.</A>
										</DL><p>
										<DT><A HREF="https://blog.glennklockwood.com/2025/02/llm-training-without-parallel-file.html">LLM training without a parallel file system</A>
									</DL><p>
									<DT><H3 FOLDED>azcopy</H3>
									<DL><p>
										<DT><A HREF="https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10?tabs=apt">Copy or move data to Azure Storage by using AzCopy v10 | Microsoft Learn</A>
										<DT><A HREF="https://grok.com/chat/254a464f-5356-43b4-98ce-13d956cdbc91">Downloading Azure Blob Storage with s5cmd via Minio - Grok</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>linux-diagnostics</H3>
								<DL><p>
									<DT><H3 FOLDED>dmesg</H3>
									<DL><p>
										<DT><A HREF="https://oneemptymind.wordpress.com/2018/06/12/dmesg-with-human-readable-timestamps/">dmesg with human readable timestamps: dmesg -T</A>
										<DT><A HREF="https://snippets.bentasker.co.uk/posts/bash/dmesg-with-human-readable-timestamps.html">DMesg with human readable timestamps (BASH) | snippets.bentasker.co.uk</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://ss64.com/osx/">An A-Z Index of the Apple macOS command line</A>
								<DT><A HREF="https://learnubuntu.com/list-users/">How to List Users in Ubuntu Command Line</A>
								<DT><A HREF="https://unix.stackexchange.com/questions/20979/how-do-i-list-all-installed-programs">application - How do I list all installed programs?</A>
								<DT><A HREF="https://unix.stackexchange.com/questions/561263/how-to-get-a-list-of-which-packages-were-installed-with-apt-get-by-a-user-and-no">How to get a list of which packages were installed with apt-get by a user and not by dependencies?</A>
								<DT><A HREF="https://www.cyberciti.biz/faq/create-a-user-account-on-ubuntu-linux/">How to create a user account on Ubuntu Linux - nixCraft</A>
								<DT><A HREF="https://www.youtube.com/watch?v=vnBCnd2L0dY">Linux Experts Read 'info' Pages (NOT 'man' pages) - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=d0gS5TXarXc&t=80s">Signals. I spent 2 years to understand this part</A>
								<DT><A HREF="https://github.com/facebookincubator/below?tab=readme-ov-file">facebookincubator/below: A time traveling resource monitor for modern Linux systems</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Ia5jyz8sOCM">No really, how does Linux run executables?</A>
							</DL><p>
							<DT><H3 FOLDED>macOS</H3>
							<DL><p>
								<DT><H3 FOLDED>M1</H3>
								<DL><p>
									<DT><A HREF="https://support.apple.com/en-us/HT211861">Rosetta 2 overview</A>
									<DT><A HREF="https://medium.com/mkdir-awesome/how-to-install-x86-64-homebrew-packages-on-apple-m1-macbook-54ba295230f">How to Install x86_64 Homebrew Packages on Apple M1 MacBook</A>
									<DT><A HREF="https://news.ycombinator.com/item?id=25132217">Run x86 Apps (including homebrew) in the Terminal on Apple Silicon | Hacker News</A>
									<DT><A HREF="https://wickedchicken.github.io/post/macos-nix-setup/">MacOS Nix Setup (an alternative to Homebrew)</A>
									<DT><H3 FOLDED>monitoring</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tlkh/asitop">tlkh/asitop: Perf monitoring CLI tool for Apple Silicon (nvtop)</A>
									</DL><p>
									<DT><H3 FOLDED>m1-monitoring</H3>
									<DL><p>
										<DT><A HREF="https://github.com/tlkh/asitop">tlkh/asitop: Perf monitoring CLI tool for Apple Silicon (nvtop)</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>finder</H3>
								<DL><p>
									<DT><A HREF="https://support.apple.com/guide/mac-help/see-the-devices-connected-to-your-mac-mchlp1039/mac">Finder options: Connected devices</A>
									<DT><A HREF="https://mac4u.tech/how-to-see-hidden-files-and-folders-in-macos-big-sur/">How to see hidden files and folders in Apple macOS Big Sur</A>
								</DL><p>
								<DT><H3 FOLDED>xterm</H3>
								<DL><p>
									<DT><A HREF="https://zsh.sourceforge.io/Doc/Release/Prompt-Expansion.html#Prompt-Expansion">zsh: 13 Prompt Expansion</A>
									<DT><A HREF="https://www.makeuseof.com/customize-zsh-prompt-macos-terminal/">PS1</A>
									<DT><A HREF="https://www.cyberciti.biz/faq/change-default-shell-to-bash-on-macos-catalina/">chsh (Catalina/BigSur)</A>
								</DL><p>
								<DT><A HREF="https://support.apple.com/en-hk/guide/terminal/apdc6c1077b-5d5d-4d35-9c19-60f2397b2369/2.10/mac/10.15">launchd - manage daemons and agents</A>
								<DT><A HREF="https://discussions.apple.com/thread/250756110">show hidden files and folders</A>
								<DT><A HREF="https://www.cyberciti.biz/faq/apple-mac-osx-terminal-color-ls-output-option/">How to enable colorized output for ls command</A>
								<DT><A HREF="https://embeddedartistry.com/blog/2017/02/24/installing-llvm-clang-on-osx/">Installing LLVM/Clang on OS X</A>
								<DT><A HREF="https://ss64.com/osx/">An A-Z Index of the Apple macOS command line</A>
							</DL><p>
							<DT><H3 FOLDED>build from source</H3>
							<DL><p>
								<DT><H3 FOLDED>make</H3>
								<DL><p>
									<DT><H3 FOLDED>debug</H3>
									<DL><p>
										<DT><A HREF="https://chat.openai.com/c/926b55b6-8995-4593-aff8-3150238c1398">.PHONY: debug \n debug: @echo</A>
									</DL><p>
									<DT><H3 FOLDED>makefile</H3>
									<DL><p>
										<DT><A HREF="https://github.com/pytorch/pytorch/blob/main/docker.Makefile">pytorch/docker.Makefile at main ¬∑ pytorch/pytorch</A>
									</DL><p>
									<DT><A HREF="https://chat.openai.com/c/926b55b6-8995-4593-aff8-3150238c1398">.PHONY: debug \n debug: @echo</A>
									<DT><H3 FOLDED>untitled folder</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>make-debug</H3>
									<DL><p>
										<DT><A HREF="https://chat.openai.com/c/926b55b6-8995-4593-aff8-3150238c1398">.PHONY: debug \n debug: @echo</A>
									</DL><p>
									<DT><H3 FOLDED>cmake</H3>
									<DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/lcy-seso/DLFrameworkTest/pull/54/files">feat: TMA load without cute API. by lcy-seso ¬∑ Pull Request #54 ¬∑ lcy-seso/DLFrameworkTest</A>
								</DL><p>
								<DT><H3 FOLDED>from-source-linker-(ld)</H3>
								<DL><p>
									<DT><A HREF="https://stackoverflow.com/questions/9688200/difference-between-shared-objects-so-static-libraries-a-and-dlls-so">Difference shared objects (.so), static libraries (.a), and DLL's (.so)</A>
								</DL><p>
								<DT><H3 FOLDED>shared-libraries</H3>
								<DL><p>
									<DT><A HREF="https://www.hpc.dtu.dk/?page_id=1180">LD_LIBRARY_PATH ‚Äì or: How to get yourself into trouble!</A>
									<DT><A HREF="https://askubuntu.com/questions/1461829/set-ld-library-path-for-with-symlinks">environment variables - Set LD_LIBRARY_PATH for with symlinks - Ask Ubuntu</A>
									<DT><A HREF="https://help.ubuntu.com/community/EnvironmentVariables#File-location_related_variables">EnvironmentVariables - Community Help Wiki</A>
								</DL><p>
								<DT><H3 FOLDED>nix</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=iPoL03tFBtU">Docker Was Too Slow, So We Replaced It: Nix in Production - YouTube</A>
								</DL><p>
								<DT><A HREF="https://serverfault.com/questions/46381/learning-to-compile-things-from-source-on-unix-linux-osx">compile things from source</A>
								<DT><A HREF="https://zig.news/kristoff/compile-a-c-c-project-with-zig-368j">Compile a C/C++ Project with Zig - Zig NEWS</A>
								<DT><A HREF="https://www.youtube.com/watch?v=wFlyUzUVFhw">Zig Build System &amp; How to Build Software From Source ‚Ä¢ Andrew Kelley ‚Ä¢ GOTO 2023 - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=wFlyUzUVFhw">Zig Build System &amp; How to Build Software From Source ‚Ä¢ Andrew Kelley</A>
							</DL><p>
							<DT><H3 FOLDED>build-system</H3>
							<DL><p>
								<DT><H3 FOLDED>bazel</H3>
								<DL><p>
									<DT><H3 FOLDED>bazel-installation</H3>
									<DL><p>
										<DT><A HREF="https://blog.bazel.build/2018/08/22/bazel-homebrew.html">Bazel in Homebrew - Bazel</A>
										<DT><A HREF="https://docs.bazel.build/versions/main/install-os-x.html#install-with-installer-mac-os-x">Installing Bazel on macOS - Bazel main</A>
										<DT><A HREF="https://github.com/bazelbuild/bazelisk">bazelbuild/bazelisk: A user-friendly launcher for Bazel.</A>
										<DT><A HREF="https://formulae.brew.sh/formula/bazelisk">bazelisk ‚Äî Homebrew Formulae</A>
									</DL><p>
									<DT><H3 FOLDED>bazel-examples</H3>
									<DL><p>
										<DT><A HREF="https://github.com/bazelbuild/examples/tree/main/bzlmod/01-depend_on_bazel_module">examples/bzlmod/01-depend_on_bazel_module</A>
										<DT><A HREF="https://github.com/grpc/grpc/blob/d68161a64f191b8d8d5afe0507e7a2291f91ff1a/examples/protos/BUILD">grpc/examples/protos/BUILD "helloworld"</A>
									</DL><p>
									<DT><H3 FOLDED>bazel-v7</H3>
									<DL><p>
										<DT><A HREF="https://github.com/bazelbuild/bazel/issues/18958">enable_bzlmod: Flip the default value of `--enable_bzlmod` to true ¬∑ Issue #18958 ¬∑ bazelbuild/bazel</A>
									</DL><p>
									<DT><H3 FOLDED>bazel-modules</H3>
									<DL><p>
										<DT><H3 FOLDED>bazel-dependency-graph</H3>
										<DL><p>
											<DT><A HREF="https://bazel.build/tutorials/cpp-dependency">Review the dependency graph ¬†|¬† Bazel</A>
										</DL><p>
										<DT><A HREF="https://bazel.build/external/module">Bazel modules</A>
										<DT><A HREF="https://bazel.build/rules/lib/globals/module">MODULE.bazel files ¬†|¬† Bazel</A>
										<DT><A HREF="https://docs.google.com/document/d/1moQfNcEIttsk6vYanNKIy3ZuK53hQUFq1b1r0rmsYVg/edit">Bazel External Dependencies Overhaul</A>
										<DT><A HREF="https://github.com/bazelbuild/bazel/issues/18958">enable_bzlmod: Flip the default value of `--enable_bzlmod` to true ¬∑ Issue #18958 ¬∑ bazelbuild/bazel</A>
									</DL><p>
									<DT><H3 FOLDED>bazel-starlark</H3>
									<DL><p>
										<DT><A HREF="https://github.com/google/starlark-go">google/starlark-go: Starlark in Go: the Starlark configuration language, implemented in Go</A>
										<DT><A HREF="https://github.com/search?q=repo%3Azml%2Fzml++language%3AStarlark&type=code">zml building examples</A>
									</DL><p>
									<DT><H3 FOLDED>bazel-rules</H3>
									<DL><p>
										<DT><H3 FOLDED>cpp</H3>
										<DL><p>
											<DT><A HREF="https://github.com/bazelbuild/examples/blob/main/cpp-tutorial/stage1/main/hello-world.cc">examples/cpp-tutorial/stage1/main/hello-world.cc at main ¬∑ bazelbuild/examples</A>
											<DT><A HREF="https://docs.bazel.build/versions/1.0.0/tutorial/cpp.html#understand-the-build-file">Build Tutorial - C++ - Bazel 1.0.0</A>
											<DT><A HREF="https://bazel.build/tutorials/cpp-dependency">Review the dependency graph ¬†|¬† Bazel</A>
										</DL><p>
										<DT><H3 FOLDED>rust</H3>
										<DL><p>
											<DT><A HREF="https://news.ycombinator.com/item?id=24847702">Not exactly true. Google uses Bazel for Rust code</A>
											<DT><A HREF="https://github.com/bazelbuild/rules_rust/tree/main/examples/ffi">rules_rust</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://github.com/OasisDigital/bazelcon-2019">OasisDigital/bazelcon-2019: Bazel examples for Bazel Boot Camp</A>
									<DT><A HREF="https://www.google.com/search?q=papers+on+Googles+build+infrastructure+bazel&client=safari&rls=en&sxsrf=AOaemvLW8YwdatuWueomwqIEZZgYu-7-Cw%3A1642121078072&ei=dsfgYYvjA9DSa727vMgG&ved=0ahUKEwiL9qTcgbD1AhVQ6RoKHb0dD2kQ4dUDCA0&uact=5&oq=papers+on+Googles+build+infrastructure+bazel&gs_lcp=Cgdnd3Mtd2l6EAMyBwghEAoQoAE6BwgAEEcQsAM6BQghEKsCSgQIQRgASgQIRhgAUJsDWOEJYLELaAFwAHgAgAGVAYgB5gWSAQMwLjaYAQCgAQHIAQjAAQE&sclient=gws-wiz">papers on Googles build infrastructure bazel - Google Search</A>
									<DT><A HREF="https://oasisdigital.com/class/bazel">Building with Bazel | Oasis Digital</A>
									<DT><A HREF="https://www.buildbuddy.io/">BuildBuddy</A>
									<DT><A HREF="https://bazel.build/reference/glossary#dependency">Bazel Glossary</A>
									<DT><A HREF="https://docs.google.com/document/d/1moQfNcEIttsk6vYanNKIy3ZuK53hQUFq1b1r0rmsYVg/edit">Bazel External Dependencies Overhaul - Documentos de Google</A>
									<DT><A HREF="https://www.visualcapitalist.com/wp-content/uploads/2017/02/1276_lines_of_code_sep2015_fb.png">1276_lines_of_code_sep2015_fb.png 1.276√ó4.670 pixels</A>
									<DT><A HREF="https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#:~:text=Google%2DScale&text=The%20Google%20codebase%20includes%20approximately,Google's%20entire%2018%2Dyear%20existence">Why Google Stores Billions of Lines of Code in a Single Repository (monorepo)</A>
									<DT><A HREF="https://github.com/jetstack/cert-manager/pull/4184/files/611bac67cf6dc8b58130b9cb43486d4ddda1b387#diff-23618edb36c476683f5a0c453d4d8fdb296b4c9fc3b21163dbd05b0c7d038708">code example in Go</A>
									<DT><A HREF="https://docs.bazel.build/versions/1.0.0/tutorial/cpp.html#understand-the-build-file">Build Tutorial - C++ - Bazel 1.0.0</A>
									<DT><A HREF="https://www.reddit.com/r/bazel/">bazel subreddit</A>
									<DT><A HREF="https://blog.bazel.build/2024/12/09/bazel-8-release.html">Bazel 8.0 LTS - Bazel</A>
									<DT><A HREF="https://www.youtube.com/watch?v=mPtRKrM6FTA">Building Real-time Systems with Bazel w/ SpaceX - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>facebook-getdeps</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebook/proxygen/blob/8e338869dc41dee6d197d5cf627482f0a9159bb8/build/fbcode_builder/README.md">proxygen/build/fbcode_builder/README.md at 8e338869dc41dee6d197d5cf627482f0a9159bb8 ¬∑ facebook/proxygen</A>
								</DL><p>
								<DT><H3 FOLDED>language-interoperability</H3>
								<DL><p>
									<DT><A HREF="https://github.com/kriasoft/relay-starter-kit/blob/c985206/src/utils/password_hash.cc">NAPI C++ example</A>
									<DT><A HREF="https://koistya.medium.com/how-to-call-c-c-code-from-node-js-86a773033892">How to call C/C++ code from Node.js</A>
									<DT><A HREF="https://en.wikipedia.org/wiki/Interface_description_language">Interface description language (IDL) - Wikipedia</A>
									<DT><A HREF="https://cxx.rs/">Rust ‚ù§Ô∏è C++</A>
								</DL><p>
								<DT><H3 FOLDED>build-system-papers</H3>
								<DL><p>
									<DT><A HREF="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45880.pdf">google CI</A>
									<DT><A HREF="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems-final.pdf">Build Systems aÃÄ la Carte</A>
								</DL><p>
								<DT><A HREF="https://scons.org/">SCons: A software construction tool - SCons</A>
								<DT><A HREF="https://docs.engflow.com/docs/re.html">Remote Execution Service | Documentation</A>
								<DT><A HREF="https://github.com/web3infra-foundation/mega">web3infra-foundation/mega: Mega is an unofficial open source implementation of Google Piper.</A>
								<DT><A HREF="https://buck2.build/">Buck2 build system website | Buck2</A>
								<DT><A HREF="https://github.com/facebook/buck2/tree/main/examples/hello_world">buck2/examples/hello_world at main ¬∑ facebook/buck2</A>
								<DT><A HREF="https://github.com/facebook/buck2/blob/main/examples/hello_world/BUCK">buck2/examples/hello_world/BUCK at main ¬∑ facebook/buck2</A>
								<DT><A HREF="https://github.com/facebook/buck2">facebook/buck2: Build system, successor to Buck</A>
							</DL><p>
							<DT><H3 FOLDED>os-file-formats</H3>
							<DL><p>
								<DT><H3 FOLDED>parquet</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=bISBNVtXZ6M">Nimble, A New Columnar File Format - Yoav Helfman, Meta - YouTube</A>
								<DT><A HREF="https://github.com/facebookexternal/nimble">facebookexternal/nimble: New file format for storage of large columnar datasets.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-ZtyRgD1c40">Velox and Composable Data Management - Pedro Pedreira, Meta - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=bISBNVtXZ6M&t=1169s">Nimble, A New Columnar File Format - Yoav Helfman, Meta - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>os-emulation</H3>
							<DL><p>
								<DT><A HREF="https://fms.komkon.org/EMUL8/HOWTO.html">HOWTO: Writing a Computer Emulator</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Kq849CpGd88">QEMU Performance</A>
							</DL><p>
							<DT><H3 FOLDED>security</H3>
							<DL><p>
								<DT><A HREF="https://arstechnica.com/security/2024/07/secure-boot-is-completely-compromised-on-200-models-from-5-big-device-makers/">Secure Boot is completely broken on 200+ models from 5 big device makers | Ars Technica</A>
								<DT><A HREF="https://www.youtube.com/watch?v=eKpv5xjSqs0">this is getting ridiculous... - YouTube</A>
							</DL><p>
							<DT><A HREF="https://en.wikipedia.org/wiki/POSIX">POSIX</A>
							<DT><A HREF="https://www.youtube.com/watch?v=d0gS5TXarXc&t=80s">Signals. I spent 2 years to understand this part</A>
							<DT><A HREF="https://github.com/sdmg15/Best-websites-a-programmer-should-visit?tab=readme-ov-file">sdmg15/Best-websites-a-programmer-should-visit: :link: Some useful websites for programmers.</A>
						</DL><p>
						<DT><H3 FOLDED>supercomputing-networking</H3>
						<DL><p>
							<DT><H3 FOLDED>IP</H3>
							<DL><p>
								<DT><A HREF="https://lwn.net/Articles/960913/">So you think you understand IP fragmentation? [LWN.net]</A>
							</DL><p>
							<DT><H3 FOLDED>RDMA</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=kDJHA7TNtDk">NSDI '23 - Empowering Azure Storage with RDMA - YouTube</A>
								<DT><A HREF="https://le.qun.ch/en/blog/2024/12/25/libfabric-efa-0-intro/">Harnessing 3200 Gbps Network: A Journey with RDMA, EFA, and libfabric</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/329198771">12. RDMA‰πãVerbs - Áü•‰πé</A>
								<DT><A HREF="https://www.zhihu.com/column/c_1231181516811390976">RDMAÊùÇË∞à - Áü•‰πé</A>
								<DT><A HREF="https://research.perplexity.ai/articles/weight-transfer-for-rl-post-training-in-under-2-seconds">Weight Transfer for RL Post-Training in under 2 seconds</A>
								<DT><A HREF="https://le.qun.ch/en/blog/2025/11/09/rdma-p2p-for-llm/">Explorations of RDMA in LLM Systems</A>
								<DT><A HREF="https://github.com/perplexityai/pplx-garden">perplexityai/pplx-garden: Perplexity open source garden for inference technology</A>
								<DT><A HREF="https://github.com/perplexityai/pplx-garden/blob/main/benchmarks/bench_all_to_all.py">pplx-garden/benchmarks/bench_all_to_all.py at main ¬∑ perplexityai/pplx-garden</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/1982525738998588869">[Notes] RDMA Basics</A>
								<DT><A HREF="https://mp.weixin.qq.com/s?__biz=MzUxNzQ5MTExNw==&mid=2247495506&idx=1&sn=385c2b750379214ea1deefaf7587837b&scene=21&poc_token=HJmkd2mjNoN3CIT1c2XNEQFchJwHawJS1wRFa0OZ">Discuss reliable transmission using RDMA and ScaleUP.</A>
							</DL><p>
							<DT><A HREF="https://www.linkedin.com/pulse/network-acceleration-genai-workloads-sharada-yeluri-g8xbc/?trackingId=4J97SZQpTwenJBkn4Hr6nA%3D%3D">(1) In Network Acceleration for AI/ML Workloads | LinkedIn</A>
							<DT><A HREF="https://www.linkedin.com/pulse/gpu-fabrics-genai-workloads-sharada-yeluri-j8ghc/?trackingId=5mCxOsDBSoG07wlKbx6o2g%3D%3D">(1) GPU Fabrics for GenAI Workloads | LinkedIn</A>
							<DT><A HREF="https://www.linkedin.com/pulse/network-acceleration-genai-workloads-sharada-yeluri-g8xbc/?trackingId=JYRFyD33QkmHY5eoE24rCg%3D%3D">(1) In Network Acceleration for AI/ML Workloads | LinkedIn</A>
							<DT><A HREF="https://www.linkedin.com/pulse/llm-inference-hwsw-optimizations-sharada-yeluri-wfdyc/?trackingId=IAo88qPrQLeVto9JLwix6w%3D%3D">(1) LLM Inference - HW/SW Optimizations | LinkedIn</A>
							<DT><A HREF="https://www.linkedin.com/pulse/tearing-down-memory-wall-sharada-yeluri/?trackingId=dn9NrSPARD2R%2BUQ9KN6CXQ%3D%3D">(1) Tearing Down the Memory Wall | LinkedIn</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ck4WvYM9V4c">Linux Networking: How The Kernel Handles A TCP Connection - YouTube</A>
							<DT><A HREF="https://github.com/coreweave/perftest">coreweave/perftest: Infiniband Verbs Performance Tests</A>
							<DT><A HREF="https://www.youtube.com/watch?v=kH7P1ZX44DQ&t=997s">How to Design a Network Messaging Protocol! - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>cluster-health-checks</H3>
						<DL><p>
							<DT><H3 FOLDED>Node Health Check (nhc)</H3>
							<DL><p>
								<DT><A HREF="https://github.com/mej/nhc">mej/nhc: LBNL Node Health Check</A>
							</DL><p>
							<DT><H3 FOLDED>cluster-health-nccl</H3>
							<DL><p>
								<DT><A HREF="https://gist.github.com/geohot/e11dc1b1058ed9e0bc6610249263b024">Test Bandwidth of all reduce</A>
								<DT><A HREF="https://github.com/NVIDIA/nccl-tests">NVIDIA/nccl-tests: NCCL Tests</A>
								<DT><A HREF="https://github.com/alpa-projects/alpa/blob/main/playground/other/test_cupy_partial_transfer.py">alpa/playground/other/test_cupy_partial_transfer.py at main ¬∑ alpa-projects/alpa</A>
							</DL><p>
							<DT><H3 FOLDED>azurehpc</H3>
							<DL><p>
								<DT><A HREF="https://github.com/Azure/azurehpc-health-checks">Azure/azurehpc-health-checks: Health checks for Azure N- and H-series VMs.</A>
								<DT><A HREF="https://github.com/search?q=repo%3AAzure%2Fazurehpc-health-checks%20ALL_REDUCE_PATH&type=code">ALL_REDUCE_PATH: nccl-tests</A>
							</DL><p>
							<DT><H3 FOLDED>coreweave-tests</H3>
							<DL><p>
								<DT><H3 FOLDED>reference-architecture</H3>
								<DL><p>
									<DT><A HREF="https://github.com/coreweave/reference-architecture/tree/main">coreweave/reference-architecture</A>
								</DL><p>
								<DT><H3 FOLDED>perftest</H3>
								<DL><p>
									<DT><A HREF="https://github.com/coreweave/perftest">coreweave/perftest: Infiniband Verbs Performance Tests</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>1X-cluster</H3>
							<DL><p>
								<DT><A HREF="https://github.com/DataCrunch-io/1x-cluster/tree/main">DataCrunch-io/1x-cluster: Ansible Project to create users</A>
								<DT><A HREF="https://github.com/datacrunch-research/cluster-job-orchestration/blob/main/health_check/health_checks.py#L164">cluster-job-orchestration/health_check/health_checks.py at main ¬∑ datacrunch-research/cluster-job-orchestration</A>
							</DL><p>
							<DT><A HREF="https://github.com/imbue-ai/cluster-health">imbue-ai/cluster-health</A>
							<DT><A HREF="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">Linux Performance Analysis in 60,000 Milliseconds | by Netflix Technology Blog | Netflix TechBlog</A>
							<DT><A HREF="https://imbue.com/research/70b-infrastructure/">From bare metal to a 70B model: infrastructure set-up and scripts - imbue</A>
							<DT><A HREF="https://github.com/HanGuo97/cluster-utils/blob/master/server.py">cluster-utils/server.py at master ¬∑ HanGuo97/cluster-utils</A>
							<DT><A HREF="https://developer.nvidia.com/blog/automate-kubernetes-ai-cluster-health-with-nvsentinel/">Automate Kubernetes AI Cluster Health with NVSentinel | NVIDIA Technical Blog</A>
						</DL><p>
						<DT><H3 FOLDED>Systems Performance: Enterprise and the Cloud</H3>
						<DL><p>
							<DT><H3 FOLDED>eBPF</H3>
							<DL><p>
								<DT><H3 FOLDED>ebpf-learning</H3>
								<DL><p>
									<DT><A HREF="https://github.com/eunomia-bpf/bpf-developer-tutorial">eunomia-bpf/bpf-developer-tutorial: eBPF Developer Tutorial: Learning eBPF Step by Step with Examples</A>
								</DL><p>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/bpftoolkit">Netflix-Skunkworks/bpftoolkit</A>
								<DT><A HREF="https://www.youtube.com/watch?v=7pmXdG8-7WU&list=PLZT-fvrVTVfPVLkSYPlGo6Vwp9uze9H2q&index=5">Netflix talks about Extended BPF - A new software type</A>
								<DT><A HREF="https://manpages.ubuntu.com/manpages/focal/en/man8/biosnoop.bt.8.html">biosnoop.bt - Block I/O tracing tool, showing per I/O latency</A>
								<DT><A HREF="https://github.com/aquasecurity/tracee">aquasecurity/tracee: Linux Runtime Security and Forensics using eBPF</A>
								<DT><A HREF="https://github.com/Netflix/bpftop">Netflix/bpftop: bpftop provides a dynamic real-time view of running eBPF programs. It displays the average runtime, events per second, and estimated total CPU % for each program.</A>
							</DL><p>
							<DT><H3 FOLDED>WSPerfLab</H3>
							<DL><p>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/WSPerfLab">Netflix-Skunkworks/WSPerfLab: Project for testing web-service implementations.</A>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/WSPerfLab/blob/master/test-results/RxNetty_vs_Tomcat_April2015.pdf">RxNetty vs Tomcat Performance Results</A>
							</DL><p>
							<DT><H3 FOLDED>Service Capacity Modeling</H3>
							<DL><p>
								<DT><H3 FOLDED>AWS</H3>
								<DL><p>
									<DT><A HREF="https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html">Amazon EBS volume types - Amazon EBS</A>
								</DL><p>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/service-capacity-modeling">Netflix-Skunkworks/service-capacity-modeling</A>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/service-capacity-modeling/blob/main/notebooks/demo.ipynb">service-capacity-modeling/notebooks/demo.ipynb at main ¬∑ Netflix-Skunkworks/service-capacity-modeling</A>
							</DL><p>
							<DT><H3 FOLDED>sys-perftools</H3>
							<DL><p>
								<DT><H3 FOLDED>Performance Monitoring Counters (PMC)</H3>
								<DL><p>
									<DT><A HREF="https://github.com/brendangregg/pmc-cloud-tools">brendangregg/pmc-cloud-tools: PMC (Performance Monitoring Counter) tools for the cloud</A>
									<DT><A HREF="https://www.brendangregg.com/blog/2017-05-04/the-pmcs-of-ec2.html">The PMCs of EC2: Measuring IPC</A>
									<DT><A HREF="https://twitter.com/__tinygrad__/status/1768408123826721045">tinybox shows:</A>
								</DL><p>
								<DT><A HREF="https://manpages.ubuntu.com/manpages/focal/en/man8/biosnoop.bt.8.html">biosnoop.bt - Block I/O tracing tool, showing per I/O latency</A>
								<DT><A HREF="https://github.com/hoytech/vmtouch">hoytech/vmtouch: Portable file system cache diagnostics and control</A>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/corepipe">Netflix-Skunkworks/corepipe: perform a coredump of a running process</A>
								<DT><A HREF="https://github.com/Netflix-Skunkworks/diffy">netflix/diffy: digital forensics and incident response (DFIR)</A>
								<DT><A HREF="https://www.redhat.com/sysadmin/stop-using-telnet-test-port">Stop using Telnet to test ports | Red Hat</A>
								<DT><A HREF="https://manpages.ubuntu.com/manpages/focal/en/man8/iotop.8.html">Ubuntu Manpage: iotop - simple top-like I/O monitor</A>
								<DT><A HREF="https://github.com/wagoodman/dive">wagoodman/dive: A tool for exploring each layer in a docker image</A>
								<DT><A HREF="https://justine.lol/rusage/">Portable rusage command: Report resource usage statistics when launching cmd programms</A>
								<DT><A HREF="https://chat.openai.com/c/6f34e9bd-60ae-4c54-848e-479b93d3e219">df -h: list disk usage of volumes or mount points</A>
								<DT><A HREF="https://mariusschulz.com/blog/fast-searching-with-ripgrep">Fast Searching with ripgrep</A>
								<DT><A HREF="https://github.com/facebookincubator/below">facebookincubator/below: A time traveling resource monitor for modern Linux systems</A>
							</DL><p>
							<DT><H3 FOLDED>observability</H3>
							<DL><p>
								<DT><A HREF="https://netflixtechblog.com/tagged/observability">Observability ‚Äì Netflix TechBlog</A>
								<DT><A HREF="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">Linux Performance Analysis in 60,000 Milliseconds | by Netflix Technology Blog | Netflix TechBlog</A>
							</DL><p>
							<DT><H3 FOLDED>linux-perf</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NAThompson/performance_tuning_tutorial">NAThompson/performance_tuning_tutorial: Performance Tuning Tutorial given at Oak Ridge National Laboratory</A>
							</DL><p>
							<DT><A HREF="https://www.brendangregg.com/">Performance Monitoring Counters (PMC)</A>
							<DT><A HREF="https://www.brendangregg.com/linuxperf.html">Linux Performance</A>
							<DT><A HREF="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">Linux Performance Analysis in 60,000 Milliseconds | by Netflix Technology Blog | Netflix TechBlog</A>
							<DT><A HREF="https://github.com/quickwit-oss/quickwit">quickwit-oss/quickwit: Cloud-native search engine for observability. An open-source alternative to Datadog, Elasticsearch, Loki, and Tempo.</A>
							<DT><A HREF="https://www.brendangregg.com/Slides/SBSRE_perf_meetup_aug2017.pdf">Netflix Performance Meetup (2017)</A>
							<DT><A HREF="https://github.com/facebook/watchman">facebook/watchman: Watches files and records, or triggers actions, when they change.</A>
							<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:activity:7189636365620240384/">Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services</A>
						</DL><p>
						<DT><H3 FOLDED>HPC</H3>
						<DL><p>
							<DT><H3 FOLDED>hpc-simulation</H3>
							<DL><p>
								<DT><A HREF="https://www.gameenginebook.com/">Game Engine Architecture</A>
							</DL><p>
							<DT><H3 FOLDED>hpc-observability</H3>
							<DL><p>
								<DT><A HREF="https://www.smartmontools.org/">smartmontools</A>
								<DT><A HREF="https://twitter.com/marcan42/status/1361151198921826308?lang=en">M1 SSD degradation</A>
								<DT><A HREF="https://serverfault.com/questions/480726/how-to-measure-total-writes-performed-to-ssd-in-linux">ubuntu - How to measure total writes performed to SSD in Linux? - Server Fault</A>
							</DL><p>
							<DT><H3 FOLDED>FluidX3D</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ProjectPhysX/FluidX3D">ProjectPhysX/FluidX3D: The fastest and most memory efficient lattice Boltzmann CFD software, running on all GPUs and CPUs via OpenCL. Free for non-commercial use.</A>
								<DT><A HREF="https://github.com/morkev/FluidX3D-easy-run">morkev/FluidX3D-easy-run: This is a ready to deploy fork of FluidX3D. For people that want to get started with Computer Fluid Dynamics.</A>
								<DT><A HREF="https://github.com/ProjectPhysX/OpenCL-Benchmark">ProjectPhysX/OpenCL-Benchmark: A small OpenCL benchmark program to measure peak GPU/CPU performance.</A>
							</DL><p>
							<DT><A HREF="https://web.stanford.edu/class/cs245/">CS 245: Principles of Data-Intensive Systems (Winter 2021)</A>
							<DT><A HREF="https://biojulia.net/post/hardware/">What scientists must know about hardware to write fast code</A>
							<DT><A HREF="https://unias.github.io/docklet/book/en/notebook/gallery.html#linguistics-and-text-mining">Scientific Computation ¬∑ GitBook</A>
							<DT><A HREF="https://willcrichton.net/notes/k-corrset/">Analyzing Data 180,000x Faster with Rust</A>
							<DT><A HREF="https://foresitelabs.com/">Homepage - Foresite Labs</A>
						</DL><p>
						<DT><H3 FOLDED>supercomputing-storage</H3>
						<DL><p>
							<DT><H3 FOLDED>fio</H3>
							<DL><p>
								<DT><A HREF="https://github.com/louwrentius/fio-plot">louwrentius/fio-plot: Create charts from FIO storage benchmark tool output</A>
								<DT><A HREF="https://github.com/datenlord/datenlord?tab=readme-ov-file">datenlord/datenlord: DatenLord, Computing Defined Storage, an application-orientated, cloud-native distributed storage system</A>
								<DT><A HREF="https://github.com/axboe/fio">axboe/fio: Flexible I/O Tester</A>
								<DT><A HREF="https://github.com/coreweave/ioperftest">coreweave/ioperftest: This repo holds the Public IO test scripts</A>
							</DL><p>
							<DT><A HREF="https://github.com/louwrentius/showtools">louwrentius/showtools: Shows detailed disk or network device information</A>
							<DT><A HREF="https://github.com/datenlord/s3-server">datenlord/s3-server: Generic S3 server implementation</A>
						</DL><p>
						<DT><H3 FOLDED>job scheduler</H3>
						<DL><p>
							<DT><H3 FOLDED>SLURM</H3>
							<DL><p>
								<DT><H3 FOLDED>slurm-containers</H3>
								<DL><p>
									<DT><H3 FOLDED>pyxis</H3>
									<DL><p>
										<DT><H3 FOLDED>datacrunch-on-demand-cluster-pyxis</H3>
										<DL><p>
											<DT><A HREF="https://gitlab.datacrunch.io/datacrunch/vm-images/-/commit/241c3fcbd2342d05c24cf1ac2d00e4b066dd2696">https://gitlab.datacrunch.io/datacrunch/vm-images/-/commit/241c3fcbd2342d05c24cf1ac2d00e4b066dd2696</A>
										</DL><p>
										<DT><A HREF="https://github.com/NVIDIA/pyxis">NVIDIA/pyxis: Container plugin for Slurm Workload Manager</A>
										<DT><A HREF="https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/dgx-cloud-benchmarking-on-azure/4410826">DGX Cloud Benchmarking on Azure | Microsoft Community Hub</A>
									</DL><p>
									<DT><H3 FOLDED>enroot</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/enroot">NVIDIA/enroot: A simple yet powerful tool to turn traditional container/OS images into unprivileged sandboxes.</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/pyxis">NVIDIA/pyxis: Container plugin for Slurm Workload Manager</A>
									<DT><A HREF="https://github.com/NVIDIA/enroot">NVIDIA/enroot: A simple yet powerful tool to turn traditional container/OS images into unprivileged sandboxes.</A>
									<DT><A HREF="https://chatgpt.com/c/67f94568-2c2c-800c-b9cf-a97b0777ad7c">SLURM Pyxis Enroot AI</A>
									<DT><A HREF="https://slurm.schedmd.com/SC24/Containers.pdf">Containers in Slurm</A>
									<DT><A HREF="https://github.com/yanring/Megatron-MoE-ModelZoo/blob/main/sbatch_benchmarking.sh">Megatron-MoE-ModelZoo/sbatch_benchmarking.sh at main ¬∑ yanring/Megatron-MoE-ModelZoo</A>
								</DL><p>
								<DT><H3 FOLDED>nccl-config</H3>
								<DL><p>
									<DT><A HREF="https://www.schedmd.com/slurm-version-25-05-0rc1-is-now-available/">Slurm Version 25.05.0rc1: multiple topology configurations per partition</A>
									<DT><A HREF="https://grok.com/chat/2fba2e7f-4b71-4cba-8fb4-a5e0b67d9070">SLURM Topology and nccl.conf Optimization - Grok</A>
								</DL><p>
								<DT><H3 FOLDED>slurm-topo</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/topograph/blob/main/docs/slurm.md">topograph/docs/slurm.md at main ¬∑ NVIDIA/topograph</A>
									<DT><A HREF="https://github.com/NVIDIA/topograph">NVIDIA/topograph: A toolkit for discovering cluster network topology.</A>
								</DL><p>
								<DT><H3 FOLDED>slurm-kubernetes</H3>
								<DL><p>
									<DT><H3 FOLDED>Slinky</H3>
									<DL><p>
										<DT><A HREF="https://slurm.schedmd.com/MISC25/Slinky-CUG2025.pdf">Slinky: The Missing Link Between Slurm and Kubernetes</A>
										<DT><A HREF="https://www.schedmd.com/publications/">Slurm Publications - SchedMD</A>
										<DT><A HREF="https://github.com/slinkyproject">SlinkyProject</A>
									</DL><p>
									<DT><A HREF="https://slurm.schedmd.com/SC22/Slurm-and-or-vs-Kubernetes.pdf">Slurm and kubernetes</A>
									<DT><A HREF="https://slurm.schedmd.com/MISC25/Slinky-CUG2025.pdf">Slinky: The Missing Link Between Slurm and Kubernetes</A>
									<DT><A HREF="https://www.youtube.com/watch?v=ts7bI51gRCo">Meta‚Äôs Kubernetes-based Portable AI Research Environment - Shaun Hopper, Meta &amp; Navarre Pratt - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>kubernetes-job-manager</H3>
								<DL><p>
									<DT><H3 FOLDED>GKE</H3>
									<DL><p>
										<DT><H3 FOLDED>gke-ray</H3>
										<DL><p>
											<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/ray-on-tpus-with-gke-a-more-native-experience">Ray on TPUs with GKE: A more native experience | Google Cloud Blog</A>
										</DL><p>
										<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/whats-new-with-gke-at-google-cloud-next">What‚Äôs new with GKE at Google Cloud Next</A>
									</DL><p>
									<DT><H3 FOLDED>Dynamic Resource Allocation</H3>
									<DL><p>
										<DT><A HREF="https://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna">Dynamic Resource Allocation for GPUs in Kubernetes - Google Docs</A>
										<DT><A HREF="https://www.youtube.com/watch?v=1QfShSQLsbs">Unlocking the Full Potential of GPUs for AI Workloads on Kubernetes - Kevin Klues, NVIDIA - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>kserve</H3>
									<DL><p>
										<DT><A HREF="https://github.com/kserve/modelmesh-serving">kserve/modelmesh-serving: Controller for ModelMesh</A>
									</DL><p>
									<DT><H3 FOLDED>basics</H3>
									<DL><p>
										<DT><A HREF="https://hamel.dev/notes/k8s/02-Basics.html">k8s</A>
										<DT><A HREF="https://www.youtube.com/watch?v=90kZRyPcRZw">Kubernetes Deconstructed: Understanding Kubernetes by Breaking It Down - Carson Anderson, DOMO - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>utils</H3>
									<DL><p>
										<DT><A HREF="https://github.com/alibaba/kt-connect">alibaba/kt-connect: A toolkit for Integrating with your kubernetes dev environment more efficiently</A>
										<DT><A HREF="https://github.com/alibaba/kubeskoop">alibaba/kubeskoop</A>
									</DL><p>
									<DT><A HREF="https://cloud.google.com/anthos-config-management/docs/concepts/kustomize">Configure Kubernetes with Kustomize ¬†|¬† Anthos Config Management ¬†|¬† Google Cloud</A>
									<DT><A HREF="https://www.youtube.com/watch?v=06bKlSmVwIg">CNCF Live Webinar: Overcoming the GPU shortage with virtual Kubelets &amp; distributed cloud - YouTube</A>
									<DT><A HREF="https://virtual-kubelet.io/">Virtual Kubelet | Home</A>
									<DT><A HREF="https://github.com/virtual-kubelet/virtual-kubelet">virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.</A>
									<DT><A HREF="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelet | Kubernetes</A>
									<DT><A HREF="https://www.youtube.com/watch?v=cwiAW5TZsfo">On-Demand Systems and Scaled Training Using the JobSet API - Abdullah Gharaibeh &amp; Vanessa Sochat - YouTube</A>
									<DT><A HREF="https://github.com/kubernetes/kubernetes/issues/95492">Kubernetes won't run 50,000 Jobs ¬∑ Issue #95492 ¬∑ kubernetes/kubernetes</A>
									<DT><A HREF="https://www.cncf.io/blog/2020/08/10/why-the-kubernetes-scheduler-is-not-enough-for-your-ai-workloads/">Scheduler (Level 2)</A>
									<DT><A HREF="https://www.run.ai/">Run:ai - AI Optimization and Orchestration</A>
									<DT><A HREF="https://www.cncf.io/wp-content/uploads/2020/10/Kube-two-level-RM.pdf">Kubernetes native two-level resource managment for AI workloads</A>
									<DT><A HREF="https://github.com/project-codeflare/multi-cluster-app-dispatcher">project-codeflare/multi-cluster-app-dispatcher: Holistic job manager on Kubernetes</A>
									<DT><A HREF="https://github.com/bentoml/Yatai">bentoml/Yatai: Model Deployment at Scale on Kubernetes ü¶ÑÔ∏è</A>
									<DT><A HREF="https://docs.aws.amazon.com/parallelcluster/latest/ug/build-image.html">buildImage - AWS ParallelCluster</A>
									<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/high-performance-aiml-storage-through-local-ssd-support-on-gke">High performance AI/ML storage through Local SSD support on GKE | Google Cloud Blog</A>
								</DL><p>
								<DT><H3 FOLDED>slurm-rest</H3>
								<DL><p>
									<DT><A HREF="https://slurm.schedmd.com/SC24/REST-API.pdf">slurmrestd</A>
								</DL><p>
								<DT><H3 FOLDED>slurm-directories</H3>
								<DL><p>
									<DT><A HREF="https://github.com/DataCrunch-io/1x-cluster/pull/36">Implement SLURM job-specific temporary directories on fast local storage #36</A>
								</DL><p>
								<DT><H3 FOLDED>slurm-prolog-epilog</H3>
								<DL><p>
									<DT><A HREF="https://github.com/DataCrunch-io/1x-cluster/pull/36/files#diff-de69d1f790fa74161a1356abc30e9206f0de501851950343b6104875722c4cae">Implement SLURM job-specific temporary directories on fast local storage by Guitaricet ¬∑ Pull Request #36 ¬∑ DataCrunch-io/1x-cluster</A>
									<DT><A HREF="https://slurm.schedmd.com/prolog_epilog.html">Slurm Workload Manager - Prolog and Epilog Guide</A>
								</DL><p>
								<DT><A HREF="https://slurm.schedmd.com/">slurm.schedmd.com</A>
								<DT><A HREF="https://github.com/GoogleCloudPlatform/slurm-gcp">GoogleCloudPlatform/slurm-gcp</A>
								<DT><A HREF="https://github.com/GoogleCloudPlatform/hpc-toolkit">GoogleCloudPlatform/hpc-toolkit: Cloud HPC Toolkit is an open-source software offered by Google Cloud which makes it easy for customers to deploy HPC environments on Google Cloud.</A>
								<DT><A HREF="https://github.com/facebookincubator/submitit">facebookincubator/submitit: Python 3.8+ toolbox for submitting jobs to Slurm</A>
								<DT><A HREF="https://github.com/NVIDIA/pyxis">NVIDIA/pyxis: Container plugin for Slurm Workload Manager</A>
								<DT><A HREF="https://github.com/datacrunch-research/micro/commit/d28f998269e735a540797589e7916be59c478dec">slurm guide ¬∑ datacrunch-research/micro@d28f998</A>
								<DT><A HREF="https://github.com/datacrunch-research/micro/blob/main/slurm/multinode-slurm.md">micro/slurm/multinode-slurm.md at main ¬∑ datacrunch-research/micro</A>
								<DT><A HREF="https://www.schedmd.com/publications/">Slurm Publications - SchedMD</A>
							</DL><p>
							<DT><H3 FOLDED>TorchX</H3>
							<DL><p>
								<DT><A HREF="https://pytorch.org/torchx/main/basics.html">Basic Concepts ‚Äî PyTorch/TorchX main documentation</A>
								<DT><A HREF="https://airflow.apache.org/">Apache Airflow</A>
								<DT><A HREF="https://pytorch.org/torchx/main/quickstart.html">Quickstart ‚Äî PyTorch/TorchX main documentation</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Y7T01L0a4G4">Automating PyTorch Using TorchX to Make Data Centric ML Workflows</A>
							</DL><p>
							<DT><A HREF="https://docs.cerebras.net/en/latest/wsc/getting-started/csctl.html#csctl">csctl: CLI tool for job monitoring ‚Äî Cerebras Developer Documentation</A>
							<DT><A HREF="https://github.com/GoogleCloudPlatform/hpc-toolkit">GoogleCloudPlatform/hpc-toolkit: Cloud HPC Toolkit is an open-source software offered by Google Cloud which makes it easy for customers to deploy HPC environments on Google Cloud.</A>
							<DT><A HREF="https://github.com/Google/saxml">google/saxml</A>
							<DT><A HREF="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/core/exp_manager.html">Experiment Manager ‚Äî NVIDIA NeMo</A>
							<DT><A HREF="https://github.com/google-deepmind/xmanager">google-deepmind/xmanager: A platform for managing machine learning experiments</A>
							<DT><A HREF="https://storage.googleapis.com/gresearch/xmanager/deepmind_xmanager_slides.pdf">XManager (Slides)</A>
							<DT><A HREF="https://github.com/google/xpk">google/xpk: xpk (Accelerated Processing Kit) is a software tool to help Cloud developers to orchestrate training jobs on accelerators such as TPUs and GPUs on GKE.</A>
							<DT><A HREF="https://github.com/GoogleCloudPlatform/ai-on-gke/blob/main/gke-a100-jax/train.py">ai-on-gke/gke-a100-jax/train.py at main ¬∑ GoogleCloudPlatform/ai-on-gke</A>
							<DT><A HREF="https://github.com/NVIDIA/pyxis">NVIDIA/pyxis: Container plugin for Slurm Workload Manager</A>
						</DL><p>
						<DT><H3 FOLDED>Cloud</H3>
						<DL><p>
							<DT><H3 FOLDED>GenAI Infrastructure</H3>
							<DL><p>
								<DT><H3 FOLDED>Open Compute Project (OCP)</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=2l6gI-ksdKs">What's inside a Facebook Datacenter Open Compute Rack? - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=PrOEznqzq40">Intro to the Open Compute Project OCP - YouTube</A>
									<DT><A HREF="https://www.cio.com/article/250874/how-and-why-facebook-excels-at-data-center-efficiency.html#:~:text=Facebook's%20data%20center%20design%2C%20which,in%20hours%20rather%20than%20months.">How (and Why) Facebook Excels at Data Center Efficiency</A>
									<DT><A HREF="https://engineering.fb.com/2022/10/18/open-source/ocp-summit-2022-grand-teton/">OCP Summit 2022: Open hardware for AI infrastructure</A>
									<DT><A HREF="https://www.opencompute.org/projects/cooling-environments">Cooling Environments ¬ª Open Compute Project</A>
									<DT><A HREF="https://www.youtube.com/watch?v=2udD56VHEK0">Facebook's Open Networking Hardware - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>GPU Platform</H3>
								<DL><p>
									<DT><A HREF="https://cos.googlesource.com/cos/tools">cos/tools - Git at Google</A>
									<DT><A HREF="https://github.com/GoogleCloudPlatform/cos-gpu-installer">GoogleCloudPlatform/cos-gpu-installer: Scripts to build and use a container to install GPU drivers on Container-Optimized OS images</A>
									<DT><A HREF="https://github.com/GoogleCloudPlatform/hpc-toolkit">GoogleCloudPlatform/hpc-toolkit: Cloud HPC Toolkit is an open-source software offered by Google Cloud which makes it easy for customers to deploy HPC environments on Google Cloud.</A>
									<DT><A HREF="https://github.com/GoogleCloudPlatform/slurm-gcp#hybrid">GoogleCloudPlatform/slurm-gcp</A>
									<DT><A HREF="https://docs.coreweave.com/coreweave-machine-learning-and-ai/get-started-with-ml-and-ai#sunk-slurm-on-kubernetes">Sunk: SLURM on Kubernetes (CoreWeave)</A>
									<DT><A HREF="https://github.com/coreweave/kubernetes-cloud">coreweave/kubernetes-cloud: Getting Started with the CoreWeave Kubernetes GPU Cloud</A>
									<DT><A HREF="https://googlecloudplatform.github.io/magic-modules/">Overview | Magic Modules</A>
									<DT><A HREF="https://github.com/GoogleCloudPlatform/ml-testing-accelerators/tree/52b290a149b760b270085d4f8191188f986047ed">GoogleCloudPlatform/ml-testing-accelerators</A>
								</DL><p>
								<DT><A HREF="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/">Building Meta‚Äôs GenAI Infrastructure - Engineering at Meta</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ptGDaGUXInw">Mark Russinovich | Generative AI in the Cloud: Inside Microsoft AI Innovation - YouTube</A>
								<DT><A HREF="https://arxiv.org/pdf/2311.18677.pdf">Splitwise: Efficient Generative LLM Inference Using Phase Splitting (MS)</A>
								<DT><A HREF="https://github.com/S-LoRA/S-LoRA">S-LoRA/S-LoRA: S-LoRA: Serving Thousands of Concurrent LoRA Adapters</A>
								<DT><A HREF="https://github.com/predibase/lorax">predibase/lorax: Multi-LoRA inference server that scales to 1000s of fine-tuned LLMs</A>
								<DT><A HREF="https://github.com/sabetAI/BLoRA">sabetAI/BLoRA: batched loras</A>
								<DT><A HREF="https://arxiv.org/abs/2305.07759">[2305.07759] TinyStories: How Small Can Language Models Be and Still Speak Coherent English?</A>
								<DT><A HREF="https://arxiv.org/abs/2306.11644">[2306.11644] Textbooks Are All You Need</A>
								<DT><A HREF="https://arxiv.org/pdf/2310.02238.pdf">Who‚Äôs Harry Potter? Approximate Unlearning in LLMs</A>
								<DT><A HREF="https://news.microsoft.com/source/features/innovation/azure-quantum-majorana-topological-qubit/">In a historic milestone, Azure Quantum demonstrates formerly elusive physics needed to build scalable topological qubits - Source</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Rk3nTUfRZmo&t=330s">What runs ChatGPT? Inside Microsoft's AI supercomputer</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ptGDaGUXInw">Mark Russinovich | Generative AI in the Cloud: Inside Microsoft AI Innovation</A>
								<DT><A HREF="https://news.microsoft.com/source/features/innovation/azure-quantum-majorana-topological-qubit/">elusive physics needed to build scalable topological qubits</A>
							</DL><p>
							<DT><H3 FOLDED>cloud-system</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google/paxml">google/paxml: Pax is a Jax-based machine learning framework for training large scale models. Pax allows for advanced and fully configurable experimentation and parallelization, and has demonstrated industry leading model flop utilization rates.</A>
								<DT><A HREF="https://github.com/NVIDIA/JAX-Toolbox/tree/main/rosetta/rosetta/projects/pax">JAX-Toolbox/rosetta/rosetta/projects/pax at main ¬∑ NVIDIA/JAX-Toolbox</A>
								<DT><A HREF="https://nats.io/">NATS.io ‚Äì Cloud Native, Open Source, High-performance Messaging</A>
								<DT><A HREF="https://websites.umich.edu/~amberljc/file/LLM-Systems-Basics.pdf">LLM-Systems-Basics (Jiachen Liu)</A>
							</DL><p>
							<DT><H3 FOLDED>Kubernetes</H3>
							<DL><p>
								<DT><H3 FOLDED>Containerd</H3>
								<DL><p>
									<DT><H3 FOLDED>k8s-playground</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/chat/8a2fdc44-889a-4dce-bd82-646500305c86">Kubernetes Interactive Dev Pod Setup - Grok</A>
										<DT><A HREF="https://www.youtube.com/watch?v=18JDsDe6W98">Kubernetes by Example - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>kubeflow</H3>
									<DL><p>
										<DT><H3 FOLDED>PyTorchJob</H3>
										<DL><p>
											<DT><A HREF="https://www.kubeflow.org/docs/components/trainer/legacy-v1/user-guides/pytorch/">PyTorch Training (PyTorchJob) | Kubeflow</A>
										</DL><p>
									</DL><p>
									<DT><A HREF="https://chatgpt.com/c/6800f4ce-f924-800c-9387-d3272c5e6772">K8s AI Workflow Adaptation</A>
								</DL><p>
								<DT><H3 FOLDED>podman</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>kubectl</H3>
								<DL><p>
									<DT><H3 FOLDED>CRD</H3>
									<DL><p>
										<DT><A HREF="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">Custom Resources | Kubernetes</A>
										<DT><A HREF="https://x.com/BenBajarin/status/1984283196872339607">(1) Ben Bajarin en X: "Your $CRDO bull case in one paragraph. This from a Meta datacenter engineer on the topic of AECs. https://t.co/IT86GSpFmM" / X</A>
									</DL><p>
									<DT><H3 FOLDED>kubectl-interactive</H3>
									<DL><p>
										<DT><A HREF="https://grok.com/chat/8a2fdc44-889a-4dce-bd82-646500305c86">Kubernetes Interactive Dev Pod Setup - Grok</A>
									</DL><p>
									<DT><A HREF="https://kubernetes.io/docs/reference/kubectl/">Command line tool (kubectl) | Kubernetes</A>
								</DL><p>
								<DT><H3 FOLDED>GKE</H3>
								<DL><p>
									<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/whats-new-with-gke-at-google-cloud-next">What‚Äôs new with GKE at Google Cloud Next</A>
								</DL><p>
								<DT><H3 FOLDED>control-plane</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>Dynamic Resource Allocation</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna">Dynamic Resource Allocation for GPUs in Kubernetes - Google Docs</A>
								</DL><p>
								<DT><H3 FOLDED>kubernetes-local</H3>
								<DL><p>
									<DT><H3 FOLDED>kind</H3>
									<DL><p>
										<DT><A HREF="https://kind.sigs.k8s.io/">kind: local run</A>
									</DL><p>
									<DT><H3 FOLDED>minikube</H3>
									<DL><p>
										<DT><A HREF="https://kubernetes.io/docs/tutorials/hello-minikube/">Hello Minikube | Kubernetes</A>
										<DT><A HREF="https://kubernetes.io/docs/tutorials/kubernetes-basics/create-cluster/cluster-intro/">Using Minikube to Create a Cluster | Kubernetes</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>k8s-concepts</H3>
								<DL><p>
									<DT><A HREF="https://hamel.dev/notes/k8s/02-Basics.html">k8s</A>
									<DT><A HREF="https://www.youtube.com/watch?v=90kZRyPcRZw">Kubernetes Deconstructed: Understanding Kubernetes by Breaking It</A>
									<DT><H3 FOLDED>kubelet</H3>
									<DL><p>
										<DT><A HREF="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelet | Kubernetes</A>
									</DL><p>
									<DT><A HREF="https://kubernetes.io/docs/concepts/overview/components/">Kubernetes Components | Kubernetes</A>
								</DL><p>
								<DT><H3 FOLDED>k8s-utils</H3>
								<DL><p>
									<DT><A HREF="https://github.com/alibaba/kt-connect">alibaba/kt-connect: A toolkit for Integrating with your kubernetes dev environment more efficiently</A>
									<DT><A HREF="https://github.com/alibaba/kubeskoop">alibaba/kubeskoop</A>
								</DL><p>
								<DT><H3 FOLDED>k8s-etcd</H3>
								<DL><p>
								</DL><p>
								<DT><H3 FOLDED>k8s-storage</H3>
								<DL><p>
									<DT><H3 FOLDED>pvc</H3>
									<DL><p>
										<DT><A HREF="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">Persistent Volumes | Kubernetes</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>k8s-device-sharing</H3>
								<DL><p>
									<DT><H3 FOLDED>Time-Slicing</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-sharing.html">Time-Slicing GPUs in Kubernetes ‚Äî NVIDIA GPU Operator 23.9.2 documentation</A>
									</DL><p>
									<DT><H3 FOLDED>NVIDIA Multi-Instance GPU</H3>
									<DL><p>
										<DT><A HREF="https://www.nvidia.com/en-us/technologies/multi-instance-gpu/">Multi-Instance GPU (MIG) | NVIDIA</A>
									</DL><p>
									<DT><H3 FOLDED>CUDA Multi-Process Service (MPS)</H3>
									<DL><p>
										<DT><A HREF="https://docs.nvidia.com/deploy/mps/index.html">Multi-Process Service :: GPU Deployment and Management Documentation</A>
										<DT><A HREF="https://www.olcf.ornl.gov/wp-content/uploads/2021/06/MPS_ORNL_20210817.pdf">Introduction (slides)</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=Q2GuTUO170w">Sharing Is Caring: GPU Sharing and CDI in Device Plugins - Evan Lezar, NVIDIA &amp; David Porter, Google - YouTube</A>
									<DT><A HREF="https://www.youtube.com/watch?v=jbpIFCkEEng">Mastering GPU Management in Kubernetes Using the Operator Pattern (2024)</A>
								</DL><p>
								<DT><H3 FOLDED>k8s-container</H3>
								<DL><p>
									<DT><A HREF="https://kubernetes.io/docs/setup/production-environment/container-runtimes/">Container Runtimes | Kubernetes</A>
								</DL><p>
								<DT><H3 FOLDED>k9s</H3>
								<DL><p>
									<DT><A HREF="https://github.com/derailed/k9s">derailed/k9s: üê∂ Kubernetes CLI To Manage Your Clusters In Style!</A>
								</DL><p>
								<DT><H3 FOLDED>helm</H3>
								<DL><p>
									<DT><A HREF="https://helm.sh/">Helm</A>
								</DL><p>
								<DT><H3 FOLDED>kserve</H3>
								<DL><p>
									<DT><A HREF="https://github.com/kserve/modelmesh-serving">kserve/modelmesh-serving: Controller for ModelMesh</A>
								</DL><p>
								<DT><A HREF="https://cloud.google.com/anthos-config-management/docs/concepts/kustomize">Configure Kubernetes with Kustomize ¬†|¬† Anthos Config Management ¬†|¬† Google Cloud</A>
								<DT><A HREF="https://www.youtube.com/watch?v=06bKlSmVwIg">CNCF Live Webinar: Overcoming the GPU shortage with virtual Kubelets &amp; distributed cloud - YouTube</A>
								<DT><A HREF="https://virtual-kubelet.io/">Virtual Kubelet | Home</A>
								<DT><A HREF="https://github.com/virtual-kubelet/virtual-kubelet">virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.</A>
								<DT><A HREF="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelet | Kubernetes</A>
								<DT><A HREF="https://www.youtube.com/watch?v=cwiAW5TZsfo">On-Demand Systems and Scaled Training Using the JobSet API - Abdullah Gharaibeh &amp; Vanessa Sochat - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Q2GuTUO170w">Sharing Is Caring: GPU Sharing and CDI in Device Plugins - Evan Lezar, NVIDIA &amp; David Porter, Google - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=jbpIFCkEEng">Mastering GPU Management in Kubernetes Using the Operator Pattern (2024)</A>
								<DT><A HREF="https://www.youtube.com/watch?v=cwiAW5TZsfo">On-Demand Systems and Scaled Training Using the JobSet API</A>
								<DT><A HREF="https://www.cncf.io/wp-content/uploads/2020/10/Kube-two-level-RM.pdf">Kubernetes native two-level resource managment for AI workloads</A>
								<DT><A HREF="https://github.com/project-codeflare/multi-cluster-app-dispatcher">project-codeflare/multi-cluster-app-dispatcher: Holistic job manager on Kubernetes</A>
								<DT><A HREF="https://github.com/bentoml/Yatai">bentoml/Yatai: Model Deployment at Scale on Kubernetes ü¶ÑÔ∏è</A>
								<DT><A HREF="https://docs.aws.amazon.com/parallelcluster/latest/ug/build-image.html">buildImage - AWS ParallelCluster</A>
								<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/high-performance-aiml-storage-through-local-ssd-support-on-gke">High performance AI/ML storage through Local SSD support on GKE | Google Cloud Blog</A>
								<DT><A HREF="https://grok.com/chat/9a910d96-103e-4a6c-b88d-002abf5c2b44">NVIDIA B200 Cluster for AI Experiments - Grok</A>
								<DT><A HREF="https://www.youtube.com/watch?v=6IPu3WU_M0o">Kubernetes Basics: Pods, Nodes, Containers, Deployments &amp; Clusters - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>Infrasctructure as Code</H3>
							<DL><p>
								<DT><H3 FOLDED>Ansible</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=2c5b8Olk6Fk">Ansible and Automation before Mexico Vacation - Skills to get engineering roles. - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>Terraform</H3>
								<DL><p>
									<DT><A HREF="https://googlecloudplatform.github.io/magic-modules/">Magic Modules: Extending Terraform</A>
								</DL><p>
								<DT><H3 FOLDED>Pulumi</H3>
								<DL><p>
									<DT><H3 FOLDED>xAI</H3>
									<DL><p>
										<DT><A HREF="https://x.ai/career/">Join xAI</A>
										<DT><A HREF="https://boards.greenhouse.io/xai/jobs/4099452007">Job Application for Infrastructure Engineer at xAI</A>
										<DT><A HREF="https://boards.greenhouse.io/xai/jobs/4099456007">Job Application for AI Engineer &amp; Researcher at xAI</A>
										<DT><A HREF="https://www.pulumi.com/solutions/ai/">AI Infrastructure at Any Scale | Pulumi</A>
										<DT><A HREF="https://github.com/pulumi/pulumi">pulumi/pulumi: Pulumi - Infrastructure as Code in any programming language. Build infrastructure intuitively on any cloud using familiar languages üöÄ</A>
									</DL><p>
									<DT><A HREF="https://www.pulumi.com/solutions/ai/">AI Infrastructure at Any Scale | Pulumi</A>
								</DL><p>
								<DT><A HREF="https://github.com/kykosic/remote">kykosic/remote: Simple CLI tool for managing remote development instances</A>
								<DT><A HREF="https://github.com/pulumi/pulumi">pulumi/pulumi: Pulumi - Infrastructure as Code in any programming language. Build infrastructure intuitively on any cloud using familiar languages üöÄ</A>
								<DT><A HREF="https://github.com/matklad/xshell">matklad/xshell: Making Rust a Better Bash</A>
							</DL><p>
							<DT><H3 FOLDED>cloud-benchmarking</H3>
							<DL><p>
								<DT><H3 FOLDED>Artificial Analysis</H3>
								<DL><p>
									<DT><A HREF="https://artificialanalysis.ai/">Model &amp; API Providers Analysis | Artificial Analysis</A>
								</DL><p>
								<DT><A HREF="https://artificialanalysis.ai/">Model &amp; API Providers Analysis | Artificial Analysis</A>
								<DT><A HREF="https://artificialanalysis.ai/models/gpt-4o-mini">GPT-4o mini - Quality, Performance &amp; Price Analysis | Artificial Analysis</A>
								<DT><A HREF="https://artificialanalysis.ai/models/deepseek-v2">DeepSeek-V2 - Quality, Performance &amp; Price Analysis | Artificial Analysis</A>
								<DT><A HREF="https://x.com/ArtificialAnlys/status/1813975855468560621">(1) Artificial Analysis en X: "GPT-4o Mini, announced today, is very impressive for how cheap it is being offered üëÄ With a MMLU score of 82% (reported by TechCrunch), it surpasses the quality of other smaller models including Gemini 1.5 Flash (79%) and Claude 3 Haiku (75%). What is particularly exciting is https://t.co/5x7dTvpEQL" / X</A>
								<DT><A HREF="https://twitter.com/ArtificialAnlys">(1) Artificial Analysis (@ArtificialAnlys) / X</A>
								<DT><A HREF="https://twitter.com/lqiao/status/1767406833692737971">Fireworks beats Groq (Lin Qiao)</A>
								<DT><A HREF="https://www.linkedin.com/feed/update/urn:li:activity:7189636365620240384/">Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services</A>
								<DT><A HREF="https://llm-qoe.github.io/">Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services ¬∑ Andes Blog</A>
							</DL><p>
							<DT><H3 FOLDED>cloud-providers</H3>
							<DL><p>
								<DT><H3 FOLDED>Google Cloud Platform</H3>
								<DL><p>
									<DT><H3 FOLDED>Google Collab</H3>
									<DL><p>
										<DT><H3 FOLDED>third-party apps integration</H3>
										<DL><p>
											<DT><H3 FOLDED>Github</H3>
											<DL><p>
												<DT><A HREF="https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d">How to use Google Colab with GitHub via Google Drive - medium</A>
												<DT><A HREF="https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228">Google Drive + Google Colab + GitHub; Don‚Äôt Just Read, Do It!</A>
												<DT><A HREF="https://towardsdatascience.com/colaboratory-drive-github-the-workflow-made-simpler-bde89fba8a39">Colaboratory + Drive + Github</A>
												<DT><A HREF="https://medium.com/@ashwindesilva/how-to-use-google-colaboratory-to-clone-a-github-repository-e07cf8d3d22b">git clone</A>
											</DL><p>
											<DT><H3 FOLDED>Google Drive</H3>
											<DL><p>
												<DT><A HREF="https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d">How to use Google Colab with GitHub via Google Drive - medium</A>
												<DT><A HREF="https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228">Google Drive + Google Colab + GitHub; Don‚Äôt Just Read, Do It!</A>
												<DT><A HREF="https://towardsdatascience.com/colaboratory-drive-github-the-workflow-made-simpler-bde89fba8a39">Colaboratory + Drive + Github</A>
											</DL><p>
											<DT><A HREF="https://medium.com/@ashwindesilva/how-to-use-google-colaboratory-to-clone-a-github-repository-e07cf8d3d22b">Basic interoperability usage: Google Drive-Github</A>
										</DL><p>
										<DT><H3 FOLDED>remote rendering</H3>
										<DL><p>
											<DT><A HREF="https://davidrpugh.github.io/stochastic-expatriate-descent/openai/binder/google-colab/2020/04/16/remote-rendering-gym-envs.html">Rendering OpenAI Gym Envs on Binder and Google Colab</A>
											<DT><A HREF="https://stackoverflow.com/questions/53472940/nameerror-name-base-is-not-defined-openai-gym">Cannot render display - NameError: name 'base' is not defined OpenAI Gym - Stack Overflow</A>
											<DT><A HREF="https://colab.research.google.com/github/davidrpugh/stochastic-expatriate-descent/blob/2020-04-16-remote-rendering-gym-envs/_notebooks/2020-04-16-remote-rendering-gym-envs.ipynb#scrollTo=iS3_S__W01cs">remote-rendering-gym-envs.ipynb - Colaboratory</A>
										</DL><p>
										<DT><A HREF="https://medium.com/@oribarel/getting-the-most-out-of-your-google-colab-2b0585f82403">memory mapped file formats like HDF5 (aka H5) or LMDB</A>
									</DL><p>
									<DT><A HREF="https://cloud.google.com/products/calculator/#id=4b1ece6b-db16-4e2b-bdf2-0d7370d75fb7">Google Cloud Pricing Calculator</A>
									<DT><A HREF="https://cloud.google.com/compute/gpus-pricing#tpus">GPU pricing ¬†|¬† Compute Engine: Virtual Machines (VMs) ¬†|¬† Google Cloud</A>
									<DT><A HREF="https://cloud.google.com/compute/docs/gpus">GPU platforms ¬†|¬† Compute Engine Documentation ¬†|¬† Google Cloud</A>
								</DL><p>
								<DT><H3 FOLDED>CoreWeave</H3>
								<DL><p>
									<DT><H3 FOLDED>coreweave-training</H3>
									<DL><p>
										<DT><A HREF="https://cdn.prod.website-files.com/62bc66d283fd9c34ffec780a/689fa33a0e99f19c11c8ecbe_CoreWeave%20Training%20Benchmarks%20Whitepaper%20August%202025.pdf">Purpose-Built Cloud for AI at Scale: Achieving 20% Higher MFU and 10x Reliability on Thousand-GPU Clusters</A>
									</DL><p>
									<DT><A HREF="https://docs.coreweave.com/">CoreWeave Cloud - CoreWeave</A>
									<DT><A HREF="https://docs.coreweave.com/compass/examples/triton-inference-server-fastertransformer">https://docs.coreweave.com/compass/examples/triton-inference-server-fastertransformer</A>
								</DL><p>
								<DT><H3 FOLDED>AWS DJL</H3>
								<DL><p>
									<DT><A HREF="https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-tutorials-fastertransformer.html">Large model inference with FasterTransformer and DJL Serving - Amazon SageMaker</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>CI/CD</H3>
							<DL><p>
								<DT><H3 FOLDED>github-actions</H3>
								<DL><p>
									<DT><H3 FOLDED>checkoutv4</H3>
									<DL><p>
										<DT><A HREF="https://github.com/actions/checkout/blob/09d2acae674a48949e3602304ab46fd20ae0c42f/README.md">checkout/README.md at 09d2acae674a48949e3602304ab46fd20ae0c42f ¬∑ actions/checkout</A>
									</DL><p>
									<DT><A HREF="https://github.com/nektos/act">nektos/act: Run your GitHub Actions locally üöÄ</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://twitter.com/TigerBeetleDB/status/1729054660223553933">(1) TigerBeetle en X: "How do you catch up (and overtake) 30 years of test time? - We've ramped to 100 CPU cores. - 100 simultaneous TigerBeetle simulations, 24x7. - Each simulation (in 3.3 seconds) tests 39 minutes on avg. of real world runtime. 10 cores = 20 years 100 cores = 200 years (every day) https://t.co/mDDCBE74nY" / X</A>
							<DT><A HREF="https://www.tritondatacenter.com/">Take Control of Your Cloud Data | Triton DataCenter</A>
							<DT><A HREF="https://github.com/GoogleCloudPlatform/slurm-gcp">GoogleCloudPlatform/slurm-gcp</A>
							<DT><A HREF="https://github.com/quickwit-oss/quickwit">quickwit-oss/quickwit: Cloud-native search engine for observability. An open-source alternative to Datadog, Elasticsearch, Loki, and Tempo.</A>
							<DT><A HREF="https://gpulist.ai/">gpulist</A>
							<DT><A HREF="https://twitter.com/TigerBeetleDB/status/1729054660223553933">(1) TigerBeetle en X: "How do you catch up (and overtake) 30 years of test time?</A>
							<DT><A HREF="https://github.com/quickwit-oss/quickwit">quickwit-oss/quickwit: Cloud-native search engine for observability. An open-source alternative to Datadog, Elasticsearch</A>
						</DL><p>
						<DT><H3 FOLDED>sw-testing</H3>
						<DL><p>
							<DT><H3 FOLDED>sw-testing-errors</H3>
							<DL><p>
								<DT><A HREF="https://www.inngest.com/blog/python-errors-as-values">Python errors as values: Comparing useful patterns from Go and Rust - Inngest Blog</A>
								<DT><A HREF="https://github.com/huggingface/safetensors/blob/079781fd0dc455ba0fe851e2b4507c33d0c0d407/bindings/python/convert.py#L4">errors as values: safetensors/bindings/python/convert.py</A>
							</DL><p>
							<DT><H3 FOLDED>sw-testing-exception-handling</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>sw-testing-bugs</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ProjectPhysX/FluidX3D/releases/tag/v2.16">Release FluidX3D v2.16 (bug fixes) ¬∑ ProjectPhysX/FluidX3D</A>
								<DT><A HREF="https://private-user-images.githubusercontent.com/90851087/327656146-d013fc95-d977-460f-9de8-2a6fc7ddaec5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQ3MzM2NDUsIm5iZiI6MTcxNDczMzM0NSwicGF0aCI6Ii85MDg1MTA4Ny8zMjc2NTYxNDYtZDAxM2ZjOTUtZDk3Ny00NjBmLTlkZTgtMmE2ZmM3ZGRhZWM1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTAzVDEwNDkwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ4ZTJiY2I4NTU2MzBmZmFkNWJiMzI1MzdkYjc4NTg1N2Q5ZjU0ZmZlYmQ3MTNlODFkNDE1NjYyMjlkNmZmY2EmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QXKhYOoKDu0s5FNsEZsht_Psxxfb1exaRzg8-OrI45Q">327656146-d013fc95-d977-460f-9de8-2a6fc7ddaec5.png 1.886√ó960 pixels</A>
								<DT><A HREF="https://chat.openai.com/">github-bug-issues</A>
							</DL><p>
							<DT><H3 FOLDED>Deterministic Simulation Testing</H3>
							<DL><p>
								<DT><A HREF="https://www.polarsignals.com/blog/posts/2024/05/28/mostly-dst-in-go">(Mostly) Deterministic Simulation Testing in Go</A>
							</DL><p>
							<DT><A HREF="https://twitter.com/karpathy/status/1786085254006202541">(1) Andrej Karpathy en X: "Clearly LLMs must one day run in Space Step 1 we harden llm.c to pass the NASA code standards and style guides, certifying that the code is super safe, safe enough to run in Space. https://t.co/tYGrfdka4X (see the linked PDF) LLM training/inference in principle should be super..." / X</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code">The Power of 10: Rules for Developing Safety-Critical Code</A>
							<DT><A HREF="https://x.com/realGeorgeHotz/status/1874228009550700809">(2) George Hotz üåë en X: "@ns123abc @AMD We still have a very long journey ahead. For sure our driver has bugs to find and performance optimizations to make. The key thing is that it's 696 lines, written in Python, and easy to understand and debug. Testing and simplicity are our strengths." / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gcwzWzC7gUA">Rails World 2025 Opening Keynote - David Heinemeier Hansson - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>programming-behaviour-invariance</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/shorts/M-VU0fLjIUU">This Is A Game Changer - YouTube</A>
							<DT><A HREF="https://softwareengineering.stackexchange.com/questions/32727/what-are-invariants-how-can-they-be-used-and-have-you-ever-used-it-in-your-pro">What are invariants, how can they be used, and have you ever used it in your program? - Software Engineering Stack Exchange</A>
							<DT><A HREF="https://wiki.python.org/moin/UsingAssertionsEffectively">UsingAssertionsEffectively - Python Wiki</A>
						</DL><p>
						<DT><H3 FOLDED>supercomputing-jobs</H3>
						<DL><p>
							<DT><A HREF="https://jobs.careers.microsoft.com/global/en/job/1835249/Software-Engineer-II%3A-HPC-%26-AI-Benchmarking?amp;utm_campaign=LinkedIn-job-share">Software Engineer II: HPC &amp; AI Benchmarking | Microsoft Careers</A>
						</DL><p>
						<DT><A HREF="https://notes.ekzhang.com/events/nysrg">NYSRG (k8s, git, S3)</A>
						<DT><A HREF="https://imbue.com/research/70b-infrastructure/">From bare metal to a 70B model: infrastructure set-up and scripts - imbue</A>
						<DT><A HREF="https://websites.umich.edu/~amberljc/file/LLM-Systems-Basics.pdf">LLM-Systems-Basics (Jiachen Liu)</A>
						<DT><A HREF="https://web.stanford.edu/class/cs245/">CS 245: Principles of Data-Intensive Systems (Winter 2021)</A>
						<DT><A HREF="https://www.youtube.com/watch?v=TOyD-5QgpuE">Design a Code Execution System | System Design - YouTube</A>
						<DT><A HREF="https://www.youtube.com/watch?v=jFrGhodqC08">The cloud is over-engineered and overpriced (no music) - YouTube</A>
						<DT><A HREF="https://github.com/cuda-mode/awesomeMLSys">cuda-mode/awesomeMLSys: An ML Systems Onboarding list</A>
						<DT><A HREF="https://www.youtube.com/watch?v=GA4ONupSl8Y">Two Decades of Hardware Optimizations Down The Drain - YouTube</A>
						<DT><A HREF="https://12factor.net/">The Twelve-Factor App</A>
						<DT><A HREF="https://discord.com/blog/how-discord-supercharges-network-disks-for-extreme-low-latency">How Discord Supercharges Network Disks for Extreme Low Latency</A>
						<DT><A HREF="https://x.com/mvpatel2000/status/1803941734629388590">(1) Mihir Patel en X: "@StasBekman See blog https://t.co/A0JWbNWHVl in particular the HSDP section. When you shard across many GPUs with HSDP, you have multiple replicas. When a node goes down (take top left red square), we can bring up a new node and restore it's copy by pulling from top left green square (1/n) https://t.co/5jsGSr3ca6" / X</A>
						<DT><A HREF="https://github.com/hao-ai-lab">Hao AI Lab</A>
						<DT><A HREF="https://github.com/imbue-ai/cluster-health">imbue-ai/cluster-health</A>
						<DT><A HREF="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">Linux Performance Analysis in 60,000 Milliseconds | by Netflix Technology Blog | Netflix TechBlog</A>
						<DT><A HREF="https://github.com/facebookresearch/DCPerf/tree/main/packages/feedsim/third_party/src/scripts">DCPerf/packages/feedsim/third_party/src/scripts at main ¬∑ facebookresearch/DCPerf</A>
						<DT><A HREF="https://github.com/linkedin/school-of-sre?tab=readme-ov-file">linkedin/school-of-sre: At LinkedIn, we are using this curriculum for onboarding our entry-level talents into the SRE role.</A>
						<DT><A HREF="http://mlforsystems.org/">Announcement | ML For Systems</A>
						<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/compute/accelerator#power-consumption">ml-engineering/compute/accelerator at master ¬∑ stas00/ml-engineering</A>
						<DT><A HREF="https://github.com/MLSys-Learner-Resources/Awesome-MLSys-Blogger">MLSys-Learner-Resources/Awesome-MLSys-Blogger: The repository has collected a batch of noteworthy MLSys bloggers (Algorithms/Systems)</A>
					</DL><p>
					<DT><H3 FOLDED>training-infrastructure</H3>
					<DL><p>
						<DT><H3 FOLDED>training-playbook</H3>
						<DL><p>
							<DT><A HREF="https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook">The Smol Training Playbook: The Secrets to Building World-Class LLMs - a Hugging Face Space by HuggingFaceTB</A>
							<DT><A HREF="https://huggingface.co/spaces/nanotron/ultrascale-playbook">The Ultra-Scale Playbook - a Hugging Face Space by nanotron</A>
							<DT><A HREF="https://www.youtube.com/watch?v=1E8GDR8QXKw">Lecture 48: The Ultra Scale Playbook - YouTube</A>
							<DT><A HREF="https://jax-ml.github.io/scaling-book/">How To Scale Your Model</A>
							<DT><A HREF="https://x.com/eliebakouch/status/1983930328751153159">(1) elie en X: "Training LLMs end to end is hard. Very excited to share our new blog (book?) that cover the full pipeline: pre-training, post-training and infra. 200+ pages of what worked, what didn‚Äôt, and how to make it run reliably https://t.co/iN2JtWhn23 https://t.co/hJxwhYb2TH" / X</A>
						</DL><p>
						<DT><H3 FOLDED>training-checkpointing</H3>
						<DL><p>
							<DT><H3 FOLDED>checkpointing-io</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/abs/2101.08734">[2101.08734] Clairvoyant Prefetching for Distributed Machine Learning I/O</A>
								<DT><A HREF="https://github.com/NVIDIA/aistore/blob/master/docs/overview.md">aistore/docs/overview.md at master ¬∑ NVIDIA/aistore</A>
								<DT><A HREF="https://arxiv.org/abs/2001.01858">[2001.01858] High Performance I/O For Large Scale Deep Learning</A>
								<DT><A HREF="https://www.youtube.com/watch?v=1CdduHa-KgA&t=2186s">File I/O for Game Developers: Past, Present, and Future with C++ - Guy Davidson - CppCon 2023 - YouTube</A>
								<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/storage">Filesystems and IO</A>
							</DL><p>
							<DT><H3 FOLDED>checkpoint-engine</H3>
							<DL><p>
								<DT><A HREF="https://github.com/MoonshotAI/checkpoint-engine">MoonshotAI/checkpoint-engine: Checkpoint-engine is a simple middleware to update model weights in LLM inference engines</A>
								<DT><A HREF="https://moonshotai.github.io/checkpoint-engine/">How Kimi K2 Achieves Efficient RL Parameter Updates</A>
							</DL><p>
							<DT><H3 FOLDED>torch-checkpointing</H3>
							<DL><p>
								<DT><H3 FOLDED>torch-distributed-checkpointing</H3>
								<DL><p>
									<DT><H3 FOLDED>async-checkpoint</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=VmFcwjpt8vE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=136">Lightning Talk: In-Cluster Distributed Checkpointing: Optimizing Training... - G. Kroiz &amp; S. Mishra - YouTube</A>
									</DL><p>
									<DT><H3 FOLDED>in-cluster-checkpointing</H3>
									<DL><p>
										<DT><A HREF="https://www.youtube.com/watch?v=VmFcwjpt8vE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=136">Lightning Talk: In-Cluster Distributed Checkpointing: Optimizing Training... - G. Kroiz &amp; S. Mishra - YouTube</A>
									</DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=VmFcwjpt8vE&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=136">Lightning Talk: In-Cluster Distributed Checkpointing: Optimizing Training... - G. Kroiz &amp; S. Mishra - YouTube</A>
									<DT><A HREF="https://docs.pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html">Getting Started with Distributed Checkpoint (DCP) ‚Äî PyTorch Tutorials 2.9.0+cu128 documentation</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=bfexfASu9h4">Scalable and Efficient AI: From Supercomputers to Smartphones (Microsoft)</A>
							<DT><A HREF="https://pytorch.org/docs/stable/distributed.checkpoint.html">Distributed Checkpoint - torch.distributed.checkpoint ‚Äî PyTorch 2.1</A>
							<DT><A HREF="https://blog.research.google/2022/09/tensorstore-for-high-performance.html?m=1">TensorStore for High-Performance, Scalable Array Storage</A>
							<DT><A HREF="https://learn.microsoft.com/en-us/azure/machine-learning/reference-checkpoint-performance-for-large-models?view=azureml-api-2&tabs=PYTORCH">Optimize Checkpoint Performance for Large Models - Azure Machine Learning | Microsoft Learn</A>
							<DT><A HREF="https://github.com/libffcv/ffcv">libffcv/ffcv: FFCV: Fast Forward Computer Vision (and other ML workloads!)</A>
							<DT><A HREF="https://github.com/google/orbax">google/orbax: Orbax provides common utility libraries for JAX users.</A>
							<DT><A HREF="https://github.com/ByteDance-Seed/ByteCheckpoint">ByteDance-Seed/ByteCheckpoint: ByteCheckpoint: An Unified Checkpointing Library for LFMs</A>
						</DL><p>
						<DT><H3 FOLDED>comm-inter-process</H3>
						<DL><p>
							<DT><H3 FOLDED>multi-threading</H3>
							<DL><p>
								<DT><A HREF="https://www.pythonpool.com/cant-pickle-local-object/">Pickling local variables context</A>
								<DT><A HREF="http://jakascorner.com/blog/2016/06/omp-for-scheduling.html">OpenMP: For &amp; Scheduling</A>
								<DT><A HREF="https://www.youtube.com/watch?v=Iqrd9vsLrak">Coroutine Patterns: Problems and Solutions Using Coroutines in a Modern Codebase</A>
								<DT><A HREF="https://x.com/7etsuo/status/1823584755398664370">Tetsuo en X: "Mastering Multithreading in C: A Comprehensive Guide to Concurrency Primitives" / X</A>
							</DL><p>
							<DT><H3 FOLDED>OpenMP</H3>
							<DL><p>
								<DT><A HREF="https://github.com/jakaspeh/concurrency/blob/master/ompForSchedule.cpp">ompForSchedule.cpp examples</A>
								<DT><A HREF="http://jakascorner.com/blog/2016/06/omp-for-scheduling.html">OpenMP: For &amp; Scheduling</A>
								<DT><A HREF="https://smileipic.github.io/tutorials/perfs_parallel_computing.html">Parallel computing ‚Äî Smilei tutorials X.Y documentation</A>
								<DT><A HREF="https://github.com/facebookincubator/dispenso">facebookincubator/dispenso: The project provides high-performance concurrency, enabling highly parallel computation.</A>
							</DL><p>
							<DT><H3 FOLDED>MPI</H3>
							<DL><p>
								<DT><A HREF="https://mpi4py.readthedocs.io/en/stable/">MPI for Python ‚Äî MPI for Python 3.1.6 documentation</A>
								<DT><A HREF="https://mpitutorial.com/tutorials/">Tutorials ¬∑ MPI Tutorial</A>
								<DT><A HREF="https://www.youtube.com/watch?v=5vfcTjosGLg&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=116">PyTorch Symmetric Memory: A New Programming Paradigm for Distributed AI - Ke Wen &amp; Chien-Chin Huang - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>message-passing</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>shared-memory</H3>
							<DL><p>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>model-parallelism-mpi</H3>
						<DL><p>
							<DT><A HREF="https://www.open-mpi.org/">Open MPI: Open Source High Performance Computing</A>
						</DL><p>
						<DT><H3 FOLDED>modded-nanogpt</H3>
						<DL><p>
							<DT><H3 FOLDED>nanopgt-medium</H3>
							<DL><p>
								<DT><A HREF="https://x.com/YouJiacheng/status/1912498302018629746">GPT Medium new record: ~1525s (25.43 minutes)</A>
								<DT><A HREF="https://gist.github.com/YouJiacheng/4d0cff9187cbc8f887fedeb9f240ff63">train_gpt_log_20250416.txt</A>
							</DL><p>
							<DT><H3 FOLDED>nanogpt-bos_token</H3>
							<DL><p>
								<DT><A HREF="https://www.lesswrong.com/posts/tr3DrQiuyxkDpPqx2/the-curious-case-of-the-bos_token">The Curious Case of the bos_token ‚Äî LessWrong</A>
							</DL><p>
							<DT><H3 FOLDED>modded-nanogpt-runs</H3>
							<DL><p>
								<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt/pull/201">New Record: Bigram Hash Embedding (-5.6s, -165 steps) by ClassicLarry ¬∑ Pull Request #201 ¬∑ KellerJordan/modded-nanogpt</A>
								<DT><A HREF="https://x.com/classiclarryd/status/2013520088297558274?s=12">(1) Larry Dial en X: "New NanoGPT Speedrun WR at 99.3s (-5.6s) with a bigram hash embedding that is added to the residual stream before every layer. Inspiration from Svenstrup et al 2017 paper on Hash Embeddings, and Deepseek's Engram. Modded-NanoGPT now uses fewer training tokens than its parameter https://t.co/ykGVKtrOM0" / X</A>
							</DL><p>
							<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt">KellerJordan/modded-nanogpt: NanoGPT (124M) in 3 minutes</A>
							<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt/pull/136">New record 146.8s 09/30/25 (-0.6s): CustomBatching, only update Adam Params every other step by ClassicLarry ¬∑ Pull Request #136 ¬∑ KellerJordan/modded-nanogpt</A>
							<DT><A HREF="https://www.lesswrong.com/posts/j3gp8tebQiFJqzBgg/how-the-nanogpt-speedrun-wr-dropped-by-20-in-3-months">How the NanoGPT Speedrun WR dropped by 20% in 3 months ‚Äî LessWrong</A>
							<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt/blob/ba3e54f378b11af1ee33c2d518820e4532020190/train_gpt.py">modded-nanogpt/train_gpt.py at ba3e54f378b11af1ee33c2d518820e4532020190 ¬∑ KellerJordan/modded-nanogpt</A>
							<DT><A HREF="https://damek.github.io/random/modded-nanogpt-walkthrough-i/">Modded-NanoGPT Walkthrough I: initial setup, compiler config, and custom FP8 operations | Damek Davis‚Äô Website</A>
							<DT><A HREF="https://github.com/KellerJordan/modded-nanogpt/pull/169">New WR 128.8s: Partial Key Offset (-2.4s, -50 steps) by ClassicLarry ¬∑ Pull Request #169 ¬∑ KellerJordan/modded-nanogpt</A>
						</DL><p>
						<DT><H3 FOLDED>torchtitan</H3>
						<DL><p>
							<DT><H3 FOLDED>torchtitan-train-configs</H3>
							<DL><p>
								<DT><A HREF="https://github.com/pytorch/torchtitan/blob/7281e0be8feeb607f3c3f12cc3ceaafed87912c9/train_configs/llama3_405b.toml">torchtitan/train_configs/llama3_405b.toml at 7281e0be8feeb607f3c3f12cc3ceaafed87912c9 ¬∑ pytorch/torchtitan</A>
								<DT><A HREF="https://github.com/pytorch/torchtitan/blob/main/train_configs/debug_model.toml">torchtitan/train_configs/debug_model.toml at main ¬∑ pytorch/torchtitan</A>
							</DL><p>
							<DT><H3 FOLDED>torchtitan-docs</H3>
							<DL><p>
								<DT><A HREF="https://deepwiki.com/pytorch/torchtitan">pytorch/torchtitan | DeepWiki</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-enabling-float8-all-gather-in-fsdp2/209323">Topic 1: [Distributed w/ Torchtitan] Enabling Float8 All-Gather in FSDP2 - distributed / torchtitan - PyTorch Forums</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-introducing-async-tensor-parallelism-in-pytorch/209487">Topic 2: Introducing Async Tensor Parallelism in PyTorch</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-optimizing-checkpointing-efficiency-with-pytorch-dcp/211250">Topic 3: Optimizing Checkpointing Efficiency with PyTorch DCP</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-training-with-zero-bubble-pipeline-parallelism/214420">Topic 4: Training with Zero-Bubble Pipeline Parallelism</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-breaking-barriers-training-long-context-llms-with-1m-sequence-length-in-pytorch-using-context-parallel/215082">Topic 5: Breaking Barriers: Training Long Context LLMs with 1M Sequence Length in PyTorch Using Context Parallel</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-semi-synchronous-training-using-torchft/219874">Topic 6: Semi synchronous training in combination using TorchFT</A>
								<DT><A HREF="https://discuss.pytorch.org/t/distributed-w-torchtitan-flux-is-here-experience-diffusion-model-training-on-torchtitan/221119">Topic 7: FLUX is Here: Experience Diffusion Model Training on TorchTitan</A>
								<DT><A HREF="https://x.com/wanchao_/status/1946364078705758645">(1) Wanchao Liang en X: "I‚Äôll be presenting TorchTitan: a PyTorch native platform for training foundation models tomorrow at the ICML @ESFoMo workshop! Come and say Hi!" / X</A>
							</DL><p>
							<DT><H3 FOLDED>lingua</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/lingua">facebookresearch/lingua: Meta Lingua: a lean, efficient, and easy-to-hack codebase to research LLMs.</A>
							</DL><p>
							<DT><H3 FOLDED>veScale</H3>
							<DL><p>
								<DT><A HREF="https://volcengine.github.io/veScaleWeb/">veScale</A>
								<DT><A HREF="https://github.com/volcengine/veScale">volcengine/veScale: A PyTorch Native LLM Training Framework</A>
							</DL><p>
							<DT><H3 FOLDED>MegaScale</H3>
							<DL><p>
								<DT><H3 FOLDED>computation-communication-overlap</H3>
								<DL><p>
									<DT><H3 FOLDED>FlashOverlap</H3>
									<DL><p>
										<DT><A HREF="https://github.com/infinigence/FlashOverlap">infinigence/FlashOverlap: A lightweight design for computation-communication overlap.</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1900910901017679250">Triton-distributed: Áî®PythonÂÜôÂá∫È´òÊÄßËÉΩËÆ°ÁÆóÈÄö‰ø°ÈáçÂè†kernel - Áü•‰πé</A>
										<DT><A HREF="https://zhuanlan.zhihu.com/p/1897633068380054002">Êó†ÈóÆËäØÁ©πËÆ°ÁÆóÈÄö‰ø°ÈáçÂè†Êñ∞ËåÉÂºè‚Äî‚ÄîFlashOverlapÊäÄÊúØËß£Êûê - Áü•‰πé</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2402.15627v1">MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs</A>
								<DT><A HREF="https://arxiv.org/abs/2502.21231">[2502.21231] ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs</A>
								<DT><A HREF="https://arxiv.org/pdf/2502.19811">Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts</A>
								<DT><A HREF="https://arxiv.org/pdf/2504.02263">MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism</A>
								<DT><A HREF="https://github.com/ByteDance-Seed/SDP4Bit">ByteDance-Seed/SDP4Bit: official implementation of paper SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training</A>
								<DT><A HREF="https://arxiv.org/abs/2505.11432">[2505.11432] MegaScale-MoE: Large-Scale Communication-Efficient Training of Mixture-of-Experts Models in Production</A>
							</DL><p>
							<DT><H3 FOLDED>torchtitan-multinode</H3>
							<DL><p>
								<DT><H3 FOLDED>torchtitan-blackwell</H3>
								<DL><p>
									<DT><A HREF="https://github.com/pytorch/torchtitan/blob/9610d272b16c11ff1867c75b41926448bb414b7a/docs/mxfp8.md">torchtitan/docs/mxfp8.md MXFp8 training on (G)B200 Blackwell</A>
									<DT><A HREF="https://www.notion.so/datacrunchio/Meta-MXFp8-Training-on-G-B200-Blackwell-222b9e769144809c8e48f75cf6b66cf3">Meta MXFp8 Training on (G)B200 Blackwell</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/torchtitan/issues/708">Low multi-node performance on SLURM cluster (32x H100): NCCL_IB_DISABLE=0 NCCL_NET=IB</A>
								<DT><A HREF="https://github.com/linux-rdma/rdma-core/blob/master/debian/ibverbs-utils.install">apt install ibverbs-utils</A>
								<DT><A HREF="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/env.html">Environment Variables ‚Äî NCCL 2.26.5 documentation: NCCL_IB_DISABLE</A>
								<DT><A HREF="https://pytorch.org/blog/accelerating-2k-scale-pre-training-up-to-1-28x-with-torchao-mxfp8-and-torchtitan-on-crusoe-b200-cluster/">Accelerating 2K scale pre-training up to 1.28x with TorchAO, MXFP8 and TorchTitan on Crusoe B200 Cluster ‚Äì PyTorch</A>
							</DL><p>
							<DT><H3 FOLDED>torchtitan-models</H3>
							<DL><p>
								<DT><H3 FOLDED>torchtitan-moe</H3>
								<DL><p>
									<DT><A HREF="https://x.com/kalomaze/status/1951182144975388789">(1) kalomaze en X: "me earlier today: "surely torchtitan will not use a for loop for experts in MoE like the inefficient Transformers implementation!" me 5 minutes later: "oh. oh no"" / X</A>
									<DT><A HREF="https://github.com/pytorch/torchtitan/blob/d655e1673d5f15d31a9514092f281e744107d821/torchtitan/experiments/kernels/triton_mg_group_gemm/torchao_pr/mg_grouped_gemm.py#L1277">torchtitan/torchtitan/experiments/kernels/triton_mg_group_gemm/torchao_pr/mg_grouped_gemm.py at d655e1673d5f15d31a9514092f281e744107d821 ¬∑ pytorch/torchtitan</A>
									<DT><A HREF="https://x.com/m_sirovatka/status/2013071382440006099?s=12">Matej Sirovatka en X: "how hard can hotswapping torchtitan moe layers with ones custom built on top of TE GroupedLinear and not breaking checkpointing be üò≠ turns out quite a bit" / X</A>
								</DL><p>
								<DT><A HREF="https://github.com/pytorch/torchtitan/pull/1451">publish instructions on adding a new model by tianyu-l ¬∑ Pull Request #1451 ¬∑ pytorch/torchtitan</A>
								<DT><A HREF="https://github.com/pytorch/torchtitan/blob/8bba8d8bbf3e52e56076188c3abbba02b12e5ae1/torchtitan/models/README.md">torchtitan/torchtitan/models/README.md</A>
								<DT><A HREF="https://github.com/Wan-Video/Wan2.1/blob/7c81b2f27defa56c7e627a4b6717c8f2292eee58/wan/utils/vace_processor.py">Wan2.1/wan/utils/vace_processor.py</A>
							</DL><p>
							<DT><H3 FOLDED>torchtitan-quant</H3>
							<DL><p>
								<DT><H3 FOLDED>torchtitan-mxfp8</H3>
								<DL><p>
									<DT><A HREF="https://pytorch.org/blog/accelerating-2k-scale-pre-training-up-to-1-28x-with-torchao-mxfp8-and-torchtitan-on-crusoe-b200-cluster/">Accelerating 2K scale pre-training up to 1.28x with TorchAO, MXFP8 and TorchTitan on Crusoe B200 Cluster ‚Äì PyTorch</A>
								</DL><p>
								<DT><A HREF="https://developer.nvidia.com/blog/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/">NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit | NVIDIA Technical Blog</A>
							</DL><p>
							<DT><H3 FOLDED>torchtitan-compiler</H3>
							<DL><p>
								<DT><A HREF="https://github.com/datacrunch-research/torchtitan/commit/edbf3491d1b02bb36f4b5aca07283e0804802459">[easy] [compiler toolkit] Clean up unused function (#2014) ¬∑ datacrunch-research/torchtitan@edbf349</A>
							</DL><p>
							<DT><A HREF="https://github.com/pytorch/torchtitan">pytorch/torchtitan: A native PyTorch Library for large model training</A>
							<DT><A HREF="https://github.com/pytorch/torchtune">pytorch/torchtune: A Native-PyTorch Library for LLM Fine-tuning</A>
							<DT><A HREF="https://github.com/huggingface/nanotron">huggingface/nanotron: Minimalistic large language model 3D-parallelism training</A>
							<DT><A HREF="https://github.com/pytorch-labs/gpt-fast">pytorch-labs/gpt-fast: Simple and efficient pytorch-native transformer text generation in &lt;1000 LOC of python.</A>
							<DT><A HREF="https://github.com/pytorch-labs/gpt-fast/blob/main/tp.py#L124">gpt-fast/tp.py at main ¬∑ pytorch-labs/gpt-fast</A>
							<DT><A HREF="https://volcengine.github.io/veScaleWeb/">veScale</A>
							<DT><A HREF="https://github.com/volcengine/veScale">volcengine/veScale: A PyTorch Native LLM Training Framework</A>
							<DT><A HREF="https://arxiv.org/abs/2402.15627">[2402.15627] MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs</A>
							<DT><A HREF="https://arxiv.org/abs/2408.03505">[2408.03505] Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation</A>
							<DT><A HREF="https://www.youtube.com/watch?v=VYWRjcUqW6w">Lecture 39: Torchtitan - YouTube</A>
							<DT><A HREF="https://github.com/AmberLJC/LLMSys-PaperList">AmberLJC/LLMSys-PaperList: Large Language Model (LLM) Systems Paper List</A>
							<DT><A HREF="https://github.com/IST-DASLab/Quartet">IST-DASLab/Quartet fp4 training</A>
							<DT><A HREF="https://github.com/AI-Hypercomputer/gpu-recipes?tab=readme-ov-file">AI-Hypercomputer/gpu-recipes: Recipes for reproducing training and serving benchmarks for large machine learning models using GPUs on Google Cloud.</A>
							<DT><A HREF="https://cdn.prod.website-files.com/62bc66d283fd9c34ffec780a/689fa33a0e99f19c11c8ecbe_CoreWeave%20Training%20Benchmarks%20Whitepaper%20August%202025.pdf?utm_source=linkedin&utm_medium=social&utm_content=344263446">https://cdn.prod.website-files.com/62bc66d283fd9c34ffec780a/689fa33a0e99f19c11c8ecbe_CoreWeave%20Training%20Benchmarks%20Whitepaper%20August%202025.pdf?utm_source=linkedin&amp;utm_medium=social&amp;utm_content=344263446</A>
							<DT><A HREF="https://github.com/pytorch/torchtitan/pull/1754">gpt-oss model enablement by wwwjn ¬∑ Pull Request #1754 ¬∑ pytorch/torchtitan</A>
							<DT><A HREF="https://x.com/khoomeik/status/1973492812802039823">(1) Rohan Pandey en X: "periodic ‚ù§Ô∏è open-source! for example, we‚Äôve been collaborating with the @PyTorch team to build the highest MFU gpt-oss training implementation (includes thinky sinky flexattn) here‚Äôs a few SFT runs of gpt-oss-20b &amp;amp; 120b, where i get ~24% MFU for 20b and ~8% for 120b https://t.co/EjvjBGnWJW" / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=o1Ftb3gpeDs&list=PL_lsbAsL_o2BUUxo6coMBFwQE31U4Eb2q&index=12">Our Journey With TorchTitan - Linsong Chu &amp; Garrett Goon, IBM Research - YouTube</A>
							<DT><A HREF="https://nousresearch.com/moe-scaling-field-notes/">Foundation MoE Training Worklogs Part 1 - NOUS RESEARCH</A>
						</DL><p>
						<DT><H3 FOLDED>bytedn-VeOmni</H3>
						<DL><p>
							<DT><A HREF="https://github.com/ByteDance-Seed/VeOmni">ByteDance-Seed/VeOmni: VeOmni: Scaling any Modality Model Training to any Accelerators with PyTorch native Training Framework</A>
							<DT><A HREF="https://github.com/ByteDance-Seed/VeOmni/blob/main/docs/start/best_practice.md">VeOmni/docs/start/best_practice.md at main ¬∑ ByteDance-Seed/VeOmni</A>
						</DL><p>
						<DT><H3 FOLDED>Megatron</H3>
						<DL><p>
							<DT><H3 FOLDED>megatron-nvl72</H3>
							<DL><p>
								<DT><H3 FOLDED>megatron-deepseek</H3>
								<DL><p>
									<DT><H3 FOLDED>megatron-deepseek-fp8</H3>
									<DL><p>
										<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s72778/">Stable and Scalable FP8 Deep Learning Training on Blackwell S72778 | GTC 2025 | NVIDIA On-Demand</A>
										<DT><A HREF="https://cursor.com/en-US/blog/kernels">1.5x faster MoE training with custom MXFP8 kernels ¬∑ Cursor</A>
									</DL><p>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/dev/docs/discussions/deepseek-v3-gb200-optimization/deepseek-v3-gb200-optimization.md">Megatron-LM/docs/discussions/deepseek-v3-gb200-optimization/deepseek-v3-gb200-optimization.md at dev ¬∑ NVIDIA/Megatron-LM</A>
									<DT><A HREF="https://github.com/zartbot/blog/issues/3">Inside Nvidia GPU: Discussing Blackwell's Limitations and Predicting Rubin's Microarchitecture ¬∑ Issue #3 ¬∑ zartbot/blog</A>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/dev/docs/discussions/deepseek-v3-gb200-optimization/deepseek-v3-gb200-reproduce-guide.md">Megatron-LM/docs/discussions/deepseek-v3-gb200-optimization/deepseek-v3-gb200-reproduce-guide.md at dev ¬∑ NVIDIA/Megatron-LM</A>
									<DT><A HREF="https://github.com/yanring/Megatron-MoE-ModelZoo/tree/main/best_practice/DeepSeekV3">Megatron-MoE-ModelZoo/best_practice/DeepSeekV3 at main ¬∑ yanring/Megatron-MoE-ModelZoo</A>
									<DT><A HREF="https://www.bilibili.com/video/BV1mpMwz9Ey5/">FP8 Training Recipes, Performance and Convergence. A video in Chinese introduces FP8 training recipes, performance and convergence.</A>
									<DT><A HREF="https://www.bilibili.com/video/BV1MpMwzREjU/?spm_id_from=333.788.recommend_more_video.0">Megatron Core MoE in 2025- Êû∂ÊûÑ„ÄÅÁâπÊÄß„ÄÅÊÄßËÉΩ‰ºòÂåñ‰ª•ÂèäÂú®DeepseekV3 ‰∏äÁöÑÊúÄ‰Ω≥ÂÆûË∑µ_ÂìîÂì©ÂìîÂì©_bilibili</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>megatron-parallelism</H3>
							<DL><p>
								<DT><H3 FOLDED>megatron-collectives</H3>
								<DL><p>
									<DT><H3 FOLDED>megatron-a2a</H3>
									<DL><p>
										<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/a32ff750191d04713ea1c15dcc65308324681016/megatron/core/transformer/moe/fused_a2a.py#L4">Megatron-LM/megatron/core/transformer/moe/fused_a2a.py at a32ff750191d04713ea1c15dcc65308324681016 ¬∑ NVIDIA/Megatron-LM</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/03/30/illustrated-megatron.html">An illustrated deep-dive into Megatron-style tensor parallelism | ML Perf Notes</A>
								<DT><A HREF="https://zhuanlan.zhihu.com/p/693425934">Research on Load Imbalance Problem in Megatron 1F1B Pipeline Parallelism</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-attention</H3>
							<DL><p>
								<DT><H3 FOLDED>megatron-mla</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/a32ff750191d04713ea1c15dcc65308324681016/docs/source/api-guide/multi_latent_attention.rst#L7">Megatron-LM/docs/source/api-guide/multi_latent_attention.rst at a32ff750191d04713ea1c15dcc65308324681016 ¬∑ NVIDIA/Megatron-LM</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>megatron-MoE</H3>
							<DL><p>
								<DT><A HREF="https://github.com/yanring/Megatron-MoE-ModelZoo">yanring/Megatron-MoE-ModelZoo: Best practices for training DeepSeek, Mixtral, Qwen and other MoE models using Megatron Core.</A>
								<DT><A HREF="https://cursor.com/en-US/blog/kernels">1.5x faster MoE training with custom MXFP8 kernels ¬∑ Cursor</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-objectives</H3>
							<DL><p>
								<DT><A HREF="https://github.com/bigscience-workshop/Megatron-DeepSpeed/pull/353/files#diff-df547fcaa58ea4cb2f31099e838dd94f10c92fbb14a5111ed4ffced4ee5f0c4e">Pre-train UL2</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-memory</H3>
							<DL><p>
								<DT><A HREF="http://giantpandacv.com/project/PyTorch/AI%20Infra%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E4%B9%8B%E3%80%8A%E5%9C%A8LLM%E8%AE%AD%E7%BB%83%E4%B8%AD%E5%87%8F%E5%B0%91%E6%BF%80%E6%B4%BB%E5%80%BC%E5%86%85%E5%AD%98%E3%80%8B/">AI Infra paper reading: "Reducing activation value memory in LLM training"</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-examples</H3>
							<DL><p>
								<DT><A HREF="https://github.com/bigcode-project/Megatron-LM/blob/c4468364e4225b32adb648d7918a3e645ff9e409/examples/pretrain_gpt_1B_santacoder.sh">BigCode: pretrain_gpt_1_santacoder.sh</A>
								<DT><A HREF="https://github.com/THUDM/CodeGeeX/blob/f1afae7b26ceaa040adcd4b4812b64f259b05647/scripts/pretrain_codegeex.sh#L47">CodeGeeX/pretrain_codegeex.sh</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-slurm</H3>
							<DL><p>
								<DT><A HREF="https://github.com/yanring/Megatron-MoE-ModelZoo/blob/main/sbatch_benchmarking.sh">Megatron-MoE-ModelZoo/sbatch_benchmarking.sh at main ¬∑ yanring/Megatron-MoE-ModelZoo</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-rocm</H3>
							<DL><p>
								<DT><A HREF="https://github.com/TurkuNLP/Megatron-DeepSpeed">TurkuNLP/Megatron-DeepSpeed: Ongoing research training transformer language models at scale, including: BERT &amp; GPT-2</A>
								<DT><A HREF="https://github.com/vosen/ZLUDA">vosen/ZLUDA: CUDA on AMD GPUs</A>
							</DL><p>
							<DT><H3 FOLDED>NeMO</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/NeMo">NVIDIA/NeMo: NeMo: a toolkit for conversational AI</A>
								<DT><A HREF="https://docs.nvidia.com/nemo-framework/user-guide/latest/multimodalmodels/text2image/imagen/index.html">Imagen ‚Äî NVIDIA NeMo Framework User Guide latest documentation</A>
							</DL><p>
							<DT><H3 FOLDED>picotron</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/nanotron">nanotron (Nanotron Research)</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-symm-mem</H3>
							<DL><p>
								<DT><A HREF="https://github.com/yifuwang/symm-mem-recipes">yifuwang/symm-mem-recipes</A>
								<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/497d42de9862a446a08c4c2649f68d4aa5a7b7a7/megatron/core/inference/communication/torch_symm_triton/multimem_asm.py#L61">Megatron-LM/megatron/core/inference/communication/torch_symm_triton/multimem_asm.py at 497d42de9862a446a08c4c2649f68d4aa5a7b7a7 ¬∑ NVIDIA/Megatron-LM</A>
							</DL><p>
							<DT><H3 FOLDED>megatron-shard_map</H3>
							<DL><p>
								<DT><A HREF="https://blog.ezyang.com/2026/01/megatron-via-shard-map/">Megatron via shard_map : ezyang's blog</A>
								<DT><A HREF="https://blog.ezyang.com/2026/01/computing-sharding-with-einsum/">Computing sharding with einsum : ezyang's blog</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/1909.08053">[1909.08053] Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism</A>
							<DT><A HREF="https://arxiv.org/abs/2104.04473">[2104.04473] Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM</A>
							<DT><A HREF="https://arxiv.org/abs/2410.15526">[2410.15526] SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training</A>
							<DT><A HREF="https://github.com/alibaba/Megatron-LLaMA">alibaba/Megatron-LLaMA: Best practice for training LLaMA models in Megatron-LM</A>
							<DT><A HREF="https://twitter.com/YangYou1991/status/1770334665678970882">Dynamic Sequence Parallelism: parallel axis</A>
							<DT><A HREF="https://huggingface.co/spaces/BBuf/megatron-lm-parallel-group-playground">Megatron Lm Parallel Group Playground - a Hugging Face Space by BBuf</A>
							<DT><A HREF="https://github.com/EleutherAI/cookbook/blob/main/benchmarks/sizing/megatron_wrapper.py#L102">cookbook/benchmarks/sizing/megatron_wrapper.py at main ¬∑ EleutherAI/cookbook</A>
							<DT><A HREF="https://strint.notion.site/Megatron-LM-86381cfe51184b9c888be10ee82f3812">Megatron-LM ÁöÑÂàÜÂ∏ÉÂºèÊâßË°åË∞ÉÁ†îÔºöÂéüÁêÜÂíåÊúÄ‰Ω≥ÂÆûË∑µ</A>
							<DT><A HREF="https://www.youtube.com/watch?v=ImKyR1tsPPE">ML Scalability &amp; Performance Reading Group Session 8: Megatron-LM - YouTube</A>
							<DT><A HREF="https://github.com/yanring/Megatron-MoE-ModelZoo">yanring/Megatron-MoE-ModelZoo: Best practices for training DeepSeek, Mixtral, Qwen and other MoE models using Megatron Core.</A>
							<DT><A HREF="https://danielvegamyhre.github.io/ml/performance/2025/03/30/illustrated-megatron.html">An illustrated deep-dive into Megatron-style tensor parallelism | ML Perf Notes</A>
							<DT><A HREF="https://github.com/danielvegamyhre/ml-perf-reading-group/tree/main/session_8">ml-perf-reading-group/session_8 at main ¬∑ danielvegamyhre/ml-perf-reading-group</A>
						</DL><p>
						<DT><H3 FOLDED>DeepSpeed</H3>
						<DL><p>
							<DT><H3 FOLDED>ZeRO-stage-1</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>ZeRO-stage-2</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>ZeRO-stage-3</H3>
							<DL><p>
								<DT><A HREF="https://github.com/stas00/ml-engineering/tree/master/training/model-parallelism">ml-engineering/training/model-parallelism at master ¬∑ stas00/ml-engineering</A>
							</DL><p>
							<DT><H3 FOLDED>ZeRO-infinity</H3>
							<DL><p>
								<DT><H3 FOLDED>Videos</H3>
								<DL><p>
									<DT><A HREF="https://www.youtube.com/watch?v=smDC_mOGQ5U">[REFAI Seminar 03/30/23] Efficient Trillion Parameter Scale Training</A>
									<DT><A HREF="https://www.youtube.com/watch?v=YEdtLCjSZFY">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale</A>
									<DT><A HREF="https://www.youtube.com/watch?v=7IposV4_LY4">Unleashing the Power of BLOOM 176B with AWS</A>
								</DL><p>
								<DT><A HREF="https://arxiv.org/pdf/2104.07857.pdf">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</A>
								<DT><A HREF="https://dl.acm.org/doi/10.1145/3458817.3476205">ZeRO-infinity | Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis</A>
								<DT><A HREF="https://arxiv.org/pdf/2306.09782.pdf">LOMO: Heterogeneous Training System (ZeRO-Infinity)</A>
								<DT><A HREF="https://sliu583.gitbook.io/blog/specific-work/shivarams-group/group-papers/lists/zero-infinity-and-deepspeed-unlocking-unprecedented-model-scale-for-deep-learning-training">ZeRO-Infinity and DeepSpeed: Unlocking unprecedented model</A>
								<DT><A HREF="https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html">TRAIN 1 TRILLION+ PARAMETER MODELS</A>
								<DT><A HREF="https://www.amazon.science/blog/scaling-to-trillion-parameter-model-training-on-aws">Scaling to trillion-parameter model training on AWS</A>
							</DL><p>
							<DT><H3 FOLDED>DeepSpeed-domino</H3>
							<DL><p>
								<DT><A HREF="https://x.com/MSFTDeepSpeed/status/1861171902506549532">DeepSpeed en X: "Introducing Domino: a novel zero-cost communication tensor parallelism (TP) training engine for both single node and multi-node settings. - Near-complete communication hiding - Novel multi-node scalable TP solution Blog: https://t.co/08bPanyr9M https://t.co/KudHdIs3aY" / X</A>
								<DT><A HREF="https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-domino/README.md">DeepSpeed/blogs/deepspeed-domino/README.md at master ¬∑ microsoft/DeepSpeed</A>
								<DT><A HREF="https://arxiv.org/abs/2409.15241">[2409.15241] Domino: Eliminating Communication in LLM Training via Generic Tensor Slicing and Overlapping</A>
							</DL><p>
							<DT><H3 FOLDED>deepspeed-config</H3>
							<DL><p>
								<DT><A HREF="https://www.deepspeed.ai/docs/config-json/">DeepSpeed Configuration JSON - DeepSpeed</A>
							</DL><p>
							<DT><H3 FOLDED>deepspeed-profiler</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google/paxml/issues/65">[Question] Very low MFU(30%~35%) when train bf16 Llama2 and GPT model with single SXM4 A100 machine. ¬∑ Issue #65 ¬∑ google/paxml</A>
							</DL><p>
							<DT><A HREF="https://github.com/cloneofsimo/min-max-gpt">cloneofsimo/min-max-gpt: minGPT that scales</A>
							<DT><A HREF="https://arxiv.org/abs/1910.02054">[1910.02054] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</A>
							<DT><A HREF="https://github.com/microsoft/Megatron-DeepSpeed">microsoft/Megatron-DeepSpeed</A>
							<DT><A HREF="https://huggingface.co/docs/transformers/main/main_classes/deepspeed#deepspeed-trainer-integration">DeepSpeed Integration</A>
							<DT><A HREF="https://www.youtube.com/watch?v=wbG2ZEDPIyw">Microsoft DeepSpeed introduction at KAUST</A>
							<DT><A HREF="https://github.com/alpa-projects/alpa/blob/824f2ffd5124d24935811bc738ed903796ab13ac/benchmark/deepspeed/benchmark_gpt2.py#L86">alpa/benchmark/deepspeed/benchmark_gpt2.py</A>
							<DT><A HREF="https://github.com/cloneofsimo/reverse_eng_deepspeed_study">cloneofsimo/reverse_eng_deepspeed_study: DeepSpeed Study</A>
							<DT><A HREF="https://mp.weixin.qq.com/s/8F3eAHDBjQkHHBmrAEoOfw">Illustrated explanation of large model training: Data parallelism, Part 2 (ZeRO, zero redundancy optimization)</A>
							<DT><A HREF="https://nn.labml.ai/scaling/zero3/index.html">Zero-DP Memory Optimization</A>
							<DT><A HREF="https://github.com/cloneofsimo/min-fsdp/tree/main/journey/understanding_zero">min-fsdp/journey/understanding_zero at main ¬∑ cloneofsimo/min-fsdp</A>
							<DT><A HREF="https://github.com/intelligent-machine-learning/dlrover">intelligent-machine-learning/dlrover: DLRover: An Automatic Distributed Deep Learning System</A>
							<DT><A HREF="https://dev.to/lewis_won/data-parallelism-4g3m">ZeRO by hand with a 4-parameter model - DEV Community</A>
						</DL><p>
						<DT><H3 FOLDED>training-fault-tolerant</H3>
						<DL><p>
							<DT><H3 FOLDED>nvidia-resiliency-ext</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA/nvidia-resiliency-ext">NVIDIA/nvidia-resiliency-ext: NVIDIA Resiliency Extension is a python package for framework developers and users to implement fault-tolerant features. It improves the effective training time by minimizing the downtime due to failures and interruptions.</A>
								<DT><A HREF="https://github.com/NVIDIA/Megatron-LM/blob/148284dcf6c64b3abdaa2dca2e784f9c245425f6/megatron/training/inprocess_restart.py#L98">Megatron-LM/megatron/training/inprocess_restart.py: import nvidia_resiliency_ext.inprocess as inprocess</A>
								<DT><A HREF="https://github.com/search?q=repo%3ANVIDIA-NeMo%2FNeMo%20nvidia_resiliency_ext&type=code">NeMo fault tolerant nvidia_resilency_ext</A>
								<DT><A HREF="https://github.com/NVIDIA-NeMo/NeMo/blob/280075283e392b94fb1546a4bb4eb0e516636c84/tests/collections/llm/test_local_ckpt.py#L46">NeMo/tests/collections/llm/test_local_ckpt.py at 280075283e392b94fb1546a4bb4eb0e516636c84 ¬∑ NVIDIA-NeMo/NeMo</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>deepspeed</H3>
						<DL><p>
							<DT><A HREF="https://www.deepspeed.ai/tutorials/inference-tutorial/">Getting Started with DeepSpeed for Inferencing Transformer based Models - DeepSpeed</A>
							<DT><A HREF="https://www.deepspeed.ai/tutorials/inference-tutorial/#end-to-end-gpt-neo-27b-inference">GPT-NEOX-20B</A>
							<DT><A HREF="https://www.philschmid.de/bert-deepspeed-inference">Accelerate BERT inference with DeepSpeed-Inference on GPUs</A>
							<DT><A HREF="https://www.deepspeed.ai/tutorials/megatron/">Megatron-LM GPT2 - DeepSpeed</A>
							<DT><A HREF="https://www.deepspeed.ai/tutorials/zero/#zero-overview">Zero Redundancy Optimizer</A>
							<DT><A HREF="https://github.com/huggingface/transformers/blob/main/tests/deepspeed/ds_config_zero2.json">transformers/ds_config_zero2.json</A>
							<DT><A HREF="https://github.com/microsoft/Megatron-DeepSpeed">microsoft/Megatron-DeepSpeed: Ongoing research training transformer language models at scale, including: BERT &amp; GPT-2</A>
							<DT><A HREF="https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/deepspeed">Huggingface Transformers DeepSpeed Integration</A>
						</DL><p>
						<DT><H3 FOLDED>llm.c</H3>
						<DL><p>
							<DT><H3 FOLDED>llm.c-videos</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=l8pRSuU81PU">Let's reproduce GPT-2 (124M) - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4577s">Let's build GPT: from scratch, in code, spelled out. - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>llm.c-profiling</H3>
							<DL><p>
								<DT><A HREF="https://github.com/karpathy/llm.c/discussions/331">LLM.c Speed of Light &amp; Beyond (A100 Performance Analysis) ¬∑ karpathy/llm.c ¬∑ Discussion #331</A>
							</DL><p>
							<DT><H3 FOLDED>llm.c-hand</H3>
							<DL><p>
								<DT><A HREF="https://x.com/ProfTomYeh/status/1985376111782711560">(1) Tom Yeh en X: "llm.c by hand ‚úçÔ∏è C meets Transformer This combination is perhaps as low as we can get! Special thanks to @karpathy -- Part 1: gpt2_forward Karpathy's llm.c implements the transformer forward step as the following sequence. (skip)layernorm_forward 1. matmul_forward 2. https://t.co/TzMoouYsdv" / X</A>
							</DL><p>
							<DT><A HREF="https://github.com/karpathy/llm.c">karpathy/llm.c: LLM training in simple, raw C/CUDA</A>
							<DT><A HREF="https://github.com/Chillee/llm.c/commit/c39de5916835b5ade292bc96a8b81de4a517972e">attach a simple tutorial (layernorm)</A>
							<DT><A HREF="https://gist.github.com/geohot/7c9f10f5770f058a1de6ef0598e4c9d8">Outputted llm.c from tinygrad</A>
							<DT><A HREF="https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/core/providers/cuda/math/softmax_warpwise_impl.cuh">onnxruntime/onnxruntime/core/providers/cuda/math/softmax_warpwise_impl.cuh</A>
							<DT><A HREF="https://x.com/karpathy/status/1799949853289804266">(1) Andrej Karpathy en X: "üìΩÔ∏è New 4 hour (lol) video lecture on YouTube: "Let‚Äôs reproduce GPT-2 (124M)" https://t.co/NMIVD1V6zr The video ended up so long because it is... comprehensive: we start with empty file and end up with a GPT-2 (124M) model: - first we build the GPT-2 network - then we optimize https://t.co/NDqTrLbrO4" / X</A>
							<DT><A HREF="https://github.com/karpathy/llm.c/discussions/481">Reproducing GPT-2 (124M) in llm.c in 90 minutes for $20 ¬∑ karpathy/llm.c ¬∑ Discussion #481</A>
							<DT><A HREF="https://arxiv.org/abs/2212.14034">[2212.14034] Cramming: Training a Language Model on a Single GPU in One Day</A>
							<DT><A HREF="https://x.com/karpathy/status/1841536804073439268">Andrej Karpathy en X: "I gave a talk at GPU MODE workshop last week on llm.c - the origin story of llm.c - being naked in the world without PyTorch and having to re-invent Array, Autograd, Device, Dtype, Compile, Distributed - how to port a PyTorch layer to 1) explicit PyTorch - and then to 2) write https://t.co/u8JXyy90VE" / X</A>
							<DT><A HREF="https://github.com/karpathy/llm.c/discussions/331">LLM.c Speed of Light &amp; Beyond (A100 Performance Analysis) ¬∑ karpathy/llm.c ¬∑ Discussion #331</A>
							<DT><A HREF="https://github.com/LambdaLabsML/llm.c-1cc/tree/main">LambdaLabsML/llm.c-1cc</A>
						</DL><p>
						<DT><H3 FOLDED>ray</H3>
						<DL><p>
							<DT><A HREF="https://docs.anyscale.com/rayturbo/mid-epoch-resumption">Mid-epoch training resumption | Anyscale Docs</A>
						</DL><p>
						<DT><H3 FOLDED>nanotron</H3>
						<DL><p>
							<DT><H3 FOLDED>nanotron-dataloader</H3>
							<DL><p>
							</DL><p>
							<DT><A HREF="https://github.com/huggingface/nanotron/tree/main">huggingface/nanotron: Minimalistic large language model 3D-parallelism training</A>
							<DT><A HREF="https://jeremybernste.in/modula/history/">The science of scale - Modula documentation</A>
						</DL><p>
						<DT><H3 FOLDED>cosmos-predict2.5</H3>
						<DL><p>
							<DT><H3 FOLDED>cosmos-s3</H3>
							<DL><p>
								<DT><A HREF="https://github.com/nvidia-cosmos/cosmos-predict2.5/blob/f947d443dce20ada6babaf9b5c7c1fe2966eacd1/cosmos_predict2/_src/imaginaire/datasets/webdataset/utils/iterators.py#L132">cosmos-predict2.5/cosmos_predict2/_src/imaginaire/datasets/webdataset/utils/iterators.py at f947d443dce20ada6babaf9b5c7c1fe2966eacd1 ¬∑ nvidia-cosmos/cosmos-predict2.5</A>
								<DT><A HREF="https://github.com/mosaicml/streaming/blob/89e7bb9082457a59f6efcfa4ef910102e07a9729/streaming/base/stream.py">streaming/streaming/base/stream.py at 89e7bb9082457a59f6efcfa4ef910102e07a9729 ¬∑ mosaicml/streaming</A>
							</DL><p>
							<DT><A HREF="https://github.com/nvidia-cosmos/cosmos-predict2.5">nvidia-cosmos/cosmos-predict2.5: Cosmos-Predict2.5, the latest version of the Cosmos World Foundation Models (WFMs) family, specialized for simulating and predicting the future state of the world in the form of video.</A>
							<DT><A HREF="https://d1qx31qr3h6wln.cloudfront.net/publications/World_Simulation_with_Video_Foundation_Models_for_Physical_AI.pdf">World Simulation with Video Foundation Models for Physical AI</A>
						</DL><p>
						<DT><H3 FOLDED>jax-training</H3>
						<DL><p>
							<DT><H3 FOLDED>Maxtext</H3>
							<DL><p>
								<DT><H3 FOLDED>maxtext-docs</H3>
								<DL><p>
									<DT><A HREF="https://www.nvidia.com/en-us/on-demand/session/gtc25-s73266/">Horizontal Scaling of LLM Training with JAX S73266 | GTC 2025 | NVIDIA On-Demand</A>
									<DT><A HREF="https://cloud.google.com/blog/products/compute/the-worlds-largest-distributed-llm-training-job-on-tpu-v5e">the world‚Äôs largest distributed LLM training job on TPU v5e | Google Cloud Blog</A>
								</DL><p>
								<DT><H3 FOLDED>maxtext-deepseek</H3>
								<DL><p>
									<DT><A HREF="https://github.com/AI-Hypercomputer/maxtext/blob/cb136bc404c226bd618ff19b283e4887db23adee/end_to_end/tpu/deepseek/Run_DeepSeek.md">maxtext/end_to_end/tpu/deepseek/Run_DeepSeek.md</A>
								</DL><p>
								<DT><H3 FOLDED>Optax</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google-deepmind/optax">google-deepmind/optax: Optax is a gradient processing and optimization library for JAX.</A>
								</DL><p>
								<DT><H3 FOLDED>Orbax</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/orbax">google/orbax: Orbax provides common checkpointing and persistence utilities for JAX users</A>
								</DL><p>
								<DT><H3 FOLDED>Qwix</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/qwix">google/qwix: a Jax quantization library</A>
								</DL><p>
								<DT><H3 FOLDED>AQT</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/aqt">google/aqt</A>
								</DL><p>
								<DT><H3 FOLDED>metrax</H3>
								<DL><p>
									<DT><A HREF="https://metrax.readthedocs.io/en/latest/">metrax Documentation ‚Äî metrax documentation</A>
								</DL><p>
								<DT><H3 FOLDED>tunix</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/tunix">google/tunix: A JAX-native LLM Post-Training Library</A>
								</DL><p>
								<DT><H3 FOLDED>goodput-measurement</H3>
								<DL><p>
									<DT><A HREF="https://github.com/AI-Hypercomputer/ml-goodput-measurement">AI-Hypercomputer/ml-goodput-measurement</A>
								</DL><p>
								<DT><A HREF="https://github.com/google/maxtext">google/maxtext: A simple, performant and scalable Jax LLM!</A>
								<DT><A HREF="https://cloud.google.com/blog/products/compute/inside-the-ironwood-tpu-codesigned-ai-stack?e=48754805?utm_source%3Dtwitter?utm_source=twitter&utm_medium=unpaidsoc&utm_campaign=fy25q4-googlecloudtech-blog-ai-in_feed-no-brand-global&utm_content=-&utm_term=-&linkId=17613360">Inside the Ironwood TPU codesigned AI stack | Google Cloud Blog</A>
							</DL><p>
							<DT><H3 FOLDED>t5x + seqio</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google-research/text-to-text-transfer-transformer">google-research/text-to-text-transfer-transformer: Code for the paper "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"</A>
								<DT><A HREF="https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md">Checkpoints</A>
								<DT><A HREF="https://github.com/google/flaxformer/blob/main/flaxformer/architectures/t5/t5_1_1.py#L70">flaxformer/flaxformer/architectures/t5/t5_1_1.py at main ¬∑ google/flaxformer</A>
								<DT><A HREF="https://github.com/google/maxtext">google/maxtext: A simple, performant and scalable Jax LLM!</A>
								<DT><A HREF="https://github.com/google-research/t5x">google-research/t5x</A>
							</DL><p>
							<DT><H3 FOLDED>FLAX</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=__eG63ZP_5g">Day 2 Talks: JAX, Flax &amp; Transformers ü§ó - YouTube</A>
								<DT><A HREF="https://github.com/google/maxtext">google/maxtext: A simple, performant and scalable Jax LLM!</A>
								<DT><H3 FOLDED>flaxformer</H3>
								<DL><p>
									<DT><A HREF="https://github.com/google/flaxformer">google/flaxformer</A>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>Haliax</H3>
							<DL><p>
								<DT><A HREF="https://github.com/stanford-crfm/haliax">stanford-crfm/haliax: Named Tensors for Legible Deep Learning in JAX</A>
								<DT><A HREF="https://levanter.readthedocs.io/en/latest/Fine-Tuning/">Custom Fine-Tuning: Alpaca Tutorial - Levanter</A>
								<DT><A HREF="https://twitter.com/dlwh/status/1716901560532521100">(David Hall): Haliax release</A>
								<DT><A HREF="https://twitter.com/dlwh/status/1716900734120464834/photo/1">Named tensor library</A>
							</DL><p>
							<DT><H3 FOLDED>Paxml</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google/paxml">google/paxml: Pax is a Jax-based machine learning framework for training large scale models. Pax allows for advanced and fully configurable experimentation and parallelization, and has demonstrated industry leading model flop utilization rates.</A>
								<DT><A HREF="https://github.com/NVIDIA/JAX-Toolbox/tree/main/rosetta/rosetta/projects/pax">JAX-Toolbox/rosetta/rosetta/projects/pax at main ¬∑ NVIDIA/JAX-Toolbox</A>
								<DT><A HREF="https://github.com/google/praxis/tree/main">google/praxis</A>
							</DL><p>
							<DT><H3 FOLDED>Levanter</H3>
							<DL><p>
								<DT><A HREF="https://github.com/stanford-crfm/levanter">stanford-crfm/levanter: Legibile, Scalable, Reproducible Foundation Models with Named Tensors and Jax</A>
								<DT><A HREF="https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html">Levanter ‚Äî Legible, Scalable, Reproducible Foundation Models with JAX</A>
								<DT><H3 FOLDED>configs</H3>
								<DL><p>
									<DT><A HREF="https://github.com/NbAiLab/nb-levanter/blob/main/configs/mimir-mistral-7b-extended.yaml">nb-levanter/configs/mimir-mistral-7b-extended.yaml</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2311.08105">[2311.08105] DiLoCo: Distributed Low-Communication Training of Language Models</A>
						</DL><p>
						<DT><H3 FOLDED>hf-accelerate</H3>
						<DL><p>
							<DT><H3 FOLDED>hf-accelerate-inference</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/docs/transformers/perf_infer_gpu_one">Efficient Inference on a Single GPU</A>
							</DL><p>
							<DT><A HREF="https://github.com/huggingface/accelerate">huggingface/accelerate: Train and use PyTorch models with multi-GPU, TPU, mixed-precision</A>
							<DT><A HREF="https://huggingface.co/blog/bloom-inference-pytorch-scripts">Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate</A>
							<DT><A HREF="https://huggingface.co/docs/accelerate/usage_guides/big_modeling">Handling big models for inference (Sharding &amp; device map)</A>
							<DT><A HREF="https://huggingface.co/docs/transformers/perf_train_gpu_many">Efficient Training on Multiple GPUs</A>
							<DT><A HREF="https://github.com/huggingface/accelerate/blob/d4f5fd694e3acf9178b8075ea2379fd1839954f2/docs/source/usage_guides/big_modeling.mdx">Handling big models for inference</A>
							<DT><A HREF="https://github.com/huggingface/transformers/issues/16884">Transformers model shards</A>
							<DT><A HREF="https://towardsdatascience.com/sharded-a-new-technique-to-double-the-size-of-pytorch-models-3af057466dba">Sharded</A>
							<DT><A HREF="https://github.com/kingoflolz/mesh-transformer-jax">Mesh-Transformer-jax: Model parallel transformers in JAX and Haiku</A>
						</DL><p>
						<DT><H3 FOLDED>mosaicml-training</H3>
						<DL><p>
							<DT><H3 FOLDED>mosaic-composer</H3>
							<DL><p>
								<DT><A HREF="https://github.com/mosaicml/composer">mosaicml/composer: Supercharge Your Model Training</A>
							</DL><p>
							<DT><A HREF="https://www.mosaicml.com/">MosaicML | Home</A>
							<DT><A HREF="https://www.mosaicml.com/blog/coreweave-nvidia-h100-part-1?utm_source=twitter&utm_medium=social&utm_campaign=h100-blog-post">Benchmarking Large Language Models on NVIDIA H100 GPUs with CoreWeave (Part 1)</A>
						</DL><p>
						<DT><H3 FOLDED>training-infra-eth-zurich</H3>
						<DL><p>
							<DT><A HREF="https://github.com/eth-easl/fmengine">eth-easl/fmengine: Utilities for Training Very Large Models</A>
						</DL><p>
						<DT><H3 FOLDED>tensorflow-training</H3>
						<DL><p>
							<DT><H3 FOLDED>tensorflow-installation</H3>
							<DL><p>
								<DT><A HREF="https://velog.io/@qone/Apple-silicon-m1-%EB%A7%A5%EC%97%90-tensorflow%EC%84%A4%EC%B9%98%ED%95%98%EA%B3%A0-GPU%EA%B0%80%EC%86%8D-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0">Enable tensorflow metal (ARM GPU)</A>
								<DT><A HREF="https://gist.github.com/juliasilge/035d54c59436604d6142ebebf29aa224?permalink_comment_id=3981784">Installing R + Tensorflow on M1</A>
								<DT><A HREF="https://developer.apple.com/metal/tensorflow-plugin/">Tensorflow Plugin - Metal - Apple Developer</A>
								<DT><A HREF="https://github.com/robotology/robotology-superbuild/blob/master/doc/install-mambaforge.md#macos">Install mambaforge</A>
							</DL><p>
							<DT><H3 FOLDED>tensorflow-errors</H3>
							<DL><p>
								<DT><A HREF="https://stackoverflow.com/questions/58012741/error-importing-tensorflow-alreadyexistserror-another-metric-with-the-same-nam">two Keras packages installed</A>
								<DT><A HREF="https://stackoverflow.com/questions/57082918/tensorflow-attributeerror-module-tensorflow-python-ops-nn-has-no-attribute">calling v1 API when using v2</A>
							</DL><p>
							<DT><H3 FOLDED>tensorflow-data</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google-research/google-research/blob/master/protein_lm/data.py">TFRecords $ data.py</A>
								<DT><A HREF="https://github.com/google/gin-config">Gin provides a lightweight configuration framework for Python</A>
							</DL><p>
							<DT><H3 FOLDED>tensorflow-docs</H3>
							<DL><p>
								<DT><A HREF="https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/tutorials/mnist/tf/index.md">TensorFlow - TensorFlow Mechanics 101</A>
								<DT><A HREF="https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/how_tos/documentation/index.md">TensorFlow - Writing TensorFlow Documentation</A>
							</DL><p>
							<DT><H3 FOLDED>tensorflow-visualization</H3>
							<DL><p>
								<DT><A HREF="https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin">Visualizing Data using the Embedding Projector in TensorBoard ¬†|¬† TensorFlow</A>
								<DT><A HREF="http://projector.tensorflow.org/">Embedding projector - visualization of high-dimensional data</A>
							</DL><p>
							<DT><H3 FOLDED>tensorflow-configuration</H3>
							<DL><p>
								<DT><A HREF="https://github.com/google/gin-config">Gin provides a lightweight configuration framework for Python</A>
							</DL><p>
							<DT><A HREF="https://www.tensorflow.org/api_docs/python/tf/nn">Module: tf.nn ¬†|¬† TensorFlow Core v2.8.0 (API)</A>
						</DL><p>
						<DT><H3 FOLDED>training-configuration</H3>
						<DL><p>
							<DT><H3 FOLDED>Hydra</H3>
							<DL><p>
								<DT><A HREF="https://github.com/facebookresearch/hydra/blob/main/examples/experimental/rerun/my_app.py">hydra/examples/experimental/rerun/my_app.py at main ¬∑ facebookresearch/hydra</A>
								<DT><A HREF="https://github.com/facebookresearch/hydra">facebookresearch/hydra: Hydra is a framework for elegantly configuring complex applications</A>
								<DT><A HREF="https://blog.helsing.ai/strongly-typed-structured-configuration-in-hydra-8fb43522d224">Strongly-typed structured configuration in Hydra | by Robert Fink | Helsing Blog</A>
							</DL><p>
							<DT><H3 FOLDED>Gin</H3>
							<DL><p>
							</DL><p>
							<DT><A HREF="https://twitter.com/karpathy/status/1529159374672830464">how to flexibly configure and instantiate neural net architectures and trainers</A>
							<DT><A HREF="https://twitter.com/karpathy/status/1528808361558306817">How they store, catalogue, override, manage and plumb hyperparamaters configs</A>
							<DT><A HREF="https://github.com/google/gin-config">Gin provides a lightweight configuration framework for Python</A>
						</DL><p>
						<DT><H3 FOLDED>full-model-gradient-updates</H3>
						<DL><p>
							<DT><H3 FOLDED>full-model-gradient-updates-notebooks</H3>
							<DL><p>
								<DT><A HREF="https://colab.research.google.com/drive/1ft6wQU0BhqG5PRlwgaZJv2VukKKjU4Es">finetune-gpt-j-6B-8bit.ipynb</A>
							</DL><p>
							<DT><A HREF="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/deepseed-flan-t5-summarization.ipynb">Fine-tune FLAN-T5 XL/XXL using DeepSpeed &amp; Hugging Face Transformers</A>
							<DT><A HREF="https://lightning.ai/pages/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/">How To Finetune GPT Like Large Language Models on a Custom Dataset - Lightning AI</A>
							<DT><A HREF="https://arxiv.org/abs/2405.05904#:~:text=We%20demonstrate%20that%20large%20language,consistent%20with%20the%20model's%20knowledge.">[2405.05904] Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?</A>
						</DL><p>
						<DT><H3 FOLDED>training-infra-peft</H3>
						<DL><p>
							<DT><H3 FOLDED>training-infra-LoRA</H3>
							<DL><p>
								<DT><A HREF="https://github.com/tloen/alpaca-lora">Code for reproducing the Stanford Alpaca InstructLLaMA</A>
								<DT><A HREF="https://www.youtube.com/watch?v=4LiKEghyoBo">LoRA - Low Rank Adaptation of Large Language Model: Source Code - YouTube</A>
								<DT><A HREF="https://github.com/punica-ai/punica">punica-ai/punica: Serving multiple LoRA finetuned LLM as one</A>
								<DT><A HREF="https://github.com/predibase/lorax">predibase/lorax: Multi-LoRA inference server that scales to 1000s of fine-tuned LLMs</A>
								<DT><A HREF="https://github.com/S-LoRA/S-LoRA">S-LoRA/S-LoRA: S-LoRA: Serving Thousands of Concurrent LoRA Adapters</A>
							</DL><p>
							<DT><H3 FOLDED>training-infra-prompt-tuning</H3>
							<DL><p>
								<DT><A HREF="https://colab.research.google.com/github/corolla-johnson/mkultra/blob/master/tuning_finetune.ipynb">tuning_finetune_alice.ipynb - Colaboratory</A>
								<DT><A HREF="https://colab.research.google.com/github/corolla-johnson/mkultra/blob/master/tuning_world_info.ipynb#scrollTo=qyfpqA5po5FX">tuning_finetune_lite_3.ipynb - Colaboratory</A>
							</DL><p>
							<DT><A HREF="https://arxiv.org/abs/2403.14608">[2403.14608] Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey</A>
							<DT><A HREF="https://github.com/huggingface/peft">huggingface/peft: ü§ó PEFT: State-of-the-art Parameter-Efficient Fine-Tuning.</A>
							<DT><A HREF="https://www.youtube.com/watch?v=KoOlcX3XLd4">EMNLP 2022 Tutorial - "Modular and Parameter-Efficient Fine-Tuning for NLP Models" - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gCcgM7sl4Q4">LaMA-Adapter Finetuning: Source Code: Paper: PseudoCode</A>
							<DT><A HREF="https://twitter.com/giffmana/status/1776156462252761222">(1) Lucas Beyer (bl16) en X: "A bit late, but I just read ReFT, here's a quick thread. - A PEFT method - acts on activs `h` -&amp;gt; small inference overhead 1/5 https://t.co/iN1emxyXQ6" / X</A>
						</DL><p>
						<DT><H3 FOLDED>training-infra-huggingface</H3>
						<DL><p>
							<DT><H3 FOLDED>hf-datasets</H3>
							<DL><p>
								<DT><H3 FOLDED>hf-datasets-preprocessing</H3>
								<DL><p>
									<DT><A HREF="https://github.com/leogao2/lm_dataformat">LM_Dataformat: Utilities for storing data for LM training</A>
									<DT><A HREF="https://github.com/GEM-benchmark/NL-Augmenter">GEM-benchmark/NL-Augmenter: NL-Augmenter ü¶é ‚Üí üêç A Collaborative Repository of Natural Language Transformations</A>
								</DL><p>
								<DT><A HREF="https://huggingface.co/datasets/the_pile">the_pile ¬∑ Datasets at Hugging Face</A>
								<DT><A HREF="https://huggingface.co/docs/datasets/v1.15.1/installation.html">Installation ‚Äî datasets 1.15.1 documentation</A>
								<DT><A HREF="https://huggingface.co/course/chapter5/5">Creating your own dataset - Hugging Face Course</A>
								<DT><A HREF="https://huggingface.co/docs/datasets/loading">In-Memory data</A>
								<DT><A HREF="https://huggingface.co/docs/datasets/process">Datasets: Process</A>
							</DL><p>
							<DT><H3 FOLDED>hf-hub</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/docs/huggingface_hub/v0.10.1/en/how-to-upstream">Hub Client Library</A>
							</DL><p>
							<DT><H3 FOLDED>hf-eval</H3>
							<DL><p>
								<DT><A HREF="https://huggingface.co/spaces/evaluate-metric/code_eval">Code Eval - a Hugging Face Space by evaluate-metric</A>
							</DL><p>
							<DT><H3 FOLDED>hf-transformers</H3>
							<DL><p>
								<DT><H3 FOLDED>hf-transformers-releases</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/transformers/releases/tag/v4.36.0">Release v4.36: Mixtral, Llava/BakLlava, SeamlessM4T v2, AMD ROCm, F.sdpa wide-spread support ¬∑ huggingface/transformers</A>
								</DL><p>
								<DT><H3 FOLDED>hf-transformers-t5</H3>
								<DL><p>
									<DT><A HREF="https://twitter.com/LiamFedus/status/1536791574612303872">Switch Transformer models in T5X/JAX (1.6T param)</A>
									<DT><A HREF="https://github.com/google-research/t5x">google-research/t5x: Text-To-Text Transfer Transformer</A>
									<DT><A HREF="https://github.com/google-research/t5x">google-research/t5x</A>
									<DT><A HREF="https://colab.research.google.com/drive/1xx7SgdLaAu23YFBirXmaQViDr8caowX_">T0 by mishin_learning.ipynb - Colaboratory</A>
									<DT><A HREF="https://github.com/bigscience-workshop/t-zero/blob/master/inference/README.md">Running inference with T0</A>
								</DL><p>
								<DT><H3 FOLDED>hf-transformers-generation</H3>
								<DL><p>
									<DT><A HREF="https://github.com/huggingface/transformers/releases/tag/v4.26.0">Release v4.26.0: Generation configs, image processors, backbones and plenty of new models! ¬∑ huggingface/transformers</A>
									<DT><A HREF="https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model">Generation Config: Text generation strategies</A>
									<DT><A HREF="https://huggingface.co/gpt2/blob/main/generation_config.json">generation_config.json ¬∑ gpt2 at main</A>
									<DT><A HREF="https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/text_generation#transformers.GenerationConfig">Generation</A>
									<DT><A HREF="https://github.com/huggingface/transformers/blob/e3d832ff87c6ec997125deaa4f1b239db8f9e613/src/transformers/generation/configuration_utils.py#L663">transformers/configuration_utils.py at e3d832ff87c6ec997125deaa4f1b239db8f9e613 ¬∑ huggingface/transformers ¬∑ GitHub</A>
									<DT><H3 FOLDED>Pipelines</H3>
									<DL><p>
										<DT><A HREF="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/pipelines#transformers.TextGenerationPipeline">Pipelines</A>
									</DL><p>
								</DL><p>
								<DT><H3 FOLDED>hf-transformers-models</H3>
								<DL><p>
									<DT><A HREF="https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2LMHeadModel">OpenAI GPT2</A>
								</DL><p>
								<DT><H3 FOLDED>hf-transformers-training</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://twitter.com/yacineMTB/status/1691208981698498560">HF Transformers Software Complexity</A>
								<DT><A HREF="https://github.com/THUDM/SwissArmyTransformer">Flexible and powerful library to develop your own Transformer variants</A>
								<DT><A HREF="https://huggingface.co/spaces/nielsr/LayoutLMv2-FUNSD">LayoutLMv 2 FUNSD - a Hugging Face Space by nielsr</A>
								<DT><A HREF="https://huggingface.co/transformers/v4.8.0/glossary.html">Glossary ‚Äî transformers 4.7.0 documentation</A>
								<DT><A HREF="https://pypi.org/project/cascades/">cascades ¬∑ PyPI</A>
								<DT><A HREF="https://colab.research.google.com/drive/14wnxMvD9zsiBQo2FtTpxn6w2cpXCcb-7">OPT (30B) - Colaboratory</A>
								<DT><A HREF="https://huggingface.co/docs/transformers/model_doc/auto">Auto Classes</A>
								<DT><A HREF="https://twitter.com/NeelNanda5/status/1582876613397467137">Interpretability</A>
								<DT><A HREF="https://github.com/NielsRogge/Transformers-Tutorials?search=1">Transformers-Tutorials/ at master: NielsRogge</A>
								<DT><A HREF="https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L223">transformers/trainer.py at main ¬∑ huggingface/transformers ¬∑ GitHub</A>
							</DL><p>
							<DT><A HREF="https://huggingface.co/">The AI community building the future.</A>
							<DT><A HREF="https://www.philschmid.de/bert-deepspeed-inference">Accelerate BERT inference with DeepSpeed-Inference on GPUs</A>
							<DT><A HREF="https://huggingface.co/search/full-text">Full Text Search - Hugging Face</A>
						</DL><p>
						<DT><H3 FOLDED>training-infra-job-scheduler</H3>
						<DL><p>
							<DT><H3 FOLDED>SLURM</H3>
							<DL><p>
								<DT><A HREF="https://oatml.cs.ox.ac.uk/code.html#JvASlurm">Reproducibility and Code - OATML</A>
								<DT><A HREF="https://github.com/y0ast/slurm-for-ml">y0ast/slurm-for-ml: A Machine Learning workflow for Slurm.</A>
							</DL><p>
							<DT><A HREF="https://github.com/it4innovations/hyperqueue">It4innovations/hyperqueue: Scheduler for sub-node tasks for HPC systems with batch scheduling</A>
							<DT><A HREF="https://github.com/Google/saxml">google/saxml</A>
						</DL><p>
						<DT><H3 FOLDED>training-infra-model-registry</H3>
						<DL><p>
							<DT><A HREF="https://twitter.com/_ScottCondron/status/1529420711034556416/photo/1">Centralized place for ML teams</A>
							<DT><A HREF="https://wandb.ai/home">Home ‚Äì Weights &amp; Biases</A>
						</DL><p>
						<DT><H3 FOLDED>training-job-scheduler</H3>
						<DL><p>
							<DT><H3 FOLDED>SLURM</H3>
							<DL><p>
								<DT><H3 FOLDED>slurm-submitit</H3>
								<DL><p>
									<DT><A HREF="https://github.com/facebookincubator/submitit">facebookincubator/submitit: Python 3.8+ toolbox for submitting jobs to Slurm</A>
								</DL><p>
								<DT><A HREF="https://slurm.schedmd.com/">slurm.schedmd.com</A>
								<DT><A HREF="https://github.com/GoogleCloudPlatform/slurm-gcp">GoogleCloudPlatform/slurm-gcp</A>
								<DT><A HREF="https://github.com/GoogleCloudPlatform/hpc-toolkit">GoogleCloudPlatform/hpc-toolkit: Cloud HPC Toolkit is an open-source software offered by Google Cloud which makes it easy for customers to deploy HPC environments on Google Cloud.</A>
								<DT><A HREF="https://oatml.cs.ox.ac.uk/code.html#JvASlurm">Reproducibility and Code - OATML</A>
								<DT><A HREF="https://github.com/y0ast/slurm-for-ml">y0ast/slurm-for-ml: A Machine Learning workflow for Slurm.</A>
							</DL><p>
							<DT><H3 FOLDED>job-manager-kubernetes</H3>
							<DL><p>
								<DT><H3 FOLDED>GKE</H3>
								<DL><p>
									<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/whats-new-with-gke-at-google-cloud-next">What‚Äôs new with GKE at Google Cloud Next</A>
								</DL><p>
								<DT><H3 FOLDED>Dynamic Resource Allocation</H3>
								<DL><p>
									<DT><A HREF="https://docs.google.com/document/d/1BNWqgx_SmZDi-va_V31v3DnuVwYnF2EmN7D-O_fB6Oo/edit#heading=h.bxuci8gx6hna">Dynamic Resource Allocation for GPUs in Kubernetes - Google Docs</A>
								</DL><p>
								<DT><H3 FOLDED>kubernetes-local</H3>
								<DL><p>
									<DT><A HREF="https://kind.sigs.k8s.io/">kind: local run</A>
								</DL><p>
								<DT><H3 FOLDED>kubernetes-kserve</H3>
								<DL><p>
									<DT><A HREF="https://github.com/kserve/modelmesh-serving">kserve/modelmesh-serving: Controller for ModelMesh</A>
								</DL><p>
								<DT><H3 FOLDED>kubernetes-basics</H3>
								<DL><p>
									<DT><A HREF="https://hamel.dev/notes/k8s/02-Basics.html">k8s</A>
									<DT><A HREF="https://www.youtube.com/watch?v=90kZRyPcRZw">Kubernetes Deconstructed: Understanding Kubernetes by Breaking It Down - Carson Anderson, DOMO - YouTube</A>
								</DL><p>
								<DT><H3 FOLDED>kubernetes-utils</H3>
								<DL><p>
									<DT><A HREF="https://github.com/alibaba/kt-connect">alibaba/kt-connect: A toolkit for Integrating with your kubernetes dev environment more efficiently</A>
									<DT><A HREF="https://github.com/alibaba/kubeskoop">alibaba/kubeskoop</A>
								</DL><p>
								<DT><A HREF="https://cloud.google.com/anthos-config-management/docs/concepts/kustomize">Configure Kubernetes with Kustomize ¬†|¬† Anthos Config Management ¬†|¬† Google Cloud</A>
								<DT><A HREF="https://www.youtube.com/watch?v=06bKlSmVwIg">CNCF Live Webinar: Overcoming the GPU shortage with virtual Kubelets &amp; distributed cloud - YouTube</A>
								<DT><A HREF="https://virtual-kubelet.io/">Virtual Kubelet | Home</A>
								<DT><A HREF="https://github.com/virtual-kubelet/virtual-kubelet">virtual-kubelet/virtual-kubelet: Virtual Kubelet is an open source Kubernetes kubelet implementation.</A>
								<DT><A HREF="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelet | Kubernetes</A>
								<DT><A HREF="https://www.youtube.com/watch?v=cwiAW5TZsfo">On-Demand Systems and Scaled Training Using the JobSet API - Abdullah Gharaibeh &amp; Vanessa Sochat - YouTube</A>
								<DT><A HREF="https://github.com/kubernetes/kubernetes/issues/95492">Kubernetes won't run 50,000 Jobs ¬∑ Issue #95492 ¬∑ kubernetes/kubernetes</A>
								<DT><A HREF="https://www.cncf.io/blog/2020/08/10/why-the-kubernetes-scheduler-is-not-enough-for-your-ai-workloads/">Scheduler (Level 2)</A>
								<DT><A HREF="https://www.run.ai/">Run:ai - AI Optimization and Orchestration</A>
								<DT><A HREF="https://www.cncf.io/wp-content/uploads/2020/10/Kube-two-level-RM.pdf">Kubernetes native two-level resource managment for AI workloads</A>
								<DT><A HREF="https://github.com/project-codeflare/multi-cluster-app-dispatcher">project-codeflare/multi-cluster-app-dispatcher: Holistic job manager on Kubernetes</A>
								<DT><A HREF="https://github.com/bentoml/Yatai">bentoml/Yatai: Model Deployment at Scale on Kubernetes ü¶ÑÔ∏è</A>
								<DT><A HREF="https://docs.aws.amazon.com/parallelcluster/latest/ug/build-image.html">buildImage - AWS ParallelCluster</A>
								<DT><A HREF="https://cloud.google.com/blog/products/containers-kubernetes/high-performance-aiml-storage-through-local-ssd-support-on-gke">High performance AI/ML storage through Local SSD support on GKE | Google Cloud Blog</A>
							</DL><p>
							<DT><A HREF="https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/core/exp_manager.html">Experiment Manager ‚Äî NVIDIA NeMo</A>
							<DT><A HREF="https://github.com/google-deepmind/xmanager">google-deepmind/xmanager: A platform for managing machine learning experiments</A>
							<DT><A HREF="https://storage.googleapis.com/gresearch/xmanager/deepmind_xmanager_slides.pdf">XManager (Slides)</A>
							<DT><A HREF="https://github.com/google/xpk">google/xpk: xpk (Accelerated Processing Kit) is a software tool to help Cloud developers to orchestrate training jobs on accelerators such as TPUs and GPUs on GKE.</A>
							<DT><A HREF="https://github.com/GoogleCloudPlatform/ai-on-gke/blob/main/gke-a100-jax/train.py">ai-on-gke/gke-a100-jax/train.py at main ¬∑ GoogleCloudPlatform/ai-on-gke</A>
							<DT><A HREF="https://github.com/it4innovations/hyperqueue">It4innovations/hyperqueue: Scheduler for sub-node tasks for HPC systems with batch scheduling</A>
							<DT><A HREF="https://github.com/Google/saxml">google/saxml</A>
						</DL><p>
						<DT><H3 FOLDED>training-logs</H3>
						<DL><p>
							<DT><H3 FOLDED>wandb</H3>
							<DL><p>
								<DT><A HREF="https://github.com/huggingface/nanotron/blob/03d67f2103d5be0dc15ea6022a6cf16d6a633064/scripts/log_lighteval_to_wandb.py">nanotron/scripts/log_lighteval_to_wandb.py</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>training-infrastructure-benchmark</H3>
						<DL><p>
							<DT><H3 FOLDED>DGX Cloud Benchmarking</H3>
							<DL><p>
								<DT><H3 FOLDED>nvidia-exemplar-clouds</H3>
								<DL><p>
									<DT><A HREF="https://developer.nvidia.com/blog/announcing-nvidia-exemplar-clouds-for-benchmarking-ai-cloud-infrastructure/">Announcing NVIDIA Exemplar Clouds for Benchmarking AI Cloud Infrastructure | NVIDIA Technical Blog</A>
								</DL><p>
								<DT><A HREF="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/dgxc-benchmarking/collections/dgxc-benchmarking">DGX Cloud Benchmarking | NVIDIA NGC</A>
								<DT><A HREF="https://developer.nvidia.com/dgx-cloud/benchmarking">DGX Cloud Benchmarking | NVIDIA Developer</A>
								<DT><A HREF="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/dgxc-benchmarking/resources/nemo-nemotron4-dgxc-benchmarking-f">NeMo Nemotron4 Pretrain 25.04 (DGXC Benchmarking) | NVIDIA NGC</A>
								<DT><A HREF="https://techcommunity.microsoft.com/blog/azurehighperformancecomputingblog/dgx-cloud-benchmarking-on-azure/4410826">DGX Cloud Benchmarking on Azure | Microsoft Community Hub</A>
								<DT><A HREF="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/dgxc-benchmarking/resources/grok1-314b-dgxc-benchmarking-b/files">Grok1 314B 25.01 (DGXC Benchmarking) | NVIDIA NGC</A>
							</DL><p>
							<DT><H3 FOLDED>MLPerf</H3>
							<DL><p>
								<DT><H3 FOLDED>mlperf-membership</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://github.com/neuralmagic/inference?tab=readme-ov-file">neuralmagic/inference: Reference implementations of MLPerf‚Ñ¢ inference benchmarks</A>
								<DT><A HREF="https://mlcommons.org/">MLCommons - Better AI for Everyone</A>
								<DT><A HREF="https://mlcommons.org/2025/05/training-llama31405b/">MLCommons MLPerf Training Expands with Llama 3.1 405B - MLCommons</A>
								<DT><A HREF="https://gist.github.com/dfeddema/6d7b8bc2c81343f4d2dec31d8acf4959">Nvidia MLPerf Inference code drop tar file: successful make prebuild on GH200 perf-arm-15 with RHEL 9.4 + (real) docker</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>training-scaling</H3>
						<DL><p>
							<DT><H3 FOLDED>training-CrashCallback</H3>
							<DL><p>
								<DT><A HREF="https://github.com/NVIDIA-NeMo/NeMo/blob/280075283e392b94fb1546a4bb4eb0e516636c84/tests/collections/llm/test_local_ckpt.py#L100">NeMo/tests/collections/llm/test_local_ckpt.py</A>
								<DT><A HREF="https://github.com/NVIDIA-NeMo/NeMo/blob/280075283e392b94fb1546a4bb4eb0e516636c84/tests/collections/llm/test_local_ckpt.py#L94">test_local_ckpt.py#L94: class CrashException(Exception):    """Custom exception for triggering simulated crashes in tests."""</A>
								<DT><A HREF="https://github.com/NVIDIA-NeMo/NeMo/blob/280075283e392b94fb1546a4bb4eb0e516636c84/tests/collections/llm/test_local_ckpt.py#L326">test_local_ckpt.py#L326: crash_callback = CrashCallback(crash_step=args.crash_step if args.crash_step &gt; 0 else None)</A>
							</DL><p>
							<DT><A HREF="https://cdn.prod.website-files.com/62bc66d283fd9c34ffec780a/689fa33a0e99f19c11c8ecbe_CoreWeave%20Training%20Benchmarks%20Whitepaper%20August%202025.pdf">Purpose-Built Cloud for AI at Scale: Achieving 20% Higher MFU and 10x Reliability on Thousand-GPU Clusters</A>
						</DL><p>
						<DT><H3 FOLDED>training-infra-bytedn</H3>
						<DL><p>
							<DT><H3 FOLDED>ByteRobust</H3>
							<DL><p>
								<DT><A HREF="https://arxiv.org/html/2509.16293v1">Robust LLM Training Infrastructure at ByteDance</A>
								<DT><A HREF="https://arxiv.org/pdf/2509.16293v1">Robust LLM Training Infrastructure at ByteDance</A>
								<DT><A HREF="https://docs.google.com/document/d/1X2b1VZaCv_Wnsm2mAeQW5iilEwjM_WenAioVXcFsXhE/edit?tab=t.0#heading=h.aw93i0kn9c0a">GPU cluster performance - Google Docs</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>diffusion-training-infrastructure</H3>
						<DL><p>
							<DT><H3 FOLDED>FastGen</H3>
							<DL><p>
								<DT><H3 FOLDED>wan-training</H3>
								<DL><p>
								</DL><p>
								<DT><A HREF="https://github.com/NVlabs/FastGen">NVlabs/FastGen: NVIDIA FastGen: Fast Generation from Diffusion Models</A>
								<DT><A HREF="https://developer.nvidia.com/blog/accelerating-diffusion-models-with-an-open-plug-and-play-offering/">Accelerating Diffusion Models with an Open, Plug-and-Play Offering | NVIDIA Technical Blog</A>
								<DT><A HREF="https://github.com/NVlabs/FastGen/blob/a4308b91e004035959fa5936a18c3e89b1315331/fastgen/networks/Wan/network_causal.py#L32">FastGen/fastgen/networks/Wan/network_causal.py dispatch_attention_fn</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>Power Smoothing</H3>
						<DL><p>
							<DT><A HREF="https://techcommunity.microsoft.com/blog/azurecompute/power-stabilization-for-ai-training-datacenters/4460937">Power stabilization for AI training datacenters | Microsoft Community Hub</A>
							<DT><A HREF="https://arxiv.org/pdf/2508.14318v2">Power Stabilization for AI Training Datacenters</A>
						</DL><p>
						<DT><A HREF="https://x.com/leilavclark/status/1805700631199642094">From bare metal to a 70B model: infrastructure set-up and scripts</A>
						<DT><A HREF="https://github.com/imbue-ai/cluster-health">imbue-ai/cluster-health</A>
						<DT><A HREF="https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py#L148">transformers/training_args.py</A>
						<DT><A HREF="https://github.com/apple/corenet">apple/corenet: CoreNet: A library for training deep neural networks</A>
						<DT><A HREF="https://github.com/pytorch/torchtitan">pytorch/torchtitan: A native PyTorch Library for large model training</A>
						<DT><A HREF="https://developer.nvidia.com/blog/tips-on-scaling-storage-for-ai-training-and-inferencing/">Tips on Scaling Storage for AI Training and Inferencing | NVIDIA Technical Blog</A>
						<DT><A HREF="https://developer.nvidia.com/blog/storage-performance-basics-for-deep-learning/">Storage Performance Basics for Deep Learning | NVIDIA Technical Blog</A>
						<DT><A HREF="https://github.com/alibaba/Megatron-LLaMA">alibaba/Megatron-LLaMA: Best practice for training LLaMA models in Megatron-LM</A>
						<DT><A HREF="https://github.com/kingoflolz/mesh-transformer-jax">Mesh-Transformer-jax: Model parallel transformers in JAX and Haiku</A>
						<DT><A HREF="https://www.youtube.com/watch?v=HYvhj9W2qHQ">Cloud Native Data Loaders for Machine Learning Using Zarr and Xarray - YouTube</A>
						<DT><A HREF="https://x.com/JingyuanLiu123/status/1966887747622453560">(1) JingyuanLiu en X: "I was lucky to work in both China and the US LLM labs, and I've been thinking this for a while. The current values of pretraining are indeed different: US labs be like: - lots of GPUs and much larger flops run - Treating stabilities more seriously, and could not tolerate spikes" / X</A>
						<DT><A HREF="https://arxiv.org/html/2509.16293v1">Robust LLM Training Infrastructure at ByteDance</A>
						<DT><A HREF="https://github.com/EvolvingLMMs-Lab/lmms-engine">EvolvingLMMs-Lab/lmms-engine: A simple, unified multimodal models training engine. Lean, flexible, and built for hacking at scale.</A>
						<DT><A HREF="https://www.yitay.net/blog/training-great-llms-entirely-from-ground-zero-in-the-wilderness">Training great LLMs entirely from ground up in the wilderness as a startup ‚Äî Yi Tay</A>
					</DL><p>
					<DT><H3 FOLDED>SW</H3>
					<DL><p>
						<DT><H3 FOLDED>Distributed Systems</H3>
						<DL><p>
							<DT><H3 FOLDED>Large-Scale Information Retrieval Systems</H3>
							<DL><p>
								<DT><A HREF="https://videolectures.net/wsdm09_dean_cblirs/">Videolectures</A>
								<DT><A HREF="https://x.com/arvidkahl/status/1803441726767366420">(1) Arvid Kahl en X: "Full-text search on 500GB+ of data is keeping me awake at night. MySQL's full-text index just can't handle this. Often takes minutes. And Meilisearch, as fast as it is, is hard to wrangle to get it to get only precise results. Anyone here experienced with search at this size?" / X</A>
								<DT><A HREF="https://www.postgresql.org/docs/current/textsearch.html">PostgreSQL: Documentation: 16: Chapter¬†12.¬†Full Text Search</A>
								<DT><A HREF="https://hive.apache.org/">Apache Hive</A>
								<DT><A HREF="https://prestodb.io/">Presto: Free, Open-Source SQL Query Engine for any Data</A>
								<DT><A HREF="https://github.com/quickwit-oss/tantivy">quickwit-oss/tantivy: Tantivy is a full-text search engine library inspired by Apache Lucene and written in Rust</A>
							</DL><p>
							<DT><H3 FOLDED>distributed-sys-lectures</H3>
							<DL><p>
								<DT><H3 FOLDED>6.824</H3>
								<DL><p>
									<DT><A HREF="https://pdos.csail.mit.edu/6.824/index.html">6.824 Home Page: Spring 2021</A>
									<DT><A HREF="https://mit-6824-notes.book.triplez.cn/lectures/1-introduction/">Lecture 1: Introduction | MIT 6.824 Notebook</A>
									<DT><A HREF="https://wizardforcel.gitbooks.io/distributed-systems-engineering-lecture-notes/content/l01-intro.html">Introduction ¬∑ Distributed Systems Engineering Lecture notes (MIT 6.824)</A>
									<DT><A HREF="https://www.youtube.com/watch?v=3HunZHHrk1Q">Remote Procedure Call (RPC)</A>
									<DT><A HREF="https://learncs.me/mit/6.824">NOTES</A>
									<DT><H3 FOLDED>source code</H3>
									<DL><p>
										<DT><A HREF="https://github.com/glodknife/MIT-6.824-2016/blob/46100bcf7b276b8824a8aac979e7c4e12b217038/src/kvpaxos/server.go#L58">MIT-6.824-2016/server.go</A>
										<DT><A HREF="https://github.com/glodknife/MIT-6.824-2016/tree/master/src">MIT-6.824-2016/src at master ¬∑ glodknife/MIT-6.824-2016</A>
									</DL><p>
									<DT><H3 FOLDED>labs</H3>
									<DL><p>
									</DL><p>
									<DT><H3 FOLDED>questions</H3>
									<DL><p>
									</DL><p>
								</DL><p>
							</DL><p>
							<DT><H3 FOLDED>distributed-sys-queue-systems</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/watch?v=yKPVZgA6Oe0">What makes Kafka special? | System Design - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>distributed-sys-actor-model</H3>
							<DL><p>
								<DT><A HREF="http://dist-prog-book.com/chapter/3/message-passing.html#akka">Message Passing and the Actor Model</A>
							</DL><p>
							<DT><H3 FOLDED>blockchain</H3>
							<DL><p>
								<DT><A HREF="https://bitcoin.org/bitcoin.pdf">Bitcoin whitepaper</A>
							</DL><p>
							<DT><H3 FOLDED>databases</H3>
							<DL><p>
								<DT><H3 FOLDED>key-value store</H3>
								<DL><p>
									<DT><H3 FOLDED>REST</H3>
									<DL><p>
										<DT><A HREF="https://medium.com/extend/what-is-rest-a-simple-explanation-for-beginners-part-1-introduction-b4a072f8740f">What is REST?</A>
										<DT><A HREF="https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm">Representational State Transfer (REST)</A>
										<DT><A HREF="https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm">Architectural Styles and the Design of Network-based Software Architectures</A>
									</DL><p>
									<DT><H3 FOLDED>Seaweedfs</H3>
									<DL><p>
										<DT><A HREF="https://github.com/chrislusf/seaweedfs">chrislusf/seaweedfs</A>
									</DL><p>
									<DT><H3 FOLDED>Bigtable</H3>
									<DL><p>
										<DT><A HREF="https://cloud.google.com/bigtable">Bigtable |¬† Google Cloud</A>
									</DL><p>
									<DT><H3 FOLDED>kv-python</H3>
									<DL><p>
										<DT><H3 FOLDED>uWSGI</H3>
										<DL><p>
											<DT><A HREF="https://flask.palletsprojects.com/en/1.1.x/deploying/uwsgi/">uWSGI ‚Äî Flask Documentation (1.1.x)</A>
											<DT><A HREF="https://uwsgi-docs.readthedocs.io/en/latest/">uWSGI ‚Äî uWSGI 2.0 documentation</A>
											<DT><A HREF="https://uwsgi-docs.readthedocs.io/en/latest/Download.html">Getting uWSGI ‚Äî uWSGI 2.0 documentation</A>
										</DL><p>
										<DT><H3 FOLDED>Flask</H3>
										<DL><p>
											<DT><A HREF="https://flask.palletsprojects.com/en/1.1.x/">Welcome to Flask ‚Äî Flask Documentation (1.1.x)</A>
										</DL><p>
										<DT><H3 FOLDED>Plyvel</H3>
										<DL><p>
											<DT><A HREF="https://plyvel.readthedocs.io/en/latest/">Plyvel ‚Äî Plyvel 1.3.0 documentation</A>
											<DT><A HREF="https://readthedocs.org/projects/plyvel/downloads/pdf/latest/">plyvel docs</A>
											<DT><A HREF="https://githubmemory.com/repo/wbolster/plyvel/issues/114?page=2">installation failed on mac osx 10.15 - plyvel</A>
											<DT><A HREF="https://github.com/wbolster/plyvel/issues/13">IOError: IO error: lock ¬∑ Issue #13 ¬∑ wbolster/plyvel</A>
										</DL><p>
										<DT><H3 FOLDED>Gunicorn</H3>
										<DL><p>
											<DT><A HREF="https://gunicorn.org/">Gunicorn - Python WSGI HTTP Server for UNIX</A>
										</DL><p>
										<DT><H3 FOLDED>tempfile</H3>
										<DL><p>
											<DT><A HREF="https://docs.python.org/3/library/tempfile.html">tempfile ‚Äî Generate temporary files and directories</A>
											<DT><A HREF="http://www.chiark.greenend.org.uk/doc/python-pyxattr/html/module.html">Interface to extended filesystem attributes</A>
										</DL><p>
										<DT><A HREF="https://docs.python.org/3/library/json.html">json ‚Äî JSON encoder and decoder</A>
										<DT><A HREF="https://stackoverflow.com/questions/6269765/what-does-the-b-character-do-in-front-of-a-string-literal">'b' character in front of a string literal? -- Python</A>
										<DT><A HREF="https://ipython.org/install.html">Installing IPython ‚Äî IPython</A>
										<DT><A HREF="https://stackoverflow.com/questions/56658553/module-not-found-error-in-vs-code-despite-the-fact-that-i-installed-it">Module not found error in VS code despite the fact that I installed it - Stack Overflow</A>
									</DL><p>
									<DT><H3 FOLDED>leveldb</H3>
									<DL><p>
										<DT><A HREF="https://github.com/bagonyi/homebrew-formulae">bagonyi/homebrew-formulae -- 1.22 Stable</A>
										<DT><A HREF="https://github.com/google/leveldb/blob/master/doc/index.md#concurrency">google/leveldb</A>
										<DT><A HREF="https://github.com/google/leveldb/blob/master/doc/index.md#concurrency">leveldb/index.md at master ¬∑ google/leveldb</A>
										<DT><A HREF="https://en.wikipedia.org/wiki/LevelDB">LevelDB - Wikipedia</A>
									</DL><p>
									<DT><A HREF="http://localhost:3000/">‚Äélocalhost:3000</A>
									<DT><A HREF="https://www.youtube.com/watch?v=cAFjZ1gXBxc&t=6222s">Geohot : A distributed key value store in under 1000 lines</A>
									<DT><A HREF="https://httpstatuses.com/">HTTP Status Codes ‚Äî httpstatuses.com</A>
									<DT><A HREF="https://stackoverflow.com/questions/11583562/how-to-kill-a-process-running-on-particular-port-in-linux">lsof - How to kill a process running on particular port in Linux?</A>
									<DT><A HREF="https://www.youtube.com/watch?v=v44bAtgEEUw">Building Redis From Scratch In Golang</A>
									<DT><A HREF="https://github.com/danielealbano/cachegrand">danielealbano/cachegrand: cachegrand - a modern data ingestion, processing and serving platform built for today's hardware</A>
								</DL><p>
								<DT><H3 FOLDED>db-relational</H3>
								<DL><p>
									<DT><H3 FOLDED>postgreSQL</H3>
									<DL><p>
										<DT><A HREF="https://stackoverflow.com/questions/17633422/psql-fatal-database-user-does-not-exist">psql: FATAL: database "&lt;user&gt;" does not exist</A>
										<DT><A HREF="https://www.postgresql.org/docs/9.2/app-psql.html">PostgreSQL: Documentation: 9.2: psql</A>
										<DT><A HREF="https://alvinalexander.com/blog/post/postgresql/log-in-postgresql-database/">How to log into a Postgresql database</A>
										<DT><A HREF="https://stackoverflow.com/questions/26040493/how-to-show-data-in-a-table-by-using-psql-command-line-interface">How to show data in a table by using psql</A>
										<DT><A HREF="https://stackoverflow.com/questions/48180282/how-to-populate-a-heroku-postgresql-database-with-a-sql-file">How to populate a heroku postgresql database with a sql file</A>
										<DT><A HREF="https://stackoverflow.com/questions/21307786/load-sql-file-data-in-to-single-table-in-postgres">Load sql file data in to single table in postgres</A>
										<DT><A HREF="https://dba.stackexchange.com/questions/46125/why-does-postgres-generate-an-already-used-pk-value">already used PK value?</A>
										<DT><A HREF="https://stackoverflow.com/questions/64354458/named-parameter-not-bound-date-format-native-query-in-spring-boot">Named parameter not bound :</A>
										<DT><A HREF="https://devcenter.heroku.com/articles/heroku-cli-commands">Heroku CLI Commands | Heroku Dev Center</A>
										<DT><A HREF="https://www.postgresql.org/docs/9.5/sql-insert.html">PostgreSQL: Documentation: 9.5: INSERT</A>
										<DT><A HREF="https://ketansingh.me/posts/how-postgres-stores-rows/">How Postgres Stores Rows</A>
									</DL><p>
									<DT><A HREF="https://www.w3schools.com/sql/sql_groupby.asp">w3schools sql clauses</A>
									<DT><A HREF="https://wiki.eclipse.org/EclipseLink/UserGuide/JPA/Basic_JPA_Development/Querying/JPQL">JPA</A>
									<DT><A HREF="https://en.wikibooks.org/wiki/Structured_Query_Language/Create_Table">Structured Query Language/Create Table</A>
									<DT><A HREF="https://www.w3schools.com/sql/">SQL Tutorial</A>
									<DT><A HREF="https://www.pearson.com/us/higher-education/program/Garcia-Molina-Database-Systems-The-Complete-Book-2nd-Edition/PGM2429.html">Database Systems: The Complete Book, 2nd Edition | Pearson</A>
								</DL><p>
								<DT><H3 FOLDED>prql</H3>
								<DL><p>
									<DT><A HREF="https://github.com/PRQL/prql">PRQL/prql: PRQL is a modern language for transforming data ‚Äî a simple, powerful, pipelined SQL replacement</A>
								</DL><p>
								<DT><H3 FOLDED>db-gpu</H3>
								<DL><p>
									<DT><A HREF="https://www.vldb.org/pvldb/vol18/p4518-li.pdf">ScalingGPU-Accelerated Databases beyondGPUMemorySize</A>
								</DL><p>
								<DT><H3 FOLDED>influxdb</H3>
								<DL><p>
									<DT><A HREF="https://github.com/influxdata/influxdb">influxdata/influxdb: Scalable datastore for metrics, events, and real-time analytics</A>
								</DL><p>
								<DT><A HREF="https://dbdb.io/db/leveldb">Database of Databases - LevelDB</A>
								<DT><A HREF="https://web.stanford.edu/class/cs245/">CS 245: Principles of Data-Intensive Systems (Winter 2021)</A>
								<DT><A HREF="https://towardsdatascience.com/10-quick-sql-tips-after-writing-daily-in-sql-for-3-years-37bdba0637d0">10 Quick SQL Tips After Writing Daily in SQL for 3 Years | Mar, 2022</A>
								<DT><A HREF="https://engineering.fb.com/2022/04/26/developer-tools/sql-notebooks/">SQL Notebooks: Combining the power of Jupyter and SQL editors for data analytics - Engineering at Meta</A>
								<DT><A HREF="http://airbnb.io/airpal/">A web-based query execution tool built on top of Facebook's PrestoDB.</A>
								<DT><A HREF="https://www.youtube.com/watch?v=-1VGwmFKKf8">The Billion Rows Challenge in Rust - an intro to Rust for data engineering - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=zSn8il5Mo5s">The Rise of Oracle, SQL and the Relational Database - YouTube</A>
								<DT><A HREF="https://www.youtube.com/watch?v=PgGV5dTNu9A">How AI Killed "Database Startups" - YouTube</A>
							</DL><p>
							<DT><H3 FOLDED>canary vs shadow traffic</H3>
							<DL><p>
								<DT><A HREF="https://www.youtube.com/shorts/ckYBLT1VG-M">Shadow Trafficking Explained - YouTube</A>
								<DT><A HREF="https://x.com/basetenco/status/1852025274734719061">Baseten en X: "We‚Äôre excited to launch canary deployments on Baseten! üê¶ üéâ Canary deployments let you gradually shift traffic to new model deployments, with seamless rollback if needed. Learn more in our launch blog üëá https://t.co/brn8pDqlai" / X</A>
							</DL><p>
							<DT><H3 FOLDED>bluetooth</H3>
							<DL><p>
								<DT><H3 FOLDED>bitchat</H3>
								<DL><p>
									<DT><A HREF="https://github.com/permissionlesstech/bitchat">permissionlesstech/bitchat: bluetooth mesh chat, IRC vibes</A>
								</DL><p>
							</DL><p>
							<DT><A HREF="https://jsonformatter.curiousconcept.com/#">JSON Formatter &amp; Validator</A>
							<DT><A HREF="https://www.youtube.com/watch?v=VWrpnT8rwVY">"Functional distributed systems beyond request/response" by Melinda Lu - YouTube</A>
							<DT><A HREF="https://canvas.mit.edu/courses/11164">6.829 Computer Networks</A>
							<DT><A HREF="https://raft.github.io/">Raft Consensus Algorithm</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/%CE%A0-calculus">œÄ-calculus - Wikipedia</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/Petri_net">Petri net - Wikipedia</A>
							<DT><A HREF="http://dist-prog-book.com/chapter/3/message-passing.html#akka">Message Passing and the Actor Model</A>
							<DT><A HREF="https://www.youtube.com/watch?v=Vch4BWUVzMM">SimTigerBeetle (Director's Cut!): Distributed systems failure simulator</A>
							<DT><A HREF="https://www.youtube.com/watch?v=DfLKd3WlTuw">Programming Distributed Systems - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=m3HwXlQPCEU">Testing a Single-Node, Single Threaded, Distributed System Written in 1985 By Will Wilson - YouTube</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gcwzWzC7gUA">Rails World 2025 Opening Keynote - David Heinemeier Hansson - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>sw-testing</H3>
						<DL><p>
							<DT><H3 FOLDED>sw-testing-errors</H3>
							<DL><p>
								<DT><A HREF="https://www.inngest.com/blog/python-errors-as-values">Python errors as values: Comparing useful patterns from Go and Rust - Inngest Blog</A>
								<DT><A HREF="https://github.com/huggingface/safetensors/blob/079781fd0dc455ba0fe851e2b4507c33d0c0d407/bindings/python/convert.py#L4">errors as values: safetensors/bindings/python/convert.py</A>
							</DL><p>
							<DT><H3 FOLDED>sw-testing-exception-handling</H3>
							<DL><p>
							</DL><p>
							<DT><H3 FOLDED>sw-testing-bugs</H3>
							<DL><p>
								<DT><A HREF="https://github.com/ProjectPhysX/FluidX3D/releases/tag/v2.16">Release FluidX3D v2.16 (bug fixes) ¬∑ ProjectPhysX/FluidX3D</A>
								<DT><A HREF="https://private-user-images.githubusercontent.com/90851087/327656146-d013fc95-d977-460f-9de8-2a6fc7ddaec5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQ3MzM2NDUsIm5iZiI6MTcxNDczMzM0NSwicGF0aCI6Ii85MDg1MTA4Ny8zMjc2NTYxNDYtZDAxM2ZjOTUtZDk3Ny00NjBmLTlkZTgtMmE2ZmM3ZGRhZWM1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTAzVDEwNDkwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ4ZTJiY2I4NTU2MzBmZmFkNWJiMzI1MzdkYjc4NTg1N2Q5ZjU0ZmZlYmQ3MTNlODFkNDE1NjYyMjlkNmZmY2EmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QXKhYOoKDu0s5FNsEZsht_Psxxfb1exaRzg8-OrI45Q">327656146-d013fc95-d977-460f-9de8-2a6fc7ddaec5.png 1.886√ó960 pixels</A>
								<DT><A HREF="https://chat.openai.com/">github-bug-issues</A>
							</DL><p>
							<DT><H3 FOLDED>Deterministic Simulation Testing</H3>
							<DL><p>
								<DT><A HREF="https://www.polarsignals.com/blog/posts/2024/05/28/mostly-dst-in-go">(Mostly) Deterministic Simulation Testing in Go</A>
							</DL><p>
							<DT><A HREF="https://twitter.com/karpathy/status/1786085254006202541">(1) Andrej Karpathy en X: "Clearly LLMs must one day run in Space Step 1 we harden llm.c to pass the NASA code standards and style guides, certifying that the code is super safe, safe enough to run in Space. https://t.co/tYGrfdka4X (see the linked PDF) LLM training/inference in principle should be super..." / X</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code">The Power of 10: Rules for Developing Safety-Critical Code</A>
							<DT><A HREF="https://x.com/realGeorgeHotz/status/1874228009550700809">(2) George Hotz üåë en X: "@ns123abc @AMD We still have a very long journey ahead. For sure our driver has bugs to find and performance optimizations to make. The key thing is that it's 696 lines, written in Python, and easy to understand and debug. Testing and simplicity are our strengths." / X</A>
							<DT><A HREF="https://www.youtube.com/watch?v=gcwzWzC7gUA">Rails World 2025 Opening Keynote - David Heinemeier Hansson - YouTube</A>
						</DL><p>
						<DT><H3 FOLDED>programming-behaviour-invariance</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/shorts/M-VU0fLjIUU">This Is A Game Changer - assert programming to gurantee behaviour</A>
							<DT><A HREF="https://softwareengineering.stackexchange.com/questions/32727/what-are-invariants-how-can-they-be-used-and-have-you-ever-used-it-in-your-pro">What are invariants, how can they be used, and have you ever used it in your program? - Software Engineering Stack Exchange</A>
							<DT><A HREF="https://wiki.python.org/moin/UsingAssertionsEffectively">UsingAssertionsEffectively - Python Wiki</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code">The Power of 10: Rules for Developing Safety-Critical Code - assertations</A>
						</DL><p>
						<DT><H3 FOLDED>One Billion Row Challenge</H3>
						<DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=tCY7p6dVAGE">impl Rust: One Billion Row Challenge - YouTube</A>
						</DL><p>
					</DL><p>
					<DT><H3 FOLDED>sw-physics-simulation</H3>
					<DL><p>
						<DT><H3 FOLDED>MuJoCo</H3>
						<DL><p>
							<DT><H3 FOLDED>mujoco-installation</H3>
							<DL><p>
								<DT><A HREF="https://formulae.brew.sh/formula/glfw#default">glfw ‚Äî Homebrew Formulae</A>
								<DT><A HREF="https://blog.birost.com/a?ID=b71caef0-c790-4bde-933c-f3b3a0b3312b">Some tiny steps</A>
								<DT><A HREF="https://www.fullstaq.com/knowledge-hub/blogs/an-alternative-to-macos-dyld-library-path">DYLD_LIBRARY_PATH</A>
								<DT><A HREF="https://medium.com/macos-is-not-linux-and-other-nix-reflections/d-o-y-ou-ld-library-path-you-6ab0a6135a33">D(o) Y(ou) LD_LIBRARY_PATH</A>
							</DL><p>
							<DT><A HREF="https://mujoco.org/">MuJoCo ‚Äî Advanced Physics Simulation</A>
							<DT><A HREF="https://mujoco.readthedocs.io/en/latest/programming.html#initialization">Programming ‚Äî MuJoCo documentation</A>
							<DT><A HREF="https://twitter.com/GoogleDeepMind/status/1714627619742683245">GPU &amp; TPU acceleration through JAX</A>
						</DL><p>
					</DL><p>
					<DT><H3 FOLDED>sw-graphs</H3>
					<DL><p>
						<DT><H3 FOLDED>graphs-jax</H3>
						<DL><p>
							<DT><A HREF="https://github.com/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb">educational/intro_to_graph_nets_tutorial_with_jraph.ipynb at master ¬∑ deepmind/educational</A>
							<DT><A HREF="https://github.com/deepmind/jraph">deepmind/jraph: A Graph Neural Network Library in Jax</A>
						</DL><p>
						<DT><A HREF="https://www.dgl.ai/">Deep Graph Library</A>
					</DL><p>
					<DT><H3 FOLDED>sw-graphs-neural-networks</H3>
					<DL><p>
						<DT><A HREF="https://github.com/deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb">educational/intro_to_graph_nets_tutorial_with_jraph.ipynb at master ¬∑ deepmind/educational</A>
						<DT><A HREF="https://github.com/deepmind/jraph">deepmind/jraph: A Graph Neural Network Library in Jax</A>
						<DT><A HREF="https://github.com/a-r-j/graphtype">a-r-j/graphtype: Type hinting for networkx Graphs</A>
					</DL><p>
					<DT><H3 FOLDED>sw-reinforcement-learning</H3>
					<DL><p>
						<DT><H3 FOLDED>pufferLib</H3>
						<DL><p>
							<DT><H3 FOLDED>pufferLib-tinybox</H3>
							<DL><p>
								<DT><A HREF="https://x.com/jsuarez5341/status/1940095091869131184">Reinforcement Learning on a Petabyte of Data at Home</A>
							</DL><p>
							<DT><A HREF="https://www.youtube.com/watch?v=UVZMc36tdtY">Reinforcement Learning Dev on PufferLib - YouTube</A>
							<DT><A HREF="https://github.com/drubinstein/pokemonred_puffer">drubinstein/pokemonred_puffer</A>
							<DT><A HREF="https://www.mechanize.work/blog/sweatshop-data-is-over/">Good RL environments are the bottleneck</A>
							<DT><A HREF="https://x.com/yacineMTB/status/1943718467623903326">(1) kache en X: "when i started looking at RL 3 weeks ago, I felt like I was going crazy, because all the research &amp;amp; stuff that people were doing seemed.. wrong. Like, there were all these obvious things that people should be doing but weren't I felt like I was going crazy. was it just" / X</A>
							<DT><A HREF="https://x.com/yacineMTB/status/1949099513513214000">(1) kache en X: "Puffer AI is truly a game changer You actually don't understand how much room there is left as well Trust me on this" / X</A>
							<DT><A HREF="https://x.com/spenccheng/status/1948806364542726188">My first year in reinforcement learning (Spencer)</A>
							<DT><A HREF="https://x.com/jsuarez5341/status/1972495167543468450">(1) Joseph Suarez üê° en X: "Frontier RL is open source. PufferLib 3.0 uses a strict generalization of GAE and VTrace. You can recover either algorithm by setting gamma, lambda, rho_clip, and c_clip appropriately. It is very similar to retrace but for PPO. https://t.co/GPQmH6ZVDR" / X</A>
							<DT><A HREF="https://x.com/jsuarez5341/status/1984288808251412661">(1) Joseph Suarez üê° en X: "Dr Suarez Reinforces your Learning in C-- and CUDA https://t.co/WdisN1KXQP" / X</A>
						</DL><p>
						<DT><H3 FOLDED>rl-openai</H3>
						<DL><p>
							<DT><H3 FOLDED>gym</H3>
							<DL><p>
								<DT><A HREF="https://stackoverflow.com/questions/44150310/openai-gym-nameerror">python - openAi-gym NameError</A>
								<DT><A HREF="https://openai.github.io/mujoco-py/build/html/reference.html#mjviewer-3d-rendering">API reference ‚Äî mujoco-py 1.50.1.0 documentation</A>
							</DL><p>
							<DT><A HREF="https://beta.openai.com/docs/guides/embeddings/what-are-embeddings">Embeddings - OpenAI API</A>
							<DT><A HREF="http://gptprompts.wikidot.com/intro:logprobs">Logprobs</A>
						</DL><p>
						<DT><A HREF="https://github.com/kaesve/muzero">A clean implementation of MuZero and AlphaZero following the AlphaZero General framework.</A>
						<DT><A HREF="https://github.com/chiamp/muzero-cartpole">chiamp/muzero-cartpole: Applying DeepMind's MuZero algorithm to the cart pole environment in gym</A>
						<DT><A HREF="https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver">Introduction to Reinforcement Learning with David Silver (Deepmind)</A>
						<DT><A HREF="https://github.com/openai/baselines">openai/baselines: OpenAI Baselines: high-quality implementations of reinforcement learning algorithms</A>
					</DL><p>
					<DT><H3 FOLDED>sw-notebooks</H3>
					<DL><p>
						<DT><H3 FOLDED>jupyter</H3>
						<DL><p>
							<DT><A HREF="https://jupyter.org/">Project Jupyter | Home</A>
							<DT><A HREF="https://stackoverflow.com/questions/50982686/what-is-the-difference-between-jupyter-notebook-and-jupyterlab">python - What is the difference between Jupyter Notebook and JupyterLab? - Stack Overflow</A>
							<DT><A HREF="https://towardsdatascience.com/jypyter-notebook-shortcuts-bf0101a98330">Jupyter Notebook Shortcuts</A>
						</DL><p>
						<DT><A HREF="https://nn.labml.ai/normalization/deep_norm/index.html">Labml.ai</A>
						<DT><A HREF="https://notebooks.quantumstat.com/">NLP</A>
						<DT><A HREF="https://github.com/amrzv/awesome-colab-notebooks">awesome-colab-notebooks: Collection of google colaboratory notebooks for fast and easy experiments</A>
					</DL><p>
					<DT><H3 FOLDED>sw-interoperability</H3>
					<DL><p>
						<DT><H3 FOLDED>webassembly</H3>
						<DL><p>
							<DT><H3 FOLDED>wasm-internals</H3>
							<DL><p>
								<DT><A HREF="https://developer.mozilla.org/en-US/docs/WebAssembly/Understanding_the_text_format">Understanding WebAssembly text format - WebAssembly | MDN</A>
								<DT><A HREF="https://www.youtube.com/watch?v=ojYEfRye6aE&t=13s">HELLO WEBASSEMBLY - wat</A>
								<DT><A HREF="https://developer.mozilla.org/en-US/docs/WebAssembly/Text_format_to_wasm">Converting WebAssembly text format to wasm - WebAssembly | MDN</A>
								<DT><A HREF="https://rustwasm.github.io/docs.html">Rust and WebAssembly Documentation | Rust and WebAssembly</A>
							</DL><p>
							<DT><H3 FOLDED>wasm-cpp</H3>
							<DL><p>
								<DT><H3 FOLDED>Emscripten</H3>
								<DL><p>
									<DT><A HREF="https://emscripten.org/">Main ‚Äî Emscripten 3.0.1-git (dev) documentation</A>
									<DT><H3 FOLDED>installation</H3>
									<DL><p>
										<DT><A HREF="https://emscripten.org/docs/building_from_source/toolchain_what_is_needed.html#toolchain-what-you-need">Emscripten Toolchain Requirements ‚Äî Emscripten 3.1.9</A>
										<DT><A HREF="https://formulae.brew.sh/formula/emscripten">emscripten ‚Äî Homebrew Formulae</A>
										<DT><A HREF="https://formulae.brew.sh/formula/llvm#default">llvm ‚Äî Homebrew Formulae</A>
									</DL><p>
								</DL><p>
								<DT><A HREF="https://medium.com/@tdeniffel/pragmatic-compiling-from-c-to-webassembly-a-guide-a496cc5954b8">Pragmatic compiling of C++ to WebAssembly. A Guide. | by Thomas Deniffel | Medium</A>
								<DT><A HREF="https://web.dev/loading-wasm/">Loading WebAssembly modules efficiently</A>
								<DT><A HREF="https://nodejs.dev/learn/nodejs-with-webassembly">Node.js with WebAssembly</A>
								<DT><A HREF="https://emscripten.org/docs/porting/connecting_cpp_and_javascript/Interacting-with-code.html">Interacting with code ‚Äî Emscripten 3.1.9-git (dev) documentation</A>
								<DT><A HREF="https://web.dev/emscripten-npm/">Emscripten and npm</A>
								<DT><A HREF="https://log2base2.com/c-with-dsa?utm_src=youtube&utm_target=ycwdeug1&gclid=CjwKCAjwt52mBhB5EiwA05YKo4S_xtW1JucfNad8OMbuQj0b_tg5eej5VfMOx5M8PdeFGvIrlEiHeRoCxHkQAvD_BwE">Learn C Programming | Pointers Visualization | Log2Base2</A>
							</DL><p>
							<DT><A HREF="https://wasmcloud.dev/">wasmCloud Documentation</A>
							<DT><A HREF="https://pragprog.com/titles/khrust/programming-webassembly-with-rust/">Programming WebAssembly with Rust: Unified Development for Web, Mobile, and Embedded Applications by Kevin Hoffman</A>
							<DT><A HREF="https://pspdfkit.com/blog/2017/webassembly-a-new-hope/">WebAssembly: A New Hope | PSPDFKit</A>
							<DT><A HREF="https://github.com/WebAssembly/wabt">WebAssembly/wabt: The WebAssembly Binary Toolkit</A>
						</DL><p>
						<DT><H3 FOLDED>Rust bindings for Python</H3>
						<DL><p>
							<DT><A HREF="https://github.com/prql/prql/tree/main/prql-python">prql/prql-python at main ¬∑ prql/prql</A>
							<DT><A HREF="https://github.com/PyO3/pyo3">PyO3/pyo3: Rust bindings for the Python interpreter</A>
							<DT><A HREF="https://pyo3.rs/v0.14.5/index.html">Introduction - PyO3 user guide</A>
							<DT><A HREF="https://medium.com/@MatthieuL49/a-mixed-rust-python-project-24491e2af424">How to Mix Rust and Python in Your Project | by Matt | Medium</A>
							<DT><A HREF="https://github.com/PyO3/pyo3/issues/941">Running rust unit tests ¬∑ Issue #941 ¬∑ PyO3/pyo3</A>
							<DT><A HREF="http://saidvandeklundert.net/learn/2021-11-18-calling-rust-from-python-using-pyo3/">Calling Rust from Python using PyO3</A>
						</DL><p>
					</DL><p>
					<DT><H3 FOLDED>sw-profiling</H3>
					<DL><p>
						<DT><H3 FOLDED>sw-profiling-micro-benchmarking</H3>
						<DL><p>
						</DL><p>
						<DT><A HREF="https://www.techrepublic.com/article/how-to-check-drive-space-on-linux-from-the-command-line/">How to check drive space on Linux from the command line</A>
						<DT><A HREF="https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html#using-profiler-to-analyze-long-running-jobs%23using-profiler-to-analyze-long-running-jobs">PyTorch Profiler ‚Äî PyTorch Tutorials 1.12.1+cu102 documentation</A>
						<DT><A HREF="https://odsc.medium.com/optimizing-pytorch-performance-batch-size-with-pytorch-profiler-80e0bf39e80e">Optimizing PyTorch Performance: Batch Size with PyTorch Profiler | by ODSC - Open Data Science | Medium</A>
						<DT><A HREF="https://github.com/Syllo/nvtop">Syllo/nvtop: GPUs process monitoring for AMD, Intel and NVIDIA</A>
						<DT><A HREF="https://docs.contrastsecurity.com/en/python-middleware.html">Configure middleware</A>
						<DT><A HREF="https://www.cyberciti.biz/open-source/install-ncdu-on-linux-unix-ncurses-disk-usage/">ncdu</A>
						<DT><A HREF="https://unix.stackexchange.com/questions/125429/tracking-down-where-disk-space-has-gone-on-linux">du</A>
						<DT><A HREF="https://serverfault.com/questions/517483/how-to-read-memory-usage-in-htop">How to read memory usage in htop?</A>
					</DL><p>
					<DT><H3 FOLDED>concurrency</H3>
					<DL><p>
						<DT><A HREF="https://go.dev/blog/codelab-share">Share Memory By Communicating - The Go Programming Language</A>
						<DT><A HREF="https://go.dev/ref/mem">The Go Memory Model - The Go Programming Language</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Concurrency_(computer_science)">Concurrency (computer science) - Wikipedia</A>
						<DT><A HREF="https://stackoverflow.com/questions/36391421/explain-dont-communicate-by-sharing-memory-share-memory-by-communicating">go - Explain: Don't communicate by sharing memory; share memory by communicating - Stack Overflow</A>
						<DT><A HREF="https://man7.org/linux/man-pages/man7/shm_overview.7.html">shm_overview(7) - Linux manual page</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Communicating_sequential_processes">Communicating sequential processes - Wikipedia</A>
						<DT><A HREF="https://github.com/LaurentMazare/hojo">LaurentMazare/hojo: A small python library to run iterators in a separate process</A>
						<DT><A HREF="https://www.youtube.com/watch?v=Iqrd9vsLrak">Coroutine Patterns: Problems and Solutions Using Coroutines in a Modern Codebase</A>
					</DL><p>
					<DT><H3 FOLDED>sw-diffusion-optimization</H3>
					<DL><p>
						<DT><H3 FOLDED>Pseudo-Linear Multistep Sampling (PLMS)</H3>
						<DL><p>
							<DT><A HREF="https://arxiv.org/abs/2312.00858">[2312.00858] DeepCache: Accelerating Diffusion Models for Free</A>
							<DT><A HREF="https://github.com/horseee/DeepCache">horseee/DeepCache: [CVPR 2024] DeepCache: Accelerating Diffusion Models for Free</A>
						</DL><p>
						<DT><H3 FOLDED>minSDXL</H3>
						<DL><p>
							<DT><A HREF="https://github.com/cloneofsimo/minSDXL">cloneofsimo/minSDXL: Huggingface-compatible SDXL Unet implementation that is readily hackable</A>
						</DL><p>
						<DT><H3 FOLDED>stable-diffusion.cpp</H3>
						<DL><p>
							<DT><A HREF="https://github.com/leejet/stable-diffusion.cpp">leejet/stable-diffusion.cpp: Stable Diffusion in pure C/C++</A>
						</DL><p>
						<DT><A HREF="https://www.vrushankdes.ai/diffusion-inference-optimization">Diffusion Inference Optimization</A>
						<DT><A HREF="https://huggingface.co/blog/annotated-diffusion">The Annotated Diffusion Model</A>
						<DT><A HREF="https://huggingface.co/blog/deploy-deepfloydif-using-bentoml#building-and-serving-a-bento">Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action</A>
						<DT><A HREF="https://huggingface.co/docs/diffusers/main/en/stable_diffusion#memory">Effective and efficient diffusion</A>
						<DT><A HREF="https://huggingface.co/docs/diffusers/main/en/optimization/fp16">Memory and speed</A>
						<DT><A HREF="https://github.com/tmabraham/diffusion_reading_group">Diffusion Reading Group at EleutherAI</A>
						<DT><A HREF="https://huggingface.co/blog/sdxl_ort_inference">Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive</A>
						<DT><A HREF="https://github.com/siliconflow/onediff/tree/main">siliconflow/onediff: OneDiff: An out-of-the-box acceleration library for diffusion models.</A>
					</DL><p>
					<DT><H3 FOLDED>sw-embeddings</H3>
					<DL><p>
						<DT><H3 FOLDED>embedding-database</H3>
						<DL><p>
							<DT><A HREF="https://github.com/chroma-core/chroma">chroma-core/chroma: the open source embedding database</A>
							<DT><A HREF="https://www.trychroma.com/">Chroma: Open-source embedding database</A>
							<DT><A HREF="https://www.pinecone.io/">Vector Database for Vector Search | Pinecone</A>
							<DT><A HREF="https://github.com/milvus-io/milvus">milvus-io/milvus: A cloud-native vector database, storage for next generation AI applications</A>
							<DT><A HREF="https://milvus.io/">Vector database - Milvus</A>
						</DL><p>
						<DT><A HREF="https://carbon.now.sh/?bg=rgba%28171%2C+184%2C+195%2C+1%29&t=seti&wt=none&l=auto&width=680&ds=true&dsyoff=20px&dsblur=68px&wc=true&wa=true&pv=56px&ph=56px&ln=false&fl=1&fm=Hack&fs=14px&lh=133%25&si=false&es=2x&wm=false">Carbon | Create and share beautiful images of your source code</A>
						<DT><A HREF="https://twitter.com/hxiao/status/1683369244937838597">JinaAI 35 M to 6 B</A>
						<DT><A HREF="https://platform.openai.com/docs/api-reference/embeddings">API Reference - OpenAI API</A>
						<DT><A HREF="https://github.com/Gage-Technologies/embedding-server/commit/d77b9c0dd0070a3ce643f0c7fe5579524951e2ba#diff-1164ff7fc1a41ffa864162f3fca2f0407c544ece208ef32c7853b6b34c6eb445">TGI</A>
						<DT><A HREF="https://github.com/huggingface/text-generation-inference/issues/199">[Feature] Return embeddings ¬∑ Issue #199 ¬∑ huggingface/text-generation-inference</A>
						<DT><A HREF="https://www.youtube.com/watch?v=93yueQQnqpM">RetrievalQA with LLaMA 2 70b &amp; Chroma DB - YouTube</A>
						<DT><A HREF="https://github.com/HKUNLP/instructor-embedding">HKUNLP/instructor-embedding: [ACL 2023] One Embedder, Any Task: Instruction-Finetuned Text Embeddings</A>
					</DL><p>
					<DT><H3 FOLDED>sw-audio</H3>
					<DL><p>
						<DT><A HREF="https://github.com/samim23/polymath">samim23/polymath: Convert any music library into a music production sample-library with ML</A>
						<DT><A HREF="https://github.com/spotify/basic-pitch">spotify/basic-pitch: A lightweight yet powerful audio-to-MIDI converter with pitch bend detection</A>
					</DL><p>
					<DT><H3 FOLDED>sw-docs</H3>
					<DL><p>
						<DT><H3 FOLDED>markup languages</H3>
						<DL><p>
							<DT><H3 FOLDED>Markdown</H3>
							<DL><p>
								<DT><A HREF="https://support.typora.io/Markdown-Reference/">Reference</A>
								<DT><A HREF="http://theme.typora.io/">Themes Gallery ‚Äî Typora</A>
								<DT><A HREF="https://pandoc.org/#">Pandoc - About</A>
								<DT><A HREF="https://sindresorhus.com/github-markdown-css/">Manual</A>
								<DT><A HREF="https://github.com/microsoft/markitdown">microsoft/markitdown: Python tool for converting files and office documents to Markdown.</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>LaTeX</H3>
						<DL><p>
							<DT><A HREF="https://github.com/Armael/coq-procrastination/blob/master/manual/manual.tex">{coql}</A>
							<DT><A HREF="https://www.overleaf.com/learn/latex/Page_size_and_margins">Page size and margins</A>
							<DT><A HREF="https://www.overleaf.com/learn/latex/Paragraph_formatting">Paragraph formatting</A>
							<DT><A HREF="https://www.overleaf.com/learn/latex/Sections_and_chapters">Sections and chapters</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/36880/insert-a-blank-page-after-current-page">Insert a blank page after current page</A>
							<DT><A HREF="https://www.overleaf.com/learn/latex/Bold,_italics_and_underlining">Bold, italics and underlining - Overleaf, Online LaTeX Editor</A>
							<DT><A HREF="https://dle.rae.es/eximir?m=form">eximir | Definici√≥n | Diccionario de la lengua espa√±ola | RAE - ASALE</A>
							<DT><A HREF="http://www.personal.ceu.hu/tex/breaking.htm">Line and Page Breaking</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/325297/how-to-scale-a-tikzcd-diagram">How to scale a tikzcd diagram-adjust size</A>
							<DT><A HREF="https://tools.ietf.org/doc/texlive-doc/latex/tikz-cd/tikz-cd-doc.pdf">diagrams</A>
							<DT><A HREF="http://www.ccs.neu.edu/home/wand/csg264/latex/mathpartir/mathpartir.pdf">inference rules</A>
							<DT><A HREF="https://www.overleaf.com/project/60c202634ef716ece06a7e7b">Inference Rules ith the semantic Package</A>
							<DT><A HREF="https://www.geeksforgeeks.org/inequalities-in-latex/">Inequalities in LaTeX</A>
							<DT><A HREF="https://almdemo.polarion.com/polarion/help/index.jsp?topic=%2Fcom.polarion.xray.doc.user%2Fguide%2Fxid1661363.html">Help - Polarion ALM Platform</A>
							<DT><A HREF="https://truben.no/latex/table/">Untitled - Table Editor</A>
							<DT><A HREF="https://nasa.github.io/nasa-latex-docs/html/">NASA-LaTeX-Docs ‚Äî NASA-LaTeX-Docs documentation</A>
							<DT><A HREF="https://nasa.github.io/nasa-latex-docs/html/examples/table.html">LaTeX Tables ‚Äî NASA-LaTeX-Docs documentation</A>
							<DT><A HREF="https://people.engr.tamu.edu/hlee42/csce222/truth-table.pdf">disjunction truth table</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/61033/setting-toc-depth-not-working">table of contents - Setting TOC depth</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/422197/latex-environment-to-write-in-plain-text-mode">write in plain text mode</A>
							<DT><A HREF="https://liliaquituisacasamaniego.com/2013/03/25/latex-file-ended-while-scanning-use-of-writefile/">LaTeX ‚Äì file ended while scanning use of @writefile</A>
							<DT><A HREF="https://llevatilde.es/palabra/extr%C3%A1e">¬øLleva tilde extrae? | LlevaTilde.es</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/30757/change-the-word-chapter-to-something-else">naming - Change the word "Chapter" to something else - TeX - LaTeX Stack Exchange</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/12597/renaming-the-bibliography-page-using-bibtex">Renaming the bibliography page using BibTeX</A>
							<DT><A HREF="http://metodos.fam.cie.uva.es/~latex/apuntes/apuntes19.pdf">Bibtex</A>
							<DT><A HREF="https://tex.stackexchange.com/questions/329707/how-to-increase-textheight-without-changing-the-topmargin">How to increase \textheight, without changing the topmargin - TeX - LaTeX Stack Exchange</A>
							<DT><A HREF="https://en.wikipedia.org/wiki/List_of_mathematical_symbols_by_subject#Group_theory">List of mathematical symbols by subject - Wikipedia</A>
							<DT><A HREF="https://twitter.com/BorisAKnyazev/status/1531275326482956291">"Dear paper writers, consider using \ùò∂ùò¥ùò¶ùò±ùò¢ùò§ùò¨ùò¢ùò®ùò¶[ùóØùóÆùó∞ùó∏ùóøùó≤ùó≥=ùóΩùóÆùó¥ùó≤]{ùò©ùò∫ùò±ùò¶ùò≥ùò≥ùò¶ùòß} instead of simply \ùò∂ùò¥ùò¶ùò±ùò¢ùò§ùò¨ùò¢ùò®ùò¶{ùò©ùò∫ùò±ùò¶ùò≥ùò≥ùò¶ùòß}</A>
						</DL><p>
						<DT><H3 FOLDED>diverso</H3>
						<DL><p>
							<DT><A HREF="https://www.sphinx-doc.org/en/master/usage/restructuredtext/directives.html">Directives ‚Äî Sphinx documentation</A>
							<DT><A HREF="https://mkdocs.readthedocs.io/en/0.9/user-guide/writing-your-docs/">MkDocs</A>
							<DT><A HREF="https://docs.readthedocs.io/en/stable/tutorial/index.html#getting-started">Read the Docs tutorial ‚Äî Tutorial</A>
							<DT><A HREF="https://carla.readthedocs.io/en/latest/">CARLA Simulator (Example)</A>
							<DT><H3 FOLDED>Read the docs template</H3>
							<DL><p>
								<DT><A HREF="https://github.com/readthedocs/tutorial-template/">readthedocs/tutorial-template: Template for the Read the Docs tutorial</A>
								<DT><A HREF="https://docs.readthedocs.io/en/stable/tutorial/index.html">Read the Docs tutorial ‚Äî Read the Docs user documentation 7.6.0 documentation</A>
								<DT><A HREF="https://docs.readthedocs.io/en/stable/tutorial/index.html#getting-started">Read the Docs tutorial ‚Äî Read the Docs user documentation 7.6.0 documentation</A>
								<DT><A HREF="https://www.ericholscher.com/blog/2016/jul/1/sphinx-and-rtd-for-writers/">An introduction to Sphinx and Read the Docs for Technical Writers ‚Äî Eric Holscher</A>
								<DT><A HREF="https://github.com/diverso-lab/core/wiki/1.-Home">1. Home ¬∑ diverso-lab/core Wiki</A>
								<DT><A HREF="https://www.wordreference.com/es/translation.asp?tranword=languagje">languagje - English-Spanish Dictionary - WordReference.com</A>
							</DL><p>
							<DT><A HREF="https://www.ericholscher.com/blog/2016/jul/1/sphinx-and-rtd-for-writers/">An introduction to Sphinx and Read the Docs for Technical Writers</A>
						</DL><p>
						<DT><H3 FOLDED>tools</H3>
						<DL><p>
							<DT><A HREF="https://readthedocs.org/">Home | Read the Docs</A>
							<DT><H3 FOLDED>Github pages</H3>
							<DL><p>
								<DT><A HREF="https://jekyllrb.com/">Jekyll ‚Ä¢ Simple, blog-aware, static sites | Transform your plain text into static websites and blogs</A>
								<DT><A HREF="https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/about-github-pages-and-jekyll">Set up site with Jekyll</A>
								<DT><A HREF="https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/creating-a-github-pages-site-with-jekyll">Creating a GitHub Pages site with Jekyll - GitHub Docs</A>
							</DL><p>
							<DT><H3 FOLDED>gitbooks</H3>
							<DL><p>
								<DT><A HREF="https://www.gitbook.com/">GitBook - Where software teams break knowledge silos.</A>
								<DT><A HREF="https://docs.gitbook.com/editing-content/editing-pages/change-requests">Change requests - GitBook Documentation</A>
								<DT><A HREF="https://docs.gitbook.com/integrations/git-sync/enabling-github-sync">Enabling GitHub Sync - GitBook Documentation</A>
								<DT><A HREF="https://www.garyng.xyz/gtil-gitbook/GitBook/relative-internal-links-in-gitbook.html">Relative Internal Links in GitBook ¬∑ Today I Learned...</A>
								<DT><A HREF="https://seadude.gitbooks.io/learn-gitbook/content/chapter1/internal.html">Internal Links ¬∑ Learn Gitbook</A>
								<DT><A HREF="https://docs.gitbook.com/editing-content/rich-text">Rich text - GitBook Documentation</A>
								<DT><A HREF="https://stackoverflow.com/questions/2822089/how-to-link-to-part-of-the-same-document-in-markdown">multimarkdown - How to link to part of the same document in Markdown? - Stack Overflow</A>
							</DL><p>
							<DT><A HREF="https://www.mkdocs.org/">MkDocs</A>
							<DT><H3 FOLDED>Jekyll</H3>
							<DL><p>
								<DT><A HREF="https://jekyllrb.com/">Home</A>
								<DT><A HREF="https://jekyllrb.com/docs/installation/macos/">Jekyll installation on macOS</A>
								<DT><A HREF="https://github.com/sighingnow/jekyll-gitbook">jekyll-gitbook</A>
								<DT><A HREF="https://www.youtube.com/watch?v=HVLl8GaduPQ">Video overview</A>
								<DT><A HREF="https://jekyllrb.com/docs/front-matter/">Front Matter</A>
								<DT><A HREF="https://mademistakes.com/mastering-jekyll/how-to-link/#how-to-link">How to use URLs and links in Jekyll - Made Mistakes</A>
								<DT><A HREF="https://github.com/benbalter/jekyll-relative-links">benbalter/jekyll-relative-links: A Jekyll plugin to convert relative links to markdown files to their rendered equivalents</A>
								<DT><A HREF="https://unruffled-ardinghelli-55d901.netlify.app/">Latex Jekyll</A>
								<DT><A HREF="http://jekyllthemes.org/page2/">Jekyll Themes</A>
							</DL><p>
						</DL><p>
						<DT><H3 FOLDED>grammarly</H3>
						<DL><p>
							<DT><A HREF="https://support.grammarly.com/hc/en-us/articles/4412828867085-My-cursor-disappeared-in-the-Grammarly-Editor-for-Windows-and-Mac">My cursor disappeared in the Grammarly Editor</A>
						</DL><p>
						<DT><A HREF="https://towardsdatascience.com/how-to-easily-draw-neural-network-architecture-diagrams-a6b6138ed875">Diagrams: Neural Network</A>
						<DT><A HREF="https://github.com/kennethleungty/Neural-Network-Architecture-Diagrams">GitHub - kennethleungty/Neural-Network-Architecture-Diagrams: Diagrams for visualizing neural network architecture (Created with diagrams.net)</A>
						<DT><A HREF="https://x.com/_xjdr/status/1827737014315483483">(1) xjdr en X: "This is great The number 1 question I get asked by traditional enterprise execs is "what can I be doing right now to get ready for AI at our company" and this is my number 1 response (organize for LLM search, rewrite for LLM consumption)." / X</A>
					</DL><p>
					<DT><H3 FOLDED>software foundations</H3>
					<DL><p>
						<DT><H3 FOLDED>software-foundations-exercises</H3>
						<DL><p>
							<DT><A HREF="https://github.com/frankYaohua/software-foundations/blob/master/Basics.v">software-foundations/Basics.v at master ¬∑ frankYaohua/software-foundations</A>
							<DT><A HREF="https://www.seas.upenn.edu/~cis500/current/exams/index.html">Directory Index</A>
							<DT><A HREF="https://github.com/coq-community/coq-art/blob/v8.13.0/ch5_everydays_logic/SRC/class.v">coq-art/class.v at v8.13.0 ¬∑ coq-community/coq-art</A>
							<DT><A HREF="https://github.com/SatyendraBanjare/software-foundations">Repository 2</A>
							<DT><A HREF="https://github.com/paulkoerbitz/software-foundations">Repository 3</A>
							<DT><A HREF="https://github.com/StevenWongChess/software-foundations/blob/master/IndProp.v">Repository 4</A>
							<DT><A HREF="https://www.cs.uic.edu/~mansky/teaching/cs494sf/sp19/exams.html">CS 494 SF: Software Foundations ¬∑ Exams</A>
							<DT><A HREF="https://github.com/steven7woo/Coq-CIS500/blob/master/For_wenrui/Since_HW6/Imp.v">Coq-CIS500/Imp.v at master ¬∑ steven7woo/Coq-CIS500</A>
							<DT><A HREF="https://github.com/coq-community/coq-art/blob/v8.13.0/ch2_types_expressions/SRC/Zbtree.v">Binary tree</A>
							<DT><A HREF="https://github.com/bishboria/software-foundations/blob/master/Imp.v">Imp poset</A>
						</DL><p>
						<DT><H3 FOLDED>software-foundations-environment</H3>
						<DL><p>
							<DT><A HREF="https://proofgeneral.github.io/">Proof General</A>
							<DT><A HREF="https://scholar.princeton.edu/scuellar/blog/how-i-set-my-mac-brew-opam-emacs-and-coq">How I set up my mac (brew, opam, emacs and coq)</A>
							<DT><A HREF="https://www.dc.fi.udc.es/staff/freire/coqdoc/pauillac.inria.fr/coq/doc/no15.htm">5.4¬†Compiled files</A>
						</DL><p>
						<DT><H3 FOLDED>software-foundations-lectures</H3>
						<DL><p>
							<DT><A HREF="https://deepspec.org/event/dsss18/">DeepSpec: The Science of Deep Specification</A>
							<DT><A HREF="https://www.labri.fr/perso/casteran/CoqArt/">Coq'Art Home page</A>
							<DT><A HREF="https://github.com/plclub/cis670-16fa/blob/master/notes/IntuitionisticPropositionalLogicLecture.pdf">Introduction to Intuitionistic Propositional Logic</A>
							<DT><A HREF="https://www.nii.ac.jp/event/upload/talk-ShonanMeetings100th.pdf">Principles, examples and main applications</A>
							<DT><A HREF="https://www.ercim.eu/publication/Ercim_News/enw36/filiatre.html">Certification of Imperative Programs in Coq</A>
							<DT><A HREF="https://www.brics.dk/RS/97/18/BRICS-RS-97-18.pdf">How to Believe a Machine-Checked Proof</A>
						</DL><p>
						<DT><H3 FOLDED>software-foundations-theory</H3>
						<DL><p>
							<DT><A HREF="https://ncatlab.org/nlab/show/certified+programming">certified programming</A>
						</DL><p>
						<DT><H3 FOLDED>software-foundations-self-modified-code</H3>
						<DL><p>
							<DT><A HREF="https://authors.library.caltech.edu/">Welcome to CaltechAUTHORS - CaltechAUTHORS</A>
						</DL><p>
						<DT><H3 FOLDED>software-foundations-resources</H3>
						<DL><p>
							<DT><A HREF="https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/fisher">Using Formal Methods to Eliminate Exploitable Bugs | USENIX</A>
							<DT><A HREF="https://madiot.fr/files/reportru.pdf">Specification of imperative languages using operational semantics in Coq</A>
							<DT><A HREF="http://why3.lri.fr/">Why3</A>
							<DT><A HREF="https://hal.inria.fr/hal-01094195/document">Intro to the Calculus of Inductive Constructions</A>
							<DT><A HREF="http://www.cse.chalmers.se/research/group/logic/TypesSS05/Extra/filliatre.pdf">HL</A>
							<DT><A HREF="http://nickbenton.name/coqasm.pdf">x86</A>
							<DT><A HREF="https://www.lri.fr/~paulin/LASER/course-notes.pdf">Coq overview</A>
							<DT><A HREF="https://www.dragonwasrobot.com/mathematics/2015/09/26/an-interpreter-a-compiler-and-a-virtual-machine.html">An interpreter, a compiler, and a virtual machine</A>
							<DT><A HREF="https://link.springer.com/chapter/10.1007/978-3-540-70594-9_3">Next generation programming languages</A>
						</DL><p>
						<DT><A HREF="https://softwarefoundations.cis.upenn.edu/">Software Foundations</A>
						<DT><A HREF="http://www.cs.cornell.edu/courses/cs4160/2020sp/sf/lf/terse/toc.html">Alternative version</A>
						<DT><A HREF="https://xavierleroy.org/courses/Eugene-2011/">Proving a Compiler</A>
						<DT><A HREF="https://nickdrozd.github.io/">Something Something Programming | Mostly thoughts about programming. Maybe other stuff too.</A>
					</DL><p>
				</DL><p>
				<DT><H3 FOLDED>Mathematics</H3>
				<DL><p>
					<DT><H3 FOLDED>institutions</H3>
					<DL><p>
						<DT><A HREF="https://www.ias.edu/video">Institute for Advanced Study</A>
						<DT><A HREF="https://simons.berkeley.edu/">Simons Institute for the Theory of Computing</A>
						<DT><A HREF="https://plato.stanford.edu/entries/hilbert-program/">Hilbert‚Äôs Program (Stanford Encyclopedia of Philosophy)</A>
					</DL><p>
					<DT><H3 FOLDED>computing</H3>
					<DL><p>
						<DT><A HREF="https://www.abelard.org/turpap2/tp2-ie.asp">On computable numbers, with an application to the Entscheidungsproblem - A. M. Turing, 1936</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/certified+programming">certified programming</A>
					</DL><p>
					<DT><H3 FOLDED>lambda calculus</H3>
					<DL><p>
					</DL><p>
					<DT><H3 FOLDED>calculus of constructions</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/calculus+of+constructions">calculus of constructions</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/pure+type+system">pure type system</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/lambda-calculus">lambda-calculus</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/computational+trinitarianism">computational trinitarianism</A>
					</DL><p>
					<DT><H3 FOLDED>algebra</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/algebraically+injective+object">algebraically injective object</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/injection">injection</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/homomorphism">homomorphism</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/disjoint+subsets">disjoint subsets</A>
						<DT><A HREF="https://linear.axler.net/">Linear Algebra Done Right (Sheldon Axler)</A>
					</DL><p>
					<DT><H3 FOLDED>logic</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/predicate+logic">predicate logic</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/ex+falso+quodlibet">ex falso quodlibet</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/inductive+reasoning">inductive reasoning</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/proposition">proposition</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/decidable+proposition">decidable proposition</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/modus+ponens">modus ponens</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/natural+deduction">natural deduction</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/relation">relation</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/proof">proof</A>
					</DL><p>
					<DT><H3 FOLDED>Complex Analysis</H3>
					<DL><p>
						<DT><A HREF="https://www.youtube.com/watch?v=_mv0q7-WF4E&list=PLMrJAkhIeNNQBRslPb7I0yTnES981R8Cg&index=2">Complex Analysis L01: Overview &amp; Motivation, Complex Arithmetic, Euler's Formula &amp; Polar Coordinates - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>calculus on manifolds</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/semi-simplicial+set">semi-simplicial set in nLab</A>
					</DL><p>
					<DT><H3 FOLDED>type theory</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/preimage">preimage</A>
						<DT><A HREF="https://pjreddie.com/coq-tactics/">Coq Tactic Index</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Martin-L%C3%B6f+dependent+type+theory">Martin-L√∂f dependent type theory in nLab</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Phenomenology+of+Spirit">Phenomenology of Spirit in nLab</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/semantics">semantics</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/function+extensionality">function extensionality</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/identity+type">identity type</A>
						<DT><A HREF="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F2699407&file=p75-wadler-supp.pdf">Propositions as Types-Philip Wadler</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/dependent+type+theory">dependent type theory</A>
						<DT><A HREF="http://www-sop.inria.fr/members/Yves.Bertot/tsinghua/tsinghua-1.pdf">Introduction to dependent types in Coq</A>
						<DT><A HREF="https://medium.com/background-thread/the-future-of-programming-is-dependent-types-programming-word-of-the-day-fcd5f2634878">The Future of Programming is Dependent Types</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/type">type</A>
					</DL><p>
					<DT><H3 FOLDED>proof assistant</H3>
					<DL><p>
						<DT><H3 FOLDED>Coq</H3>
						<DL><p>
							<DT><A HREF="https://ncatlab.org/nlab/show/definition">definition in nLab</A>
							<DT><A HREF="https://wiki.portal.chalmers.se/cse/pmwiki.php/ForMath/ForMath">ForMath: Formalisation of Mathematics</A>
							<DT><A HREF="https://drops.dagstuhl.de/opus/volltexte/2006/432/">DROPS - Introduction to the Flyspeck Project</A>
							<DT><A HREF="https://ncatlab.org/nlab/show/Archive+of+Formal+Proofs">Archive of Formal Proofs</A>
							<DT><A HREF="https://ncatlab.org/nlab/show/Coq">Coq</A>
							<DT><A HREF="https://coq.inria.fr/distrib/current/refman/language/core/basic.html">Coq 8.13.1 documentation</A>
							<DT><A HREF="ftp://mizar.uwb.edu.pl/pub/qed/manifesto">QED manifesto</A>
						</DL><p>
						<DT><A HREF="https://coq.inria.fr/distrib/current/refman/">Introduction and Contents ‚Äî Coq 8.13.0 documentation</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/ML_(programming_language)">ML (programming language) - Wikipedia</A>
						<DT><A HREF="https://ocaml.org/">OCaml ‚Äì OCaml</A>
						<DT><A HREF="https://gmplib.org/list-archives/gmp-announce/2020-November/000049.html">GMP 6.2.1 released</A>
						<DT><A HREF="https://formulae.brew.sh/formula/coq#default">coq ‚Äî Homebrew Formulae</A>
						<DT><A HREF="https://formulae.brew.sh/cask/coqide#default">coqide ‚Äî Homebrew Formulae</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/separation+algebra">separation algebra</A>
						<DT><A HREF="https://github.com/leanprover/lean4">leanprover/lean4: Lean 4 programming language and theorem prover</A>
					</DL><p>
					<DT><H3 FOLDED>set theory</H3>
					<DL><p>
						<DT><A HREF="https://en.wikipedia.org/wiki/Groupoid">Groupoid - Wikipedia</A>
						<DT><A HREF="https://www.pinterest.es/pin/156077943317011320/">Number theory sets</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/semi-simplicial+set">semi-simplicial set in nLab</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/function">function in nLab</A>
					</DL><p>
					<DT><H3 FOLDED>category theory</H3>
					<DL><p>
						<DT><A HREF="https://arxiv.org/abs/1809.05923">What is Applied Category Theory?</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Timeline+of+category+theory+and+related+mathematics">Timeline of category theory and related mathematics</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/generalized+element">generalized element</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/morphism">morphism</A>
					</DL><p>
					<DT><H3 FOLDED>proof theory</H3>
					<DL><p>
						<DT><A HREF="https://www.google.com/search?client=safari&rls=en&sxsrf=ALeKk02CUmoD_hscdezGf0jizv1UxWm0Zw%3A1595607125474&ei=VQgbX-C-HIGOlwSBh5r4Dg&q=David+Hilbert+proof+theory&oq=David+Hilbert+proof+theory&gs_lcp=CgZwc3ktYWIQAzoHCC4QJxCTAjoHCAAQFBCHAjoCCAA6AgguOgcIIxDqAhAnOgcILhDqAhAnOgQIIxAnOgQILhBDOggILhDHARCjAjoFCC4QkQI6BwguEBQQhwI6CAguEJECEJMCOgUILhDLAToFCAAQywE6CAguEMcBEK8BOgYIABAWEB46BwghEAoQoAE6CAghEBYQHRAeOgUIIRCgAVCo4kJYjq1DYIiwQ2gIcAB4AIABtQGIAc8YkgEENS4yM5gBAKABAaoBB2d3cy13aXqwAQrAAQE&sclient=psy-ab&ved=0ahUKEwigvajfo-bqAhUBx4UKHYGDBu8Q4dUDCAs&uact=5">David Hilbert proof theory - Google Search</A>
						<DT><A HREF="https://www.marxists.org/reference/subject/philosophy/works/ge/hilbert.htm">Foundations of Mathematics By David Hilbert (1927)</A>
					</DL><p>
					<DT><H3 FOLDED>univalence foundations</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/univalence+axiom#InSimplicialSets">univalence axiom in nLab</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry‚ÄìHoward correspondence - Wikipedia</A>
						<DT><A HREF="https://www.idris-lang.org/">Idris: A Language for Type-Driven Development</A>
						<DT><A HREF="https://www.fstar-lang.org/tutorial/">F* Tutorial</A>
						<DT><A HREF="http://goto.ucsd.edu/~ravi/research/oopsla12-djs.pdf">Dependent Types for JavaScript</A>
						<DT><A HREF="http://smallcultfollowing.com/babysteps/blog/2016/11/02/associated-type-constructors-part-1-basic-concepts-and-introduction/">Associated type constructors</A>
						<DT><A HREF="https://crates.io/crates/type_level_values">type_level_values - crates.io: Rust </A>
						<DT><A HREF="https://nalgebra.org/">nalgebra linear-algebra library | nalgebra</A>
						<DT><A HREF="https://webusers.imj-prg.fr/~leila.schneps/grothendieckcircle/Letters/GS.pdf">GROTHENDIECK-SERRE CORRESPONDENCE</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Groupoid">Groupoid - Wikipedia</A>
						<DT><A HREF="https://www.probabilitycourse.com/chapter1/1_2_3_cardinality.php">Cardinality | Finite Sets | Infinite Sets </A>
						<DT><A HREF="https://www.math.ias.edu/~vladimir/Site3/Univalent_Foundations.html">Univalent Foundations of Mathematics</A>
						<DT><A HREF="https://www.math.ias.edu/~vladimir/Foundations_library/toc.html">Table of contents</A>
						<DT><A HREF="https://medium.com/background-thread/the-future-of-programming-is-dependent-types-programming-word-of-the-day-fcd5f2634878">The Future of Programming is Dependent Types</A>
						<DT><A HREF="https://flint.cs.yale.edu/flint/software.html">Yale FLINT Group: Software</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Axiomatic_system">Axiomatic system - Wikipedia</A>
						<DT><A HREF="https://www.google.com/search?client=safari&rls=en&q=Martin+lof+type+theory&ie=UTF-8&oe=UTF-8">Martin lof type theory - Google Search</A>
						<DT><A HREF="https://www.google.com/search?client=safari&rls=en&q=formal+language&ie=UTF-8&oe=UTF-8">formal language - Google Search</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/HomePage">nLab</A>
						<DT><A HREF="https://github.com/UniMath/Foundations">UniMath/Foundations: Voevodsky's original development of the univalent foundations of mathematics in Coq</A>
						<DT><A HREF="https://github.com/UniMath/UniMath">UniMath/UniMath: This coq library aims to formalize a substantial body of mathematics using the univalent point of view.</A>
						<DT><A HREF="https://github.com/EgbertRijke/HoTT-Intro">EgbertRijke/HoTT-Intro: An introductory course to Homotopy Type Theory</A>
						<DT><A HREF="https://arxiv.org/abs/1401.0053">Experimental library of univalent formalization of mathematics</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/semi-simplicial+set">semi-simplicial set in nLab</A>
					</DL><p>
					<DT><H3 FOLDED>homotopy type theory</H3>
					<DL><p>
						<DT><A HREF="https://en.wikipedia.org/wiki/Homotopy">Homotopy - Wikipedia</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/simplicial+complex#RemarkOnTerminology">simplicial complex in nLab</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/simplicial+complex">simplicial complex in nLab</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/simplicial+set">simplicial set</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/semi-simplicial+set">semi-simplicial set</A>
						<DT><A HREF="https://en.wikipedia.org/wiki/Modus_ponens">Modus ponens - Wikipedia</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/family+of+sets">family of sets in nLab</A>
						<DT><A HREF="https://golem.ph.utexas.edu/category/2013/06/the_hott_book.html#more">The HoTT Book | The n-Category Caf√©</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/homotopy.io">homotopy.io in nLab</A>
						<DT><A HREF="http://www.andrew.cmu.edu/user/erijke/hott/">Introduction to Homotopy Type Theory</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/homotopy">homotopy in nLab</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/function+extensionality">function extensionality</A>
					</DL><p>
					<DT><H3 FOLDED>Statistics</H3>
					<DL><p>
						<DT><A HREF="http://www.stat.cmu.edu/~larry/=stat705/">10-705 Intermediate Statistics, Fall 2020</A>
						<DT><A HREF="http://pub.math.leidenuniv.nl/~szabobt/STAN.html">Statistiek AN, 2018-2019</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/permutation">permutation</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/probability+distribution">probability distribution</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/supervised+learning">supervised learning</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/probability+density">probability density</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Banach+space">Banach space</A>
						<DT><A HREF="https://ncatlab.org/nlab/show/Wasserstein+metric">Wasserstein metric</A>
						<DT><A HREF="https://www.youtube.com/watch?v=R9aMV8QIEB0">The Best Book Ever Written on Mathematical Statistics - YouTube</A>
					</DL><p>
					<DT><H3 FOLDED>TeX</H3>
					<DL><p>
						<DT><A HREF="https://sourabhbajaj.com/mac-setup/LaTeX/">LaTeX ¬∑ macOS Setup Guide</A>
						<DT><A HREF="https://tex.stackexchange.com/questions/195291/inserting-graph-from-a-software-in-latex">Inserting graph from a software in Latex - TeX - LaTeX Stack Exchange</A>
						<DT><A HREF="https://en.wikibooks.org/wiki/LaTeX/Mathematics">LaTeX/Mathematics - Wikibooks, open books for an open world</A>
						<DT><A HREF="http://tex.loria.fr/general/mil.pdf">‚Äétex.loria.fr/general/mil.pdf</A>
						<DT><A HREF="https://en.wikibooks.org/wiki/LaTeX/Basics">LaTeX/Basics - Wikibooks, open books for an open world</A>
						<DT><A HREF="https://support.typora.io/Math/#limitations">Math and Academic Functions</A>
						<DT><A HREF="http://nickgeorge.net/programming/latex_setup/">Setting up LaTeX on a Mac</A>
						<DT><A HREF="https://www.overleaf.com/project/5fb2ebb49f6f3f20dfb6e766">Example - Online LaTeX Editor Overleaf</A>
						<DT><A HREF="https://i0.wp.com/texblog.org/Wordpress/wp-content/uploads/2008/02/font-modifications-latex.png">font-modifications</A>
						<DT><A HREF="https://tex.stackexchange.com/questions/115432/best-practice-for-typesetting-quantifiers">spacing - Best practice for typesetting quantifiers? - TeX - LaTeX Stack Exchange</A>
						<DT><A HREF="https://oeis.org/wiki/List_of_LaTeX_mathematical_symbols">List of LaTeX mathematical symbols - OeisWiki</A>
						<DT><A HREF="https://tex.stackexchange.com/questions/351660/double-superscript">Double Superscript - TeX - LaTeX Stack Exchange</A>
						<DT><A HREF="http://www.personal.ceu.hu/tex/breaking.htm">LaTeX Line and Page Breaking</A>
						<DT><A HREF="https://www.overleaf.com/learn/latex/sections_and_chapters">Sections and chapters - Overleaf, Online LaTeX Editor</A>
						<DT><A HREF="https://www.overleaf.com/learn/latex/Creating_a_document_in_LaTeX">Creating a document in LaTeX - Overleaf, Online LaTeX Editor</A>
						<DT><A HREF="https://www.lipsum.com/">Lorem Ipsum - All the facts - Lipsum generator</A>
						<DT><A HREF="https://tex.stackexchange.com/questions/539796/subsubsubsection-paragraph-not-showing-in-toc">table of contents - Subsubsubsection (paragraph) not showing in TOC - TeX - LaTeX Stack Exchange</A>
						<DT><A HREF="https://www.overleaf.com/learn/latex/Bold,_italics_and_underlining">Bold, italics and underlining - Overleaf, Online LaTeX Editor</A>
						<DT><A HREF="https://www.overleaf.com/learn/latex/Inserting_Images">Inserting Images - Overleaf, Online LaTeX Editor</A>
						<DT><A HREF="https://stackoverflow.com/questions/3175105/inserting-code-in-this-latex-document-with-indentation">Inserting code in this LaTeX document with indentation - Stack Overflow</A>
						<DT><A HREF="https://tex.stackexchange.com/questions/85904/showcase-of-beautiful-title-page-done-in-tex">typography - Showcase of beautiful title page done in TeX - TeX - LaTeX Stack Exchange</A>
						<DT><A HREF="https://github.com/ajvondrak/coq/blob/master/coq.tex">coq/coq.tex at master ¬∑ ajvondrak/coq</A>
						<DT><A HREF="https://tex.stackexchange.com/questions/8357/how-to-have-local-package-override-default-package/8359#8359">Internal directories structure</A>
						<DT><A HREF="https://github.com/amunn/make-local-texmf">texmf hierarchy</A>
						<DT><A HREF="https://coq.inria.fr/refman/using/tools/coqdoc.html">coqdoc</A>
					</DL><p>
					<DT><H3 FOLDED>basic algebra</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/injection">injection in nLab</A>
					</DL><p>
					<DT><H3 FOLDED>foundations</H3>
					<DL><p>
						<DT><A HREF="https://ncatlab.org/nlab/show/foundation+of+mathematics#EilenbergSteenrod">foundation of mathematics</A>
					</DL><p>
					<DT><H3 FOLDED>Sheaf Theory</H3>
					<DL><p>
					</DL><p>
					<DT><H3 FOLDED>Differential Geometry</H3>
					<DL><p>
					</DL><p>
					<DT><H3 FOLDED>Algebraic Topology</H3>
					<DL><p>
					</DL><p>
					<DT><H3 FOLDED>Chaos: Non-Linear Dynamical Systems</H3>
					<DL><p>
						<DT><A HREF="https://www.wolframalpha.com/widgets/view.jsp?id=c731077c04035ac9e92a3706288db18f">Wolfram|Alpha Widgets: "Logistic Map" - Free Mathematics Widget</A>
						<DT><A HREF="https://geoffboeing.com/2015/03/chaos-theory-logistic-map/">Chaos Theory and the Logistic Map ‚Äì Geoff Boeing</A>
						<DT><A HREF="https://github.com/brorson/FeigenbaumConstants/blob/master/CAJUNTalk.pdf">FeigenbaumConstants/CAJUNTalk.pdf at master ¬∑ brorson/FeigenbaumConstants</A>
						<DT><A HREF="https://github.com/gboeing/pynamical/blob/39478f13c98d86f5fafc23875e68c99dd15fc879/pynamical/pynamical.py#L186">pynamical/pynamical.py at 39478f13c98d86f5fafc23875e68c99dd15fc879 ¬∑ gboeing/pynamical</A>
						<DT><A HREF="https://github.com/gboeing/pynamical">gboeing/pynamical: Pynamical is a Python package for modeling and visualizing discrete nonlinear dynamical systems, chaos, and fractals.</A>
					</DL><p>
					<DT><A HREF="https://terrytao.wordpress.com/2009/01/01/245b-notes-0-a-quick-review-of-measure-and-integration-theory/">245B, notes 0: A quick review of measure and integration theory | What's new</A>
					<DT><A HREF="https://papers.labml.ai/paper/16a1cbf8f68f11ecb9b9d35608ee6155">Pen and Paper Exercises in Machine Learning</A>
				</DL><p>
			</DL><p>
		</DL><p>
	</DL><p>
</HTML>
